{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc6d36-fc6d-4916-b7b0-6a2dfaf9c4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq\n",
    "from data_loader import *\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pretty_midi\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b387469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26d6b8a-e8ec-4fa2-b14f-a45764fa7545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.piece_count:  105\n",
      "dataset_len:  10500\n",
      "val_dataset_len 5\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_name_path = f\"./midi_list.txt\"\n",
    "dataloader = get_dataloader(dataset_name_path, batch_size=128) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "val_dataset_name_path = f\"./midi_list_eval.txt\"\n",
    "val_dataloader = get_val_dataloader(val_dataset_name_path, batch_size=128) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "learning_rate = 0.001#0.001\n",
    "\n",
    "input_size_encoder = 128 #129 #128\n",
    "input_size_decoder = 102 #102 #24\n",
    "output_size = 102#102 #24\n",
    "\n",
    "# encoder_embedding_size = 300\n",
    "# decoder_embedding_size = 300\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.\n",
    "step = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23df2697-2943-4f69-89df-1f0c5cbf3343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = 128 #number of features\n",
    "hidden_size = 1024 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "output_dim = 102 #number of output classes\n",
    "\n",
    "# model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM(embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "num_epochs = 100 #10\n",
    "avg_loss_list = []\n",
    "all_loss_list = []\n",
    "val_loss_per_epoch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fb7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse_loss(output, target, prev_output, midi_array):\n",
    "    # target = target.transpose(0, 1)\n",
    "    # print(\"output\", output)\n",
    "    # print(output.shape) #torch.Size([20, 513, 102])\n",
    "    # print(target.shape) #torch.Size([20, 513, 102])\n",
    "    mse_loss = F.mse_loss(output, target)\n",
    "    # print(\"mse_loss:\", mse_loss)\n",
    "\n",
    "    var_diff = torch.var(torch.squeeze(output), dim=1, keepdim=True)\n",
    "    mean_diff = torch.mean(var_diff)\n",
    "    \n",
    "    # Condition 1: Penalize if output is similar to previous output\n",
    "    if mean_diff < 1e-4: #threshold\n",
    "        #output [512, 1, 102] => [102] <-> [102] <-> [102] <-> ... <-> [102]\n",
    "        mse_loss *= 1000\n",
    "\n",
    "    # Condition 2: Stop movement if input is all zeros\n",
    "    # midi_transpose = midi_array.transpose(0, 1)\n",
    "    # midi_sum_row = torch.sum(midi_transpose, dim=-1)\n",
    "    # mask = midi_sum_row == 0\n",
    "    # mask = mask.unsqueeze(-1)\n",
    "    # mask = mask.to(device)\n",
    "    # # according to recorded index, make a mask [0, 1, 1, 0, ..., 0], true part will be omit(set value to 0).\n",
    "    # # before compute mse, use mask first to tensor, then caculate MES loss\n",
    "    # masked_output = output.masked_fill(mask, 0) #inplace function\n",
    "    # masked_target = target.masked_fill(mask, 0)\n",
    "    # mse_loss += F.mse_loss(masked_output, masked_target) * 100 #output 和 previous output 不像的話，增大 loss\n",
    "\n",
    "    # Condition 3: Penalize if right-hand movement is too different between outputs\n",
    "    # if output.shape[-1] == 21:  # Assumes hand joints are the last 21 dimensions\n",
    "    #     rh_indices = [i for i in range(12, 21)]  # Right-hand joint indices\n",
    "    #     rh_output = output[..., rh_indices]\n",
    "    #     rh_prev_output = prev_output[..., rh_indices]\n",
    "    #     rh_loss = nn.functional.mse_loss(rh_output, rh_prev_output)\n",
    "    #     if rh_loss > 0.1:\n",
    "    #         mse_loss *= 1000\n",
    "\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee089d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(model, val_dataloader):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            print(\"inputs.shape:\", inputs.shape)\n",
    "            print(\"targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.mse_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "\n",
    "    epoch_val_loss = valid_running_loss / counter\n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e92038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0: loss = 0.176477\n",
      "Epoch 0, batch 1: loss = 0.160604\n",
      "Epoch 0, batch 2: loss = 0.132114\n",
      "Epoch 0, batch 3: loss = 0.909421\n",
      "Epoch 0, batch 4: loss = 0.108143\n",
      "Epoch 0, batch 5: loss = 0.130589\n",
      "Epoch 0, batch 6: loss = 0.139260\n",
      "Epoch 0, batch 7: loss = 0.143146\n",
      "Epoch 0, batch 8: loss = 0.143223\n",
      "Epoch 0, batch 9: loss = 0.139436\n",
      "Epoch 0, batch 10: loss = 0.134850\n",
      "Epoch 0, batch 11: loss = 0.126121\n",
      "Epoch 0, batch 12: loss = 0.107145\n",
      "Epoch 0, batch 13: loss = 0.070911\n",
      "Epoch 0, batch 14: loss = 0.026751\n",
      "Epoch 0, batch 15: loss = 0.012657\n",
      "Epoch 0, batch 16: loss = 0.026397\n",
      "Epoch 0, batch 17: loss = 0.019713\n",
      "Epoch 0, batch 18: loss = 0.009768\n",
      "Epoch 0, batch 19: loss = 0.006509\n",
      "Epoch 0, batch 20: loss = 0.007342\n",
      "Epoch 0, batch 21: loss = 0.009430\n",
      "Epoch 0, batch 22: loss = 0.010369\n",
      "Epoch 0, batch 23: loss = 0.010018\n",
      "Epoch 0, batch 24: loss = 0.008882\n",
      "Epoch 0, batch 25: loss = 0.007470\n",
      "Epoch 0, batch 26: loss = 0.005829\n",
      "Epoch 0, batch 27: loss = 0.004977\n",
      "Epoch 0, batch 28: loss = 0.004414\n",
      "Epoch 0, batch 29: loss = 0.004307\n",
      "Epoch 0, batch 30: loss = 0.004265\n",
      "Epoch 0, batch 31: loss = 0.004394\n",
      "Epoch 0, batch 32: loss = 0.004563\n",
      "Epoch 0, batch 33: loss = 0.004588\n",
      "Epoch 0, batch 34: loss = 0.004461\n",
      "Epoch 0, batch 35: loss = 0.004098\n",
      "Epoch 0, batch 36: loss = 0.003575\n",
      "Epoch 0, batch 37: loss = 0.003434\n",
      "Epoch 0, batch 38: loss = 0.003206\n",
      "Epoch 0, batch 39: loss = 0.003194\n",
      "Epoch 0, batch 40: loss = 0.003241\n",
      "Epoch 0, batch 41: loss = 0.003316\n",
      "Epoch 0, batch 42: loss = 0.003185\n",
      "Epoch 0, batch 43: loss = 0.003266\n",
      "Epoch 0, batch 44: loss = 0.003180\n",
      "Epoch 0, batch 45: loss = 0.003012\n",
      "Epoch 0, batch 46: loss = 0.003133\n",
      "Epoch 0, batch 47: loss = 0.002935\n",
      "Epoch 0, batch 48: loss = 0.002918\n",
      "Epoch 0, batch 49: loss = 0.002861\n",
      "Epoch 0, batch 50: loss = 0.002851\n",
      "Epoch 0, batch 51: loss = 0.002880\n",
      "Epoch 0, batch 52: loss = 0.002797\n",
      "Epoch 0, batch 53: loss = 0.002738\n",
      "Epoch 0, batch 54: loss = 0.002909\n",
      "Epoch 0, batch 55: loss = 0.002824\n",
      "Epoch 0, batch 56: loss = 0.002735\n",
      "Epoch 0, batch 57: loss = 0.002614\n",
      "Epoch 0, batch 58: loss = 0.002711\n",
      "Epoch 0, batch 59: loss = 0.002675\n",
      "Epoch 0, batch 60: loss = 0.002746\n",
      "Epoch 0, batch 61: loss = 0.002673\n",
      "Epoch 0, batch 62: loss = 0.002657\n",
      "Epoch 0, batch 63: loss = 0.002741\n",
      "Epoch 0, batch 64: loss = 0.002731\n",
      "Epoch 0, batch 65: loss = 0.002671\n",
      "Epoch 0, batch 66: loss = 0.002644\n",
      "Epoch 0, batch 67: loss = 0.002636\n",
      "Epoch 0, batch 68: loss = 0.002519\n",
      "Epoch 0, batch 69: loss = 0.002573\n",
      "Epoch 0, batch 70: loss = 0.002607\n",
      "Epoch 0, batch 71: loss = 0.002654\n",
      "Epoch 0, batch 72: loss = 0.002608\n",
      "Epoch 0, batch 73: loss = 0.002562\n",
      "Epoch 0, batch 74: loss = 0.002497\n",
      "Epoch 0, batch 75: loss = 0.002604\n",
      "Epoch 0, batch 76: loss = 0.002517\n",
      "Epoch 0, batch 77: loss = 0.002531\n",
      "Epoch 0, batch 78: loss = 0.002736\n",
      "Epoch 0, batch 79: loss = 0.002681\n",
      "Epoch 0, batch 80: loss = 0.002628\n",
      "Epoch 0, batch 81: loss = 0.002603\n",
      "Epoch 0, batch 82: loss = 0.002527\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 0: val_loss = 0.026811\n",
      "Epoch 1, batch 0: loss = 0.002563\n",
      "Epoch 1, batch 1: loss = 0.002502\n",
      "Epoch 1, batch 2: loss = 0.002507\n",
      "Epoch 1, batch 3: loss = 0.002671\n",
      "Epoch 1, batch 4: loss = 0.002656\n",
      "Epoch 1, batch 5: loss = 0.002612\n",
      "Epoch 1, batch 6: loss = 0.002643\n",
      "Epoch 1, batch 7: loss = 0.002606\n",
      "Epoch 1, batch 8: loss = 0.002408\n",
      "Epoch 1, batch 9: loss = 0.002533\n",
      "Epoch 1, batch 10: loss = 0.002523\n",
      "Epoch 1, batch 11: loss = 0.002517\n",
      "Epoch 1, batch 12: loss = 0.002482\n",
      "Epoch 1, batch 13: loss = 0.002614\n",
      "Epoch 1, batch 14: loss = 0.002458\n",
      "Epoch 1, batch 15: loss = 0.002509\n",
      "Epoch 1, batch 16: loss = 0.002528\n",
      "Epoch 1, batch 17: loss = 0.002572\n",
      "Epoch 1, batch 18: loss = 0.002482\n",
      "Epoch 1, batch 19: loss = 0.002551\n",
      "Epoch 1, batch 20: loss = 0.002554\n",
      "Epoch 1, batch 21: loss = 0.002496\n",
      "Epoch 1, batch 22: loss = 0.002439\n",
      "Epoch 1, batch 23: loss = 0.002672\n",
      "Epoch 1, batch 24: loss = 0.002548\n",
      "Epoch 1, batch 25: loss = 0.002436\n",
      "Epoch 1, batch 26: loss = 0.002512\n",
      "Epoch 1, batch 27: loss = 0.002631\n",
      "Epoch 1, batch 28: loss = 0.002608\n",
      "Epoch 1, batch 29: loss = 0.002507\n",
      "Epoch 1, batch 30: loss = 0.002567\n",
      "Epoch 1, batch 31: loss = 0.002570\n",
      "Epoch 1, batch 32: loss = 0.002582\n",
      "Epoch 1, batch 33: loss = 0.002545\n",
      "Epoch 1, batch 34: loss = 0.002350\n",
      "Epoch 1, batch 35: loss = 0.002518\n",
      "Epoch 1, batch 36: loss = 0.002467\n",
      "Epoch 1, batch 37: loss = 0.002596\n",
      "Epoch 1, batch 38: loss = 0.002618\n",
      "Epoch 1, batch 39: loss = 0.002493\n",
      "Epoch 1, batch 40: loss = 0.002490\n",
      "Epoch 1, batch 41: loss = 0.002575\n",
      "Epoch 1, batch 42: loss = 0.002568\n",
      "Epoch 1, batch 43: loss = 0.002620\n",
      "Epoch 1, batch 44: loss = 0.002536\n",
      "Epoch 1, batch 45: loss = 0.002429\n",
      "Epoch 1, batch 46: loss = 0.002485\n",
      "Epoch 1, batch 47: loss = 0.002461\n",
      "Epoch 1, batch 48: loss = 0.002446\n",
      "Epoch 1, batch 49: loss = 0.002605\n",
      "Epoch 1, batch 50: loss = 0.002461\n",
      "Epoch 1, batch 51: loss = 0.002539\n",
      "Epoch 1, batch 52: loss = 0.002491\n",
      "Epoch 1, batch 53: loss = 0.002477\n",
      "Epoch 1, batch 54: loss = 0.002531\n",
      "Epoch 1, batch 55: loss = 0.002517\n",
      "Epoch 1, batch 56: loss = 0.002456\n",
      "Epoch 1, batch 57: loss = 0.002494\n",
      "Epoch 1, batch 58: loss = 0.002333\n",
      "Epoch 1, batch 59: loss = 0.002587\n",
      "Epoch 1, batch 60: loss = 0.002580\n",
      "Epoch 1, batch 61: loss = 0.002401\n",
      "Epoch 1, batch 62: loss = 0.002451\n",
      "Epoch 1, batch 63: loss = 0.002452\n",
      "Epoch 1, batch 64: loss = 0.002436\n",
      "Epoch 1, batch 65: loss = 0.002450\n",
      "Epoch 1, batch 66: loss = 0.002425\n",
      "Epoch 1, batch 67: loss = 0.002471\n",
      "Epoch 1, batch 68: loss = 0.002366\n",
      "Epoch 1, batch 69: loss = 0.002340\n",
      "Epoch 1, batch 70: loss = 0.002371\n",
      "Epoch 1, batch 71: loss = 0.002501\n",
      "Epoch 1, batch 72: loss = 0.002398\n",
      "Epoch 1, batch 73: loss = 0.002539\n",
      "Epoch 1, batch 74: loss = 0.002481\n",
      "Epoch 1, batch 75: loss = 0.002469\n",
      "Epoch 1, batch 76: loss = 0.002461\n",
      "Epoch 1, batch 77: loss = 0.002661\n",
      "Epoch 1, batch 78: loss = 0.002448\n",
      "Epoch 1, batch 79: loss = 0.002428\n",
      "Epoch 1, batch 80: loss = 0.002439\n",
      "Epoch 1, batch 81: loss = 0.002385\n",
      "Epoch 1, batch 82: loss = 0.002564\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 1: val_loss = 0.027249\n",
      "Epoch 2, batch 0: loss = 0.002528\n",
      "Epoch 2, batch 1: loss = 0.002590\n",
      "Epoch 2, batch 2: loss = 0.002444\n",
      "Epoch 2, batch 3: loss = 0.002566\n",
      "Epoch 2, batch 4: loss = 0.002413\n",
      "Epoch 2, batch 5: loss = 0.002454\n",
      "Epoch 2, batch 6: loss = 0.002460\n",
      "Epoch 2, batch 7: loss = 0.002507\n",
      "Epoch 2, batch 8: loss = 0.002430\n",
      "Epoch 2, batch 9: loss = 0.002419\n",
      "Epoch 2, batch 10: loss = 0.002399\n",
      "Epoch 2, batch 11: loss = 0.002486\n",
      "Epoch 2, batch 12: loss = 0.002392\n",
      "Epoch 2, batch 13: loss = 0.002585\n",
      "Epoch 2, batch 14: loss = 0.002414\n",
      "Epoch 2, batch 15: loss = 0.002445\n",
      "Epoch 2, batch 16: loss = 0.002403\n",
      "Epoch 2, batch 17: loss = 0.002506\n",
      "Epoch 2, batch 18: loss = 0.002420\n",
      "Epoch 2, batch 19: loss = 0.002490\n",
      "Epoch 2, batch 20: loss = 0.002383\n",
      "Epoch 2, batch 21: loss = 0.002472\n",
      "Epoch 2, batch 22: loss = 0.002457\n",
      "Epoch 2, batch 23: loss = 0.002492\n",
      "Epoch 2, batch 24: loss = 0.002454\n",
      "Epoch 2, batch 25: loss = 0.002426\n",
      "Epoch 2, batch 26: loss = 0.002386\n",
      "Epoch 2, batch 27: loss = 0.002384\n",
      "Epoch 2, batch 28: loss = 0.002576\n",
      "Epoch 2, batch 29: loss = 0.002436\n",
      "Epoch 2, batch 30: loss = 0.002423\n",
      "Epoch 2, batch 31: loss = 0.002334\n",
      "Epoch 2, batch 32: loss = 0.002348\n",
      "Epoch 2, batch 33: loss = 0.002403\n",
      "Epoch 2, batch 34: loss = 0.002432\n",
      "Epoch 2, batch 35: loss = 0.002316\n",
      "Epoch 2, batch 36: loss = 0.002507\n",
      "Epoch 2, batch 37: loss = 0.002371\n",
      "Epoch 2, batch 38: loss = 0.002355\n",
      "Epoch 2, batch 39: loss = 0.002434\n",
      "Epoch 2, batch 40: loss = 0.002363\n",
      "Epoch 2, batch 41: loss = 0.002495\n",
      "Epoch 2, batch 42: loss = 0.002383\n",
      "Epoch 2, batch 43: loss = 0.002511\n",
      "Epoch 2, batch 44: loss = 0.002431\n",
      "Epoch 2, batch 45: loss = 0.002419\n",
      "Epoch 2, batch 46: loss = 0.002436\n",
      "Epoch 2, batch 47: loss = 0.002395\n",
      "Epoch 2, batch 48: loss = 0.002493\n",
      "Epoch 2, batch 49: loss = 0.002419\n",
      "Epoch 2, batch 50: loss = 0.002349\n",
      "Epoch 2, batch 51: loss = 0.002388\n",
      "Epoch 2, batch 52: loss = 0.002432\n",
      "Epoch 2, batch 53: loss = 0.002404\n",
      "Epoch 2, batch 54: loss = 0.002413\n",
      "Epoch 2, batch 55: loss = 0.002420\n",
      "Epoch 2, batch 56: loss = 0.002308\n",
      "Epoch 2, batch 57: loss = 0.002358\n",
      "Epoch 2, batch 58: loss = 0.002460\n",
      "Epoch 2, batch 59: loss = 0.002419\n",
      "Epoch 2, batch 60: loss = 0.002442\n",
      "Epoch 2, batch 61: loss = 0.002399\n",
      "Epoch 2, batch 62: loss = 0.002479\n",
      "Epoch 2, batch 63: loss = 0.002557\n",
      "Epoch 2, batch 64: loss = 0.002283\n",
      "Epoch 2, batch 65: loss = 0.002508\n",
      "Epoch 2, batch 66: loss = 0.002250\n",
      "Epoch 2, batch 67: loss = 0.002347\n",
      "Epoch 2, batch 68: loss = 0.002272\n",
      "Epoch 2, batch 69: loss = 0.002324\n",
      "Epoch 2, batch 70: loss = 0.002390\n",
      "Epoch 2, batch 71: loss = 0.002478\n",
      "Epoch 2, batch 72: loss = 0.002426\n",
      "Epoch 2, batch 73: loss = 0.002494\n",
      "Epoch 2, batch 74: loss = 0.002365\n",
      "Epoch 2, batch 75: loss = 0.002455\n",
      "Epoch 2, batch 76: loss = 0.002420\n",
      "Epoch 2, batch 77: loss = 0.002371\n",
      "Epoch 2, batch 78: loss = 0.002361\n",
      "Epoch 2, batch 79: loss = 0.002466\n",
      "Epoch 2, batch 80: loss = 0.002360\n",
      "Epoch 2, batch 81: loss = 0.002314\n",
      "Epoch 2, batch 82: loss = 0.002359\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 2: val_loss = 0.027010\n",
      "Epoch 3, batch 0: loss = 0.002436\n",
      "Epoch 3, batch 1: loss = 0.002392\n",
      "Epoch 3, batch 2: loss = 0.002424\n",
      "Epoch 3, batch 3: loss = 0.002419\n",
      "Epoch 3, batch 4: loss = 0.002453\n",
      "Epoch 3, batch 5: loss = 0.002459\n",
      "Epoch 3, batch 6: loss = 0.002451\n",
      "Epoch 3, batch 7: loss = 0.002339\n",
      "Epoch 3, batch 8: loss = 0.002384\n",
      "Epoch 3, batch 9: loss = 0.002288\n",
      "Epoch 3, batch 10: loss = 0.002284\n",
      "Epoch 3, batch 11: loss = 0.002442\n",
      "Epoch 3, batch 12: loss = 0.002447\n",
      "Epoch 3, batch 13: loss = 0.002369\n",
      "Epoch 3, batch 14: loss = 0.002312\n",
      "Epoch 3, batch 15: loss = 0.002356\n",
      "Epoch 3, batch 16: loss = 0.002348\n",
      "Epoch 3, batch 17: loss = 0.002286\n",
      "Epoch 3, batch 18: loss = 0.002522\n",
      "Epoch 3, batch 19: loss = 0.002320\n",
      "Epoch 3, batch 20: loss = 0.002231\n",
      "Epoch 3, batch 21: loss = 0.002301\n",
      "Epoch 3, batch 22: loss = 0.002381\n",
      "Epoch 3, batch 23: loss = 0.002311\n",
      "Epoch 3, batch 24: loss = 0.002298\n",
      "Epoch 3, batch 25: loss = 0.002235\n",
      "Epoch 3, batch 26: loss = 0.002380\n",
      "Epoch 3, batch 27: loss = 0.002337\n",
      "Epoch 3, batch 28: loss = 0.002346\n",
      "Epoch 3, batch 29: loss = 0.002380\n",
      "Epoch 3, batch 30: loss = 0.002324\n",
      "Epoch 3, batch 31: loss = 0.002281\n",
      "Epoch 3, batch 32: loss = 0.002396\n",
      "Epoch 3, batch 33: loss = 0.002269\n",
      "Epoch 3, batch 34: loss = 0.002239\n",
      "Epoch 3, batch 35: loss = 0.002348\n",
      "Epoch 3, batch 36: loss = 0.002148\n",
      "Epoch 3, batch 37: loss = 0.002265\n",
      "Epoch 3, batch 38: loss = 0.002351\n",
      "Epoch 3, batch 39: loss = 0.002399\n",
      "Epoch 3, batch 40: loss = 0.002270\n",
      "Epoch 3, batch 41: loss = 0.002209\n",
      "Epoch 3, batch 42: loss = 0.002287\n",
      "Epoch 3, batch 43: loss = 0.002236\n",
      "Epoch 3, batch 44: loss = 0.002296\n",
      "Epoch 3, batch 45: loss = 0.002372\n",
      "Epoch 3, batch 46: loss = 0.002358\n",
      "Epoch 3, batch 47: loss = 0.002330\n",
      "Epoch 3, batch 48: loss = 0.002236\n",
      "Epoch 3, batch 49: loss = 0.002387\n",
      "Epoch 3, batch 50: loss = 0.002278\n",
      "Epoch 3, batch 51: loss = 0.002230\n",
      "Epoch 3, batch 52: loss = 0.002384\n",
      "Epoch 3, batch 53: loss = 0.002267\n",
      "Epoch 3, batch 54: loss = 0.002390\n",
      "Epoch 3, batch 55: loss = 0.002310\n",
      "Epoch 3, batch 56: loss = 0.002389\n",
      "Epoch 3, batch 57: loss = 0.002438\n",
      "Epoch 3, batch 58: loss = 0.002215\n",
      "Epoch 3, batch 59: loss = 0.002280\n",
      "Epoch 3, batch 60: loss = 0.002276\n",
      "Epoch 3, batch 61: loss = 0.002367\n",
      "Epoch 3, batch 62: loss = 0.002335\n",
      "Epoch 3, batch 63: loss = 0.002360\n",
      "Epoch 3, batch 64: loss = 0.002299\n",
      "Epoch 3, batch 65: loss = 0.002242\n",
      "Epoch 3, batch 66: loss = 0.002324\n",
      "Epoch 3, batch 67: loss = 0.002271\n",
      "Epoch 3, batch 68: loss = 0.002296\n",
      "Epoch 3, batch 69: loss = 0.002323\n",
      "Epoch 3, batch 70: loss = 0.002209\n",
      "Epoch 3, batch 71: loss = 0.002244\n",
      "Epoch 3, batch 72: loss = 0.002336\n",
      "Epoch 3, batch 73: loss = 0.002323\n",
      "Epoch 3, batch 74: loss = 0.002214\n",
      "Epoch 3, batch 75: loss = 0.002441\n",
      "Epoch 3, batch 76: loss = 0.002256\n",
      "Epoch 3, batch 77: loss = 0.002386\n",
      "Epoch 3, batch 78: loss = 0.002418\n",
      "Epoch 3, batch 79: loss = 0.002345\n",
      "Epoch 3, batch 80: loss = 0.002274\n",
      "Epoch 3, batch 81: loss = 0.002414\n",
      "Epoch 3, batch 82: loss = 0.001928\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 3: val_loss = 0.027022\n",
      "Epoch 4, batch 0: loss = 0.002325\n",
      "Epoch 4, batch 1: loss = 0.002244\n",
      "Epoch 4, batch 2: loss = 0.002182\n",
      "Epoch 4, batch 3: loss = 0.002361\n",
      "Epoch 4, batch 4: loss = 0.002323\n",
      "Epoch 4, batch 5: loss = 0.002283\n",
      "Epoch 4, batch 6: loss = 0.002297\n",
      "Epoch 4, batch 7: loss = 0.002202\n",
      "Epoch 4, batch 8: loss = 0.002321\n",
      "Epoch 4, batch 9: loss = 0.002334\n",
      "Epoch 4, batch 10: loss = 0.002459\n",
      "Epoch 4, batch 11: loss = 0.002376\n",
      "Epoch 4, batch 12: loss = 0.002321\n",
      "Epoch 4, batch 13: loss = 0.002335\n",
      "Epoch 4, batch 14: loss = 0.002230\n",
      "Epoch 4, batch 15: loss = 0.002192\n",
      "Epoch 4, batch 16: loss = 0.002287\n",
      "Epoch 4, batch 17: loss = 0.002431\n",
      "Epoch 4, batch 18: loss = 0.002334\n",
      "Epoch 4, batch 19: loss = 0.002348\n",
      "Epoch 4, batch 20: loss = 0.002238\n",
      "Epoch 4, batch 21: loss = 0.002194\n",
      "Epoch 4, batch 22: loss = 0.002219\n",
      "Epoch 4, batch 23: loss = 0.002354\n",
      "Epoch 4, batch 24: loss = 0.002316\n",
      "Epoch 4, batch 25: loss = 0.002284\n",
      "Epoch 4, batch 26: loss = 0.002156\n",
      "Epoch 4, batch 27: loss = 0.002239\n",
      "Epoch 4, batch 28: loss = 0.002243\n",
      "Epoch 4, batch 29: loss = 0.002197\n",
      "Epoch 4, batch 30: loss = 0.002242\n",
      "Epoch 4, batch 31: loss = 0.002192\n",
      "Epoch 4, batch 32: loss = 0.002338\n",
      "Epoch 4, batch 33: loss = 0.002343\n",
      "Epoch 4, batch 34: loss = 0.002227\n",
      "Epoch 4, batch 35: loss = 0.002245\n",
      "Epoch 4, batch 36: loss = 0.002163\n",
      "Epoch 4, batch 37: loss = 0.002356\n",
      "Epoch 4, batch 38: loss = 0.002282\n",
      "Epoch 4, batch 39: loss = 0.002208\n",
      "Epoch 4, batch 40: loss = 0.002162\n",
      "Epoch 4, batch 41: loss = 0.002238\n",
      "Epoch 4, batch 42: loss = 0.002300\n",
      "Epoch 4, batch 43: loss = 0.002319\n",
      "Epoch 4, batch 44: loss = 0.002222\n",
      "Epoch 4, batch 45: loss = 0.002231\n",
      "Epoch 4, batch 46: loss = 0.002228\n",
      "Epoch 4, batch 47: loss = 0.002239\n",
      "Epoch 4, batch 48: loss = 0.002201\n",
      "Epoch 4, batch 49: loss = 0.002202\n",
      "Epoch 4, batch 50: loss = 0.002225\n",
      "Epoch 4, batch 51: loss = 0.002196\n",
      "Epoch 4, batch 52: loss = 0.002240\n",
      "Epoch 4, batch 53: loss = 0.002322\n",
      "Epoch 4, batch 54: loss = 0.002175\n",
      "Epoch 4, batch 55: loss = 0.002192\n",
      "Epoch 4, batch 56: loss = 0.002139\n",
      "Epoch 4, batch 57: loss = 0.002201\n",
      "Epoch 4, batch 58: loss = 0.002285\n",
      "Epoch 4, batch 59: loss = 0.002362\n",
      "Epoch 4, batch 60: loss = 0.002113\n",
      "Epoch 4, batch 61: loss = 0.002296\n",
      "Epoch 4, batch 62: loss = 0.002224\n",
      "Epoch 4, batch 63: loss = 0.002099\n",
      "Epoch 4, batch 64: loss = 0.002321\n",
      "Epoch 4, batch 65: loss = 0.002142\n",
      "Epoch 4, batch 66: loss = 0.002207\n",
      "Epoch 4, batch 67: loss = 0.002151\n",
      "Epoch 4, batch 68: loss = 0.002242\n",
      "Epoch 4, batch 69: loss = 0.002264\n",
      "Epoch 4, batch 70: loss = 0.002218\n",
      "Epoch 4, batch 71: loss = 0.002243\n",
      "Epoch 4, batch 72: loss = 0.002304\n",
      "Epoch 4, batch 73: loss = 0.002263\n",
      "Epoch 4, batch 74: loss = 0.002138\n",
      "Epoch 4, batch 75: loss = 0.002174\n",
      "Epoch 4, batch 76: loss = 0.002194\n",
      "Epoch 4, batch 77: loss = 0.002070\n",
      "Epoch 4, batch 78: loss = 0.002168\n",
      "Epoch 4, batch 79: loss = 0.002272\n",
      "Epoch 4, batch 80: loss = 0.002129\n",
      "Epoch 4, batch 81: loss = 0.002231\n",
      "Epoch 4, batch 82: loss = 0.002006\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 4: val_loss = 0.026668\n",
      "Epoch 5, batch 0: loss = 0.002232\n",
      "Epoch 5, batch 1: loss = 0.002197\n",
      "Epoch 5, batch 2: loss = 0.002331\n",
      "Epoch 5, batch 3: loss = 0.002215\n",
      "Epoch 5, batch 4: loss = 0.002234\n",
      "Epoch 5, batch 5: loss = 0.002332\n",
      "Epoch 5, batch 6: loss = 0.002264\n",
      "Epoch 5, batch 7: loss = 0.002137\n",
      "Epoch 5, batch 8: loss = 0.002269\n",
      "Epoch 5, batch 9: loss = 0.002105\n",
      "Epoch 5, batch 10: loss = 0.002149\n",
      "Epoch 5, batch 11: loss = 0.002166\n",
      "Epoch 5, batch 12: loss = 0.002220\n",
      "Epoch 5, batch 13: loss = 0.002252\n",
      "Epoch 5, batch 14: loss = 0.002109\n",
      "Epoch 5, batch 15: loss = 0.002194\n",
      "Epoch 5, batch 16: loss = 0.002089\n",
      "Epoch 5, batch 17: loss = 0.002232\n",
      "Epoch 5, batch 18: loss = 0.002231\n",
      "Epoch 5, batch 19: loss = 0.002169\n",
      "Epoch 5, batch 20: loss = 0.002144\n",
      "Epoch 5, batch 21: loss = 0.002176\n",
      "Epoch 5, batch 22: loss = 0.002170\n",
      "Epoch 5, batch 23: loss = 0.002246\n",
      "Epoch 5, batch 24: loss = 0.002205\n",
      "Epoch 5, batch 25: loss = 0.002275\n",
      "Epoch 5, batch 26: loss = 0.002190\n",
      "Epoch 5, batch 27: loss = 0.002174\n",
      "Epoch 5, batch 28: loss = 0.002219\n",
      "Epoch 5, batch 29: loss = 0.002181\n",
      "Epoch 5, batch 30: loss = 0.002231\n",
      "Epoch 5, batch 31: loss = 0.002219\n",
      "Epoch 5, batch 32: loss = 0.002033\n",
      "Epoch 5, batch 33: loss = 0.002143\n",
      "Epoch 5, batch 34: loss = 0.002266\n",
      "Epoch 5, batch 35: loss = 0.002299\n",
      "Epoch 5, batch 36: loss = 0.002231\n",
      "Epoch 5, batch 37: loss = 0.002103\n",
      "Epoch 5, batch 38: loss = 0.002179\n",
      "Epoch 5, batch 39: loss = 0.002107\n",
      "Epoch 5, batch 40: loss = 0.002195\n",
      "Epoch 5, batch 41: loss = 0.002253\n",
      "Epoch 5, batch 42: loss = 0.002113\n",
      "Epoch 5, batch 43: loss = 0.002195\n",
      "Epoch 5, batch 44: loss = 0.002311\n",
      "Epoch 5, batch 45: loss = 0.002128\n",
      "Epoch 5, batch 46: loss = 0.002195\n",
      "Epoch 5, batch 47: loss = 0.002118\n",
      "Epoch 5, batch 48: loss = 0.002212\n",
      "Epoch 5, batch 49: loss = 0.002061\n",
      "Epoch 5, batch 50: loss = 0.002048\n",
      "Epoch 5, batch 51: loss = 0.002090\n",
      "Epoch 5, batch 52: loss = 0.002273\n",
      "Epoch 5, batch 53: loss = 0.002113\n",
      "Epoch 5, batch 54: loss = 0.002062\n",
      "Epoch 5, batch 55: loss = 0.002174\n",
      "Epoch 5, batch 56: loss = 0.002114\n",
      "Epoch 5, batch 57: loss = 0.002143\n",
      "Epoch 5, batch 58: loss = 0.002116\n",
      "Epoch 5, batch 59: loss = 0.002162\n",
      "Epoch 5, batch 60: loss = 0.002113\n",
      "Epoch 5, batch 61: loss = 0.002109\n",
      "Epoch 5, batch 62: loss = 0.002119\n",
      "Epoch 5, batch 63: loss = 0.002121\n",
      "Epoch 5, batch 64: loss = 0.002129\n",
      "Epoch 5, batch 65: loss = 0.002305\n",
      "Epoch 5, batch 66: loss = 0.002058\n",
      "Epoch 5, batch 67: loss = 0.002237\n",
      "Epoch 5, batch 68: loss = 0.002163\n",
      "Epoch 5, batch 69: loss = 0.002307\n",
      "Epoch 5, batch 70: loss = 0.002165\n",
      "Epoch 5, batch 71: loss = 0.002201\n",
      "Epoch 5, batch 72: loss = 0.002153\n",
      "Epoch 5, batch 73: loss = 0.002205\n",
      "Epoch 5, batch 74: loss = 0.001994\n",
      "Epoch 5, batch 75: loss = 0.002121\n",
      "Epoch 5, batch 76: loss = 0.002066\n",
      "Epoch 5, batch 77: loss = 0.002118\n",
      "Epoch 5, batch 78: loss = 0.002226\n",
      "Epoch 5, batch 79: loss = 0.002273\n",
      "Epoch 5, batch 80: loss = 0.002143\n",
      "Epoch 5, batch 81: loss = 0.002056\n",
      "Epoch 5, batch 82: loss = 0.002718\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 5: val_loss = 0.026879\n",
      "Epoch 6, batch 0: loss = 0.002164\n",
      "Epoch 6, batch 1: loss = 0.002380\n",
      "Epoch 6, batch 2: loss = 0.002075\n",
      "Epoch 6, batch 3: loss = 0.002131\n",
      "Epoch 6, batch 4: loss = 0.002183\n",
      "Epoch 6, batch 5: loss = 0.002348\n",
      "Epoch 6, batch 6: loss = 0.002130\n",
      "Epoch 6, batch 7: loss = 0.002224\n",
      "Epoch 6, batch 8: loss = 0.002073\n",
      "Epoch 6, batch 9: loss = 0.002211\n",
      "Epoch 6, batch 10: loss = 0.002193\n",
      "Epoch 6, batch 11: loss = 0.002124\n",
      "Epoch 6, batch 12: loss = 0.002102\n",
      "Epoch 6, batch 13: loss = 0.002218\n",
      "Epoch 6, batch 14: loss = 0.002161\n",
      "Epoch 6, batch 15: loss = 0.002041\n",
      "Epoch 6, batch 16: loss = 0.002135\n",
      "Epoch 6, batch 17: loss = 0.002098\n",
      "Epoch 6, batch 18: loss = 0.002131\n",
      "Epoch 6, batch 19: loss = 0.002022\n",
      "Epoch 6, batch 20: loss = 0.002163\n",
      "Epoch 6, batch 21: loss = 0.002270\n",
      "Epoch 6, batch 22: loss = 0.002183\n",
      "Epoch 6, batch 23: loss = 0.002293\n",
      "Epoch 6, batch 24: loss = 0.002191\n",
      "Epoch 6, batch 25: loss = 0.002339\n",
      "Epoch 6, batch 26: loss = 0.002244\n",
      "Epoch 6, batch 27: loss = 0.002141\n",
      "Epoch 6, batch 28: loss = 0.002153\n",
      "Epoch 6, batch 29: loss = 0.002098\n",
      "Epoch 6, batch 30: loss = 0.002094\n",
      "Epoch 6, batch 31: loss = 0.002144\n",
      "Epoch 6, batch 32: loss = 0.002099\n",
      "Epoch 6, batch 33: loss = 0.002027\n",
      "Epoch 6, batch 34: loss = 0.002103\n",
      "Epoch 6, batch 35: loss = 0.002128\n",
      "Epoch 6, batch 36: loss = 0.002100\n",
      "Epoch 6, batch 37: loss = 0.002155\n",
      "Epoch 6, batch 38: loss = 0.002172\n",
      "Epoch 6, batch 39: loss = 0.002021\n",
      "Epoch 6, batch 40: loss = 0.001976\n",
      "Epoch 6, batch 41: loss = 0.001970\n",
      "Epoch 6, batch 42: loss = 0.002113\n",
      "Epoch 6, batch 43: loss = 0.002114\n",
      "Epoch 6, batch 44: loss = 0.002132\n",
      "Epoch 6, batch 45: loss = 0.002228\n",
      "Epoch 6, batch 46: loss = 0.002132\n",
      "Epoch 6, batch 47: loss = 0.002051\n",
      "Epoch 6, batch 48: loss = 0.002040\n",
      "Epoch 6, batch 49: loss = 0.002336\n",
      "Epoch 6, batch 50: loss = 0.002127\n",
      "Epoch 6, batch 51: loss = 0.001975\n",
      "Epoch 6, batch 52: loss = 0.002109\n",
      "Epoch 6, batch 53: loss = 0.002077\n",
      "Epoch 6, batch 54: loss = 0.002018\n",
      "Epoch 6, batch 55: loss = 0.002110\n",
      "Epoch 6, batch 56: loss = 0.002082\n",
      "Epoch 6, batch 57: loss = 0.002013\n",
      "Epoch 6, batch 58: loss = 0.002092\n",
      "Epoch 6, batch 59: loss = 0.002065\n",
      "Epoch 6, batch 60: loss = 0.002137\n",
      "Epoch 6, batch 61: loss = 0.002114\n",
      "Epoch 6, batch 62: loss = 0.002080\n",
      "Epoch 6, batch 63: loss = 0.002046\n",
      "Epoch 6, batch 64: loss = 0.002212\n",
      "Epoch 6, batch 65: loss = 0.002038\n",
      "Epoch 6, batch 66: loss = 0.002083\n",
      "Epoch 6, batch 67: loss = 0.002385\n",
      "Epoch 6, batch 68: loss = 0.002107\n",
      "Epoch 6, batch 69: loss = 0.002063\n",
      "Epoch 6, batch 70: loss = 0.002152\n",
      "Epoch 6, batch 71: loss = 0.002055\n",
      "Epoch 6, batch 72: loss = 0.002067\n",
      "Epoch 6, batch 73: loss = 0.002037\n",
      "Epoch 6, batch 74: loss = 0.002076\n",
      "Epoch 6, batch 75: loss = 0.002156\n",
      "Epoch 6, batch 76: loss = 0.002175\n",
      "Epoch 6, batch 77: loss = 0.001982\n",
      "Epoch 6, batch 78: loss = 0.002095\n",
      "Epoch 6, batch 79: loss = 0.002154\n",
      "Epoch 6, batch 80: loss = 0.002029\n",
      "Epoch 6, batch 81: loss = 0.002010\n",
      "Epoch 6, batch 82: loss = 0.002666\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 6: val_loss = 0.027792\n",
      "Epoch 7, batch 0: loss = 0.002179\n",
      "Epoch 7, batch 1: loss = 0.002215\n",
      "Epoch 7, batch 2: loss = 0.002264\n",
      "Epoch 7, batch 3: loss = 0.002098\n",
      "Epoch 7, batch 4: loss = 0.002120\n",
      "Epoch 7, batch 5: loss = 0.002158\n",
      "Epoch 7, batch 6: loss = 0.002194\n",
      "Epoch 7, batch 7: loss = 0.002252\n",
      "Epoch 7, batch 8: loss = 0.002114\n",
      "Epoch 7, batch 9: loss = 0.002106\n",
      "Epoch 7, batch 10: loss = 0.001979\n",
      "Epoch 7, batch 11: loss = 0.002085\n",
      "Epoch 7, batch 12: loss = 0.002063\n",
      "Epoch 7, batch 13: loss = 0.001987\n",
      "Epoch 7, batch 14: loss = 0.002171\n",
      "Epoch 7, batch 15: loss = 0.002050\n",
      "Epoch 7, batch 16: loss = 0.002132\n",
      "Epoch 7, batch 17: loss = 0.002116\n",
      "Epoch 7, batch 18: loss = 0.002208\n",
      "Epoch 7, batch 19: loss = 0.002034\n",
      "Epoch 7, batch 20: loss = 0.002096\n",
      "Epoch 7, batch 21: loss = 0.002027\n",
      "Epoch 7, batch 22: loss = 0.002145\n",
      "Epoch 7, batch 23: loss = 0.002172\n",
      "Epoch 7, batch 24: loss = 0.002025\n",
      "Epoch 7, batch 25: loss = 0.002126\n",
      "Epoch 7, batch 26: loss = 0.002125\n",
      "Epoch 7, batch 27: loss = 0.002008\n",
      "Epoch 7, batch 28: loss = 0.002098\n",
      "Epoch 7, batch 29: loss = 0.002045\n",
      "Epoch 7, batch 30: loss = 0.002280\n",
      "Epoch 7, batch 31: loss = 0.002127\n",
      "Epoch 7, batch 32: loss = 0.002100\n",
      "Epoch 7, batch 33: loss = 0.001970\n",
      "Epoch 7, batch 34: loss = 0.002084\n",
      "Epoch 7, batch 35: loss = 0.002046\n",
      "Epoch 7, batch 36: loss = 0.002035\n",
      "Epoch 7, batch 37: loss = 0.001967\n",
      "Epoch 7, batch 38: loss = 0.002024\n",
      "Epoch 7, batch 39: loss = 0.002116\n",
      "Epoch 7, batch 40: loss = 0.002075\n",
      "Epoch 7, batch 41: loss = 0.002106\n",
      "Epoch 7, batch 42: loss = 0.002127\n",
      "Epoch 7, batch 43: loss = 0.002077\n",
      "Epoch 7, batch 44: loss = 0.002037\n",
      "Epoch 7, batch 45: loss = 0.002033\n",
      "Epoch 7, batch 46: loss = 0.002063\n",
      "Epoch 7, batch 47: loss = 0.002030\n",
      "Epoch 7, batch 48: loss = 0.002003\n",
      "Epoch 7, batch 49: loss = 0.002149\n",
      "Epoch 7, batch 50: loss = 0.002054\n",
      "Epoch 7, batch 51: loss = 0.002044\n",
      "Epoch 7, batch 52: loss = 0.001927\n",
      "Epoch 7, batch 53: loss = 0.002059\n",
      "Epoch 7, batch 54: loss = 0.002060\n",
      "Epoch 7, batch 55: loss = 0.002109\n",
      "Epoch 7, batch 56: loss = 0.002067\n",
      "Epoch 7, batch 57: loss = 0.002135\n",
      "Epoch 7, batch 58: loss = 0.001981\n",
      "Epoch 7, batch 59: loss = 0.002025\n",
      "Epoch 7, batch 60: loss = 0.002088\n",
      "Epoch 7, batch 61: loss = 0.002244\n",
      "Epoch 7, batch 62: loss = 0.002146\n",
      "Epoch 7, batch 63: loss = 0.002126\n",
      "Epoch 7, batch 64: loss = 0.002005\n",
      "Epoch 7, batch 65: loss = 0.002056\n",
      "Epoch 7, batch 66: loss = 0.002194\n",
      "Epoch 7, batch 67: loss = 0.002139\n",
      "Epoch 7, batch 68: loss = 0.001978\n",
      "Epoch 7, batch 69: loss = 0.002028\n",
      "Epoch 7, batch 70: loss = 0.001964\n",
      "Epoch 7, batch 71: loss = 0.002146\n",
      "Epoch 7, batch 72: loss = 0.002110\n",
      "Epoch 7, batch 73: loss = 0.002088\n",
      "Epoch 7, batch 74: loss = 0.002069\n",
      "Epoch 7, batch 75: loss = 0.001992\n",
      "Epoch 7, batch 76: loss = 0.002111\n",
      "Epoch 7, batch 77: loss = 0.001985\n",
      "Epoch 7, batch 78: loss = 0.002065\n",
      "Epoch 7, batch 79: loss = 0.002063\n",
      "Epoch 7, batch 80: loss = 0.001952\n",
      "Epoch 7, batch 81: loss = 0.002144\n",
      "Epoch 7, batch 82: loss = 0.001920\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 7: val_loss = 0.027111\n",
      "Epoch 8, batch 0: loss = 0.002279\n",
      "Epoch 8, batch 1: loss = 0.002179\n",
      "Epoch 8, batch 2: loss = 0.002106\n",
      "Epoch 8, batch 3: loss = 0.002047\n",
      "Epoch 8, batch 4: loss = 0.002099\n",
      "Epoch 8, batch 5: loss = 0.002114\n",
      "Epoch 8, batch 6: loss = 0.002047\n",
      "Epoch 8, batch 7: loss = 0.002102\n",
      "Epoch 8, batch 8: loss = 0.002115\n",
      "Epoch 8, batch 9: loss = 0.002116\n",
      "Epoch 8, batch 10: loss = 0.002118\n",
      "Epoch 8, batch 11: loss = 0.002084\n",
      "Epoch 8, batch 12: loss = 0.001996\n",
      "Epoch 8, batch 13: loss = 0.002117\n",
      "Epoch 8, batch 14: loss = 0.002055\n",
      "Epoch 8, batch 15: loss = 0.002106\n",
      "Epoch 8, batch 16: loss = 0.001907\n",
      "Epoch 8, batch 17: loss = 0.002101\n",
      "Epoch 8, batch 18: loss = 0.002010\n",
      "Epoch 8, batch 19: loss = 0.002076\n",
      "Epoch 8, batch 20: loss = 0.002046\n",
      "Epoch 8, batch 21: loss = 0.001971\n",
      "Epoch 8, batch 22: loss = 0.002065\n",
      "Epoch 8, batch 23: loss = 0.002072\n",
      "Epoch 8, batch 24: loss = 0.002098\n",
      "Epoch 8, batch 25: loss = 0.001957\n",
      "Epoch 8, batch 26: loss = 0.002003\n",
      "Epoch 8, batch 27: loss = 0.002004\n",
      "Epoch 8, batch 28: loss = 0.002060\n",
      "Epoch 8, batch 29: loss = 0.002081\n",
      "Epoch 8, batch 30: loss = 0.002021\n",
      "Epoch 8, batch 31: loss = 0.001997\n",
      "Epoch 8, batch 32: loss = 0.002014\n",
      "Epoch 8, batch 33: loss = 0.002079\n",
      "Epoch 8, batch 34: loss = 0.002102\n",
      "Epoch 8, batch 35: loss = 0.002187\n",
      "Epoch 8, batch 36: loss = 0.001960\n",
      "Epoch 8, batch 37: loss = 0.002151\n",
      "Epoch 8, batch 38: loss = 0.001957\n",
      "Epoch 8, batch 39: loss = 0.002149\n",
      "Epoch 8, batch 40: loss = 0.002039\n",
      "Epoch 8, batch 41: loss = 0.002027\n",
      "Epoch 8, batch 42: loss = 0.002045\n",
      "Epoch 8, batch 43: loss = 0.002143\n",
      "Epoch 8, batch 44: loss = 0.002003\n",
      "Epoch 8, batch 45: loss = 0.001972\n",
      "Epoch 8, batch 46: loss = 0.002124\n",
      "Epoch 8, batch 47: loss = 0.002022\n",
      "Epoch 8, batch 48: loss = 0.002097\n",
      "Epoch 8, batch 49: loss = 0.002079\n",
      "Epoch 8, batch 50: loss = 0.002106\n",
      "Epoch 8, batch 51: loss = 0.002001\n",
      "Epoch 8, batch 52: loss = 0.001987\n",
      "Epoch 8, batch 53: loss = 0.001992\n",
      "Epoch 8, batch 54: loss = 0.002209\n",
      "Epoch 8, batch 55: loss = 0.002152\n",
      "Epoch 8, batch 56: loss = 0.002068\n",
      "Epoch 8, batch 57: loss = 0.001947\n",
      "Epoch 8, batch 58: loss = 0.002109\n",
      "Epoch 8, batch 59: loss = 0.001964\n",
      "Epoch 8, batch 60: loss = 0.002019\n",
      "Epoch 8, batch 61: loss = 0.002075\n",
      "Epoch 8, batch 62: loss = 0.002076\n",
      "Epoch 8, batch 63: loss = 0.001988\n",
      "Epoch 8, batch 64: loss = 0.002162\n",
      "Epoch 8, batch 65: loss = 0.002002\n",
      "Epoch 8, batch 66: loss = 0.002016\n",
      "Epoch 8, batch 67: loss = 0.002019\n",
      "Epoch 8, batch 68: loss = 0.001980\n",
      "Epoch 8, batch 69: loss = 0.001997\n",
      "Epoch 8, batch 70: loss = 0.002006\n",
      "Epoch 8, batch 71: loss = 0.002029\n",
      "Epoch 8, batch 72: loss = 0.001990\n",
      "Epoch 8, batch 73: loss = 0.001996\n",
      "Epoch 8, batch 74: loss = 0.001918\n",
      "Epoch 8, batch 75: loss = 0.001997\n",
      "Epoch 8, batch 76: loss = 0.001979\n",
      "Epoch 8, batch 77: loss = 0.002017\n",
      "Epoch 8, batch 78: loss = 0.002102\n",
      "Epoch 8, batch 79: loss = 0.002083\n",
      "Epoch 8, batch 80: loss = 0.002026\n",
      "Epoch 8, batch 81: loss = 0.002001\n",
      "Epoch 8, batch 82: loss = 0.002361\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 8: val_loss = 0.027016\n",
      "Epoch 9, batch 0: loss = 0.002171\n",
      "Epoch 9, batch 1: loss = 0.002389\n",
      "Epoch 9, batch 2: loss = 0.002254\n",
      "Epoch 9, batch 3: loss = 0.002101\n",
      "Epoch 9, batch 4: loss = 0.002125\n",
      "Epoch 9, batch 5: loss = 0.002120\n",
      "Epoch 9, batch 6: loss = 0.002069\n",
      "Epoch 9, batch 7: loss = 0.002000\n",
      "Epoch 9, batch 8: loss = 0.002109\n",
      "Epoch 9, batch 9: loss = 0.001987\n",
      "Epoch 9, batch 10: loss = 0.002055\n",
      "Epoch 9, batch 11: loss = 0.001931\n",
      "Epoch 9, batch 12: loss = 0.002153\n",
      "Epoch 9, batch 13: loss = 0.002029\n",
      "Epoch 9, batch 14: loss = 0.001920\n",
      "Epoch 9, batch 15: loss = 0.002026\n",
      "Epoch 9, batch 16: loss = 0.002155\n",
      "Epoch 9, batch 17: loss = 0.002049\n",
      "Epoch 9, batch 18: loss = 0.002068\n",
      "Epoch 9, batch 19: loss = 0.001991\n",
      "Epoch 9, batch 20: loss = 0.001947\n",
      "Epoch 9, batch 21: loss = 0.002054\n",
      "Epoch 9, batch 22: loss = 0.002050\n",
      "Epoch 9, batch 23: loss = 0.002057\n",
      "Epoch 9, batch 24: loss = 0.002019\n",
      "Epoch 9, batch 25: loss = 0.001864\n",
      "Epoch 9, batch 26: loss = 0.002121\n",
      "Epoch 9, batch 27: loss = 0.002130\n",
      "Epoch 9, batch 28: loss = 0.001935\n",
      "Epoch 9, batch 29: loss = 0.002025\n",
      "Epoch 9, batch 30: loss = 0.002070\n",
      "Epoch 9, batch 31: loss = 0.001952\n",
      "Epoch 9, batch 32: loss = 0.002041\n",
      "Epoch 9, batch 33: loss = 0.001950\n",
      "Epoch 9, batch 34: loss = 0.002086\n",
      "Epoch 9, batch 35: loss = 0.002017\n",
      "Epoch 9, batch 36: loss = 0.001937\n",
      "Epoch 9, batch 37: loss = 0.001967\n",
      "Epoch 9, batch 38: loss = 0.002044\n",
      "Epoch 9, batch 39: loss = 0.002118\n",
      "Epoch 9, batch 40: loss = 0.002028\n",
      "Epoch 9, batch 41: loss = 0.002046\n",
      "Epoch 9, batch 42: loss = 0.002041\n",
      "Epoch 9, batch 43: loss = 0.002060\n",
      "Epoch 9, batch 44: loss = 0.002026\n",
      "Epoch 9, batch 45: loss = 0.002044\n",
      "Epoch 9, batch 46: loss = 0.001971\n",
      "Epoch 9, batch 47: loss = 0.001993\n",
      "Epoch 9, batch 48: loss = 0.001906\n",
      "Epoch 9, batch 49: loss = 0.001997\n",
      "Epoch 9, batch 50: loss = 0.001907\n",
      "Epoch 9, batch 51: loss = 0.002032\n",
      "Epoch 9, batch 52: loss = 0.002079\n",
      "Epoch 9, batch 53: loss = 0.001975\n",
      "Epoch 9, batch 54: loss = 0.001966\n",
      "Epoch 9, batch 55: loss = 0.002057\n",
      "Epoch 9, batch 56: loss = 0.002022\n",
      "Epoch 9, batch 57: loss = 0.001972\n",
      "Epoch 9, batch 58: loss = 0.001954\n",
      "Epoch 9, batch 59: loss = 0.001909\n",
      "Epoch 9, batch 60: loss = 0.002034\n",
      "Epoch 9, batch 61: loss = 0.001972\n",
      "Epoch 9, batch 62: loss = 0.002140\n",
      "Epoch 9, batch 63: loss = 0.001955\n",
      "Epoch 9, batch 64: loss = 0.001972\n",
      "Epoch 9, batch 65: loss = 0.002022\n",
      "Epoch 9, batch 66: loss = 0.001991\n",
      "Epoch 9, batch 67: loss = 0.001963\n",
      "Epoch 9, batch 68: loss = 0.002036\n",
      "Epoch 9, batch 69: loss = 0.002051\n",
      "Epoch 9, batch 70: loss = 0.001914\n",
      "Epoch 9, batch 71: loss = 0.001966\n",
      "Epoch 9, batch 72: loss = 0.001983\n",
      "Epoch 9, batch 73: loss = 0.001960\n",
      "Epoch 9, batch 74: loss = 0.001935\n",
      "Epoch 9, batch 75: loss = 0.001934\n",
      "Epoch 9, batch 76: loss = 0.002061\n",
      "Epoch 9, batch 77: loss = 0.001968\n",
      "Epoch 9, batch 78: loss = 0.002007\n",
      "Epoch 9, batch 79: loss = 0.001892\n",
      "Epoch 9, batch 80: loss = 0.001967\n",
      "Epoch 9, batch 81: loss = 0.001930\n",
      "Epoch 9, batch 82: loss = 0.001880\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 9: val_loss = 0.026908\n",
      "Epoch 10, batch 0: loss = 0.001988\n",
      "Epoch 10, batch 1: loss = 0.002041\n",
      "Epoch 10, batch 2: loss = 0.002022\n",
      "Epoch 10, batch 3: loss = 0.002066\n",
      "Epoch 10, batch 4: loss = 0.001972\n",
      "Epoch 10, batch 5: loss = 0.001986\n",
      "Epoch 10, batch 6: loss = 0.001928\n",
      "Epoch 10, batch 7: loss = 0.002047\n",
      "Epoch 10, batch 8: loss = 0.001849\n",
      "Epoch 10, batch 9: loss = 0.001870\n",
      "Epoch 10, batch 10: loss = 0.001896\n",
      "Epoch 10, batch 11: loss = 0.001932\n",
      "Epoch 10, batch 12: loss = 0.001874\n",
      "Epoch 10, batch 13: loss = 0.001943\n",
      "Epoch 10, batch 14: loss = 0.002000\n",
      "Epoch 10, batch 15: loss = 0.002083\n",
      "Epoch 10, batch 16: loss = 0.001986\n",
      "Epoch 10, batch 17: loss = 0.002066\n",
      "Epoch 10, batch 18: loss = 0.001996\n",
      "Epoch 10, batch 19: loss = 0.001965\n",
      "Epoch 10, batch 20: loss = 0.001957\n",
      "Epoch 10, batch 21: loss = 0.002056\n",
      "Epoch 10, batch 22: loss = 0.001952\n",
      "Epoch 10, batch 23: loss = 0.001859\n",
      "Epoch 10, batch 24: loss = 0.001929\n",
      "Epoch 10, batch 25: loss = 0.001915\n",
      "Epoch 10, batch 26: loss = 0.002021\n",
      "Epoch 10, batch 27: loss = 0.001906\n",
      "Epoch 10, batch 28: loss = 0.002009\n",
      "Epoch 10, batch 29: loss = 0.001910\n",
      "Epoch 10, batch 30: loss = 0.002034\n",
      "Epoch 10, batch 31: loss = 0.001943\n",
      "Epoch 10, batch 32: loss = 0.001936\n",
      "Epoch 10, batch 33: loss = 0.001968\n",
      "Epoch 10, batch 34: loss = 0.001997\n",
      "Epoch 10, batch 35: loss = 0.001960\n",
      "Epoch 10, batch 36: loss = 0.001963\n",
      "Epoch 10, batch 37: loss = 0.001862\n",
      "Epoch 10, batch 38: loss = 0.001890\n",
      "Epoch 10, batch 39: loss = 0.002035\n",
      "Epoch 10, batch 40: loss = 0.001992\n",
      "Epoch 10, batch 41: loss = 0.001960\n",
      "Epoch 10, batch 42: loss = 0.002043\n",
      "Epoch 10, batch 43: loss = 0.002054\n",
      "Epoch 10, batch 44: loss = 0.001983\n",
      "Epoch 10, batch 45: loss = 0.001952\n",
      "Epoch 10, batch 46: loss = 0.001893\n",
      "Epoch 10, batch 47: loss = 0.001984\n",
      "Epoch 10, batch 48: loss = 0.002083\n",
      "Epoch 10, batch 49: loss = 0.001905\n",
      "Epoch 10, batch 50: loss = 0.001929\n",
      "Epoch 10, batch 51: loss = 0.001967\n",
      "Epoch 10, batch 52: loss = 0.002003\n",
      "Epoch 10, batch 53: loss = 0.002092\n",
      "Epoch 10, batch 54: loss = 0.002057\n",
      "Epoch 10, batch 55: loss = 0.002131\n",
      "Epoch 10, batch 56: loss = 0.001901\n",
      "Epoch 10, batch 57: loss = 0.001945\n",
      "Epoch 10, batch 58: loss = 0.002004\n",
      "Epoch 10, batch 59: loss = 0.001943\n",
      "Epoch 10, batch 60: loss = 0.002036\n",
      "Epoch 10, batch 61: loss = 0.001975\n",
      "Epoch 10, batch 62: loss = 0.001964\n",
      "Epoch 10, batch 63: loss = 0.002012\n",
      "Epoch 10, batch 64: loss = 0.002012\n",
      "Epoch 10, batch 65: loss = 0.001965\n",
      "Epoch 10, batch 66: loss = 0.002075\n",
      "Epoch 10, batch 67: loss = 0.001880\n",
      "Epoch 10, batch 68: loss = 0.001948\n",
      "Epoch 10, batch 69: loss = 0.001981\n",
      "Epoch 10, batch 70: loss = 0.001842\n",
      "Epoch 10, batch 71: loss = 0.001918\n",
      "Epoch 10, batch 72: loss = 0.001912\n",
      "Epoch 10, batch 73: loss = 0.001905\n",
      "Epoch 10, batch 74: loss = 0.001816\n",
      "Epoch 10, batch 75: loss = 0.002022\n",
      "Epoch 10, batch 76: loss = 0.001923\n",
      "Epoch 10, batch 77: loss = 0.001926\n",
      "Epoch 10, batch 78: loss = 0.001956\n",
      "Epoch 10, batch 79: loss = 0.001923\n",
      "Epoch 10, batch 80: loss = 0.002002\n",
      "Epoch 10, batch 81: loss = 0.002050\n",
      "Epoch 10, batch 82: loss = 0.002292\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 10: val_loss = 0.027927\n",
      "Epoch 11, batch 0: loss = 0.002013\n",
      "Epoch 11, batch 1: loss = 0.002165\n",
      "Epoch 11, batch 2: loss = 0.002136\n",
      "Epoch 11, batch 3: loss = 0.002114\n",
      "Epoch 11, batch 4: loss = 0.002117\n",
      "Epoch 11, batch 5: loss = 0.002194\n",
      "Epoch 11, batch 6: loss = 0.002136\n",
      "Epoch 11, batch 7: loss = 0.002141\n",
      "Epoch 11, batch 8: loss = 0.001905\n",
      "Epoch 11, batch 9: loss = 0.001930\n",
      "Epoch 11, batch 10: loss = 0.001963\n",
      "Epoch 11, batch 11: loss = 0.001975\n",
      "Epoch 11, batch 12: loss = 0.001984\n",
      "Epoch 11, batch 13: loss = 0.002077\n",
      "Epoch 11, batch 14: loss = 0.001970\n",
      "Epoch 11, batch 15: loss = 0.001912\n",
      "Epoch 11, batch 16: loss = 0.002093\n",
      "Epoch 11, batch 17: loss = 0.002109\n",
      "Epoch 11, batch 18: loss = 0.001956\n",
      "Epoch 11, batch 19: loss = 0.001968\n",
      "Epoch 11, batch 20: loss = 0.002067\n",
      "Epoch 11, batch 21: loss = 0.001895\n",
      "Epoch 11, batch 22: loss = 0.001880\n",
      "Epoch 11, batch 23: loss = 0.002075\n",
      "Epoch 11, batch 24: loss = 0.001951\n",
      "Epoch 11, batch 25: loss = 0.001949\n",
      "Epoch 11, batch 26: loss = 0.002008\n",
      "Epoch 11, batch 27: loss = 0.002020\n",
      "Epoch 11, batch 28: loss = 0.001931\n",
      "Epoch 11, batch 29: loss = 0.002071\n",
      "Epoch 11, batch 30: loss = 0.002002\n",
      "Epoch 11, batch 31: loss = 0.001971\n",
      "Epoch 11, batch 32: loss = 0.001915\n",
      "Epoch 11, batch 33: loss = 0.002017\n",
      "Epoch 11, batch 34: loss = 0.001954\n",
      "Epoch 11, batch 35: loss = 0.001886\n",
      "Epoch 11, batch 36: loss = 0.001927\n",
      "Epoch 11, batch 37: loss = 0.001845\n",
      "Epoch 11, batch 38: loss = 0.001837\n",
      "Epoch 11, batch 39: loss = 0.002007\n",
      "Epoch 11, batch 40: loss = 0.001886\n",
      "Epoch 11, batch 41: loss = 0.001968\n",
      "Epoch 11, batch 42: loss = 0.001985\n",
      "Epoch 11, batch 43: loss = 0.001883\n",
      "Epoch 11, batch 44: loss = 0.001920\n",
      "Epoch 11, batch 45: loss = 0.001910\n",
      "Epoch 11, batch 46: loss = 0.002017\n",
      "Epoch 11, batch 47: loss = 0.001955\n",
      "Epoch 11, batch 48: loss = 0.001830\n",
      "Epoch 11, batch 49: loss = 0.001933\n",
      "Epoch 11, batch 50: loss = 0.001971\n",
      "Epoch 11, batch 51: loss = 0.001949\n",
      "Epoch 11, batch 52: loss = 0.001914\n",
      "Epoch 11, batch 53: loss = 0.001929\n",
      "Epoch 11, batch 54: loss = 0.001801\n",
      "Epoch 11, batch 55: loss = 0.001920\n",
      "Epoch 11, batch 56: loss = 0.001890\n",
      "Epoch 11, batch 57: loss = 0.001933\n",
      "Epoch 11, batch 58: loss = 0.001915\n",
      "Epoch 11, batch 59: loss = 0.001976\n",
      "Epoch 11, batch 60: loss = 0.001905\n",
      "Epoch 11, batch 61: loss = 0.001972\n",
      "Epoch 11, batch 62: loss = 0.001881\n",
      "Epoch 11, batch 63: loss = 0.001845\n",
      "Epoch 11, batch 64: loss = 0.001920\n",
      "Epoch 11, batch 65: loss = 0.002045\n",
      "Epoch 11, batch 66: loss = 0.001899\n",
      "Epoch 11, batch 67: loss = 0.001978\n",
      "Epoch 11, batch 68: loss = 0.001881\n",
      "Epoch 11, batch 69: loss = 0.002041\n",
      "Epoch 11, batch 70: loss = 0.001806\n",
      "Epoch 11, batch 71: loss = 0.001888\n",
      "Epoch 11, batch 72: loss = 0.001903\n",
      "Epoch 11, batch 73: loss = 0.001776\n",
      "Epoch 11, batch 74: loss = 0.001885\n",
      "Epoch 11, batch 75: loss = 0.001970\n",
      "Epoch 11, batch 76: loss = 0.001894\n",
      "Epoch 11, batch 77: loss = 0.001906\n",
      "Epoch 11, batch 78: loss = 0.001926\n",
      "Epoch 11, batch 79: loss = 0.001981\n",
      "Epoch 11, batch 80: loss = 0.001952\n",
      "Epoch 11, batch 81: loss = 0.002016\n",
      "Epoch 11, batch 82: loss = 0.001643\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 11: val_loss = 0.027083\n",
      "Epoch 12, batch 0: loss = 0.002077\n",
      "Epoch 12, batch 1: loss = 0.001990\n",
      "Epoch 12, batch 2: loss = 0.002152\n",
      "Epoch 12, batch 3: loss = 0.002048\n",
      "Epoch 12, batch 4: loss = 0.001979\n",
      "Epoch 12, batch 5: loss = 0.002054\n",
      "Epoch 12, batch 6: loss = 0.001976\n",
      "Epoch 12, batch 7: loss = 0.002033\n",
      "Epoch 12, batch 8: loss = 0.001901\n",
      "Epoch 12, batch 9: loss = 0.001944\n",
      "Epoch 12, batch 10: loss = 0.001869\n",
      "Epoch 12, batch 11: loss = 0.002007\n",
      "Epoch 12, batch 12: loss = 0.001923\n",
      "Epoch 12, batch 13: loss = 0.001933\n",
      "Epoch 12, batch 14: loss = 0.001923\n",
      "Epoch 12, batch 15: loss = 0.001802\n",
      "Epoch 12, batch 16: loss = 0.001955\n",
      "Epoch 12, batch 17: loss = 0.001983\n",
      "Epoch 12, batch 18: loss = 0.001968\n",
      "Epoch 12, batch 19: loss = 0.001795\n",
      "Epoch 12, batch 20: loss = 0.001958\n",
      "Epoch 12, batch 21: loss = 0.001983\n",
      "Epoch 12, batch 22: loss = 0.001940\n",
      "Epoch 12, batch 23: loss = 0.001986\n",
      "Epoch 12, batch 24: loss = 0.001964\n",
      "Epoch 12, batch 25: loss = 0.001919\n",
      "Epoch 12, batch 26: loss = 0.001794\n",
      "Epoch 12, batch 27: loss = 0.001906\n",
      "Epoch 12, batch 28: loss = 0.001929\n",
      "Epoch 12, batch 29: loss = 0.001940\n",
      "Epoch 12, batch 30: loss = 0.001920\n",
      "Epoch 12, batch 31: loss = 0.001856\n",
      "Epoch 12, batch 32: loss = 0.001990\n",
      "Epoch 12, batch 33: loss = 0.001871\n",
      "Epoch 12, batch 34: loss = 0.001948\n",
      "Epoch 12, batch 35: loss = 0.001902\n",
      "Epoch 12, batch 36: loss = 0.002059\n",
      "Epoch 12, batch 37: loss = 0.001757\n",
      "Epoch 12, batch 38: loss = 0.001836\n",
      "Epoch 12, batch 39: loss = 0.002005\n",
      "Epoch 12, batch 40: loss = 0.001833\n",
      "Epoch 12, batch 41: loss = 0.002038\n",
      "Epoch 12, batch 42: loss = 0.001822\n",
      "Epoch 12, batch 43: loss = 0.001814\n",
      "Epoch 12, batch 44: loss = 0.001917\n",
      "Epoch 12, batch 45: loss = 0.001886\n",
      "Epoch 12, batch 46: loss = 0.001895\n",
      "Epoch 12, batch 47: loss = 0.001959\n",
      "Epoch 12, batch 48: loss = 0.001940\n",
      "Epoch 12, batch 49: loss = 0.001840\n",
      "Epoch 12, batch 50: loss = 0.001827\n",
      "Epoch 12, batch 51: loss = 0.001879\n",
      "Epoch 12, batch 52: loss = 0.001878\n",
      "Epoch 12, batch 53: loss = 0.001865\n",
      "Epoch 12, batch 54: loss = 0.001931\n",
      "Epoch 12, batch 55: loss = 0.001965\n",
      "Epoch 12, batch 56: loss = 0.001734\n",
      "Epoch 12, batch 57: loss = 0.001870\n",
      "Epoch 12, batch 58: loss = 0.001836\n",
      "Epoch 12, batch 59: loss = 0.001879\n",
      "Epoch 12, batch 60: loss = 0.001828\n",
      "Epoch 12, batch 61: loss = 0.001950\n",
      "Epoch 12, batch 62: loss = 0.001839\n",
      "Epoch 12, batch 63: loss = 0.001886\n",
      "Epoch 12, batch 64: loss = 0.001990\n",
      "Epoch 12, batch 65: loss = 0.001857\n",
      "Epoch 12, batch 66: loss = 0.001817\n",
      "Epoch 12, batch 67: loss = 0.001878\n",
      "Epoch 12, batch 68: loss = 0.001813\n",
      "Epoch 12, batch 69: loss = 0.002014\n",
      "Epoch 12, batch 70: loss = 0.001931\n",
      "Epoch 12, batch 71: loss = 0.001960\n",
      "Epoch 12, batch 72: loss = 0.001927\n",
      "Epoch 12, batch 73: loss = 0.001926\n",
      "Epoch 12, batch 74: loss = 0.001927\n",
      "Epoch 12, batch 75: loss = 0.001904\n",
      "Epoch 12, batch 76: loss = 0.001961\n",
      "Epoch 12, batch 77: loss = 0.001914\n",
      "Epoch 12, batch 78: loss = 0.002043\n",
      "Epoch 12, batch 79: loss = 0.001900\n",
      "Epoch 12, batch 80: loss = 0.001943\n",
      "Epoch 12, batch 81: loss = 0.002004\n",
      "Epoch 12, batch 82: loss = 0.002248\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 12: val_loss = 0.027293\n",
      "Epoch 13, batch 0: loss = 0.001973\n",
      "Epoch 13, batch 1: loss = 0.001957\n",
      "Epoch 13, batch 2: loss = 0.001893\n",
      "Epoch 13, batch 3: loss = 0.001951\n",
      "Epoch 13, batch 4: loss = 0.001931\n",
      "Epoch 13, batch 5: loss = 0.001969\n",
      "Epoch 13, batch 6: loss = 0.001969\n",
      "Epoch 13, batch 7: loss = 0.001873\n",
      "Epoch 13, batch 8: loss = 0.001865\n",
      "Epoch 13, batch 9: loss = 0.001933\n",
      "Epoch 13, batch 10: loss = 0.001857\n",
      "Epoch 13, batch 11: loss = 0.001907\n",
      "Epoch 13, batch 12: loss = 0.001959\n",
      "Epoch 13, batch 13: loss = 0.001933\n",
      "Epoch 13, batch 14: loss = 0.001945\n",
      "Epoch 13, batch 15: loss = 0.001905\n",
      "Epoch 13, batch 16: loss = 0.001940\n",
      "Epoch 13, batch 17: loss = 0.001885\n",
      "Epoch 13, batch 18: loss = 0.001891\n",
      "Epoch 13, batch 19: loss = 0.001872\n",
      "Epoch 13, batch 20: loss = 0.001796\n",
      "Epoch 13, batch 21: loss = 0.001916\n",
      "Epoch 13, batch 22: loss = 0.001980\n",
      "Epoch 13, batch 23: loss = 0.001803\n",
      "Epoch 13, batch 24: loss = 0.001840\n",
      "Epoch 13, batch 25: loss = 0.001917\n",
      "Epoch 13, batch 26: loss = 0.001775\n",
      "Epoch 13, batch 27: loss = 0.001918\n",
      "Epoch 13, batch 28: loss = 0.001824\n",
      "Epoch 13, batch 29: loss = 0.001768\n",
      "Epoch 13, batch 30: loss = 0.001898\n",
      "Epoch 13, batch 31: loss = 0.001951\n",
      "Epoch 13, batch 32: loss = 0.002007\n",
      "Epoch 13, batch 33: loss = 0.001882\n",
      "Epoch 13, batch 34: loss = 0.002035\n",
      "Epoch 13, batch 35: loss = 0.001854\n",
      "Epoch 13, batch 36: loss = 0.001877\n",
      "Epoch 13, batch 37: loss = 0.001844\n",
      "Epoch 13, batch 38: loss = 0.001832\n",
      "Epoch 13, batch 39: loss = 0.001989\n",
      "Epoch 13, batch 40: loss = 0.001948\n",
      "Epoch 13, batch 41: loss = 0.001938\n",
      "Epoch 13, batch 42: loss = 0.001836\n",
      "Epoch 13, batch 43: loss = 0.001968\n",
      "Epoch 13, batch 44: loss = 0.001869\n",
      "Epoch 13, batch 45: loss = 0.001866\n",
      "Epoch 13, batch 46: loss = 0.001853\n",
      "Epoch 13, batch 47: loss = 0.001785\n",
      "Epoch 13, batch 48: loss = 0.001857\n",
      "Epoch 13, batch 49: loss = 0.001832\n",
      "Epoch 13, batch 50: loss = 0.001996\n",
      "Epoch 13, batch 51: loss = 0.001852\n",
      "Epoch 13, batch 52: loss = 0.001849\n",
      "Epoch 13, batch 53: loss = 0.001957\n",
      "Epoch 13, batch 54: loss = 0.001836\n",
      "Epoch 13, batch 55: loss = 0.001781\n",
      "Epoch 13, batch 56: loss = 0.001918\n",
      "Epoch 13, batch 57: loss = 0.001852\n",
      "Epoch 13, batch 58: loss = 0.001850\n",
      "Epoch 13, batch 59: loss = 0.001916\n",
      "Epoch 13, batch 60: loss = 0.001848\n",
      "Epoch 13, batch 61: loss = 0.001877\n",
      "Epoch 13, batch 62: loss = 0.001962\n",
      "Epoch 13, batch 63: loss = 0.001923\n",
      "Epoch 13, batch 64: loss = 0.001836\n",
      "Epoch 13, batch 65: loss = 0.001833\n",
      "Epoch 13, batch 66: loss = 0.001767\n",
      "Epoch 13, batch 67: loss = 0.001910\n",
      "Epoch 13, batch 68: loss = 0.001954\n",
      "Epoch 13, batch 69: loss = 0.001720\n",
      "Epoch 13, batch 70: loss = 0.001806\n",
      "Epoch 13, batch 71: loss = 0.001858\n",
      "Epoch 13, batch 72: loss = 0.001730\n",
      "Epoch 13, batch 73: loss = 0.001806\n",
      "Epoch 13, batch 74: loss = 0.001864\n",
      "Epoch 13, batch 75: loss = 0.001814\n",
      "Epoch 13, batch 76: loss = 0.001951\n",
      "Epoch 13, batch 77: loss = 0.001864\n",
      "Epoch 13, batch 78: loss = 0.001859\n",
      "Epoch 13, batch 79: loss = 0.001823\n",
      "Epoch 13, batch 80: loss = 0.001897\n",
      "Epoch 13, batch 81: loss = 0.001804\n",
      "Epoch 13, batch 82: loss = 0.001687\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 13: val_loss = 0.027138\n",
      "Epoch 14, batch 0: loss = 0.001886\n",
      "Epoch 14, batch 1: loss = 0.001932\n",
      "Epoch 14, batch 2: loss = 0.002058\n",
      "Epoch 14, batch 3: loss = 0.001940\n",
      "Epoch 14, batch 4: loss = 0.001911\n",
      "Epoch 14, batch 5: loss = 0.001903\n",
      "Epoch 14, batch 6: loss = 0.001768\n",
      "Epoch 14, batch 7: loss = 0.001926\n",
      "Epoch 14, batch 8: loss = 0.001816\n",
      "Epoch 14, batch 9: loss = 0.001956\n",
      "Epoch 14, batch 10: loss = 0.001921\n",
      "Epoch 14, batch 11: loss = 0.001937\n",
      "Epoch 14, batch 12: loss = 0.001915\n",
      "Epoch 14, batch 13: loss = 0.001916\n",
      "Epoch 14, batch 14: loss = 0.001847\n",
      "Epoch 14, batch 15: loss = 0.001828\n",
      "Epoch 14, batch 16: loss = 0.001806\n",
      "Epoch 14, batch 17: loss = 0.001984\n",
      "Epoch 14, batch 18: loss = 0.001840\n",
      "Epoch 14, batch 19: loss = 0.001786\n",
      "Epoch 14, batch 20: loss = 0.002020\n",
      "Epoch 14, batch 21: loss = 0.001907\n",
      "Epoch 14, batch 22: loss = 0.001829\n",
      "Epoch 14, batch 23: loss = 0.001812\n",
      "Epoch 14, batch 24: loss = 0.001808\n",
      "Epoch 14, batch 25: loss = 0.001867\n",
      "Epoch 14, batch 26: loss = 0.001897\n",
      "Epoch 14, batch 27: loss = 0.001887\n",
      "Epoch 14, batch 28: loss = 0.001794\n",
      "Epoch 14, batch 29: loss = 0.001872\n",
      "Epoch 14, batch 30: loss = 0.001805\n",
      "Epoch 14, batch 31: loss = 0.001857\n",
      "Epoch 14, batch 32: loss = 0.001897\n",
      "Epoch 14, batch 33: loss = 0.001918\n",
      "Epoch 14, batch 34: loss = 0.001882\n",
      "Epoch 14, batch 35: loss = 0.001903\n",
      "Epoch 14, batch 36: loss = 0.001810\n",
      "Epoch 14, batch 37: loss = 0.001843\n",
      "Epoch 14, batch 38: loss = 0.001823\n",
      "Epoch 14, batch 39: loss = 0.001884\n",
      "Epoch 14, batch 40: loss = 0.001807\n",
      "Epoch 14, batch 41: loss = 0.001777\n",
      "Epoch 14, batch 42: loss = 0.001821\n",
      "Epoch 14, batch 43: loss = 0.001749\n",
      "Epoch 14, batch 44: loss = 0.001977\n",
      "Epoch 14, batch 45: loss = 0.001951\n",
      "Epoch 14, batch 46: loss = 0.001809\n",
      "Epoch 14, batch 47: loss = 0.001879\n",
      "Epoch 14, batch 48: loss = 0.001794\n",
      "Epoch 14, batch 49: loss = 0.001869\n",
      "Epoch 14, batch 50: loss = 0.001744\n",
      "Epoch 14, batch 51: loss = 0.001846\n",
      "Epoch 14, batch 52: loss = 0.001888\n",
      "Epoch 14, batch 53: loss = 0.001817\n",
      "Epoch 14, batch 54: loss = 0.001789\n",
      "Epoch 14, batch 55: loss = 0.001859\n",
      "Epoch 14, batch 56: loss = 0.001810\n",
      "Epoch 14, batch 57: loss = 0.001937\n",
      "Epoch 14, batch 58: loss = 0.001807\n",
      "Epoch 14, batch 59: loss = 0.001808\n",
      "Epoch 14, batch 60: loss = 0.001792\n",
      "Epoch 14, batch 61: loss = 0.001868\n",
      "Epoch 14, batch 62: loss = 0.001788\n",
      "Epoch 14, batch 63: loss = 0.001879\n",
      "Epoch 14, batch 64: loss = 0.001905\n",
      "Epoch 14, batch 65: loss = 0.001935\n",
      "Epoch 14, batch 66: loss = 0.001953\n",
      "Epoch 14, batch 67: loss = 0.001844\n",
      "Epoch 14, batch 68: loss = 0.001998\n",
      "Epoch 14, batch 69: loss = 0.001941\n",
      "Epoch 14, batch 70: loss = 0.001897\n",
      "Epoch 14, batch 71: loss = 0.001857\n",
      "Epoch 14, batch 72: loss = 0.001738\n",
      "Epoch 14, batch 73: loss = 0.001850\n",
      "Epoch 14, batch 74: loss = 0.001825\n",
      "Epoch 14, batch 75: loss = 0.001648\n",
      "Epoch 14, batch 76: loss = 0.001909\n",
      "Epoch 14, batch 77: loss = 0.001751\n",
      "Epoch 14, batch 78: loss = 0.001844\n",
      "Epoch 14, batch 79: loss = 0.001911\n",
      "Epoch 14, batch 80: loss = 0.001948\n",
      "Epoch 14, batch 81: loss = 0.002031\n",
      "Epoch 14, batch 82: loss = 0.002352\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 14: val_loss = 0.026876\n",
      "Epoch 15, batch 0: loss = 0.001893\n",
      "Epoch 15, batch 1: loss = 0.002023\n",
      "Epoch 15, batch 2: loss = 0.001861\n",
      "Epoch 15, batch 3: loss = 0.001913\n",
      "Epoch 15, batch 4: loss = 0.001809\n",
      "Epoch 15, batch 5: loss = 0.001721\n",
      "Epoch 15, batch 6: loss = 0.001872\n",
      "Epoch 15, batch 7: loss = 0.001831\n",
      "Epoch 15, batch 8: loss = 0.001816\n",
      "Epoch 15, batch 9: loss = 0.001826\n",
      "Epoch 15, batch 10: loss = 0.001937\n",
      "Epoch 15, batch 11: loss = 0.001812\n",
      "Epoch 15, batch 12: loss = 0.001823\n",
      "Epoch 15, batch 13: loss = 0.001788\n",
      "Epoch 15, batch 14: loss = 0.001858\n",
      "Epoch 15, batch 15: loss = 0.001812\n",
      "Epoch 15, batch 16: loss = 0.001754\n",
      "Epoch 15, batch 17: loss = 0.001898\n",
      "Epoch 15, batch 18: loss = 0.001851\n",
      "Epoch 15, batch 19: loss = 0.001802\n",
      "Epoch 15, batch 20: loss = 0.001814\n",
      "Epoch 15, batch 21: loss = 0.001867\n",
      "Epoch 15, batch 22: loss = 0.001796\n",
      "Epoch 15, batch 23: loss = 0.001879\n",
      "Epoch 15, batch 24: loss = 0.001785\n",
      "Epoch 15, batch 25: loss = 0.001883\n",
      "Epoch 15, batch 26: loss = 0.001893\n",
      "Epoch 15, batch 27: loss = 0.001946\n",
      "Epoch 15, batch 28: loss = 0.001948\n",
      "Epoch 15, batch 29: loss = 0.001817\n",
      "Epoch 15, batch 30: loss = 0.001825\n",
      "Epoch 15, batch 31: loss = 0.001813\n",
      "Epoch 15, batch 32: loss = 0.001706\n",
      "Epoch 15, batch 33: loss = 0.001914\n",
      "Epoch 15, batch 34: loss = 0.001780\n",
      "Epoch 15, batch 35: loss = 0.001884\n",
      "Epoch 15, batch 36: loss = 0.001791\n",
      "Epoch 15, batch 37: loss = 0.001831\n",
      "Epoch 15, batch 38: loss = 0.001814\n",
      "Epoch 15, batch 39: loss = 0.001731\n",
      "Epoch 15, batch 40: loss = 0.001855\n",
      "Epoch 15, batch 41: loss = 0.001797\n",
      "Epoch 15, batch 42: loss = 0.001883\n",
      "Epoch 15, batch 43: loss = 0.001790\n",
      "Epoch 15, batch 44: loss = 0.001955\n",
      "Epoch 15, batch 45: loss = 0.001920\n",
      "Epoch 15, batch 46: loss = 0.001880\n",
      "Epoch 15, batch 47: loss = 0.001914\n",
      "Epoch 15, batch 48: loss = 0.001904\n",
      "Epoch 15, batch 49: loss = 0.001876\n",
      "Epoch 15, batch 50: loss = 0.001779\n",
      "Epoch 15, batch 51: loss = 0.001719\n",
      "Epoch 15, batch 52: loss = 0.001762\n",
      "Epoch 15, batch 53: loss = 0.001740\n",
      "Epoch 15, batch 54: loss = 0.001831\n",
      "Epoch 15, batch 55: loss = 0.001902\n",
      "Epoch 15, batch 56: loss = 0.001741\n",
      "Epoch 15, batch 57: loss = 0.001866\n",
      "Epoch 15, batch 58: loss = 0.001778\n",
      "Epoch 15, batch 59: loss = 0.001779\n",
      "Epoch 15, batch 60: loss = 0.001708\n",
      "Epoch 15, batch 61: loss = 0.001828\n",
      "Epoch 15, batch 62: loss = 0.001919\n",
      "Epoch 15, batch 63: loss = 0.001804\n",
      "Epoch 15, batch 64: loss = 0.001731\n",
      "Epoch 15, batch 65: loss = 0.001890\n",
      "Epoch 15, batch 66: loss = 0.001833\n",
      "Epoch 15, batch 67: loss = 0.001850\n",
      "Epoch 15, batch 68: loss = 0.001847\n",
      "Epoch 15, batch 69: loss = 0.001786\n",
      "Epoch 15, batch 70: loss = 0.001864\n",
      "Epoch 15, batch 71: loss = 0.001917\n",
      "Epoch 15, batch 72: loss = 0.001872\n",
      "Epoch 15, batch 73: loss = 0.001843\n",
      "Epoch 15, batch 74: loss = 0.001800\n",
      "Epoch 15, batch 75: loss = 0.001837\n",
      "Epoch 15, batch 76: loss = 0.001885\n",
      "Epoch 15, batch 77: loss = 0.001839\n",
      "Epoch 15, batch 78: loss = 0.001827\n",
      "Epoch 15, batch 79: loss = 0.001899\n",
      "Epoch 15, batch 80: loss = 0.001843\n",
      "Epoch 15, batch 81: loss = 0.001733\n",
      "Epoch 15, batch 82: loss = 0.002687\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 15: val_loss = 0.026719\n",
      "Epoch 16, batch 0: loss = 0.001991\n",
      "Epoch 16, batch 1: loss = 0.001930\n",
      "Epoch 16, batch 2: loss = 0.001957\n",
      "Epoch 16, batch 3: loss = 0.001961\n",
      "Epoch 16, batch 4: loss = 0.001864\n",
      "Epoch 16, batch 5: loss = 0.001955\n",
      "Epoch 16, batch 6: loss = 0.001876\n",
      "Epoch 16, batch 7: loss = 0.001782\n",
      "Epoch 16, batch 8: loss = 0.001849\n",
      "Epoch 16, batch 9: loss = 0.001917\n",
      "Epoch 16, batch 10: loss = 0.001809\n",
      "Epoch 16, batch 11: loss = 0.001695\n",
      "Epoch 16, batch 12: loss = 0.001803\n",
      "Epoch 16, batch 13: loss = 0.001894\n",
      "Epoch 16, batch 14: loss = 0.001942\n",
      "Epoch 16, batch 15: loss = 0.002020\n",
      "Epoch 16, batch 16: loss = 0.001829\n",
      "Epoch 16, batch 17: loss = 0.001773\n",
      "Epoch 16, batch 18: loss = 0.001714\n",
      "Epoch 16, batch 19: loss = 0.001955\n",
      "Epoch 16, batch 20: loss = 0.001795\n",
      "Epoch 16, batch 21: loss = 0.001759\n",
      "Epoch 16, batch 22: loss = 0.001839\n",
      "Epoch 16, batch 23: loss = 0.001791\n",
      "Epoch 16, batch 24: loss = 0.001958\n",
      "Epoch 16, batch 25: loss = 0.001808\n",
      "Epoch 16, batch 26: loss = 0.001841\n",
      "Epoch 16, batch 27: loss = 0.001744\n",
      "Epoch 16, batch 28: loss = 0.001932\n",
      "Epoch 16, batch 29: loss = 0.001873\n",
      "Epoch 16, batch 30: loss = 0.001773\n",
      "Epoch 16, batch 31: loss = 0.001793\n",
      "Epoch 16, batch 32: loss = 0.001750\n",
      "Epoch 16, batch 33: loss = 0.001809\n",
      "Epoch 16, batch 34: loss = 0.001804\n",
      "Epoch 16, batch 35: loss = 0.001761\n",
      "Epoch 16, batch 36: loss = 0.001802\n",
      "Epoch 16, batch 37: loss = 0.001807\n",
      "Epoch 16, batch 38: loss = 0.001818\n",
      "Epoch 16, batch 39: loss = 0.001928\n",
      "Epoch 16, batch 40: loss = 0.001806\n",
      "Epoch 16, batch 41: loss = 0.001824\n",
      "Epoch 16, batch 42: loss = 0.001806\n",
      "Epoch 16, batch 43: loss = 0.001896\n",
      "Epoch 16, batch 44: loss = 0.001709\n",
      "Epoch 16, batch 45: loss = 0.001838\n",
      "Epoch 16, batch 46: loss = 0.001749\n",
      "Epoch 16, batch 47: loss = 0.001778\n",
      "Epoch 16, batch 48: loss = 0.001925\n",
      "Epoch 16, batch 49: loss = 0.001900\n",
      "Epoch 16, batch 50: loss = 0.001792\n",
      "Epoch 16, batch 51: loss = 0.001763\n",
      "Epoch 16, batch 52: loss = 0.001805\n",
      "Epoch 16, batch 53: loss = 0.001795\n",
      "Epoch 16, batch 54: loss = 0.001764\n",
      "Epoch 16, batch 55: loss = 0.001797\n",
      "Epoch 16, batch 56: loss = 0.001875\n",
      "Epoch 16, batch 57: loss = 0.001908\n",
      "Epoch 16, batch 58: loss = 0.001764\n",
      "Epoch 16, batch 59: loss = 0.001752\n",
      "Epoch 16, batch 60: loss = 0.001880\n",
      "Epoch 16, batch 61: loss = 0.001902\n",
      "Epoch 16, batch 62: loss = 0.001784\n",
      "Epoch 16, batch 63: loss = 0.001862\n",
      "Epoch 16, batch 64: loss = 0.001838\n",
      "Epoch 16, batch 65: loss = 0.001747\n",
      "Epoch 16, batch 66: loss = 0.001809\n",
      "Epoch 16, batch 67: loss = 0.001731\n",
      "Epoch 16, batch 68: loss = 0.001794\n",
      "Epoch 16, batch 69: loss = 0.001849\n",
      "Epoch 16, batch 70: loss = 0.001844\n",
      "Epoch 16, batch 71: loss = 0.001781\n",
      "Epoch 16, batch 72: loss = 0.001902\n",
      "Epoch 16, batch 73: loss = 0.001869\n",
      "Epoch 16, batch 74: loss = 0.001955\n",
      "Epoch 16, batch 75: loss = 0.001809\n",
      "Epoch 16, batch 76: loss = 0.001845\n",
      "Epoch 16, batch 77: loss = 0.001748\n",
      "Epoch 16, batch 78: loss = 0.001742\n",
      "Epoch 16, batch 79: loss = 0.001787\n",
      "Epoch 16, batch 80: loss = 0.001740\n",
      "Epoch 16, batch 81: loss = 0.001794\n",
      "Epoch 16, batch 82: loss = 0.003059\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 16: val_loss = 0.028062\n",
      "Epoch 17, batch 0: loss = 0.001946\n",
      "Epoch 17, batch 1: loss = 0.002077\n",
      "Epoch 17, batch 2: loss = 0.002036\n",
      "Epoch 17, batch 3: loss = 0.001912\n",
      "Epoch 17, batch 4: loss = 0.001891\n",
      "Epoch 17, batch 5: loss = 0.001875\n",
      "Epoch 17, batch 6: loss = 0.001892\n",
      "Epoch 17, batch 7: loss = 0.001953\n",
      "Epoch 17, batch 8: loss = 0.001805\n",
      "Epoch 17, batch 9: loss = 0.001856\n",
      "Epoch 17, batch 10: loss = 0.001974\n",
      "Epoch 17, batch 11: loss = 0.001848\n",
      "Epoch 17, batch 12: loss = 0.001851\n",
      "Epoch 17, batch 13: loss = 0.001850\n",
      "Epoch 17, batch 14: loss = 0.001934\n",
      "Epoch 17, batch 15: loss = 0.002063\n",
      "Epoch 17, batch 16: loss = 0.001951\n",
      "Epoch 17, batch 17: loss = 0.001873\n",
      "Epoch 17, batch 18: loss = 0.001902\n",
      "Epoch 17, batch 19: loss = 0.001652\n",
      "Epoch 17, batch 20: loss = 0.001843\n",
      "Epoch 17, batch 21: loss = 0.001772\n",
      "Epoch 17, batch 22: loss = 0.001833\n",
      "Epoch 17, batch 23: loss = 0.001851\n",
      "Epoch 17, batch 24: loss = 0.001857\n",
      "Epoch 17, batch 25: loss = 0.001884\n",
      "Epoch 17, batch 26: loss = 0.001994\n",
      "Epoch 17, batch 27: loss = 0.001849\n",
      "Epoch 17, batch 28: loss = 0.001911\n",
      "Epoch 17, batch 29: loss = 0.001732\n",
      "Epoch 17, batch 30: loss = 0.001902\n",
      "Epoch 17, batch 31: loss = 0.001930\n",
      "Epoch 17, batch 32: loss = 0.001881\n",
      "Epoch 17, batch 33: loss = 0.001842\n",
      "Epoch 17, batch 34: loss = 0.001764\n",
      "Epoch 17, batch 35: loss = 0.001833\n",
      "Epoch 17, batch 36: loss = 0.001802\n",
      "Epoch 17, batch 37: loss = 0.001759\n",
      "Epoch 17, batch 38: loss = 0.001767\n",
      "Epoch 17, batch 39: loss = 0.001861\n",
      "Epoch 17, batch 40: loss = 0.001889\n",
      "Epoch 17, batch 41: loss = 0.001839\n",
      "Epoch 17, batch 42: loss = 0.001764\n",
      "Epoch 17, batch 43: loss = 0.001735\n",
      "Epoch 17, batch 44: loss = 0.001907\n",
      "Epoch 17, batch 45: loss = 0.001822\n",
      "Epoch 17, batch 46: loss = 0.001835\n",
      "Epoch 17, batch 47: loss = 0.001730\n",
      "Epoch 17, batch 48: loss = 0.001649\n",
      "Epoch 17, batch 49: loss = 0.001830\n",
      "Epoch 17, batch 50: loss = 0.001825\n",
      "Epoch 17, batch 51: loss = 0.001812\n",
      "Epoch 17, batch 52: loss = 0.001915\n",
      "Epoch 17, batch 53: loss = 0.001836\n",
      "Epoch 17, batch 54: loss = 0.001787\n",
      "Epoch 17, batch 55: loss = 0.001839\n",
      "Epoch 17, batch 56: loss = 0.001774\n",
      "Epoch 17, batch 57: loss = 0.001794\n",
      "Epoch 17, batch 58: loss = 0.001881\n",
      "Epoch 17, batch 59: loss = 0.001881\n",
      "Epoch 17, batch 60: loss = 0.001833\n",
      "Epoch 17, batch 61: loss = 0.001883\n",
      "Epoch 17, batch 62: loss = 0.001854\n",
      "Epoch 17, batch 63: loss = 0.001830\n",
      "Epoch 17, batch 64: loss = 0.001890\n",
      "Epoch 17, batch 65: loss = 0.001757\n",
      "Epoch 17, batch 66: loss = 0.001804\n",
      "Epoch 17, batch 67: loss = 0.001836\n",
      "Epoch 17, batch 68: loss = 0.001764\n",
      "Epoch 17, batch 69: loss = 0.001874\n",
      "Epoch 17, batch 70: loss = 0.001832\n",
      "Epoch 17, batch 71: loss = 0.001743\n",
      "Epoch 17, batch 72: loss = 0.001799\n",
      "Epoch 17, batch 73: loss = 0.001792\n",
      "Epoch 17, batch 74: loss = 0.001761\n",
      "Epoch 17, batch 75: loss = 0.001674\n",
      "Epoch 17, batch 76: loss = 0.001751\n",
      "Epoch 17, batch 77: loss = 0.001715\n",
      "Epoch 17, batch 78: loss = 0.001868\n",
      "Epoch 17, batch 79: loss = 0.001816\n",
      "Epoch 17, batch 80: loss = 0.001841\n",
      "Epoch 17, batch 81: loss = 0.001672\n",
      "Epoch 17, batch 82: loss = 0.001384\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 17: val_loss = 0.027772\n",
      "Epoch 18, batch 0: loss = 0.001919\n",
      "Epoch 18, batch 1: loss = 0.001818\n",
      "Epoch 18, batch 2: loss = 0.001756\n",
      "Epoch 18, batch 3: loss = 0.001858\n",
      "Epoch 18, batch 4: loss = 0.001825\n",
      "Epoch 18, batch 5: loss = 0.001858\n",
      "Epoch 18, batch 6: loss = 0.001843\n",
      "Epoch 18, batch 7: loss = 0.001816\n",
      "Epoch 18, batch 8: loss = 0.001846\n",
      "Epoch 18, batch 9: loss = 0.001803\n",
      "Epoch 18, batch 10: loss = 0.001832\n",
      "Epoch 18, batch 11: loss = 0.001788\n",
      "Epoch 18, batch 12: loss = 0.001854\n",
      "Epoch 18, batch 13: loss = 0.001851\n",
      "Epoch 18, batch 14: loss = 0.001775\n",
      "Epoch 18, batch 15: loss = 0.001929\n",
      "Epoch 18, batch 16: loss = 0.001874\n",
      "Epoch 18, batch 17: loss = 0.001938\n",
      "Epoch 18, batch 18: loss = 0.001844\n",
      "Epoch 18, batch 19: loss = 0.001678\n",
      "Epoch 18, batch 20: loss = 0.001918\n",
      "Epoch 18, batch 21: loss = 0.001903\n",
      "Epoch 18, batch 22: loss = 0.001832\n",
      "Epoch 18, batch 23: loss = 0.001922\n",
      "Epoch 18, batch 24: loss = 0.001964\n",
      "Epoch 18, batch 25: loss = 0.001776\n",
      "Epoch 18, batch 26: loss = 0.001830\n",
      "Epoch 18, batch 27: loss = 0.001767\n",
      "Epoch 18, batch 28: loss = 0.001922\n",
      "Epoch 18, batch 29: loss = 0.001721\n",
      "Epoch 18, batch 30: loss = 0.001783\n",
      "Epoch 18, batch 31: loss = 0.001845\n",
      "Epoch 18, batch 32: loss = 0.001770\n",
      "Epoch 18, batch 33: loss = 0.001753\n",
      "Epoch 18, batch 34: loss = 0.001855\n",
      "Epoch 18, batch 35: loss = 0.001854\n",
      "Epoch 18, batch 36: loss = 0.001788\n",
      "Epoch 18, batch 37: loss = 0.001936\n",
      "Epoch 18, batch 38: loss = 0.001772\n",
      "Epoch 18, batch 39: loss = 0.001814\n",
      "Epoch 18, batch 40: loss = 0.001742\n",
      "Epoch 18, batch 41: loss = 0.001647\n",
      "Epoch 18, batch 42: loss = 0.001792\n",
      "Epoch 18, batch 43: loss = 0.001803\n",
      "Epoch 18, batch 44: loss = 0.001693\n",
      "Epoch 18, batch 45: loss = 0.001776\n",
      "Epoch 18, batch 46: loss = 0.001872\n",
      "Epoch 18, batch 47: loss = 0.001803\n",
      "Epoch 18, batch 48: loss = 0.001829\n",
      "Epoch 18, batch 49: loss = 0.001786\n",
      "Epoch 18, batch 50: loss = 0.001777\n",
      "Epoch 18, batch 51: loss = 0.001724\n",
      "Epoch 18, batch 52: loss = 0.001855\n",
      "Epoch 18, batch 53: loss = 0.001686\n",
      "Epoch 18, batch 54: loss = 0.001847\n",
      "Epoch 18, batch 55: loss = 0.001925\n",
      "Epoch 18, batch 56: loss = 0.001746\n",
      "Epoch 18, batch 57: loss = 0.001805\n",
      "Epoch 18, batch 58: loss = 0.001743\n",
      "Epoch 18, batch 59: loss = 0.001820\n",
      "Epoch 18, batch 60: loss = 0.001841\n",
      "Epoch 18, batch 61: loss = 0.001831\n",
      "Epoch 18, batch 62: loss = 0.001736\n",
      "Epoch 18, batch 63: loss = 0.001773\n",
      "Epoch 18, batch 64: loss = 0.001786\n",
      "Epoch 18, batch 65: loss = 0.001647\n",
      "Epoch 18, batch 66: loss = 0.001749\n",
      "Epoch 18, batch 67: loss = 0.001774\n",
      "Epoch 18, batch 68: loss = 0.001723\n",
      "Epoch 18, batch 69: loss = 0.001831\n",
      "Epoch 18, batch 70: loss = 0.001729\n",
      "Epoch 18, batch 71: loss = 0.001773\n",
      "Epoch 18, batch 72: loss = 0.001703\n",
      "Epoch 18, batch 73: loss = 0.001820\n",
      "Epoch 18, batch 74: loss = 0.001716\n",
      "Epoch 18, batch 75: loss = 0.001802\n",
      "Epoch 18, batch 76: loss = 0.001778\n",
      "Epoch 18, batch 77: loss = 0.001861\n",
      "Epoch 18, batch 78: loss = 0.001912\n",
      "Epoch 18, batch 79: loss = 0.001721\n",
      "Epoch 18, batch 80: loss = 0.001776\n",
      "Epoch 18, batch 81: loss = 0.001760\n",
      "Epoch 18, batch 82: loss = 0.002065\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 18: val_loss = 0.027306\n",
      "Epoch 19, batch 0: loss = 0.001800\n",
      "Epoch 19, batch 1: loss = 0.001835\n",
      "Epoch 19, batch 2: loss = 0.001743\n",
      "Epoch 19, batch 3: loss = 0.001762\n",
      "Epoch 19, batch 4: loss = 0.001826\n",
      "Epoch 19, batch 5: loss = 0.001680\n",
      "Epoch 19, batch 6: loss = 0.001827\n",
      "Epoch 19, batch 7: loss = 0.001904\n",
      "Epoch 19, batch 8: loss = 0.001687\n",
      "Epoch 19, batch 9: loss = 0.001841\n",
      "Epoch 19, batch 10: loss = 0.001808\n",
      "Epoch 19, batch 11: loss = 0.001789\n",
      "Epoch 19, batch 12: loss = 0.001792\n",
      "Epoch 19, batch 13: loss = 0.001866\n",
      "Epoch 19, batch 14: loss = 0.001848\n",
      "Epoch 19, batch 15: loss = 0.001809\n",
      "Epoch 19, batch 16: loss = 0.001686\n",
      "Epoch 19, batch 17: loss = 0.001676\n",
      "Epoch 19, batch 18: loss = 0.001872\n",
      "Epoch 19, batch 19: loss = 0.001785\n",
      "Epoch 19, batch 20: loss = 0.001789\n",
      "Epoch 19, batch 21: loss = 0.001761\n",
      "Epoch 19, batch 22: loss = 0.001775\n",
      "Epoch 19, batch 23: loss = 0.001780\n",
      "Epoch 19, batch 24: loss = 0.001719\n",
      "Epoch 19, batch 25: loss = 0.001798\n",
      "Epoch 19, batch 26: loss = 0.001755\n",
      "Epoch 19, batch 27: loss = 0.001797\n",
      "Epoch 19, batch 28: loss = 0.001889\n",
      "Epoch 19, batch 29: loss = 0.001759\n",
      "Epoch 19, batch 30: loss = 0.001906\n",
      "Epoch 19, batch 31: loss = 0.001751\n",
      "Epoch 19, batch 32: loss = 0.001775\n",
      "Epoch 19, batch 33: loss = 0.001699\n",
      "Epoch 19, batch 34: loss = 0.001781\n",
      "Epoch 19, batch 35: loss = 0.001852\n",
      "Epoch 19, batch 36: loss = 0.001759\n",
      "Epoch 19, batch 37: loss = 0.001802\n",
      "Epoch 19, batch 38: loss = 0.001756\n",
      "Epoch 19, batch 39: loss = 0.001674\n",
      "Epoch 19, batch 40: loss = 0.001749\n",
      "Epoch 19, batch 41: loss = 0.001719\n",
      "Epoch 19, batch 42: loss = 0.001826\n",
      "Epoch 19, batch 43: loss = 0.001831\n",
      "Epoch 19, batch 44: loss = 0.001819\n",
      "Epoch 19, batch 45: loss = 0.001793\n",
      "Epoch 19, batch 46: loss = 0.001823\n",
      "Epoch 19, batch 47: loss = 0.001708\n",
      "Epoch 19, batch 48: loss = 0.001794\n",
      "Epoch 19, batch 49: loss = 0.001832\n",
      "Epoch 19, batch 50: loss = 0.001922\n",
      "Epoch 19, batch 51: loss = 0.001763\n",
      "Epoch 19, batch 52: loss = 0.001777\n",
      "Epoch 19, batch 53: loss = 0.001808\n",
      "Epoch 19, batch 54: loss = 0.001832\n",
      "Epoch 19, batch 55: loss = 0.001747\n",
      "Epoch 19, batch 56: loss = 0.001797\n",
      "Epoch 19, batch 57: loss = 0.001811\n",
      "Epoch 19, batch 58: loss = 0.001785\n",
      "Epoch 19, batch 59: loss = 0.001832\n",
      "Epoch 19, batch 60: loss = 0.001870\n",
      "Epoch 19, batch 61: loss = 0.001717\n",
      "Epoch 19, batch 62: loss = 0.001711\n",
      "Epoch 19, batch 63: loss = 0.001779\n",
      "Epoch 19, batch 64: loss = 0.001798\n",
      "Epoch 19, batch 65: loss = 0.001671\n",
      "Epoch 19, batch 66: loss = 0.001731\n",
      "Epoch 19, batch 67: loss = 0.001749\n",
      "Epoch 19, batch 68: loss = 0.001673\n",
      "Epoch 19, batch 69: loss = 0.001803\n",
      "Epoch 19, batch 70: loss = 0.001703\n",
      "Epoch 19, batch 71: loss = 0.001859\n",
      "Epoch 19, batch 72: loss = 0.001758\n",
      "Epoch 19, batch 73: loss = 0.001831\n",
      "Epoch 19, batch 74: loss = 0.001762\n",
      "Epoch 19, batch 75: loss = 0.001748\n",
      "Epoch 19, batch 76: loss = 0.001804\n",
      "Epoch 19, batch 77: loss = 0.001782\n",
      "Epoch 19, batch 78: loss = 0.001856\n",
      "Epoch 19, batch 79: loss = 0.001723\n",
      "Epoch 19, batch 80: loss = 0.001742\n",
      "Epoch 19, batch 81: loss = 0.001863\n",
      "Epoch 19, batch 82: loss = 0.002571\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 19: val_loss = 0.028130\n",
      "Epoch 20, batch 0: loss = 0.002149\n",
      "Epoch 20, batch 1: loss = 0.002236\n",
      "Epoch 20, batch 2: loss = 0.002057\n",
      "Epoch 20, batch 3: loss = 0.002001\n",
      "Epoch 20, batch 4: loss = 0.002011\n",
      "Epoch 20, batch 5: loss = 0.002034\n",
      "Epoch 20, batch 6: loss = 0.002079\n",
      "Epoch 20, batch 7: loss = 0.001926\n",
      "Epoch 20, batch 8: loss = 0.001826\n",
      "Epoch 20, batch 9: loss = 0.001826\n",
      "Epoch 20, batch 10: loss = 0.002001\n",
      "Epoch 20, batch 11: loss = 0.001830\n",
      "Epoch 20, batch 12: loss = 0.001805\n",
      "Epoch 20, batch 13: loss = 0.001853\n",
      "Epoch 20, batch 14: loss = 0.001837\n",
      "Epoch 20, batch 15: loss = 0.001845\n",
      "Epoch 20, batch 16: loss = 0.001865\n",
      "Epoch 20, batch 17: loss = 0.001886\n",
      "Epoch 20, batch 18: loss = 0.001800\n",
      "Epoch 20, batch 19: loss = 0.001841\n",
      "Epoch 20, batch 20: loss = 0.001855\n",
      "Epoch 20, batch 21: loss = 0.001818\n",
      "Epoch 20, batch 22: loss = 0.001853\n",
      "Epoch 20, batch 23: loss = 0.001728\n",
      "Epoch 20, batch 24: loss = 0.001779\n",
      "Epoch 20, batch 25: loss = 0.001894\n",
      "Epoch 20, batch 26: loss = 0.001820\n",
      "Epoch 20, batch 27: loss = 0.001729\n",
      "Epoch 20, batch 28: loss = 0.001830\n",
      "Epoch 20, batch 29: loss = 0.001887\n",
      "Epoch 20, batch 30: loss = 0.001755\n",
      "Epoch 20, batch 31: loss = 0.001803\n",
      "Epoch 20, batch 32: loss = 0.001688\n",
      "Epoch 20, batch 33: loss = 0.001779\n",
      "Epoch 20, batch 34: loss = 0.001792\n",
      "Epoch 20, batch 35: loss = 0.001746\n",
      "Epoch 20, batch 36: loss = 0.001910\n",
      "Epoch 20, batch 37: loss = 0.001777\n",
      "Epoch 20, batch 38: loss = 0.001877\n",
      "Epoch 20, batch 39: loss = 0.001806\n",
      "Epoch 20, batch 40: loss = 0.001838\n",
      "Epoch 20, batch 41: loss = 0.001807\n",
      "Epoch 20, batch 42: loss = 0.001847\n",
      "Epoch 20, batch 43: loss = 0.001751\n",
      "Epoch 20, batch 44: loss = 0.001820\n",
      "Epoch 20, batch 45: loss = 0.001837\n",
      "Epoch 20, batch 46: loss = 0.001792\n",
      "Epoch 20, batch 47: loss = 0.001845\n",
      "Epoch 20, batch 48: loss = 0.001793\n",
      "Epoch 20, batch 49: loss = 0.001827\n",
      "Epoch 20, batch 50: loss = 0.001830\n",
      "Epoch 20, batch 51: loss = 0.001754\n",
      "Epoch 20, batch 52: loss = 0.001822\n",
      "Epoch 20, batch 53: loss = 0.001718\n",
      "Epoch 20, batch 54: loss = 0.001721\n",
      "Epoch 20, batch 55: loss = 0.001697\n",
      "Epoch 20, batch 56: loss = 0.001761\n",
      "Epoch 20, batch 57: loss = 0.001829\n",
      "Epoch 20, batch 58: loss = 0.001689\n",
      "Epoch 20, batch 59: loss = 0.001731\n",
      "Epoch 20, batch 60: loss = 0.001889\n",
      "Epoch 20, batch 61: loss = 0.001747\n",
      "Epoch 20, batch 62: loss = 0.001718\n",
      "Epoch 20, batch 63: loss = 0.001679\n",
      "Epoch 20, batch 64: loss = 0.001841\n",
      "Epoch 20, batch 65: loss = 0.001885\n",
      "Epoch 20, batch 66: loss = 0.001837\n",
      "Epoch 20, batch 67: loss = 0.001765\n",
      "Epoch 20, batch 68: loss = 0.001821\n",
      "Epoch 20, batch 69: loss = 0.001831\n",
      "Epoch 20, batch 70: loss = 0.001791\n",
      "Epoch 20, batch 71: loss = 0.001666\n",
      "Epoch 20, batch 72: loss = 0.001894\n",
      "Epoch 20, batch 73: loss = 0.001847\n",
      "Epoch 20, batch 74: loss = 0.001804\n",
      "Epoch 20, batch 75: loss = 0.001838\n",
      "Epoch 20, batch 76: loss = 0.001702\n",
      "Epoch 20, batch 77: loss = 0.001787\n",
      "Epoch 20, batch 78: loss = 0.001824\n",
      "Epoch 20, batch 79: loss = 0.001813\n",
      "Epoch 20, batch 80: loss = 0.001727\n",
      "Epoch 20, batch 81: loss = 0.001819\n",
      "Epoch 20, batch 82: loss = 0.001593\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 20: val_loss = 0.026904\n",
      "Epoch 21, batch 0: loss = 0.001828\n",
      "Epoch 21, batch 1: loss = 0.002068\n",
      "Epoch 21, batch 2: loss = 0.001877\n",
      "Epoch 21, batch 3: loss = 0.001936\n",
      "Epoch 21, batch 4: loss = 0.001906\n",
      "Epoch 21, batch 5: loss = 0.001916\n",
      "Epoch 21, batch 6: loss = 0.002053\n",
      "Epoch 21, batch 7: loss = 0.002041\n",
      "Epoch 21, batch 8: loss = 0.001936\n",
      "Epoch 21, batch 9: loss = 0.001869\n",
      "Epoch 21, batch 10: loss = 0.001846\n",
      "Epoch 21, batch 11: loss = 0.001903\n",
      "Epoch 21, batch 12: loss = 0.001848\n",
      "Epoch 21, batch 13: loss = 0.001835\n",
      "Epoch 21, batch 14: loss = 0.001870\n",
      "Epoch 21, batch 15: loss = 0.001865\n",
      "Epoch 21, batch 16: loss = 0.001809\n",
      "Epoch 21, batch 17: loss = 0.001812\n",
      "Epoch 21, batch 18: loss = 0.001808\n",
      "Epoch 21, batch 19: loss = 0.001798\n",
      "Epoch 21, batch 20: loss = 0.001825\n",
      "Epoch 21, batch 21: loss = 0.001806\n",
      "Epoch 21, batch 22: loss = 0.001759\n",
      "Epoch 21, batch 23: loss = 0.001790\n",
      "Epoch 21, batch 24: loss = 0.001832\n",
      "Epoch 21, batch 25: loss = 0.001795\n",
      "Epoch 21, batch 26: loss = 0.001841\n",
      "Epoch 21, batch 27: loss = 0.001743\n",
      "Epoch 21, batch 28: loss = 0.001844\n",
      "Epoch 21, batch 29: loss = 0.001746\n",
      "Epoch 21, batch 30: loss = 0.001848\n",
      "Epoch 21, batch 31: loss = 0.001687\n",
      "Epoch 21, batch 32: loss = 0.001722\n",
      "Epoch 21, batch 33: loss = 0.001682\n",
      "Epoch 21, batch 34: loss = 0.001791\n",
      "Epoch 21, batch 35: loss = 0.001670\n",
      "Epoch 21, batch 36: loss = 0.001736\n",
      "Epoch 21, batch 37: loss = 0.001883\n",
      "Epoch 21, batch 38: loss = 0.001765\n",
      "Epoch 21, batch 39: loss = 0.001691\n",
      "Epoch 21, batch 40: loss = 0.001788\n",
      "Epoch 21, batch 41: loss = 0.001799\n",
      "Epoch 21, batch 42: loss = 0.001729\n",
      "Epoch 21, batch 43: loss = 0.001767\n",
      "Epoch 21, batch 44: loss = 0.001749\n",
      "Epoch 21, batch 45: loss = 0.001778\n",
      "Epoch 21, batch 46: loss = 0.001753\n",
      "Epoch 21, batch 47: loss = 0.001735\n",
      "Epoch 21, batch 48: loss = 0.001670\n",
      "Epoch 21, batch 49: loss = 0.001696\n",
      "Epoch 21, batch 50: loss = 0.001687\n",
      "Epoch 21, batch 51: loss = 0.001886\n",
      "Epoch 21, batch 52: loss = 0.001795\n",
      "Epoch 21, batch 53: loss = 0.001825\n",
      "Epoch 21, batch 54: loss = 0.001722\n",
      "Epoch 21, batch 55: loss = 0.001773\n",
      "Epoch 21, batch 56: loss = 0.001726\n",
      "Epoch 21, batch 57: loss = 0.001724\n",
      "Epoch 21, batch 58: loss = 0.001796\n",
      "Epoch 21, batch 59: loss = 0.001708\n",
      "Epoch 21, batch 60: loss = 0.001591\n",
      "Epoch 21, batch 61: loss = 0.001879\n",
      "Epoch 21, batch 62: loss = 0.001987\n",
      "Epoch 21, batch 63: loss = 0.001878\n",
      "Epoch 21, batch 64: loss = 0.001738\n",
      "Epoch 21, batch 65: loss = 0.001877\n",
      "Epoch 21, batch 66: loss = 0.001733\n",
      "Epoch 21, batch 67: loss = 0.001828\n",
      "Epoch 21, batch 68: loss = 0.001692\n",
      "Epoch 21, batch 69: loss = 0.001730\n",
      "Epoch 21, batch 70: loss = 0.001879\n",
      "Epoch 21, batch 71: loss = 0.001783\n",
      "Epoch 21, batch 72: loss = 0.001808\n",
      "Epoch 21, batch 73: loss = 0.001754\n",
      "Epoch 21, batch 74: loss = 0.001763\n",
      "Epoch 21, batch 75: loss = 0.001701\n",
      "Epoch 21, batch 76: loss = 0.001621\n",
      "Epoch 21, batch 77: loss = 0.001764\n",
      "Epoch 21, batch 78: loss = 0.001902\n",
      "Epoch 21, batch 79: loss = 0.001727\n",
      "Epoch 21, batch 80: loss = 0.001645\n",
      "Epoch 21, batch 81: loss = 0.001750\n",
      "Epoch 21, batch 82: loss = 0.001653\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 21: val_loss = 0.027620\n",
      "Epoch 22, batch 0: loss = 0.001862\n",
      "Epoch 22, batch 1: loss = 0.001884\n",
      "Epoch 22, batch 2: loss = 0.001856\n",
      "Epoch 22, batch 3: loss = 0.001836\n",
      "Epoch 22, batch 4: loss = 0.001805\n",
      "Epoch 22, batch 5: loss = 0.001880\n",
      "Epoch 22, batch 6: loss = 0.001737\n",
      "Epoch 22, batch 7: loss = 0.001840\n",
      "Epoch 22, batch 8: loss = 0.001852\n",
      "Epoch 22, batch 9: loss = 0.001779\n",
      "Epoch 22, batch 10: loss = 0.001861\n",
      "Epoch 22, batch 11: loss = 0.001764\n",
      "Epoch 22, batch 12: loss = 0.001711\n",
      "Epoch 22, batch 13: loss = 0.001909\n",
      "Epoch 22, batch 14: loss = 0.001768\n",
      "Epoch 22, batch 15: loss = 0.001758\n",
      "Epoch 22, batch 16: loss = 0.001737\n",
      "Epoch 22, batch 17: loss = 0.001910\n",
      "Epoch 22, batch 18: loss = 0.001769\n",
      "Epoch 22, batch 19: loss = 0.001778\n",
      "Epoch 22, batch 20: loss = 0.001806\n",
      "Epoch 22, batch 21: loss = 0.001760\n",
      "Epoch 22, batch 22: loss = 0.001797\n",
      "Epoch 22, batch 23: loss = 0.001691\n",
      "Epoch 22, batch 24: loss = 0.001847\n",
      "Epoch 22, batch 25: loss = 0.001878\n",
      "Epoch 22, batch 26: loss = 0.001820\n",
      "Epoch 22, batch 27: loss = 0.001744\n",
      "Epoch 22, batch 28: loss = 0.001746\n",
      "Epoch 22, batch 29: loss = 0.001945\n",
      "Epoch 22, batch 30: loss = 0.001652\n",
      "Epoch 22, batch 31: loss = 0.001776\n",
      "Epoch 22, batch 32: loss = 0.001705\n",
      "Epoch 22, batch 33: loss = 0.001721\n",
      "Epoch 22, batch 34: loss = 0.001868\n",
      "Epoch 22, batch 35: loss = 0.001631\n",
      "Epoch 22, batch 36: loss = 0.001747\n",
      "Epoch 22, batch 37: loss = 0.001831\n",
      "Epoch 22, batch 38: loss = 0.001806\n",
      "Epoch 22, batch 39: loss = 0.001799\n",
      "Epoch 22, batch 40: loss = 0.001715\n",
      "Epoch 22, batch 41: loss = 0.001670\n",
      "Epoch 22, batch 42: loss = 0.001809\n",
      "Epoch 22, batch 43: loss = 0.001743\n",
      "Epoch 22, batch 44: loss = 0.001738\n",
      "Epoch 22, batch 45: loss = 0.001788\n",
      "Epoch 22, batch 46: loss = 0.001784\n",
      "Epoch 22, batch 47: loss = 0.001740\n",
      "Epoch 22, batch 48: loss = 0.001699\n",
      "Epoch 22, batch 49: loss = 0.001866\n",
      "Epoch 22, batch 50: loss = 0.001715\n",
      "Epoch 22, batch 51: loss = 0.001737\n",
      "Epoch 22, batch 52: loss = 0.001656\n",
      "Epoch 22, batch 53: loss = 0.001648\n",
      "Epoch 22, batch 54: loss = 0.001782\n",
      "Epoch 22, batch 55: loss = 0.001890\n",
      "Epoch 22, batch 56: loss = 0.001862\n",
      "Epoch 22, batch 57: loss = 0.001869\n",
      "Epoch 22, batch 58: loss = 0.001815\n",
      "Epoch 22, batch 59: loss = 0.001773\n",
      "Epoch 22, batch 60: loss = 0.001799\n",
      "Epoch 22, batch 61: loss = 0.001711\n",
      "Epoch 22, batch 62: loss = 0.001795\n",
      "Epoch 22, batch 63: loss = 0.001843\n",
      "Epoch 22, batch 64: loss = 0.001681\n",
      "Epoch 22, batch 65: loss = 0.001709\n",
      "Epoch 22, batch 66: loss = 0.001767\n",
      "Epoch 22, batch 67: loss = 0.001652\n",
      "Epoch 22, batch 68: loss = 0.001808\n",
      "Epoch 22, batch 69: loss = 0.001805\n",
      "Epoch 22, batch 70: loss = 0.001819\n",
      "Epoch 22, batch 71: loss = 0.001780\n",
      "Epoch 22, batch 72: loss = 0.001709\n",
      "Epoch 22, batch 73: loss = 0.001677\n",
      "Epoch 22, batch 74: loss = 0.001771\n",
      "Epoch 22, batch 75: loss = 0.001818\n",
      "Epoch 22, batch 76: loss = 0.001710\n",
      "Epoch 22, batch 77: loss = 0.001624\n",
      "Epoch 22, batch 78: loss = 0.001773\n",
      "Epoch 22, batch 79: loss = 0.001813\n",
      "Epoch 22, batch 80: loss = 0.001749\n",
      "Epoch 22, batch 81: loss = 0.001695\n",
      "Epoch 22, batch 82: loss = 0.002044\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 22: val_loss = 0.027159\n",
      "Epoch 23, batch 0: loss = 0.001743\n",
      "Epoch 23, batch 1: loss = 0.001674\n",
      "Epoch 23, batch 2: loss = 0.001719\n",
      "Epoch 23, batch 3: loss = 0.001681\n",
      "Epoch 23, batch 4: loss = 0.001729\n",
      "Epoch 23, batch 5: loss = 0.001765\n",
      "Epoch 23, batch 6: loss = 0.001764\n",
      "Epoch 23, batch 7: loss = 0.001855\n",
      "Epoch 23, batch 8: loss = 0.001768\n",
      "Epoch 23, batch 9: loss = 0.001727\n",
      "Epoch 23, batch 10: loss = 0.001838\n",
      "Epoch 23, batch 11: loss = 0.001657\n",
      "Epoch 23, batch 12: loss = 0.001784\n",
      "Epoch 23, batch 13: loss = 0.001798\n",
      "Epoch 23, batch 14: loss = 0.001726\n",
      "Epoch 23, batch 15: loss = 0.001836\n",
      "Epoch 23, batch 16: loss = 0.001892\n",
      "Epoch 23, batch 17: loss = 0.001762\n",
      "Epoch 23, batch 18: loss = 0.001716\n",
      "Epoch 23, batch 19: loss = 0.001822\n",
      "Epoch 23, batch 20: loss = 0.001880\n",
      "Epoch 23, batch 21: loss = 0.001824\n",
      "Epoch 23, batch 22: loss = 0.001912\n",
      "Epoch 23, batch 23: loss = 0.001763\n",
      "Epoch 23, batch 24: loss = 0.001743\n",
      "Epoch 23, batch 25: loss = 0.001765\n",
      "Epoch 23, batch 26: loss = 0.001779\n",
      "Epoch 23, batch 27: loss = 0.001715\n",
      "Epoch 23, batch 28: loss = 0.001652\n",
      "Epoch 23, batch 29: loss = 0.001773\n",
      "Epoch 23, batch 30: loss = 0.001838\n",
      "Epoch 23, batch 31: loss = 0.001862\n",
      "Epoch 23, batch 32: loss = 0.001685\n",
      "Epoch 23, batch 33: loss = 0.001711\n",
      "Epoch 23, batch 34: loss = 0.001908\n",
      "Epoch 23, batch 35: loss = 0.001818\n",
      "Epoch 23, batch 36: loss = 0.001776\n",
      "Epoch 23, batch 37: loss = 0.001669\n",
      "Epoch 23, batch 38: loss = 0.001754\n",
      "Epoch 23, batch 39: loss = 0.001716\n",
      "Epoch 23, batch 40: loss = 0.001742\n",
      "Epoch 23, batch 41: loss = 0.001814\n",
      "Epoch 23, batch 42: loss = 0.001818\n",
      "Epoch 23, batch 43: loss = 0.001896\n",
      "Epoch 23, batch 44: loss = 0.001813\n",
      "Epoch 23, batch 45: loss = 0.001807\n",
      "Epoch 23, batch 46: loss = 0.001711\n",
      "Epoch 23, batch 47: loss = 0.001718\n",
      "Epoch 23, batch 48: loss = 0.001797\n",
      "Epoch 23, batch 49: loss = 0.001686\n",
      "Epoch 23, batch 50: loss = 0.001717\n",
      "Epoch 23, batch 51: loss = 0.001764\n",
      "Epoch 23, batch 52: loss = 0.001822\n",
      "Epoch 23, batch 53: loss = 0.001752\n",
      "Epoch 23, batch 54: loss = 0.001832\n",
      "Epoch 23, batch 55: loss = 0.001809\n",
      "Epoch 23, batch 56: loss = 0.001735\n",
      "Epoch 23, batch 57: loss = 0.001773\n",
      "Epoch 23, batch 58: loss = 0.001697\n",
      "Epoch 23, batch 59: loss = 0.001792\n",
      "Epoch 23, batch 60: loss = 0.001853\n",
      "Epoch 23, batch 61: loss = 0.001708\n",
      "Epoch 23, batch 62: loss = 0.001758\n",
      "Epoch 23, batch 63: loss = 0.001736\n",
      "Epoch 23, batch 64: loss = 0.001799\n",
      "Epoch 23, batch 65: loss = 0.001758\n",
      "Epoch 23, batch 66: loss = 0.001803\n",
      "Epoch 23, batch 67: loss = 0.001782\n",
      "Epoch 23, batch 68: loss = 0.001666\n",
      "Epoch 23, batch 69: loss = 0.001861\n",
      "Epoch 23, batch 70: loss = 0.001886\n",
      "Epoch 23, batch 71: loss = 0.001712\n",
      "Epoch 23, batch 72: loss = 0.001716\n",
      "Epoch 23, batch 73: loss = 0.001713\n",
      "Epoch 23, batch 74: loss = 0.001682\n",
      "Epoch 23, batch 75: loss = 0.001985\n",
      "Epoch 23, batch 76: loss = 0.001795\n",
      "Epoch 23, batch 77: loss = 0.001692\n",
      "Epoch 23, batch 78: loss = 0.001801\n",
      "Epoch 23, batch 79: loss = 0.001744\n",
      "Epoch 23, batch 80: loss = 0.001723\n",
      "Epoch 23, batch 81: loss = 0.001694\n",
      "Epoch 23, batch 82: loss = 0.001334\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 23: val_loss = 0.027368\n",
      "Epoch 24, batch 0: loss = 0.001820\n",
      "Epoch 24, batch 1: loss = 0.001707\n",
      "Epoch 24, batch 2: loss = 0.001763\n",
      "Epoch 24, batch 3: loss = 0.001799\n",
      "Epoch 24, batch 4: loss = 0.001786\n",
      "Epoch 24, batch 5: loss = 0.001843\n",
      "Epoch 24, batch 6: loss = 0.001699\n",
      "Epoch 24, batch 7: loss = 0.001795\n",
      "Epoch 24, batch 8: loss = 0.001811\n",
      "Epoch 24, batch 9: loss = 0.001750\n",
      "Epoch 24, batch 10: loss = 0.001908\n",
      "Epoch 24, batch 11: loss = 0.001784\n",
      "Epoch 24, batch 12: loss = 0.001766\n",
      "Epoch 24, batch 13: loss = 0.001636\n",
      "Epoch 24, batch 14: loss = 0.001737\n",
      "Epoch 24, batch 15: loss = 0.001813\n",
      "Epoch 24, batch 16: loss = 0.001676\n",
      "Epoch 24, batch 17: loss = 0.001833\n",
      "Epoch 24, batch 18: loss = 0.001805\n",
      "Epoch 24, batch 19: loss = 0.001677\n",
      "Epoch 24, batch 20: loss = 0.001714\n",
      "Epoch 24, batch 21: loss = 0.001858\n",
      "Epoch 24, batch 22: loss = 0.001825\n",
      "Epoch 24, batch 23: loss = 0.001805\n",
      "Epoch 24, batch 24: loss = 0.001797\n",
      "Epoch 24, batch 25: loss = 0.001770\n",
      "Epoch 24, batch 26: loss = 0.001791\n",
      "Epoch 24, batch 27: loss = 0.001760\n",
      "Epoch 24, batch 28: loss = 0.001810\n",
      "Epoch 24, batch 29: loss = 0.001719\n",
      "Epoch 24, batch 30: loss = 0.001810\n",
      "Epoch 24, batch 31: loss = 0.001828\n",
      "Epoch 24, batch 32: loss = 0.001794\n",
      "Epoch 24, batch 33: loss = 0.001827\n",
      "Epoch 24, batch 34: loss = 0.001756\n",
      "Epoch 24, batch 35: loss = 0.001752\n",
      "Epoch 24, batch 36: loss = 0.001725\n",
      "Epoch 24, batch 37: loss = 0.001823\n",
      "Epoch 24, batch 38: loss = 0.001647\n",
      "Epoch 24, batch 39: loss = 0.001687\n",
      "Epoch 24, batch 40: loss = 0.001767\n",
      "Epoch 24, batch 41: loss = 0.001695\n",
      "Epoch 24, batch 42: loss = 0.001800\n",
      "Epoch 24, batch 43: loss = 0.001738\n",
      "Epoch 24, batch 44: loss = 0.001647\n",
      "Epoch 24, batch 45: loss = 0.001843\n",
      "Epoch 24, batch 46: loss = 0.001709\n",
      "Epoch 24, batch 47: loss = 0.001736\n",
      "Epoch 24, batch 48: loss = 0.001836\n",
      "Epoch 24, batch 49: loss = 0.001650\n",
      "Epoch 24, batch 50: loss = 0.001823\n",
      "Epoch 24, batch 51: loss = 0.001721\n",
      "Epoch 24, batch 52: loss = 0.001764\n",
      "Epoch 24, batch 53: loss = 0.001671\n",
      "Epoch 24, batch 54: loss = 0.001730\n",
      "Epoch 24, batch 55: loss = 0.001585\n",
      "Epoch 24, batch 56: loss = 0.001712\n",
      "Epoch 24, batch 57: loss = 0.001837\n",
      "Epoch 24, batch 58: loss = 0.001702\n",
      "Epoch 24, batch 59: loss = 0.001783\n",
      "Epoch 24, batch 60: loss = 0.001897\n",
      "Epoch 24, batch 61: loss = 0.001780\n",
      "Epoch 24, batch 62: loss = 0.001660\n",
      "Epoch 24, batch 63: loss = 0.001684\n",
      "Epoch 24, batch 64: loss = 0.001767\n",
      "Epoch 24, batch 65: loss = 0.001745\n",
      "Epoch 24, batch 66: loss = 0.001794\n",
      "Epoch 24, batch 67: loss = 0.001807\n",
      "Epoch 24, batch 68: loss = 0.001769\n",
      "Epoch 24, batch 69: loss = 0.001840\n",
      "Epoch 24, batch 70: loss = 0.001851\n",
      "Epoch 24, batch 71: loss = 0.001881\n",
      "Epoch 24, batch 72: loss = 0.001725\n",
      "Epoch 24, batch 73: loss = 0.001684\n",
      "Epoch 24, batch 74: loss = 0.001773\n",
      "Epoch 24, batch 75: loss = 0.001736\n",
      "Epoch 24, batch 76: loss = 0.001822\n",
      "Epoch 24, batch 77: loss = 0.001668\n",
      "Epoch 24, batch 78: loss = 0.001835\n",
      "Epoch 24, batch 79: loss = 0.001738\n",
      "Epoch 24, batch 80: loss = 0.001732\n",
      "Epoch 24, batch 81: loss = 0.001685\n",
      "Epoch 24, batch 82: loss = 0.001633\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 24: val_loss = 0.027203\n",
      "Epoch 25, batch 0: loss = 0.001813\n",
      "Epoch 25, batch 1: loss = 0.001709\n",
      "Epoch 25, batch 2: loss = 0.001792\n",
      "Epoch 25, batch 3: loss = 0.001772\n",
      "Epoch 25, batch 4: loss = 0.001772\n",
      "Epoch 25, batch 5: loss = 0.001688\n",
      "Epoch 25, batch 6: loss = 0.001866\n",
      "Epoch 25, batch 7: loss = 0.001739\n",
      "Epoch 25, batch 8: loss = 0.001763\n",
      "Epoch 25, batch 9: loss = 0.001747\n",
      "Epoch 25, batch 10: loss = 0.001684\n",
      "Epoch 25, batch 11: loss = 0.001648\n",
      "Epoch 25, batch 12: loss = 0.001805\n",
      "Epoch 25, batch 13: loss = 0.001734\n",
      "Epoch 25, batch 14: loss = 0.001731\n",
      "Epoch 25, batch 15: loss = 0.001792\n",
      "Epoch 25, batch 16: loss = 0.001703\n",
      "Epoch 25, batch 17: loss = 0.001782\n",
      "Epoch 25, batch 18: loss = 0.001771\n",
      "Epoch 25, batch 19: loss = 0.001658\n",
      "Epoch 25, batch 20: loss = 0.001685\n",
      "Epoch 25, batch 21: loss = 0.001710\n",
      "Epoch 25, batch 22: loss = 0.001771\n",
      "Epoch 25, batch 23: loss = 0.001749\n",
      "Epoch 25, batch 24: loss = 0.001808\n",
      "Epoch 25, batch 25: loss = 0.001837\n",
      "Epoch 25, batch 26: loss = 0.001710\n",
      "Epoch 25, batch 27: loss = 0.001724\n",
      "Epoch 25, batch 28: loss = 0.001775\n",
      "Epoch 25, batch 29: loss = 0.001827\n",
      "Epoch 25, batch 30: loss = 0.001770\n",
      "Epoch 25, batch 31: loss = 0.001669\n",
      "Epoch 25, batch 32: loss = 0.001803\n",
      "Epoch 25, batch 33: loss = 0.001711\n",
      "Epoch 25, batch 34: loss = 0.001684\n",
      "Epoch 25, batch 35: loss = 0.001768\n",
      "Epoch 25, batch 36: loss = 0.001710\n",
      "Epoch 25, batch 37: loss = 0.001791\n",
      "Epoch 25, batch 38: loss = 0.001768\n",
      "Epoch 25, batch 39: loss = 0.001706\n",
      "Epoch 25, batch 40: loss = 0.001809\n",
      "Epoch 25, batch 41: loss = 0.001812\n",
      "Epoch 25, batch 42: loss = 0.001757\n",
      "Epoch 25, batch 43: loss = 0.001680\n",
      "Epoch 25, batch 44: loss = 0.001794\n",
      "Epoch 25, batch 45: loss = 0.001661\n",
      "Epoch 25, batch 46: loss = 0.001751\n",
      "Epoch 25, batch 47: loss = 0.001665\n",
      "Epoch 25, batch 48: loss = 0.001839\n",
      "Epoch 25, batch 49: loss = 0.001921\n",
      "Epoch 25, batch 50: loss = 0.001741\n",
      "Epoch 25, batch 51: loss = 0.001642\n",
      "Epoch 25, batch 52: loss = 0.001766\n",
      "Epoch 25, batch 53: loss = 0.001817\n",
      "Epoch 25, batch 54: loss = 0.001670\n",
      "Epoch 25, batch 55: loss = 0.001834\n",
      "Epoch 25, batch 56: loss = 0.001768\n",
      "Epoch 25, batch 57: loss = 0.001838\n",
      "Epoch 25, batch 58: loss = 0.001785\n",
      "Epoch 25, batch 59: loss = 0.001684\n",
      "Epoch 25, batch 60: loss = 0.001713\n",
      "Epoch 25, batch 61: loss = 0.001833\n",
      "Epoch 25, batch 62: loss = 0.001732\n",
      "Epoch 25, batch 63: loss = 0.001711\n",
      "Epoch 25, batch 64: loss = 0.001877\n",
      "Epoch 25, batch 65: loss = 0.001765\n",
      "Epoch 25, batch 66: loss = 0.001772\n",
      "Epoch 25, batch 67: loss = 0.001689\n",
      "Epoch 25, batch 68: loss = 0.001760\n",
      "Epoch 25, batch 69: loss = 0.001684\n",
      "Epoch 25, batch 70: loss = 0.001802\n",
      "Epoch 25, batch 71: loss = 0.001803\n",
      "Epoch 25, batch 72: loss = 0.001833\n",
      "Epoch 25, batch 73: loss = 0.001714\n",
      "Epoch 25, batch 74: loss = 0.001873\n",
      "Epoch 25, batch 75: loss = 0.001641\n",
      "Epoch 25, batch 76: loss = 0.001694\n",
      "Epoch 25, batch 77: loss = 0.001648\n",
      "Epoch 25, batch 78: loss = 0.001663\n",
      "Epoch 25, batch 79: loss = 0.001634\n",
      "Epoch 25, batch 80: loss = 0.001664\n",
      "Epoch 25, batch 81: loss = 0.001728\n",
      "Epoch 25, batch 82: loss = 0.001297\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 102])\n",
      "outputs.shape: torch.Size([5, 6706, 102])\n",
      "Epoch 25: val_loss = 0.027426\n",
      "Epoch 26, batch 0: loss = 0.001744\n",
      "Epoch 26, batch 1: loss = 0.001738\n",
      "Epoch 26, batch 2: loss = 0.001784\n",
      "Epoch 26, batch 3: loss = 0.001752\n",
      "Epoch 26, batch 4: loss = 0.001776\n",
      "Epoch 26, batch 5: loss = 0.001762\n",
      "Epoch 26, batch 6: loss = 0.001881\n",
      "Epoch 26, batch 7: loss = 0.001754\n",
      "Epoch 26, batch 8: loss = 0.001776\n",
      "Epoch 26, batch 9: loss = 0.001701\n",
      "Epoch 26, batch 10: loss = 0.001739\n",
      "Epoch 26, batch 11: loss = 0.001837\n",
      "Epoch 26, batch 12: loss = 0.001818\n",
      "Epoch 26, batch 13: loss = 0.001791\n",
      "Epoch 26, batch 14: loss = 0.001779\n",
      "Epoch 26, batch 15: loss = 0.001805\n",
      "Epoch 26, batch 16: loss = 0.001622\n",
      "Epoch 26, batch 17: loss = 0.001792\n",
      "Epoch 26, batch 18: loss = 0.001682\n",
      "Epoch 26, batch 19: loss = 0.001631\n",
      "Epoch 26, batch 20: loss = 0.001697\n",
      "Epoch 26, batch 21: loss = 0.001682\n",
      "Epoch 26, batch 22: loss = 0.001768\n",
      "Epoch 26, batch 23: loss = 0.001655\n",
      "Epoch 26, batch 24: loss = 0.001730\n",
      "Epoch 26, batch 25: loss = 0.001706\n",
      "Epoch 26, batch 26: loss = 0.001749\n",
      "Epoch 26, batch 27: loss = 0.001710\n",
      "Epoch 26, batch 28: loss = 0.001765\n",
      "Epoch 26, batch 29: loss = 0.001699\n",
      "Epoch 26, batch 30: loss = 0.001813\n",
      "Epoch 26, batch 31: loss = 0.001717\n",
      "Epoch 26, batch 32: loss = 0.001733\n",
      "Epoch 26, batch 33: loss = 0.001716\n",
      "Epoch 26, batch 34: loss = 0.001679\n",
      "Epoch 26, batch 35: loss = 0.001738\n",
      "Epoch 26, batch 36: loss = 0.001834\n",
      "Epoch 26, batch 37: loss = 0.001891\n",
      "Epoch 26, batch 38: loss = 0.001802\n",
      "Epoch 26, batch 39: loss = 0.001716\n",
      "Epoch 26, batch 40: loss = 0.001716\n",
      "Epoch 26, batch 41: loss = 0.001854\n",
      "Epoch 26, batch 42: loss = 0.001712\n",
      "Epoch 26, batch 43: loss = 0.001658\n",
      "Epoch 26, batch 44: loss = 0.001766\n",
      "Epoch 26, batch 45: loss = 0.001715\n",
      "Epoch 26, batch 46: loss = 0.001762\n",
      "Epoch 26, batch 47: loss = 0.001736\n",
      "Epoch 26, batch 48: loss = 0.001776\n",
      "Epoch 26, batch 49: loss = 0.001831\n",
      "Epoch 26, batch 50: loss = 0.001790\n",
      "Epoch 26, batch 51: loss = 0.001745\n",
      "Epoch 26, batch 52: loss = 0.001854\n",
      "Epoch 26, batch 53: loss = 0.001839\n",
      "Epoch 26, batch 54: loss = 0.001705\n",
      "Epoch 26, batch 55: loss = 0.001723\n",
      "Epoch 26, batch 56: loss = 0.001796\n",
      "Epoch 26, batch 57: loss = 0.001758\n",
      "Epoch 26, batch 58: loss = 0.001828\n",
      "Epoch 26, batch 59: loss = 0.001767\n",
      "Epoch 26, batch 60: loss = 0.001775\n",
      "Epoch 26, batch 61: loss = 0.001768\n",
      "Epoch 26, batch 62: loss = 0.001655\n",
      "Epoch 26, batch 63: loss = 0.001772\n",
      "Epoch 26, batch 64: loss = 0.001748\n",
      "Epoch 26, batch 65: loss = 0.001771\n",
      "Epoch 26, batch 66: loss = 0.001777\n",
      "Epoch 26, batch 67: loss = 0.001693\n",
      "Epoch 26, batch 68: loss = 0.001634\n",
      "Epoch 26, batch 69: loss = 0.001667\n",
      "Epoch 26, batch 70: loss = 0.001816\n",
      "Epoch 26, batch 71: loss = 0.001709\n",
      "Epoch 26, batch 72: loss = 0.001757\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # previous_output = torch.zeros(1, 512, 102).to(device)\n",
    "    losses = []\n",
    "    for i, (midi_batch, motion_batch) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        \n",
    "        midi_batch = midi_batch.to(device).float()\n",
    "        motion_batch = motion_batch.to(device).float()\n",
    "        # print(\"midi_batch\", midi_batch.shape)\n",
    "        # print(\"motion_batch\", motion_batch.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(midi_batch) #midi_batch\n",
    "        # print(\"output.shape\", output.shape)\n",
    "\n",
    "        # motion_ground_truth_padding = F.pad(motion_batch, (0,0,0,1), value = 1) #<eot>\n",
    "        \n",
    "        # loss =  F.mse_loss(output, motion_ground_truth_padding)\n",
    "        loss =  F.mse_loss(output, motion_batch)\n",
    "        # loss = customized_mse_loss(output, motion_ground_truth_padding, previous_output, midi_batch)\n",
    "        # loss = customized_mse_loss(output, motion_batch, previous_output, midi_batch)\n",
    "\n",
    "        # losses 累計lose\n",
    "        losses.append(loss.cpu().item())\n",
    "        all_loss_list.append(loss.cpu().item())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "\n",
    "        print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\")\n",
    "\n",
    "        # scheduler.step(1)\n",
    "        # previous_output = output\n",
    "\n",
    "        loc_dt = datetime.datetime.today()\n",
    "        loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    val_loss = evaluate_lstm(model, val_dataloader) #CUDA out of memory\n",
    "    val_loss_per_epoch_list.append(val_loss)\n",
    "    print(f\"Epoch {epoch}: val_loss = {val_loss:.6f}\")\n",
    "    # save_best_model(\n",
    "    #         val_loss, epoch, model, optimizer, loss, loc_dt_format, mean_loss\n",
    "    #     )\n",
    "    avg_loss_list.append(mean_loss)\n",
    "    loc_dt = datetime.datetime.today()\n",
    "    loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if (epoch+1)%100 == 0:\n",
    "        torch.save({\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),\n",
    "            'loss':loss\n",
    "        }, \"./model_save/[100epoch]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-03_18-26-56\n",
      "[0.012661974706687033, 0.0015919805918820202, 0.0014384243646636606, 0.0013333117822185159, 0.0012704872731119394, 0.0011976969931274653, 0.0011586979227140547, 0.001138485220260918, 0.0011270876505877824, 0.0011238000295124948, 0.0011117435079067946, 0.0010819684315938503, 0.001058813000563532, 0.0010297775475773961, 0.0009794084406457842, 0.0009079097653739154, 0.0008526342385448515, 0.0007832597584929317, 0.000732838009018451, 0.0006872653043828905, 0.0006302889150101691, 0.0005898956164019182, 0.0005345656567951664, 0.000579691807506606, 0.00048752442689146844, 0.0004499564801808447, 0.00040553833055309953, 0.0003762234018649906, 0.00035402149125002324, 0.0003553281488129869, 0.0003112580869928934, 0.00028985252685379237, 0.0002757128956145607, 0.0002683243575738743, 0.00024743842921452595, 0.00022837740532122552, 0.00022319893247913568, 0.0002167039849446155, 0.0002062338836840354, 0.00020026504999259487, 0.00019286284013651312, 0.00018520980811445042, 0.00018459197477204724, 0.00017483300919411704, 0.00017162226067739538, 0.00016577502811560406, 0.0001619970456522424, 0.00015810226980829612, 0.00015702174222678876, 0.00015897555131232365, 0.0001464668858970981, 0.0001453422297781799, 0.00014552953423117287, 0.0001434095029544551, 0.00013659069439745508, 0.0001757882657693699, 0.00014881392175448128, 0.0001337678575073369, 0.00013059409000561572, 0.00012390351117937825, 0.00013156076250015757, 0.0001314422549912706, 0.00012620931398123504, 0.0001231282667722553, 0.000125286799215246, 0.0001258379378123209, 0.00011680467150290497, 0.00011807058184058405, 0.00012162407097639516, 0.00011868644040077925, 0.00011827895638998597, 0.00012330173855298199, 0.00011505708305048757, 0.00011160525915329344, 0.00010760666627902537, 0.00011031975701916963, 0.00010359732457436621, 0.00010305485100252553, 0.00010787486168555916, 0.00010533604220836423, 0.00010786374186864123, 0.00010342593607492744, 0.00010591485597251448, 0.00010647587312269025, 0.00010575387913559097, 0.00010713840957032517, 0.00011195376596879214, 9.979358882992529e-05, 0.00010083647110150196, 0.00010059906402602792, 9.776547334331554e-05, 9.8182704357896e-05, 9.939358760311734e-05, 9.609818214084954e-05, 0.00010249161611136515, 9.967759446590207e-05, 9.284731379011646e-05, 0.00010043825465254485, 9.015087754232809e-05, 9.463727392721921e-05]\n"
     ]
    }
   ],
   "source": [
    "print(loc_dt_format)\n",
    "print(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d43dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_lambda(epoch):\n",
    "#     # LR to be 0.1 * (1/1+0.01*epoch)\n",
    "#     base_lr = 0.1\n",
    "#     factor = 0.01\n",
    "#     return base_lr/(1+factor*epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5982f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_loss_list))\n",
    "avg_loss_list_dataframe = pd.DataFrame(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.012662\n",
       "1   0.001592\n",
       "2   0.001438\n",
       "3   0.001333\n",
       "4   0.001270\n",
       "..       ...\n",
       "95  0.000100\n",
       "96  0.000093\n",
       "97  0.000100\n",
       "98  0.000090\n",
       "99  0.000095\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(avg_loss_list_dataframe.index), np.array(avg_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_dataframe = pd.DataFrame(all_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list_dataframe.index), np.array(loss_list_dataframe[0]))\n",
    "plt.savefig(\"training_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, target, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        print(target.shape)\n",
    "        target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        # TODO: target should be <sos>, should not random\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f49577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, specific_fps):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    piano_roll = midi_data.get_piano_roll(fs=specific_fps)  # 40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_name: ./BWV1001/vs1-1ada.mid\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.mid\n",
      "(8171, 128)\n",
      "str_name: ./BWV1001/vs1-2fug.mid\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.mid\n",
      "(11537, 128)\n",
      "str_name: ./BWV1001/vs1-3sic.mid\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.mid\n",
      "(6993, 128)\n",
      "str_name: ./BWV1001/vs1-4prs.mid\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.mid\n",
      "(7897, 128)\n"
     ]
    }
   ],
   "source": [
    "test_datapath = \"./BWV1001/\"\n",
    "change_fps = 40\n",
    "test_midi_path_list = glob.glob(test_datapath + \"*.mid\")\n",
    "test_data_list = []\n",
    "test_music_list = []\n",
    "for test_midi in test_midi_path_list:\n",
    "    str_name = test_midi\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_midi)\n",
    "    read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_piano_roll_transpose = read_piano_roll.T\n",
    "    print(read_piano_roll_transpose.shape)\n",
    "    test_midi_len = read_piano_roll_transpose.shape[0]\n",
    "    test_data_list.append(read_piano_roll_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8171, 102])\n",
      "test_input (1, 8171, 128)\n",
      "test_target torch.Size([1, 8171, 102])\n",
      "torch.Size([1, 8171, 102])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.05740781  0.12252665  1.09301207]\n",
      "  [-0.00336951  0.08391601  1.10333154]\n",
      "  [ 0.10889702  0.06092275  1.10886035]\n",
      "  ...\n",
      "  [ 0.02839183  0.08412046  0.96484718]\n",
      "  [-0.18195246  0.02322661  1.09274397]\n",
      "  [ 0.10795274  0.23367205  0.80819092]]\n",
      "\n",
      " [[ 0.05568753  0.12799329  1.09553376]\n",
      "  [-0.00352431  0.09023183  1.1088855 ]\n",
      "  [ 0.10918399  0.06575996  1.11284707]\n",
      "  ...\n",
      "  [ 0.01981038  0.08547838  0.96769533]\n",
      "  [-0.17028056  0.07761087  1.10112665]\n",
      "  [ 0.0942099   0.19009569  0.79278479]]\n",
      "\n",
      " [[ 0.06520741  0.12985748  1.1017457 ]\n",
      "  [ 0.00260067  0.09447531  1.11584971]\n",
      "  [ 0.1144044   0.06379886  1.11971531]\n",
      "  ...\n",
      "  [ 0.02463806  0.08471523  0.97462485]\n",
      "  [-0.16447534  0.09507114  1.13074396]\n",
      "  [ 0.08869245  0.16840369  0.79464409]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.01725622  0.09704666  1.10023091]\n",
      "  [-0.04298529  0.05736584  1.10204468]\n",
      "  [ 0.06647322  0.03371117  1.10769663]\n",
      "  ...\n",
      "  [-0.01686242  0.08000688  0.9665204 ]\n",
      "  [-0.12771292  0.09392194  1.05584404]\n",
      "  [ 0.08818014  0.23246692  0.71768603]]\n",
      "\n",
      " [[ 0.01965927  0.09826495  1.09991316]\n",
      "  [-0.04072678  0.05894741  1.10277758]\n",
      "  [ 0.06885444  0.03452569  1.10666308]\n",
      "  ...\n",
      "  [-0.01550836  0.0811744   0.9670336 ]\n",
      "  [-0.12571491  0.09624803  1.05462   ]\n",
      "  [ 0.09410334  0.23303771  0.71533797]]\n",
      "\n",
      " [[ 0.02152885  0.09957315  1.09956495]\n",
      "  [-0.03884276  0.06044939  1.10345206]\n",
      "  [ 0.07087261  0.03562101  1.10553584]\n",
      "  ...\n",
      "  [-0.01445906  0.08246925  0.9674401 ]\n",
      "  [-0.12446431  0.09823157  1.05338845]\n",
      "  [ 0.09920631  0.23360902  0.71342496]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-1ada.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-1ada.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 189 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 185 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-1ada.wav':\n",
      "  Duration: 00:03:24.29, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55876a29d680] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55876a29d680] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55876a29d680] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-1ada_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=467 q=-1.0 Lsize=    3682kB time=00:03:24.31 bitrate= 147.6kbits/s speed= 119x    \n",
      "video:428kB audio:3202kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.429355%\n",
      "[aac @ 0x55876a29bfc0] Qavg: 182.785\n",
      "[libx264 @ 0x55876a29d680] frame I:4     Avg QP:16.21  size: 13867\n",
      "[libx264 @ 0x55876a29d680] frame P:259   Avg QP:22.71  size:  1116\n",
      "[libx264 @ 0x55876a29d680] frame B:537   Avg QP:25.21  size:   172\n",
      "[libx264 @ 0x55876a29d680] consecutive B-frames:  6.9%  8.8%  6.4% 78.0%\n",
      "[libx264 @ 0x55876a29d680] mb I  I16..4: 27.9% 47.4% 24.7%\n",
      "[libx264 @ 0x55876a29d680] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.2%  1.5%  1.6%  0.0%  0.0%    skip:95.6%\n",
      "[libx264 @ 0x55876a29d680] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.3%  0.8%  0.3%  direct: 0.2%  skip:97.4%  L0:37.1% L1:40.2% BI:22.7%\n",
      "[libx264 @ 0x55876a29d680] 8x8 transform intra:46.1% inter:23.6%\n",
      "[libx264 @ 0x55876a29d680] coded y,uvDC,uvAC intra: 19.3% 2.3% 1.9% inter: 0.9% 0.3% 0.3%\n",
      "[libx264 @ 0x55876a29d680] i16 v,h,dc,p: 81%  6% 13%  0%\n",
      "[libx264 @ 0x55876a29d680] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 46%  7% 47%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55876a29d680] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 31%  7%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55876a29d680] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55876a29d680] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55876a29d680] ref P L0: 73.5% 10.4% 10.0%  6.0%\n",
      "[libx264 @ 0x55876a29d680] ref B L0: 88.7%  8.9%  2.3%\n",
      "[libx264 @ 0x55876a29d680] ref B L1: 96.4%  3.6%\n",
      "[libx264 @ 0x55876a29d680] kb/s:174.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11537, 102])\n",
      "test_input (1, 11537, 128)\n",
      "test_target torch.Size([1, 11537, 102])\n",
      "torch.Size([1, 11537, 102])\n",
      "prediction.shape (1, 11537, 102)\n",
      "full_prediction (11537, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.06467536  0.10673109  1.09656641]\n",
      "  [ 0.00163651  0.07068096  1.1055021 ]\n",
      "  [ 0.11068165  0.04036274  1.1045625 ]\n",
      "  ...\n",
      "  [ 0.0221958   0.08207126  0.96945701]\n",
      "  [-0.07814814  0.13186203  1.05675749]\n",
      "  [ 0.11006315  0.18551746  0.74382213]]\n",
      "\n",
      " [[ 0.06741332  0.11065972  1.09911749]\n",
      "  [ 0.00214326  0.07620329  1.10832176]\n",
      "  [ 0.11072119  0.04275665  1.10967181]\n",
      "  ...\n",
      "  [ 0.0236317   0.08563796  0.96953437]\n",
      "  [-0.06930181  0.1506252   1.0649815 ]\n",
      "  [ 0.09807658  0.17473368  0.74530432]]\n",
      "\n",
      " [[ 0.07305779  0.11235394  1.09792349]\n",
      "  [ 0.00817756  0.07900236  1.1080961 ]\n",
      "  [ 0.11698719  0.04433096  1.10995541]\n",
      "  ...\n",
      "  [ 0.02728619  0.08764904  0.96850756]\n",
      "  [-0.05600654  0.16742449  1.066223  ]\n",
      "  [ 0.0952201   0.16176958  0.74373064]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.1538322   0.06491812  1.09920815]\n",
      "  [ 0.09285247  0.02422953  1.11795864]\n",
      "  [ 0.20716894 -0.00136578  1.0963814 ]\n",
      "  ...\n",
      "  [ 0.1104984   0.04297322  0.97674928]\n",
      "  [ 0.02904133  0.0763223   1.0146049 ]\n",
      "  [ 0.30259007  0.16382003  0.68039939]]\n",
      "\n",
      " [[ 0.15232073  0.0679962   1.09901557]\n",
      "  [ 0.0915432   0.02705786  1.11847291]\n",
      "  [ 0.20596568  0.00185137  1.09659586]\n",
      "  ...\n",
      "  [ 0.10869471  0.0446469   0.97768155]\n",
      "  [ 0.02767431  0.08162649  1.01748661]\n",
      "  [ 0.2976687   0.1568837   0.67441974]]\n",
      "\n",
      " [[ 0.14832464  0.07109702  1.0986521 ]\n",
      "  [ 0.08754765  0.0300928   1.11803434]\n",
      "  [ 0.20194055  0.00500686  1.09686867]\n",
      "  ...\n",
      "  [ 0.10476506  0.04686484  0.97790561]\n",
      "  [ 0.0225343   0.08605666  1.02030036]\n",
      "  [ 0.28887719  0.15233451  0.67120395]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-2fug.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-2fug.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 217 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 213 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-2fug.wav':\n",
      "  Duration: 00:04:48.34, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x556b689ba4c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x556b689ba4c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x556b689ba4c0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-2fug_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=354 q=-1.0 Lsize=    5076kB time=00:04:48.34 bitrate= 144.2kbits/s speed= 127x    \n",
      "video:492kB audio:4518kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.323093%\n",
      "[aac @ 0x556b689b8d80] Qavg: 260.041\n",
      "[libx264 @ 0x556b689ba4c0] frame I:4     Avg QP:16.19  size: 13702\n",
      "[libx264 @ 0x556b689ba4c0] frame P:239   Avg QP:22.74  size:  1329\n",
      "[libx264 @ 0x556b689ba4c0] frame B:557   Avg QP:27.76  size:   235\n",
      "[libx264 @ 0x556b689ba4c0] consecutive B-frames:  2.8% 11.8%  4.5% 81.0%\n",
      "[libx264 @ 0x556b689ba4c0] mb I  I16..4: 28.4% 47.1% 24.5%\n",
      "[libx264 @ 0x556b689ba4c0] mb P  I16..4:  0.0%  0.0%  0.1%  P16..4:  1.1%  1.8%  1.9%  0.0%  0.0%    skip:95.0%\n",
      "[libx264 @ 0x556b689ba4c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.6%  1.1%  0.4%  direct: 0.3%  skip:96.7%  L0:37.5% L1:39.2% BI:23.3%\n",
      "[libx264 @ 0x556b689ba4c0] 8x8 transform intra:47.4% inter:24.4%\n",
      "[libx264 @ 0x556b689ba4c0] coded y,uvDC,uvAC intra: 19.2% 2.7% 2.4% inter: 1.1% 0.4% 0.3%\n",
      "[libx264 @ 0x556b689ba4c0] i16 v,h,dc,p: 81%  6% 13%  0%\n",
      "[libx264 @ 0x556b689ba4c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43%  7% 49%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x556b689ba4c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 31%  8%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x556b689ba4c0] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x556b689ba4c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x556b689ba4c0] ref P L0: 69.6% 11.2% 11.8%  7.4%\n",
      "[libx264 @ 0x556b689ba4c0] ref B L0: 88.6%  8.7%  2.7%\n",
      "[libx264 @ 0x556b689ba4c0] ref B L1: 97.4%  2.6%\n",
      "[libx264 @ 0x556b689ba4c0] kb/s:201.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6993, 102])\n",
      "test_input (1, 6993, 128)\n",
      "test_target torch.Size([1, 6993, 102])\n",
      "torch.Size([1, 6993, 102])\n",
      "prediction.shape (1, 6993, 102)\n",
      "full_prediction (6993, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 6.20528832e-02  1.13266490e-01  1.10211024e+00]\n",
      "  [ 1.30927470e-03  7.03886077e-02  1.11493657e+00]\n",
      "  [ 1.17020965e-01  5.03488369e-02  1.11314831e+00]\n",
      "  ...\n",
      "  [ 2.89477352e-02  8.01345408e-02  9.75055730e-01]\n",
      "  [-1.42775625e-01  2.72767507e-02  1.03873155e+00]\n",
      "  [ 1.35203645e-01  2.65212983e-01  8.51579046e-01]]\n",
      "\n",
      " [[ 6.01846650e-02  1.16254717e-01  1.09933970e+00]\n",
      "  [-7.24230893e-04  7.58599937e-02  1.11126528e+00]\n",
      "  [ 1.11826964e-01  5.27212843e-02  1.11255679e+00]\n",
      "  ...\n",
      "  [ 3.03628817e-02  8.27326104e-02  9.71512890e-01]\n",
      "  [-1.53037697e-01  1.28382780e-02  1.03359017e+00]\n",
      "  [ 1.38790682e-01  2.85632640e-01  8.73312688e-01]]\n",
      "\n",
      " [[ 6.28431365e-02  1.18362546e-01  1.10307047e+00]\n",
      "  [ 6.24760985e-04  7.92874023e-02  1.11583767e+00]\n",
      "  [ 1.13777444e-01  5.35990410e-02  1.11741064e+00]\n",
      "  ...\n",
      "  [ 3.08908708e-02  8.36977065e-02  9.75929475e-01]\n",
      "  [-1.56776756e-01  8.09556246e-03  1.03659055e+00]\n",
      "  [ 1.34167641e-01  2.85979509e-01  8.78510690e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.34652686e-02  5.68114519e-02  1.10046206e+00]\n",
      "  [ 4.12668809e-02  2.43782438e-03  1.10994897e+00]\n",
      "  [ 1.60450161e-01  5.09274006e-03  1.10624633e+00]\n",
      "  ...\n",
      "  [ 6.67973012e-02  2.04541907e-02  9.75619352e-01]\n",
      "  [-9.05271471e-02  2.15369537e-02  1.09456763e+00]\n",
      "  [ 1.34692490e-01  1.44728512e-01  7.25915527e-01]]\n",
      "\n",
      " [[ 9.08872485e-02  5.84285557e-02  1.10045478e+00]\n",
      "  [ 3.88538800e-02  3.95304151e-03  1.11002610e+00]\n",
      "  [ 1.58115610e-01  7.06932880e-03  1.10684071e+00]\n",
      "  ...\n",
      "  [ 6.48274124e-02  2.10455582e-02  9.75625730e-01]\n",
      "  [-9.34778824e-02  2.30830163e-02  1.09651217e+00]\n",
      "  [ 1.30944818e-01  1.43053025e-01  7.25740349e-01]]\n",
      "\n",
      " [[ 8.84973258e-02  6.03342280e-02  1.10027966e+00]\n",
      "  [ 3.66583243e-02  5.72372414e-03  1.10994205e+00]\n",
      "  [ 1.55996829e-01  9.34578851e-03  1.10731039e+00]\n",
      "  ...\n",
      "  [ 6.30471259e-02  2.17819363e-02  9.75628054e-01]\n",
      "  [-9.69494954e-02  2.36347802e-02  1.09883008e+00]\n",
      "  [ 1.27226129e-01  1.42152101e-01  7.27352059e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-3sic.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-3sic.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 205 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 201 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-3sic.wav':\n",
      "  Duration: 00:02:54.71, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55d85bac38c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55d85bac38c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55d85bac38c0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-3sic_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=501 q=-1.0 Lsize=    3252kB time=00:02:54.73 bitrate= 152.5kbits/s speed= 110x    \n",
      "video:466kB audio:2739kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.472523%\n",
      "[aac @ 0x55d85bac20c0] Qavg: 180.446\n",
      "[libx264 @ 0x55d85bac38c0] frame I:4     Avg QP:16.66  size: 13801\n",
      "[libx264 @ 0x55d85bac38c0] frame P:232   Avg QP:22.72  size:  1328\n",
      "[libx264 @ 0x55d85bac38c0] frame B:564   Avg QP:27.02  size:   200\n",
      "[libx264 @ 0x55d85bac38c0] consecutive B-frames:  1.8% 11.0%  5.2% 82.0%\n",
      "[libx264 @ 0x55d85bac38c0] mb I  I16..4: 28.0% 47.5% 24.5%\n",
      "[libx264 @ 0x55d85bac38c0] mb P  I16..4:  0.0%  0.0%  0.1%  P16..4:  1.1%  1.7%  1.9%  0.0%  0.0%    skip:95.1%\n",
      "[libx264 @ 0x55d85bac38c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.4%  0.8%  0.3%  direct: 0.2%  skip:97.2%  L0:34.6% L1:39.0% BI:26.4%\n",
      "[libx264 @ 0x55d85bac38c0] 8x8 transform intra:45.7% inter:23.3%\n",
      "[libx264 @ 0x55d85bac38c0] coded y,uvDC,uvAC intra: 19.7% 2.8% 2.5% inter: 1.0% 0.3% 0.3%\n",
      "[libx264 @ 0x55d85bac38c0] i16 v,h,dc,p: 79%  7% 14%  0%\n",
      "[libx264 @ 0x55d85bac38c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43%  9% 47%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55d85bac38c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 31%  8%  2%  5%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55d85bac38c0] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55d85bac38c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55d85bac38c0] ref P L0: 70.8% 11.6% 10.5%  7.1%\n",
      "[libx264 @ 0x55d85bac38c0] ref B L0: 88.5%  8.7%  2.8%\n",
      "[libx264 @ 0x55d85bac38c0] ref B L1: 96.9%  3.1%\n",
      "[libx264 @ 0x55d85bac38c0] kb/s:190.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7897, 102])\n",
      "test_input (1, 7897, 128)\n",
      "test_target torch.Size([1, 7897, 102])\n",
      "torch.Size([1, 7897, 102])\n",
      "prediction.shape (1, 7897, 102)\n",
      "full_prediction (7897, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.05286872  0.10052781  1.10362885]\n",
      "  [-0.01084831  0.06210627  1.10957465]\n",
      "  [ 0.10044288  0.03420502  1.10794959]\n",
      "  ...\n",
      "  [ 0.01440732  0.08105334  0.97696838]\n",
      "  [-0.10480201  0.11279461  1.07885358]\n",
      "  [ 0.10670544  0.18397386  0.73580751]]\n",
      "\n",
      " [[ 0.04800601  0.10273877  1.10052619]\n",
      "  [-0.01423963  0.06329025  1.10705194]\n",
      "  [ 0.09660735  0.03814729  1.1049485 ]\n",
      "  ...\n",
      "  [ 0.0106838   0.0827593   0.9723551 ]\n",
      "  [-0.1183335   0.10224623  1.07977036]\n",
      "  [ 0.09897475  0.19115892  0.74277947]]\n",
      "\n",
      " [[ 0.04656763  0.10538645  1.10035644]\n",
      "  [-0.01497868  0.06566209  1.10791824]\n",
      "  [ 0.09685724  0.0421206   1.10527883]\n",
      "  ...\n",
      "  [ 0.00944012  0.08477984  0.97294674]\n",
      "  [-0.1279929   0.09885045  1.08560524]\n",
      "  [ 0.09278813  0.19166553  0.74470249]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.06096807  0.11595962  1.09984294]\n",
      "  [-0.00324127  0.07916334  1.10976169]\n",
      "  [ 0.10790355  0.0484788   1.10687075]\n",
      "  ...\n",
      "  [ 0.01859717  0.09213413  0.97508553]\n",
      "  [-0.07828341  0.13468902  1.03840832]\n",
      "  [ 0.15335524  0.17179003  0.67691443]]\n",
      "\n",
      " [[ 0.06094768  0.11601023  1.09974632]\n",
      "  [-0.00341188  0.07946889  1.10922179]\n",
      "  [ 0.10772589  0.0482945   1.10697565]\n",
      "  ...\n",
      "  [ 0.01864043  0.09242421  0.97491781]\n",
      "  [-0.08180866  0.13398966  1.0414227 ]\n",
      "  [ 0.15196517  0.17569853  0.68342505]]\n",
      "\n",
      " [[ 0.061495    0.1154879   1.09925435]\n",
      "  [-0.00280566  0.079029    1.10835645]\n",
      "  [ 0.10830827  0.04771031  1.10661254]\n",
      "  ...\n",
      "  [ 0.01931386  0.09214298  0.97434006]\n",
      "  [-0.08384927  0.13345277  1.04363213]\n",
      "  [ 0.15064354  0.17736238  0.68756381]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-4prs.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-4prs.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 225 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 221 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-4prs.wav':\n",
      "  Duration: 00:03:17.43, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55f035983c80] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55f035983c80] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55f035983c80] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-4prs_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=465 q=-1.0 Lsize=    3652kB time=00:03:17.43 bitrate= 151.5kbits/s speed= 115x    \n",
      "video:506kB audio:3095kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.418281%\n",
      "[aac @ 0x55f035982540] Qavg: 188.133\n",
      "[libx264 @ 0x55f035983c80] frame I:4     Avg QP:17.00  size: 13676\n",
      "[libx264 @ 0x55f035983c80] frame P:226   Avg QP:22.80  size:  1380\n",
      "[libx264 @ 0x55f035983c80] frame B:570   Avg QP:28.31  size:   265\n",
      "[libx264 @ 0x55f035983c80] consecutive B-frames:  1.6%  9.2%  2.6% 86.5%\n",
      "[libx264 @ 0x55f035983c80] mb I  I16..4: 26.1% 49.0% 24.9%\n",
      "[libx264 @ 0x55f035983c80] mb P  I16..4:  0.0%  0.0%  0.1%  P16..4:  1.1%  1.8%  2.1%  0.0%  0.0%    skip:94.9%\n",
      "[libx264 @ 0x55f035983c80] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.8%  1.3%  0.5%  direct: 0.2%  skip:96.1%  L0:39.8% L1:41.1% BI:19.1%\n",
      "[libx264 @ 0x55f035983c80] 8x8 transform intra:49.7% inter:23.5%\n",
      "[libx264 @ 0x55f035983c80] coded y,uvDC,uvAC intra: 19.1% 2.7% 2.4% inter: 1.1% 0.4% 0.3%\n",
      "[libx264 @ 0x55f035983c80] i16 v,h,dc,p: 80%  5% 14%  0%\n",
      "[libx264 @ 0x55f035983c80] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42%  9% 48%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55f035983c80] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 31%  8%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55f035983c80] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55f035983c80] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55f035983c80] ref P L0: 62.0% 10.0% 16.9% 11.1%\n",
      "[libx264 @ 0x55f035983c80] ref B L0: 86.4% 10.2%  3.4%\n",
      "[libx264 @ 0x55f035983c80] ref B L1: 96.3%  3.7%\n",
      "[libx264 @ 0x55f035983c80] kb/s:206.94\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        first_target = torch.zeros(test_batch.shape[0],102)\n",
    "        print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, test_target, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "        \n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        plot(test_datapath + test_music_list[num_count] + \".mid\", \"./video_\" + filecode + \"_test_predict.mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bac6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

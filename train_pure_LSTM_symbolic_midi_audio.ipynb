{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dc6d36-fc6d-4916-b7b0-6a2dfaf9c4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq\n",
    "from data_loader import *\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pretty_midi\n",
    "import glob\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b387469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26d6b8a-e8ec-4fa2-b14f-a45764fa7545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.piece_count:  105\n",
      "dataset_len:  10500\n",
      "val_dataset_len 5\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_name_path = f\"./both_list_symbolic.txt\" #f\"./midi_list.txt\"\n",
    "dataloader = get_all_dataloader(dataset_name_path, batch_size=128) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "val_dataset_name_path = f\"./both_list_eval_symbolic.txt\" #f\"./midi_list_eval.txt\"\n",
    "val_dataloader = get_all_val_dataloader(val_dataset_name_path, batch_size=128) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "learning_rate = 0.001#0.001\n",
    "\n",
    "input_size_encoder = 28 #128 #129 #128\n",
    "input_size_decoder = 112 #102 #24\n",
    "output_size = 112#102 #24\n",
    "\n",
    "# encoder_embedding_size = 300\n",
    "# decoder_embedding_size = 300\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.\n",
    "step = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23df2697-2943-4f69-89df-1f0c5cbf3343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = 156 #number of features\n",
    "hidden_size = 1024 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "output_dim = 112 #number of output classes\n",
    "\n",
    "# model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM(embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "num_epochs = 100 #10\n",
    "avg_loss_list = []\n",
    "all_loss_list = []\n",
    "val_loss_per_epoch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fb7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse_loss(output, target, prev_output, midi_array):\n",
    "    # target = target.transpose(0, 1)\n",
    "    # print(\"output\", output)\n",
    "    # print(output.shape) #torch.Size([20, 513, 102])\n",
    "    # print(target.shape) #torch.Size([20, 513, 102])\n",
    "    mse_loss = F.mse_loss(output, target)\n",
    "    # print(\"mse_loss:\", mse_loss)\n",
    "\n",
    "    var_diff = torch.var(torch.squeeze(output), dim=1, keepdim=True)\n",
    "    mean_diff = torch.mean(var_diff)\n",
    "    \n",
    "    # Condition 1: Penalize if output is similar to previous output\n",
    "    if mean_diff < 1e-4: #threshold\n",
    "        #output [512, 1, 102] => [102] <-> [102] <-> [102] <-> ... <-> [102]\n",
    "        mse_loss *= 1000\n",
    "\n",
    "    # Condition 2: Stop movement if input is all zeros\n",
    "    # midi_transpose = midi_array.transpose(0, 1)\n",
    "    # midi_sum_row = torch.sum(midi_transpose, dim=-1)\n",
    "    # mask = midi_sum_row == 0\n",
    "    # mask = mask.unsqueeze(-1)\n",
    "    # mask = mask.to(device)\n",
    "    # # according to recorded index, make a mask [0, 1, 1, 0, ..., 0], true part will be omit(set value to 0).\n",
    "    # # before compute mse, use mask first to tensor, then caculate MES loss\n",
    "    # masked_output = output.masked_fill(mask, 0) #inplace function\n",
    "    # masked_target = target.masked_fill(mask, 0)\n",
    "    # mse_loss += F.mse_loss(masked_output, masked_target) * 100 #output 和 previous output 不像的話，增大 loss\n",
    "\n",
    "    # Condition 3: Penalize if right-hand movement is too different between outputs\n",
    "    # if output.shape[-1] == 21:  # Assumes hand joints are the last 21 dimensions\n",
    "    #     rh_indices = [i for i in range(12, 21)]  # Right-hand joint indices\n",
    "    #     rh_output = output[..., rh_indices]\n",
    "    #     rh_prev_output = prev_output[..., rh_indices]\n",
    "    #     rh_loss = nn.functional.mse_loss(rh_output, rh_prev_output)\n",
    "    #     if rh_loss > 0.1:\n",
    "    #         mse_loss *= 1000\n",
    "\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee089d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(model, val_dataloader):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            print(\"inputs.shape:\", inputs.shape)\n",
    "            print(\"targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.mse_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "\n",
    "    epoch_val_loss = valid_running_loss / counter\n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af114cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_l1(model, val_dataloader):\n",
    "    model.eval()\n",
    "    print('Validation L1')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            print(\"inputs.shape:\", inputs.shape)\n",
    "            print(\"targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.l1_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "\n",
    "    epoch_val_loss = valid_running_loss / counter\n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37e92038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0: loss = 0.239317\n",
      "Epoch 0, batch 1: loss = 0.076427\n",
      "Epoch 0, batch 2: loss = 0.042218\n",
      "Epoch 0, batch 3: loss = 0.045830\n",
      "Epoch 0, batch 4: loss = 0.042866\n",
      "Epoch 0, batch 5: loss = 0.036171\n",
      "Epoch 0, batch 6: loss = 0.030401\n",
      "Epoch 0, batch 7: loss = 0.024924\n",
      "Epoch 0, batch 8: loss = 0.022711\n",
      "Epoch 0, batch 9: loss = 0.019896\n",
      "Epoch 0, batch 10: loss = 0.018655\n",
      "Epoch 0, batch 11: loss = 0.018178\n",
      "Epoch 0, batch 12: loss = 0.019470\n",
      "Epoch 0, batch 13: loss = 0.019169\n",
      "Epoch 0, batch 14: loss = 0.018379\n",
      "Epoch 0, batch 15: loss = 0.016918\n",
      "Epoch 0, batch 16: loss = 0.016931\n",
      "Epoch 0, batch 17: loss = 0.016836\n",
      "Epoch 0, batch 18: loss = 0.015510\n",
      "Epoch 0, batch 19: loss = 0.016195\n",
      "Epoch 0, batch 20: loss = 0.014126\n",
      "Epoch 0, batch 21: loss = 0.015149\n",
      "Epoch 0, batch 22: loss = 0.015129\n",
      "Epoch 0, batch 23: loss = 0.015155\n",
      "Epoch 0, batch 24: loss = 0.015436\n",
      "Epoch 0, batch 25: loss = 0.013678\n",
      "Epoch 0, batch 26: loss = 0.013971\n",
      "Epoch 0, batch 27: loss = 0.013979\n",
      "Epoch 0, batch 28: loss = 0.012938\n",
      "Epoch 0, batch 29: loss = 0.013710\n",
      "Epoch 0, batch 30: loss = 0.013944\n",
      "Epoch 0, batch 31: loss = 0.015661\n",
      "Epoch 0, batch 32: loss = 0.013484\n",
      "Epoch 0, batch 33: loss = 0.013610\n",
      "Epoch 0, batch 34: loss = 0.013987\n",
      "Epoch 0, batch 35: loss = 0.014583\n",
      "Epoch 0, batch 36: loss = 0.015508\n",
      "Epoch 0, batch 37: loss = 0.014448\n",
      "Epoch 0, batch 38: loss = 0.014136\n",
      "Epoch 0, batch 39: loss = 0.013264\n",
      "Epoch 0, batch 40: loss = 0.013276\n",
      "Epoch 0, batch 41: loss = 0.013038\n",
      "Epoch 0, batch 42: loss = 0.013004\n",
      "Epoch 0, batch 43: loss = 0.013349\n",
      "Epoch 0, batch 44: loss = 0.012790\n",
      "Epoch 0, batch 45: loss = 0.013165\n",
      "Epoch 0, batch 46: loss = 0.013298\n",
      "Epoch 0, batch 47: loss = 0.012888\n",
      "Epoch 0, batch 48: loss = 0.012912\n",
      "Epoch 0, batch 49: loss = 0.013421\n",
      "Epoch 0, batch 50: loss = 0.012461\n",
      "Epoch 0, batch 51: loss = 0.012275\n",
      "Epoch 0, batch 52: loss = 0.013561\n",
      "Epoch 0, batch 53: loss = 0.012260\n",
      "Epoch 0, batch 54: loss = 0.013576\n",
      "Epoch 0, batch 55: loss = 0.012150\n",
      "Epoch 0, batch 56: loss = 0.012830\n",
      "Epoch 0, batch 57: loss = 0.014401\n",
      "Epoch 0, batch 58: loss = 0.014141\n",
      "Epoch 0, batch 59: loss = 0.013129\n",
      "Epoch 0, batch 60: loss = 0.012574\n",
      "Epoch 0, batch 61: loss = 0.013208\n",
      "Epoch 0, batch 62: loss = 0.012815\n",
      "Epoch 0, batch 63: loss = 0.012565\n",
      "Epoch 0, batch 64: loss = 0.011734\n",
      "Epoch 0, batch 65: loss = 0.011982\n",
      "Epoch 0, batch 66: loss = 0.011927\n",
      "Epoch 0, batch 67: loss = 0.013420\n",
      "Epoch 0, batch 68: loss = 0.014116\n",
      "Epoch 0, batch 69: loss = 0.012174\n",
      "Epoch 0, batch 70: loss = 0.012187\n",
      "Epoch 0, batch 71: loss = 0.013280\n",
      "Epoch 0, batch 72: loss = 0.012140\n",
      "Epoch 0, batch 73: loss = 0.011802\n",
      "Epoch 0, batch 74: loss = 0.013115\n",
      "Epoch 0, batch 75: loss = 0.012011\n",
      "Epoch 0, batch 76: loss = 0.012658\n",
      "Epoch 0, batch 77: loss = 0.013871\n",
      "Epoch 0, batch 78: loss = 0.011210\n",
      "Epoch 0, batch 79: loss = 0.012020\n",
      "Epoch 0, batch 80: loss = 0.011787\n",
      "Epoch 0, batch 81: loss = 0.013549\n",
      "Epoch 0, batch 82: loss = 0.009581\n",
      "Validation\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 0: val_loss = 0.012417\n",
      "Epoch 1, batch 0: loss = 0.013401\n",
      "Epoch 1, batch 1: loss = 0.013860\n",
      "Epoch 1, batch 2: loss = 0.012095\n",
      "Epoch 1, batch 3: loss = 0.013188\n",
      "Epoch 1, batch 4: loss = 0.013507\n",
      "Epoch 1, batch 5: loss = 0.012876\n",
      "Epoch 1, batch 6: loss = 0.012649\n",
      "Epoch 1, batch 7: loss = 0.011708\n",
      "Epoch 1, batch 8: loss = 0.011822\n",
      "Epoch 1, batch 9: loss = 0.012742\n",
      "Epoch 1, batch 10: loss = 0.013300\n",
      "Epoch 1, batch 11: loss = 0.012396\n",
      "Epoch 1, batch 12: loss = 0.012586\n",
      "Epoch 1, batch 13: loss = 0.012550\n",
      "Epoch 1, batch 14: loss = 0.012331\n",
      "Epoch 1, batch 15: loss = 0.012393\n",
      "Epoch 1, batch 16: loss = 0.013240\n",
      "Epoch 1, batch 17: loss = 0.014711\n",
      "Epoch 1, batch 18: loss = 0.012508\n",
      "Epoch 1, batch 19: loss = 0.012365\n",
      "Epoch 1, batch 20: loss = 0.012774\n",
      "Epoch 1, batch 21: loss = 0.013551\n",
      "Epoch 1, batch 22: loss = 0.011663\n",
      "Epoch 1, batch 23: loss = 0.012182\n",
      "Epoch 1, batch 24: loss = 0.013658\n",
      "Epoch 1, batch 25: loss = 0.012851\n",
      "Epoch 1, batch 26: loss = 0.011820\n",
      "Epoch 1, batch 27: loss = 0.012206\n",
      "Epoch 1, batch 28: loss = 0.013811\n",
      "Epoch 1, batch 29: loss = 0.012155\n",
      "Epoch 1, batch 30: loss = 0.011222\n",
      "Epoch 1, batch 31: loss = 0.012090\n",
      "Epoch 1, batch 32: loss = 0.011909\n",
      "Epoch 1, batch 33: loss = 0.011291\n",
      "Epoch 1, batch 34: loss = 0.013532\n",
      "Epoch 1, batch 35: loss = 0.012227\n",
      "Epoch 1, batch 36: loss = 0.012101\n",
      "Epoch 1, batch 37: loss = 0.011885\n",
      "Epoch 1, batch 38: loss = 0.013185\n",
      "Epoch 1, batch 39: loss = 0.014402\n",
      "Epoch 1, batch 40: loss = 0.012057\n",
      "Epoch 1, batch 41: loss = 0.014204\n",
      "Epoch 1, batch 42: loss = 0.012024\n",
      "Epoch 1, batch 43: loss = 0.012779\n",
      "Epoch 1, batch 44: loss = 0.012626\n",
      "Epoch 1, batch 45: loss = 0.012657\n",
      "Epoch 1, batch 46: loss = 0.011471\n",
      "Epoch 1, batch 47: loss = 0.011220\n",
      "Epoch 1, batch 48: loss = 0.012457\n",
      "Epoch 1, batch 49: loss = 0.014082\n",
      "Epoch 1, batch 50: loss = 0.012307\n",
      "Epoch 1, batch 51: loss = 0.011480\n",
      "Epoch 1, batch 52: loss = 0.011711\n",
      "Epoch 1, batch 53: loss = 0.012328\n",
      "Epoch 1, batch 54: loss = 0.013407\n",
      "Epoch 1, batch 55: loss = 0.012223\n",
      "Epoch 1, batch 56: loss = 0.010914\n",
      "Epoch 1, batch 57: loss = 0.012659\n",
      "Epoch 1, batch 58: loss = 0.011426\n",
      "Epoch 1, batch 59: loss = 0.012249\n",
      "Epoch 1, batch 60: loss = 0.013259\n",
      "Epoch 1, batch 61: loss = 0.011855\n",
      "Epoch 1, batch 62: loss = 0.011534\n",
      "Epoch 1, batch 63: loss = 0.011471\n",
      "Epoch 1, batch 64: loss = 0.011485\n",
      "Epoch 1, batch 65: loss = 0.012712\n",
      "Epoch 1, batch 66: loss = 0.011967\n",
      "Epoch 1, batch 67: loss = 0.012532\n",
      "Epoch 1, batch 68: loss = 0.011800\n",
      "Epoch 1, batch 69: loss = 0.013929\n",
      "Epoch 1, batch 70: loss = 0.011971\n",
      "Epoch 1, batch 71: loss = 0.011977\n",
      "Epoch 1, batch 72: loss = 0.012802\n",
      "Epoch 1, batch 73: loss = 0.012129\n",
      "Epoch 1, batch 74: loss = 0.011404\n",
      "Epoch 1, batch 75: loss = 0.012668\n",
      "Epoch 1, batch 76: loss = 0.011902\n",
      "Epoch 1, batch 77: loss = 0.011792\n",
      "Epoch 1, batch 78: loss = 0.011873\n",
      "Epoch 1, batch 79: loss = 0.012874\n",
      "Epoch 1, batch 80: loss = 0.012034\n",
      "Epoch 1, batch 81: loss = 0.011716\n",
      "Epoch 1, batch 82: loss = 0.007809\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 1: val_loss = 0.012961\n",
      "Epoch 2, batch 0: loss = 0.011364\n",
      "Epoch 2, batch 1: loss = 0.011913\n",
      "Epoch 2, batch 2: loss = 0.011486\n",
      "Epoch 2, batch 3: loss = 0.012278\n",
      "Epoch 2, batch 4: loss = 0.013184\n",
      "Epoch 2, batch 5: loss = 0.011250\n",
      "Epoch 2, batch 6: loss = 0.011462\n",
      "Epoch 2, batch 7: loss = 0.012107\n",
      "Epoch 2, batch 8: loss = 0.010715\n",
      "Epoch 2, batch 9: loss = 0.011148\n",
      "Epoch 2, batch 10: loss = 0.011583\n",
      "Epoch 2, batch 11: loss = 0.012217\n",
      "Epoch 2, batch 12: loss = 0.012120\n",
      "Epoch 2, batch 13: loss = 0.011681\n",
      "Epoch 2, batch 14: loss = 0.011627\n",
      "Epoch 2, batch 15: loss = 0.012320\n",
      "Epoch 2, batch 16: loss = 0.013105\n",
      "Epoch 2, batch 17: loss = 0.011582\n",
      "Epoch 2, batch 18: loss = 0.012390\n",
      "Epoch 2, batch 19: loss = 0.011361\n",
      "Epoch 2, batch 20: loss = 0.010664\n",
      "Epoch 2, batch 21: loss = 0.012303\n",
      "Epoch 2, batch 22: loss = 0.012364\n",
      "Epoch 2, batch 23: loss = 0.013503\n",
      "Epoch 2, batch 24: loss = 0.012404\n",
      "Epoch 2, batch 25: loss = 0.011885\n",
      "Epoch 2, batch 26: loss = 0.011959\n",
      "Epoch 2, batch 27: loss = 0.011978\n",
      "Epoch 2, batch 28: loss = 0.012461\n",
      "Epoch 2, batch 29: loss = 0.010802\n",
      "Epoch 2, batch 30: loss = 0.011513\n",
      "Epoch 2, batch 31: loss = 0.013175\n",
      "Epoch 2, batch 32: loss = 0.011125\n",
      "Epoch 2, batch 33: loss = 0.013003\n",
      "Epoch 2, batch 34: loss = 0.011351\n",
      "Epoch 2, batch 35: loss = 0.011476\n",
      "Epoch 2, batch 36: loss = 0.012130\n",
      "Epoch 2, batch 37: loss = 0.010841\n",
      "Epoch 2, batch 38: loss = 0.012353\n",
      "Epoch 2, batch 39: loss = 0.012365\n",
      "Epoch 2, batch 40: loss = 0.011853\n",
      "Epoch 2, batch 41: loss = 0.012988\n",
      "Epoch 2, batch 42: loss = 0.011671\n",
      "Epoch 2, batch 43: loss = 0.012029\n",
      "Epoch 2, batch 44: loss = 0.011177\n",
      "Epoch 2, batch 45: loss = 0.012260\n",
      "Epoch 2, batch 46: loss = 0.011794\n",
      "Epoch 2, batch 47: loss = 0.011513\n",
      "Epoch 2, batch 48: loss = 0.011018\n",
      "Epoch 2, batch 49: loss = 0.013074\n",
      "Epoch 2, batch 50: loss = 0.011808\n",
      "Epoch 2, batch 51: loss = 0.011549\n",
      "Epoch 2, batch 52: loss = 0.012490\n",
      "Epoch 2, batch 53: loss = 0.011991\n",
      "Epoch 2, batch 54: loss = 0.011774\n",
      "Epoch 2, batch 55: loss = 0.011940\n",
      "Epoch 2, batch 56: loss = 0.011748\n",
      "Epoch 2, batch 57: loss = 0.010781\n",
      "Epoch 2, batch 58: loss = 0.012136\n",
      "Epoch 2, batch 59: loss = 0.012194\n",
      "Epoch 2, batch 60: loss = 0.012936\n",
      "Epoch 2, batch 61: loss = 0.011961\n",
      "Epoch 2, batch 62: loss = 0.011026\n",
      "Epoch 2, batch 63: loss = 0.011354\n",
      "Epoch 2, batch 64: loss = 0.011338\n",
      "Epoch 2, batch 65: loss = 0.013018\n",
      "Epoch 2, batch 66: loss = 0.011880\n",
      "Epoch 2, batch 67: loss = 0.011507\n",
      "Epoch 2, batch 68: loss = 0.012782\n",
      "Epoch 2, batch 69: loss = 0.012968\n",
      "Epoch 2, batch 70: loss = 0.011856\n",
      "Epoch 2, batch 71: loss = 0.010691\n",
      "Epoch 2, batch 72: loss = 0.012089\n",
      "Epoch 2, batch 73: loss = 0.011803\n",
      "Epoch 2, batch 74: loss = 0.011928\n",
      "Epoch 2, batch 75: loss = 0.012449\n",
      "Epoch 2, batch 76: loss = 0.011356\n",
      "Epoch 2, batch 77: loss = 0.012985\n",
      "Epoch 2, batch 78: loss = 0.011832\n",
      "Epoch 2, batch 79: loss = 0.011620\n",
      "Epoch 2, batch 80: loss = 0.011116\n",
      "Epoch 2, batch 81: loss = 0.011108\n",
      "Epoch 2, batch 82: loss = 0.007401\n",
      "Validation\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 2: val_loss = 0.013278\n",
      "Epoch 3, batch 0: loss = 0.012973\n",
      "Epoch 3, batch 1: loss = 0.011213\n",
      "Epoch 3, batch 2: loss = 0.013451\n",
      "Epoch 3, batch 3: loss = 0.012902\n",
      "Epoch 3, batch 4: loss = 0.012682\n",
      "Epoch 3, batch 5: loss = 0.011869\n",
      "Epoch 3, batch 6: loss = 0.012033\n",
      "Epoch 3, batch 7: loss = 0.012084\n",
      "Epoch 3, batch 8: loss = 0.010685\n",
      "Epoch 3, batch 9: loss = 0.011563\n",
      "Epoch 3, batch 10: loss = 0.011088\n",
      "Epoch 3, batch 11: loss = 0.011070\n",
      "Epoch 3, batch 12: loss = 0.012395\n",
      "Epoch 3, batch 13: loss = 0.011832\n",
      "Epoch 3, batch 14: loss = 0.013438\n",
      "Epoch 3, batch 15: loss = 0.012016\n",
      "Epoch 3, batch 16: loss = 0.011500\n",
      "Epoch 3, batch 17: loss = 0.011680\n",
      "Epoch 3, batch 18: loss = 0.011253\n",
      "Epoch 3, batch 19: loss = 0.011157\n",
      "Epoch 3, batch 20: loss = 0.011351\n",
      "Epoch 3, batch 21: loss = 0.013201\n",
      "Epoch 3, batch 22: loss = 0.010972\n",
      "Epoch 3, batch 23: loss = 0.012324\n",
      "Epoch 3, batch 24: loss = 0.011984\n",
      "Epoch 3, batch 25: loss = 0.010047\n",
      "Epoch 3, batch 26: loss = 0.012944\n",
      "Epoch 3, batch 27: loss = 0.010713\n",
      "Epoch 3, batch 28: loss = 0.011707\n",
      "Epoch 3, batch 29: loss = 0.011678\n",
      "Epoch 3, batch 30: loss = 0.012230\n",
      "Epoch 3, batch 31: loss = 0.011743\n",
      "Epoch 3, batch 32: loss = 0.011244\n",
      "Epoch 3, batch 33: loss = 0.010700\n",
      "Epoch 3, batch 34: loss = 0.011127\n",
      "Epoch 3, batch 35: loss = 0.011685\n",
      "Epoch 3, batch 36: loss = 0.011031\n",
      "Epoch 3, batch 37: loss = 0.012471\n",
      "Epoch 3, batch 38: loss = 0.011235\n",
      "Epoch 3, batch 39: loss = 0.011933\n",
      "Epoch 3, batch 40: loss = 0.012153\n",
      "Epoch 3, batch 41: loss = 0.012120\n",
      "Epoch 3, batch 42: loss = 0.011167\n",
      "Epoch 3, batch 43: loss = 0.011471\n",
      "Epoch 3, batch 44: loss = 0.011986\n",
      "Epoch 3, batch 45: loss = 0.010971\n",
      "Epoch 3, batch 46: loss = 0.012002\n",
      "Epoch 3, batch 47: loss = 0.010996\n",
      "Epoch 3, batch 48: loss = 0.011655\n",
      "Epoch 3, batch 49: loss = 0.011194\n",
      "Epoch 3, batch 50: loss = 0.010354\n",
      "Epoch 3, batch 51: loss = 0.011560\n",
      "Epoch 3, batch 52: loss = 0.011705\n",
      "Epoch 3, batch 53: loss = 0.010532\n",
      "Epoch 3, batch 54: loss = 0.010810\n",
      "Epoch 3, batch 55: loss = 0.011580\n",
      "Epoch 3, batch 56: loss = 0.011073\n",
      "Epoch 3, batch 57: loss = 0.011186\n",
      "Epoch 3, batch 58: loss = 0.011883\n",
      "Epoch 3, batch 59: loss = 0.011456\n",
      "Epoch 3, batch 60: loss = 0.010847\n",
      "Epoch 3, batch 61: loss = 0.010672\n",
      "Epoch 3, batch 62: loss = 0.010622\n",
      "Epoch 3, batch 63: loss = 0.011969\n",
      "Epoch 3, batch 64: loss = 0.012822\n",
      "Epoch 3, batch 65: loss = 0.011580\n",
      "Epoch 3, batch 66: loss = 0.011210\n",
      "Epoch 3, batch 67: loss = 0.010409\n",
      "Epoch 3, batch 68: loss = 0.011603\n",
      "Epoch 3, batch 69: loss = 0.011475\n",
      "Epoch 3, batch 70: loss = 0.011195\n",
      "Epoch 3, batch 71: loss = 0.012247\n",
      "Epoch 3, batch 72: loss = 0.011827\n",
      "Epoch 3, batch 73: loss = 0.010941\n",
      "Epoch 3, batch 74: loss = 0.011542\n",
      "Epoch 3, batch 75: loss = 0.010875\n",
      "Epoch 3, batch 76: loss = 0.012497\n",
      "Epoch 3, batch 77: loss = 0.011461\n",
      "Epoch 3, batch 78: loss = 0.010878\n",
      "Epoch 3, batch 79: loss = 0.012110\n",
      "Epoch 3, batch 80: loss = 0.010909\n",
      "Epoch 3, batch 81: loss = 0.011228\n",
      "Epoch 3, batch 82: loss = 0.010984\n",
      "Validation\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 3: val_loss = 0.012346\n",
      "Epoch 4, batch 0: loss = 0.012306\n",
      "Epoch 4, batch 1: loss = 0.010666\n",
      "Epoch 4, batch 2: loss = 0.011019\n",
      "Epoch 4, batch 3: loss = 0.011315\n",
      "Epoch 4, batch 4: loss = 0.011221\n",
      "Epoch 4, batch 5: loss = 0.011322\n",
      "Epoch 4, batch 6: loss = 0.010641\n",
      "Epoch 4, batch 7: loss = 0.010688\n",
      "Epoch 4, batch 8: loss = 0.011419\n",
      "Epoch 4, batch 9: loss = 0.011428\n",
      "Epoch 4, batch 10: loss = 0.010565\n",
      "Epoch 4, batch 11: loss = 0.011124\n",
      "Epoch 4, batch 12: loss = 0.011448\n",
      "Epoch 4, batch 13: loss = 0.010533\n",
      "Epoch 4, batch 14: loss = 0.012002\n",
      "Epoch 4, batch 15: loss = 0.011413\n",
      "Epoch 4, batch 16: loss = 0.011079\n",
      "Epoch 4, batch 17: loss = 0.011549\n",
      "Epoch 4, batch 18: loss = 0.011020\n",
      "Epoch 4, batch 19: loss = 0.010052\n",
      "Epoch 4, batch 20: loss = 0.010003\n",
      "Epoch 4, batch 21: loss = 0.012610\n",
      "Epoch 4, batch 22: loss = 0.011819\n",
      "Epoch 4, batch 23: loss = 0.011012\n",
      "Epoch 4, batch 24: loss = 0.011259\n",
      "Epoch 4, batch 25: loss = 0.010832\n",
      "Epoch 4, batch 26: loss = 0.010326\n",
      "Epoch 4, batch 27: loss = 0.011144\n",
      "Epoch 4, batch 28: loss = 0.011772\n",
      "Epoch 4, batch 29: loss = 0.011108\n",
      "Epoch 4, batch 30: loss = 0.010584\n",
      "Epoch 4, batch 31: loss = 0.011010\n",
      "Epoch 4, batch 32: loss = 0.010769\n",
      "Epoch 4, batch 33: loss = 0.010761\n",
      "Epoch 4, batch 34: loss = 0.011969\n",
      "Epoch 4, batch 35: loss = 0.011627\n",
      "Epoch 4, batch 36: loss = 0.010709\n",
      "Epoch 4, batch 37: loss = 0.010727\n",
      "Epoch 4, batch 38: loss = 0.010708\n",
      "Epoch 4, batch 39: loss = 0.010594\n",
      "Epoch 4, batch 40: loss = 0.011286\n",
      "Epoch 4, batch 41: loss = 0.011155\n",
      "Epoch 4, batch 42: loss = 0.010906\n",
      "Epoch 4, batch 43: loss = 0.010519\n",
      "Epoch 4, batch 44: loss = 0.010437\n",
      "Epoch 4, batch 45: loss = 0.011806\n",
      "Epoch 4, batch 46: loss = 0.011369\n",
      "Epoch 4, batch 47: loss = 0.011155\n",
      "Epoch 4, batch 48: loss = 0.009996\n",
      "Epoch 4, batch 49: loss = 0.011425\n",
      "Epoch 4, batch 50: loss = 0.011324\n",
      "Epoch 4, batch 51: loss = 0.011713\n",
      "Epoch 4, batch 52: loss = 0.010987\n",
      "Epoch 4, batch 53: loss = 0.011293\n",
      "Epoch 4, batch 54: loss = 0.011259\n",
      "Epoch 4, batch 55: loss = 0.010244\n",
      "Epoch 4, batch 56: loss = 0.010564\n",
      "Epoch 4, batch 57: loss = 0.010732\n",
      "Epoch 4, batch 58: loss = 0.011230\n",
      "Epoch 4, batch 59: loss = 0.011514\n",
      "Epoch 4, batch 60: loss = 0.011082\n",
      "Epoch 4, batch 61: loss = 0.010000\n",
      "Epoch 4, batch 62: loss = 0.011893\n",
      "Epoch 4, batch 63: loss = 0.011486\n",
      "Epoch 4, batch 64: loss = 0.010562\n",
      "Epoch 4, batch 65: loss = 0.010881\n",
      "Epoch 4, batch 66: loss = 0.010646\n",
      "Epoch 4, batch 67: loss = 0.011030\n",
      "Epoch 4, batch 68: loss = 0.010007\n",
      "Epoch 4, batch 69: loss = 0.012328\n",
      "Epoch 4, batch 70: loss = 0.011672\n",
      "Epoch 4, batch 71: loss = 0.011280\n",
      "Epoch 4, batch 72: loss = 0.011870\n",
      "Epoch 4, batch 73: loss = 0.010852\n",
      "Epoch 4, batch 74: loss = 0.012210\n",
      "Epoch 4, batch 75: loss = 0.009982\n",
      "Epoch 4, batch 76: loss = 0.011176\n",
      "Epoch 4, batch 77: loss = 0.010528\n",
      "Epoch 4, batch 78: loss = 0.010637\n",
      "Epoch 4, batch 79: loss = 0.010877\n",
      "Epoch 4, batch 80: loss = 0.011149\n",
      "Epoch 4, batch 81: loss = 0.011729\n",
      "Epoch 4, batch 82: loss = 0.011151\n",
      "Validation\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 4: val_loss = 0.012954\n",
      "Epoch 5, batch 0: loss = 0.010855\n",
      "Epoch 5, batch 1: loss = 0.011204\n",
      "Epoch 5, batch 2: loss = 0.010803\n",
      "Epoch 5, batch 3: loss = 0.010757\n",
      "Epoch 5, batch 4: loss = 0.011166\n",
      "Epoch 5, batch 5: loss = 0.011931\n",
      "Epoch 5, batch 6: loss = 0.011898\n",
      "Epoch 5, batch 7: loss = 0.011405\n",
      "Epoch 5, batch 8: loss = 0.010312\n",
      "Epoch 5, batch 9: loss = 0.011239\n",
      "Epoch 5, batch 10: loss = 0.011329\n",
      "Epoch 5, batch 11: loss = 0.010536\n",
      "Epoch 5, batch 12: loss = 0.010854\n",
      "Epoch 5, batch 13: loss = 0.010962\n",
      "Epoch 5, batch 14: loss = 0.010819\n",
      "Epoch 5, batch 15: loss = 0.011041\n",
      "Epoch 5, batch 16: loss = 0.011084\n",
      "Epoch 5, batch 17: loss = 0.011429\n",
      "Epoch 5, batch 18: loss = 0.010242\n",
      "Epoch 5, batch 19: loss = 0.010530\n",
      "Epoch 5, batch 20: loss = 0.011312\n",
      "Epoch 5, batch 21: loss = 0.010311\n",
      "Epoch 5, batch 22: loss = 0.010896\n",
      "Epoch 5, batch 23: loss = 0.010659\n",
      "Epoch 5, batch 24: loss = 0.010776\n",
      "Epoch 5, batch 25: loss = 0.010917\n",
      "Epoch 5, batch 26: loss = 0.010627\n",
      "Epoch 5, batch 27: loss = 0.010904\n",
      "Epoch 5, batch 28: loss = 0.010007\n",
      "Epoch 5, batch 29: loss = 0.010745\n",
      "Epoch 5, batch 30: loss = 0.012637\n",
      "Epoch 5, batch 31: loss = 0.011150\n",
      "Epoch 5, batch 32: loss = 0.012379\n",
      "Epoch 5, batch 33: loss = 0.012738\n",
      "Epoch 5, batch 34: loss = 0.011407\n",
      "Epoch 5, batch 35: loss = 0.010947\n",
      "Epoch 5, batch 36: loss = 0.012340\n",
      "Epoch 5, batch 37: loss = 0.010823\n",
      "Epoch 5, batch 38: loss = 0.011309\n",
      "Epoch 5, batch 39: loss = 0.010504\n",
      "Epoch 5, batch 40: loss = 0.010797\n",
      "Epoch 5, batch 41: loss = 0.010751\n",
      "Epoch 5, batch 42: loss = 0.011593\n",
      "Epoch 5, batch 43: loss = 0.010080\n",
      "Epoch 5, batch 44: loss = 0.010180\n",
      "Epoch 5, batch 45: loss = 0.011022\n",
      "Epoch 5, batch 46: loss = 0.010617\n",
      "Epoch 5, batch 47: loss = 0.011551\n",
      "Epoch 5, batch 48: loss = 0.010299\n",
      "Epoch 5, batch 49: loss = 0.011645\n",
      "Epoch 5, batch 50: loss = 0.010242\n",
      "Epoch 5, batch 51: loss = 0.011133\n",
      "Epoch 5, batch 52: loss = 0.010095\n",
      "Epoch 5, batch 53: loss = 0.010914\n",
      "Epoch 5, batch 54: loss = 0.010483\n",
      "Epoch 5, batch 55: loss = 0.011871\n",
      "Epoch 5, batch 56: loss = 0.011037\n",
      "Epoch 5, batch 57: loss = 0.009920\n",
      "Epoch 5, batch 58: loss = 0.010792\n",
      "Epoch 5, batch 59: loss = 0.010451\n",
      "Epoch 5, batch 60: loss = 0.010853\n",
      "Epoch 5, batch 61: loss = 0.011241\n",
      "Epoch 5, batch 62: loss = 0.009927\n",
      "Epoch 5, batch 63: loss = 0.010656\n",
      "Epoch 5, batch 64: loss = 0.010038\n",
      "Epoch 5, batch 65: loss = 0.011167\n",
      "Epoch 5, batch 66: loss = 0.011515\n",
      "Epoch 5, batch 67: loss = 0.010331\n",
      "Epoch 5, batch 68: loss = 0.010778\n",
      "Epoch 5, batch 69: loss = 0.010763\n",
      "Epoch 5, batch 70: loss = 0.011512\n",
      "Epoch 5, batch 71: loss = 0.010146\n",
      "Epoch 5, batch 72: loss = 0.011150\n",
      "Epoch 5, batch 73: loss = 0.010943\n",
      "Epoch 5, batch 74: loss = 0.010970\n",
      "Epoch 5, batch 75: loss = 0.010832\n",
      "Epoch 5, batch 76: loss = 0.010535\n",
      "Epoch 5, batch 77: loss = 0.010295\n",
      "Epoch 5, batch 78: loss = 0.010386\n",
      "Epoch 5, batch 79: loss = 0.010436\n",
      "Epoch 5, batch 80: loss = 0.010970\n",
      "Epoch 5, batch 81: loss = 0.011451\n",
      "Epoch 5, batch 82: loss = 0.009273\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 5: val_loss = 0.012106\n",
      "Epoch 6, batch 0: loss = 0.010751\n",
      "Epoch 6, batch 1: loss = 0.010762\n",
      "Epoch 6, batch 2: loss = 0.010753\n",
      "Epoch 6, batch 3: loss = 0.010348\n",
      "Epoch 6, batch 4: loss = 0.011006\n",
      "Epoch 6, batch 5: loss = 0.010358\n",
      "Epoch 6, batch 6: loss = 0.010473\n",
      "Epoch 6, batch 7: loss = 0.010477\n",
      "Epoch 6, batch 8: loss = 0.011161\n",
      "Epoch 6, batch 9: loss = 0.012228\n",
      "Epoch 6, batch 10: loss = 0.012331\n",
      "Epoch 6, batch 11: loss = 0.011229\n",
      "Epoch 6, batch 12: loss = 0.010594\n",
      "Epoch 6, batch 13: loss = 0.010487\n",
      "Epoch 6, batch 14: loss = 0.011525\n",
      "Epoch 6, batch 15: loss = 0.011800\n",
      "Epoch 6, batch 16: loss = 0.012050\n",
      "Epoch 6, batch 17: loss = 0.010772\n",
      "Epoch 6, batch 18: loss = 0.010254\n",
      "Epoch 6, batch 19: loss = 0.011482\n",
      "Epoch 6, batch 20: loss = 0.009616\n",
      "Epoch 6, batch 21: loss = 0.011585\n",
      "Epoch 6, batch 22: loss = 0.010008\n",
      "Epoch 6, batch 23: loss = 0.009813\n",
      "Epoch 6, batch 24: loss = 0.010889\n",
      "Epoch 6, batch 25: loss = 0.010562\n",
      "Epoch 6, batch 26: loss = 0.010665\n",
      "Epoch 6, batch 27: loss = 0.010681\n",
      "Epoch 6, batch 28: loss = 0.010494\n",
      "Epoch 6, batch 29: loss = 0.010679\n",
      "Epoch 6, batch 30: loss = 0.010448\n",
      "Epoch 6, batch 31: loss = 0.011493\n",
      "Epoch 6, batch 32: loss = 0.010869\n",
      "Epoch 6, batch 33: loss = 0.011856\n",
      "Epoch 6, batch 34: loss = 0.010928\n",
      "Epoch 6, batch 35: loss = 0.010504\n",
      "Epoch 6, batch 36: loss = 0.010441\n",
      "Epoch 6, batch 37: loss = 0.010515\n",
      "Epoch 6, batch 38: loss = 0.010791\n",
      "Epoch 6, batch 39: loss = 0.010623\n",
      "Epoch 6, batch 40: loss = 0.010430\n",
      "Epoch 6, batch 41: loss = 0.011327\n",
      "Epoch 6, batch 42: loss = 0.011633\n",
      "Epoch 6, batch 43: loss = 0.011834\n",
      "Epoch 6, batch 44: loss = 0.010096\n",
      "Epoch 6, batch 45: loss = 0.011190\n",
      "Epoch 6, batch 46: loss = 0.012139\n",
      "Epoch 6, batch 47: loss = 0.011771\n",
      "Epoch 6, batch 48: loss = 0.011109\n",
      "Epoch 6, batch 49: loss = 0.010199\n",
      "Epoch 6, batch 50: loss = 0.011303\n",
      "Epoch 6, batch 51: loss = 0.011043\n",
      "Epoch 6, batch 52: loss = 0.011552\n",
      "Epoch 6, batch 53: loss = 0.010846\n",
      "Epoch 6, batch 54: loss = 0.011374\n",
      "Epoch 6, batch 55: loss = 0.011070\n",
      "Epoch 6, batch 56: loss = 0.010388\n",
      "Epoch 6, batch 57: loss = 0.010037\n",
      "Epoch 6, batch 58: loss = 0.011077\n",
      "Epoch 6, batch 59: loss = 0.010630\n",
      "Epoch 6, batch 60: loss = 0.010827\n",
      "Epoch 6, batch 61: loss = 0.011418\n",
      "Epoch 6, batch 62: loss = 0.009928\n",
      "Epoch 6, batch 63: loss = 0.010686\n",
      "Epoch 6, batch 64: loss = 0.010451\n",
      "Epoch 6, batch 65: loss = 0.009587\n",
      "Epoch 6, batch 66: loss = 0.010655\n",
      "Epoch 6, batch 67: loss = 0.009744\n",
      "Epoch 6, batch 68: loss = 0.010581\n",
      "Epoch 6, batch 69: loss = 0.009658\n",
      "Epoch 6, batch 70: loss = 0.010166\n",
      "Epoch 6, batch 71: loss = 0.010862\n",
      "Epoch 6, batch 72: loss = 0.010650\n",
      "Epoch 6, batch 73: loss = 0.010943\n",
      "Epoch 6, batch 74: loss = 0.011625\n",
      "Epoch 6, batch 75: loss = 0.010637\n",
      "Epoch 6, batch 76: loss = 0.010096\n",
      "Epoch 6, batch 77: loss = 0.009895\n",
      "Epoch 6, batch 78: loss = 0.010008\n",
      "Epoch 6, batch 79: loss = 0.011006\n",
      "Epoch 6, batch 80: loss = 0.010351\n",
      "Epoch 6, batch 81: loss = 0.010069\n",
      "Epoch 6, batch 82: loss = 0.008824\n",
      "Validation\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 6: val_loss = 0.011913\n",
      "Epoch 7, batch 0: loss = 0.010342\n",
      "Epoch 7, batch 1: loss = 0.011398\n",
      "Epoch 7, batch 2: loss = 0.011632\n",
      "Epoch 7, batch 3: loss = 0.011110\n",
      "Epoch 7, batch 4: loss = 0.011228\n",
      "Epoch 7, batch 5: loss = 0.011675\n",
      "Epoch 7, batch 6: loss = 0.010820\n",
      "Epoch 7, batch 7: loss = 0.010615\n",
      "Epoch 7, batch 8: loss = 0.011691\n",
      "Epoch 7, batch 9: loss = 0.012012\n",
      "Epoch 7, batch 10: loss = 0.011471\n",
      "Epoch 7, batch 11: loss = 0.010371\n",
      "Epoch 7, batch 12: loss = 0.010694\n",
      "Epoch 7, batch 13: loss = 0.010308\n",
      "Epoch 7, batch 14: loss = 0.010587\n",
      "Epoch 7, batch 15: loss = 0.011096\n",
      "Epoch 7, batch 16: loss = 0.011411\n",
      "Epoch 7, batch 17: loss = 0.010549\n",
      "Epoch 7, batch 18: loss = 0.011483\n",
      "Epoch 7, batch 19: loss = 0.009905\n",
      "Epoch 7, batch 20: loss = 0.011104\n",
      "Epoch 7, batch 21: loss = 0.011077\n",
      "Epoch 7, batch 22: loss = 0.010075\n",
      "Epoch 7, batch 23: loss = 0.009580\n",
      "Epoch 7, batch 24: loss = 0.011328\n",
      "Epoch 7, batch 25: loss = 0.009855\n",
      "Epoch 7, batch 26: loss = 0.009723\n",
      "Epoch 7, batch 27: loss = 0.011284\n",
      "Epoch 7, batch 28: loss = 0.010691\n",
      "Epoch 7, batch 29: loss = 0.009697\n",
      "Epoch 7, batch 30: loss = 0.010256\n",
      "Epoch 7, batch 31: loss = 0.010182\n",
      "Epoch 7, batch 32: loss = 0.011173\n",
      "Epoch 7, batch 33: loss = 0.010338\n",
      "Epoch 7, batch 34: loss = 0.010490\n",
      "Epoch 7, batch 35: loss = 0.010888\n",
      "Epoch 7, batch 36: loss = 0.011154\n",
      "Epoch 7, batch 37: loss = 0.011132\n",
      "Epoch 7, batch 38: loss = 0.010149\n",
      "Epoch 7, batch 39: loss = 0.010848\n",
      "Epoch 7, batch 40: loss = 0.011840\n",
      "Epoch 7, batch 41: loss = 0.011172\n",
      "Epoch 7, batch 42: loss = 0.009859\n",
      "Epoch 7, batch 43: loss = 0.011513\n",
      "Epoch 7, batch 44: loss = 0.010404\n",
      "Epoch 7, batch 45: loss = 0.011034\n",
      "Epoch 7, batch 46: loss = 0.009954\n",
      "Epoch 7, batch 47: loss = 0.010021\n",
      "Epoch 7, batch 48: loss = 0.009888\n",
      "Epoch 7, batch 49: loss = 0.010579\n",
      "Epoch 7, batch 50: loss = 0.011196\n",
      "Epoch 7, batch 51: loss = 0.010921\n",
      "Epoch 7, batch 52: loss = 0.011295\n",
      "Epoch 7, batch 53: loss = 0.010772\n",
      "Epoch 7, batch 54: loss = 0.010897\n",
      "Epoch 7, batch 55: loss = 0.009894\n",
      "Epoch 7, batch 56: loss = 0.010600\n",
      "Epoch 7, batch 57: loss = 0.009773\n",
      "Epoch 7, batch 58: loss = 0.010839\n",
      "Epoch 7, batch 59: loss = 0.010061\n",
      "Epoch 7, batch 60: loss = 0.009933\n",
      "Epoch 7, batch 61: loss = 0.010972\n",
      "Epoch 7, batch 62: loss = 0.009908\n",
      "Epoch 7, batch 63: loss = 0.010895\n",
      "Epoch 7, batch 64: loss = 0.009958\n",
      "Epoch 7, batch 65: loss = 0.010046\n",
      "Epoch 7, batch 66: loss = 0.009352\n",
      "Epoch 7, batch 67: loss = 0.009949\n",
      "Epoch 7, batch 68: loss = 0.010454\n",
      "Epoch 7, batch 69: loss = 0.009431\n",
      "Epoch 7, batch 70: loss = 0.011162\n",
      "Epoch 7, batch 71: loss = 0.010598\n",
      "Epoch 7, batch 72: loss = 0.011171\n",
      "Epoch 7, batch 73: loss = 0.010660\n",
      "Epoch 7, batch 74: loss = 0.009874\n",
      "Epoch 7, batch 75: loss = 0.010706\n",
      "Epoch 7, batch 76: loss = 0.010084\n",
      "Epoch 7, batch 77: loss = 0.010304\n",
      "Epoch 7, batch 78: loss = 0.010691\n",
      "Epoch 7, batch 79: loss = 0.010504\n",
      "Epoch 7, batch 80: loss = 0.009934\n",
      "Epoch 7, batch 81: loss = 0.010253\n",
      "Epoch 7, batch 82: loss = 0.015081\n",
      "Validation\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 7: val_loss = 0.014152\n",
      "Epoch 8, batch 0: loss = 0.011624\n",
      "Epoch 8, batch 1: loss = 0.010470\n",
      "Epoch 8, batch 2: loss = 0.011382\n",
      "Epoch 8, batch 3: loss = 0.011790\n",
      "Epoch 8, batch 4: loss = 0.011499\n",
      "Epoch 8, batch 5: loss = 0.011965\n",
      "Epoch 8, batch 6: loss = 0.011050\n",
      "Epoch 8, batch 7: loss = 0.011179\n",
      "Epoch 8, batch 8: loss = 0.011848\n",
      "Epoch 8, batch 9: loss = 0.011296\n",
      "Epoch 8, batch 10: loss = 0.011407\n",
      "Epoch 8, batch 11: loss = 0.011488\n",
      "Epoch 8, batch 12: loss = 0.010291\n",
      "Epoch 8, batch 13: loss = 0.011414\n",
      "Epoch 8, batch 14: loss = 0.009918\n",
      "Epoch 8, batch 15: loss = 0.010537\n",
      "Epoch 8, batch 16: loss = 0.011227\n",
      "Epoch 8, batch 17: loss = 0.009702\n",
      "Epoch 8, batch 18: loss = 0.010242\n",
      "Epoch 8, batch 19: loss = 0.010915\n",
      "Epoch 8, batch 20: loss = 0.010220\n",
      "Epoch 8, batch 21: loss = 0.010905\n",
      "Epoch 8, batch 22: loss = 0.012056\n",
      "Epoch 8, batch 23: loss = 0.011091\n",
      "Epoch 8, batch 24: loss = 0.010408\n",
      "Epoch 8, batch 25: loss = 0.011023\n",
      "Epoch 8, batch 26: loss = 0.010131\n",
      "Epoch 8, batch 27: loss = 0.010844\n",
      "Epoch 8, batch 28: loss = 0.010178\n",
      "Epoch 8, batch 29: loss = 0.010354\n",
      "Epoch 8, batch 30: loss = 0.010467\n",
      "Epoch 8, batch 31: loss = 0.009503\n",
      "Epoch 8, batch 32: loss = 0.010344\n",
      "Epoch 8, batch 33: loss = 0.010467\n",
      "Epoch 8, batch 34: loss = 0.010046\n",
      "Epoch 8, batch 35: loss = 0.010008\n",
      "Epoch 8, batch 36: loss = 0.010244\n",
      "Epoch 8, batch 37: loss = 0.010327\n",
      "Epoch 8, batch 38: loss = 0.010333\n",
      "Epoch 8, batch 39: loss = 0.010161\n",
      "Epoch 8, batch 40: loss = 0.009953\n",
      "Epoch 8, batch 41: loss = 0.010689\n",
      "Epoch 8, batch 42: loss = 0.010309\n",
      "Epoch 8, batch 43: loss = 0.010292\n",
      "Epoch 8, batch 44: loss = 0.010249\n",
      "Epoch 8, batch 45: loss = 0.010755\n",
      "Epoch 8, batch 46: loss = 0.010318\n",
      "Epoch 8, batch 47: loss = 0.009819\n",
      "Epoch 8, batch 48: loss = 0.010717\n",
      "Epoch 8, batch 49: loss = 0.010071\n",
      "Epoch 8, batch 50: loss = 0.009682\n",
      "Epoch 8, batch 51: loss = 0.010334\n",
      "Epoch 8, batch 52: loss = 0.010702\n",
      "Epoch 8, batch 53: loss = 0.010389\n",
      "Epoch 8, batch 54: loss = 0.010056\n",
      "Epoch 8, batch 55: loss = 0.009648\n",
      "Epoch 8, batch 56: loss = 0.009818\n",
      "Epoch 8, batch 57: loss = 0.010155\n",
      "Epoch 8, batch 58: loss = 0.009624\n",
      "Epoch 8, batch 59: loss = 0.009749\n",
      "Epoch 8, batch 60: loss = 0.010260\n",
      "Epoch 8, batch 61: loss = 0.010577\n",
      "Epoch 8, batch 62: loss = 0.010067\n",
      "Epoch 8, batch 63: loss = 0.010729\n",
      "Epoch 8, batch 64: loss = 0.010074\n",
      "Epoch 8, batch 65: loss = 0.010302\n",
      "Epoch 8, batch 66: loss = 0.009701\n",
      "Epoch 8, batch 67: loss = 0.010128\n",
      "Epoch 8, batch 68: loss = 0.011220\n",
      "Epoch 8, batch 69: loss = 0.009791\n",
      "Epoch 8, batch 70: loss = 0.010825\n",
      "Epoch 8, batch 71: loss = 0.010299\n",
      "Epoch 8, batch 72: loss = 0.009797\n",
      "Epoch 8, batch 73: loss = 0.010783\n",
      "Epoch 8, batch 74: loss = 0.010587\n",
      "Epoch 8, batch 75: loss = 0.009774\n",
      "Epoch 8, batch 76: loss = 0.010134\n",
      "Epoch 8, batch 77: loss = 0.009493\n",
      "Epoch 8, batch 78: loss = 0.010294\n",
      "Epoch 8, batch 79: loss = 0.010327\n",
      "Epoch 8, batch 80: loss = 0.010304\n",
      "Epoch 8, batch 81: loss = 0.009976\n",
      "Epoch 8, batch 82: loss = 0.009513\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 8: val_loss = 0.011669\n",
      "Epoch 9, batch 0: loss = 0.011342\n",
      "Epoch 9, batch 1: loss = 0.011752\n",
      "Epoch 9, batch 2: loss = 0.011824\n",
      "Epoch 9, batch 3: loss = 0.011168\n",
      "Epoch 9, batch 4: loss = 0.010990\n",
      "Epoch 9, batch 5: loss = 0.009527\n",
      "Epoch 9, batch 6: loss = 0.010911\n",
      "Epoch 9, batch 7: loss = 0.009793\n",
      "Epoch 9, batch 8: loss = 0.009956\n",
      "Epoch 9, batch 9: loss = 0.010373\n",
      "Epoch 9, batch 10: loss = 0.010919\n",
      "Epoch 9, batch 11: loss = 0.010576\n",
      "Epoch 9, batch 12: loss = 0.011077\n",
      "Epoch 9, batch 13: loss = 0.011031\n",
      "Epoch 9, batch 14: loss = 0.010136\n",
      "Epoch 9, batch 15: loss = 0.010135\n",
      "Epoch 9, batch 16: loss = 0.011275\n",
      "Epoch 9, batch 17: loss = 0.011256\n",
      "Epoch 9, batch 18: loss = 0.010333\n",
      "Epoch 9, batch 19: loss = 0.010876\n",
      "Epoch 9, batch 20: loss = 0.010154\n",
      "Epoch 9, batch 21: loss = 0.010747\n",
      "Epoch 9, batch 22: loss = 0.009754\n",
      "Epoch 9, batch 23: loss = 0.009375\n",
      "Epoch 9, batch 24: loss = 0.010883\n",
      "Epoch 9, batch 25: loss = 0.010156\n",
      "Epoch 9, batch 26: loss = 0.010540\n",
      "Epoch 9, batch 27: loss = 0.010513\n",
      "Epoch 9, batch 28: loss = 0.009930\n",
      "Epoch 9, batch 29: loss = 0.010286\n",
      "Epoch 9, batch 30: loss = 0.010782\n",
      "Epoch 9, batch 31: loss = 0.010253\n",
      "Epoch 9, batch 32: loss = 0.009296\n",
      "Epoch 9, batch 33: loss = 0.010200\n",
      "Epoch 9, batch 34: loss = 0.010110\n",
      "Epoch 9, batch 35: loss = 0.009947\n",
      "Epoch 9, batch 36: loss = 0.009525\n",
      "Epoch 9, batch 37: loss = 0.011351\n",
      "Epoch 9, batch 38: loss = 0.009502\n",
      "Epoch 9, batch 39: loss = 0.009599\n",
      "Epoch 9, batch 40: loss = 0.010005\n",
      "Epoch 9, batch 41: loss = 0.011048\n",
      "Epoch 9, batch 42: loss = 0.010944\n",
      "Epoch 9, batch 43: loss = 0.010900\n",
      "Epoch 9, batch 44: loss = 0.010230\n",
      "Epoch 9, batch 45: loss = 0.010378\n",
      "Epoch 9, batch 46: loss = 0.010152\n",
      "Epoch 9, batch 47: loss = 0.010493\n",
      "Epoch 9, batch 48: loss = 0.010039\n",
      "Epoch 9, batch 49: loss = 0.009441\n",
      "Epoch 9, batch 50: loss = 0.010636\n",
      "Epoch 9, batch 51: loss = 0.009652\n",
      "Epoch 9, batch 52: loss = 0.010131\n",
      "Epoch 9, batch 53: loss = 0.008894\n",
      "Epoch 9, batch 54: loss = 0.010897\n",
      "Epoch 9, batch 55: loss = 0.010646\n",
      "Epoch 9, batch 56: loss = 0.010979\n",
      "Epoch 9, batch 57: loss = 0.009246\n",
      "Epoch 9, batch 58: loss = 0.009344\n",
      "Epoch 9, batch 59: loss = 0.010651\n",
      "Epoch 9, batch 60: loss = 0.009187\n",
      "Epoch 9, batch 61: loss = 0.009990\n",
      "Epoch 9, batch 62: loss = 0.010796\n",
      "Epoch 9, batch 63: loss = 0.010969\n",
      "Epoch 9, batch 64: loss = 0.010188\n",
      "Epoch 9, batch 65: loss = 0.009989\n",
      "Epoch 9, batch 66: loss = 0.010400\n",
      "Epoch 9, batch 67: loss = 0.009911\n",
      "Epoch 9, batch 68: loss = 0.010009\n",
      "Epoch 9, batch 69: loss = 0.010424\n",
      "Epoch 9, batch 70: loss = 0.009232\n",
      "Epoch 9, batch 71: loss = 0.009509\n",
      "Epoch 9, batch 72: loss = 0.010275\n",
      "Epoch 9, batch 73: loss = 0.009946\n",
      "Epoch 9, batch 74: loss = 0.009343\n",
      "Epoch 9, batch 75: loss = 0.010238\n",
      "Epoch 9, batch 76: loss = 0.009419\n",
      "Epoch 9, batch 77: loss = 0.010226\n",
      "Epoch 9, batch 78: loss = 0.009774\n",
      "Epoch 9, batch 79: loss = 0.010199\n",
      "Epoch 9, batch 80: loss = 0.011080\n",
      "Epoch 9, batch 81: loss = 0.009467\n",
      "Epoch 9, batch 82: loss = 0.008553\n",
      "Validation\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 9: val_loss = 0.012060\n",
      "Epoch 10, batch 0: loss = 0.009358\n",
      "Epoch 10, batch 1: loss = 0.010096\n",
      "Epoch 10, batch 2: loss = 0.010266\n",
      "Epoch 10, batch 3: loss = 0.010487\n",
      "Epoch 10, batch 4: loss = 0.009947\n",
      "Epoch 10, batch 5: loss = 0.010169\n",
      "Epoch 10, batch 6: loss = 0.010827\n",
      "Epoch 10, batch 7: loss = 0.010554\n",
      "Epoch 10, batch 8: loss = 0.010371\n",
      "Epoch 10, batch 9: loss = 0.011171\n",
      "Epoch 10, batch 10: loss = 0.009905\n",
      "Epoch 10, batch 11: loss = 0.010096\n",
      "Epoch 10, batch 12: loss = 0.010386\n",
      "Epoch 10, batch 13: loss = 0.010801\n",
      "Epoch 10, batch 14: loss = 0.010200\n",
      "Epoch 10, batch 15: loss = 0.009764\n",
      "Epoch 10, batch 16: loss = 0.010481\n",
      "Epoch 10, batch 17: loss = 0.009793\n",
      "Epoch 10, batch 18: loss = 0.009817\n",
      "Epoch 10, batch 19: loss = 0.010142\n",
      "Epoch 10, batch 20: loss = 0.009596\n",
      "Epoch 10, batch 21: loss = 0.010066\n",
      "Epoch 10, batch 22: loss = 0.009556\n",
      "Epoch 10, batch 23: loss = 0.010468\n",
      "Epoch 10, batch 24: loss = 0.009586\n",
      "Epoch 10, batch 25: loss = 0.010200\n",
      "Epoch 10, batch 26: loss = 0.010384\n",
      "Epoch 10, batch 27: loss = 0.010240\n",
      "Epoch 10, batch 28: loss = 0.009990\n",
      "Epoch 10, batch 29: loss = 0.010807\n",
      "Epoch 10, batch 30: loss = 0.009344\n",
      "Epoch 10, batch 31: loss = 0.009336\n",
      "Epoch 10, batch 32: loss = 0.009599\n",
      "Epoch 10, batch 33: loss = 0.010144\n",
      "Epoch 10, batch 34: loss = 0.009734\n",
      "Epoch 10, batch 35: loss = 0.010057\n",
      "Epoch 10, batch 36: loss = 0.009967\n",
      "Epoch 10, batch 37: loss = 0.009267\n",
      "Epoch 10, batch 38: loss = 0.010558\n",
      "Epoch 10, batch 39: loss = 0.010033\n",
      "Epoch 10, batch 40: loss = 0.010740\n",
      "Epoch 10, batch 41: loss = 0.009765\n",
      "Epoch 10, batch 42: loss = 0.010168\n",
      "Epoch 10, batch 43: loss = 0.009919\n",
      "Epoch 10, batch 44: loss = 0.009548\n",
      "Epoch 10, batch 45: loss = 0.009737\n",
      "Epoch 10, batch 46: loss = 0.009034\n",
      "Epoch 10, batch 47: loss = 0.010152\n",
      "Epoch 10, batch 48: loss = 0.010792\n",
      "Epoch 10, batch 49: loss = 0.009883\n",
      "Epoch 10, batch 50: loss = 0.009513\n",
      "Epoch 10, batch 51: loss = 0.009614\n",
      "Epoch 10, batch 52: loss = 0.009779\n",
      "Epoch 10, batch 53: loss = 0.010089\n",
      "Epoch 10, batch 54: loss = 0.009581\n",
      "Epoch 10, batch 55: loss = 0.009993\n",
      "Epoch 10, batch 56: loss = 0.009795\n",
      "Epoch 10, batch 57: loss = 0.009773\n",
      "Epoch 10, batch 58: loss = 0.010218\n",
      "Epoch 10, batch 59: loss = 0.009038\n",
      "Epoch 10, batch 60: loss = 0.009959\n",
      "Epoch 10, batch 61: loss = 0.009310\n",
      "Epoch 10, batch 62: loss = 0.009860\n",
      "Epoch 10, batch 63: loss = 0.009668\n",
      "Epoch 10, batch 64: loss = 0.010985\n",
      "Epoch 10, batch 65: loss = 0.009560\n",
      "Epoch 10, batch 66: loss = 0.009826\n",
      "Epoch 10, batch 67: loss = 0.009509\n",
      "Epoch 10, batch 68: loss = 0.009313\n",
      "Epoch 10, batch 69: loss = 0.010574\n",
      "Epoch 10, batch 70: loss = 0.009711\n",
      "Epoch 10, batch 71: loss = 0.009879\n",
      "Epoch 10, batch 72: loss = 0.010149\n",
      "Epoch 10, batch 73: loss = 0.009709\n",
      "Epoch 10, batch 74: loss = 0.009793\n",
      "Epoch 10, batch 75: loss = 0.009518\n",
      "Epoch 10, batch 76: loss = 0.009909\n",
      "Epoch 10, batch 77: loss = 0.010246\n",
      "Epoch 10, batch 78: loss = 0.009841\n",
      "Epoch 10, batch 79: loss = 0.009967\n",
      "Epoch 10, batch 80: loss = 0.009529\n",
      "Epoch 10, batch 81: loss = 0.009602\n",
      "Epoch 10, batch 82: loss = 0.007950\n",
      "Validation\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 10: val_loss = 0.011931\n",
      "Epoch 11, batch 0: loss = 0.011076\n",
      "Epoch 11, batch 1: loss = 0.010420\n",
      "Epoch 11, batch 2: loss = 0.010929\n",
      "Epoch 11, batch 3: loss = 0.010154\n",
      "Epoch 11, batch 4: loss = 0.010469\n",
      "Epoch 11, batch 5: loss = 0.009561\n",
      "Epoch 11, batch 6: loss = 0.008882\n",
      "Epoch 11, batch 7: loss = 0.009815\n",
      "Epoch 11, batch 8: loss = 0.009940\n",
      "Epoch 11, batch 9: loss = 0.009210\n",
      "Epoch 11, batch 10: loss = 0.010330\n",
      "Epoch 11, batch 11: loss = 0.010417\n",
      "Epoch 11, batch 12: loss = 0.010635\n",
      "Epoch 11, batch 13: loss = 0.009699\n",
      "Epoch 11, batch 14: loss = 0.010052\n",
      "Epoch 11, batch 15: loss = 0.011011\n",
      "Epoch 11, batch 16: loss = 0.010166\n",
      "Epoch 11, batch 17: loss = 0.009784\n",
      "Epoch 11, batch 18: loss = 0.009611\n",
      "Epoch 11, batch 19: loss = 0.009860\n",
      "Epoch 11, batch 20: loss = 0.009253\n",
      "Epoch 11, batch 21: loss = 0.009725\n",
      "Epoch 11, batch 22: loss = 0.010114\n",
      "Epoch 11, batch 23: loss = 0.010386\n",
      "Epoch 11, batch 24: loss = 0.009778\n",
      "Epoch 11, batch 25: loss = 0.009892\n",
      "Epoch 11, batch 26: loss = 0.010233\n",
      "Epoch 11, batch 27: loss = 0.009323\n",
      "Epoch 11, batch 28: loss = 0.010175\n",
      "Epoch 11, batch 29: loss = 0.010742\n",
      "Epoch 11, batch 30: loss = 0.009145\n",
      "Epoch 11, batch 31: loss = 0.009651\n",
      "Epoch 11, batch 32: loss = 0.009434\n",
      "Epoch 11, batch 33: loss = 0.009134\n",
      "Epoch 11, batch 34: loss = 0.009872\n",
      "Epoch 11, batch 35: loss = 0.010048\n",
      "Epoch 11, batch 36: loss = 0.010317\n",
      "Epoch 11, batch 37: loss = 0.009633\n",
      "Epoch 11, batch 38: loss = 0.010753\n",
      "Epoch 11, batch 39: loss = 0.009483\n",
      "Epoch 11, batch 40: loss = 0.010200\n",
      "Epoch 11, batch 41: loss = 0.011054\n",
      "Epoch 11, batch 42: loss = 0.010577\n",
      "Epoch 11, batch 43: loss = 0.009393\n",
      "Epoch 11, batch 44: loss = 0.009543\n",
      "Epoch 11, batch 45: loss = 0.008926\n",
      "Epoch 11, batch 46: loss = 0.009268\n",
      "Epoch 11, batch 47: loss = 0.010029\n",
      "Epoch 11, batch 48: loss = 0.010190\n",
      "Epoch 11, batch 49: loss = 0.010138\n",
      "Epoch 11, batch 50: loss = 0.008795\n",
      "Epoch 11, batch 51: loss = 0.009455\n",
      "Epoch 11, batch 52: loss = 0.009591\n",
      "Epoch 11, batch 53: loss = 0.010043\n",
      "Epoch 11, batch 54: loss = 0.009308\n",
      "Epoch 11, batch 55: loss = 0.009546\n",
      "Epoch 11, batch 56: loss = 0.009919\n",
      "Epoch 11, batch 57: loss = 0.009310\n",
      "Epoch 11, batch 58: loss = 0.009917\n",
      "Epoch 11, batch 59: loss = 0.009940\n",
      "Epoch 11, batch 60: loss = 0.009209\n",
      "Epoch 11, batch 61: loss = 0.009358\n",
      "Epoch 11, batch 62: loss = 0.009479\n",
      "Epoch 11, batch 63: loss = 0.008677\n",
      "Epoch 11, batch 64: loss = 0.009068\n",
      "Epoch 11, batch 65: loss = 0.010224\n",
      "Epoch 11, batch 66: loss = 0.009664\n",
      "Epoch 11, batch 67: loss = 0.009438\n",
      "Epoch 11, batch 68: loss = 0.010618\n",
      "Epoch 11, batch 69: loss = 0.009943\n",
      "Epoch 11, batch 70: loss = 0.009990\n",
      "Epoch 11, batch 71: loss = 0.009511\n",
      "Epoch 11, batch 72: loss = 0.009936\n",
      "Epoch 11, batch 73: loss = 0.009912\n",
      "Epoch 11, batch 74: loss = 0.009261\n",
      "Epoch 11, batch 75: loss = 0.009933\n",
      "Epoch 11, batch 76: loss = 0.010608\n",
      "Epoch 11, batch 77: loss = 0.009426\n",
      "Epoch 11, batch 78: loss = 0.009201\n",
      "Epoch 11, batch 79: loss = 0.009015\n",
      "Epoch 11, batch 80: loss = 0.010563\n",
      "Epoch 11, batch 81: loss = 0.009780\n",
      "Epoch 11, batch 82: loss = 0.008528\n",
      "Validation\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 11: val_loss = 0.012038\n",
      "Epoch 12, batch 0: loss = 0.010075\n",
      "Epoch 12, batch 1: loss = 0.010935\n",
      "Epoch 12, batch 2: loss = 0.009582\n",
      "Epoch 12, batch 3: loss = 0.010975\n",
      "Epoch 12, batch 4: loss = 0.009673\n",
      "Epoch 12, batch 5: loss = 0.010268\n",
      "Epoch 12, batch 6: loss = 0.009320\n",
      "Epoch 12, batch 7: loss = 0.009230\n",
      "Epoch 12, batch 8: loss = 0.009542\n",
      "Epoch 12, batch 9: loss = 0.009929\n",
      "Epoch 12, batch 10: loss = 0.009088\n",
      "Epoch 12, batch 11: loss = 0.009458\n",
      "Epoch 12, batch 12: loss = 0.009068\n",
      "Epoch 12, batch 13: loss = 0.008795\n",
      "Epoch 12, batch 14: loss = 0.010323\n",
      "Epoch 12, batch 15: loss = 0.009458\n",
      "Epoch 12, batch 16: loss = 0.009818\n",
      "Epoch 12, batch 17: loss = 0.009123\n",
      "Epoch 12, batch 18: loss = 0.009639\n",
      "Epoch 12, batch 19: loss = 0.009946\n",
      "Epoch 12, batch 20: loss = 0.009328\n",
      "Epoch 12, batch 21: loss = 0.009187\n",
      "Epoch 12, batch 22: loss = 0.009669\n",
      "Epoch 12, batch 23: loss = 0.009553\n",
      "Epoch 12, batch 24: loss = 0.009936\n",
      "Epoch 12, batch 25: loss = 0.009980\n",
      "Epoch 12, batch 26: loss = 0.009415\n",
      "Epoch 12, batch 27: loss = 0.009187\n",
      "Epoch 12, batch 28: loss = 0.009795\n",
      "Epoch 12, batch 29: loss = 0.009403\n",
      "Epoch 12, batch 30: loss = 0.009779\n",
      "Epoch 12, batch 31: loss = 0.009571\n",
      "Epoch 12, batch 32: loss = 0.008867\n",
      "Epoch 12, batch 33: loss = 0.009390\n",
      "Epoch 12, batch 34: loss = 0.009860\n",
      "Epoch 12, batch 35: loss = 0.009504\n",
      "Epoch 12, batch 36: loss = 0.009243\n",
      "Epoch 12, batch 37: loss = 0.009226\n",
      "Epoch 12, batch 38: loss = 0.009585\n",
      "Epoch 12, batch 39: loss = 0.009858\n",
      "Epoch 12, batch 40: loss = 0.009965\n",
      "Epoch 12, batch 41: loss = 0.009135\n",
      "Epoch 12, batch 42: loss = 0.009641\n",
      "Epoch 12, batch 43: loss = 0.008793\n",
      "Epoch 12, batch 44: loss = 0.009108\n",
      "Epoch 12, batch 45: loss = 0.009548\n",
      "Epoch 12, batch 46: loss = 0.009428\n",
      "Epoch 12, batch 47: loss = 0.009216\n",
      "Epoch 12, batch 48: loss = 0.008971\n",
      "Epoch 12, batch 49: loss = 0.008913\n",
      "Epoch 12, batch 50: loss = 0.008097\n",
      "Epoch 12, batch 51: loss = 0.009826\n",
      "Epoch 12, batch 52: loss = 0.009440\n",
      "Epoch 12, batch 53: loss = 0.009221\n",
      "Epoch 12, batch 54: loss = 0.009437\n",
      "Epoch 12, batch 55: loss = 0.009036\n",
      "Epoch 12, batch 56: loss = 0.009327\n",
      "Epoch 12, batch 57: loss = 0.008965\n",
      "Epoch 12, batch 58: loss = 0.009415\n",
      "Epoch 12, batch 59: loss = 0.009586\n",
      "Epoch 12, batch 60: loss = 0.008915\n",
      "Epoch 12, batch 61: loss = 0.009415\n",
      "Epoch 12, batch 62: loss = 0.008975\n",
      "Epoch 12, batch 63: loss = 0.009123\n",
      "Epoch 12, batch 64: loss = 0.009512\n",
      "Epoch 12, batch 65: loss = 0.009822\n",
      "Epoch 12, batch 66: loss = 0.009848\n",
      "Epoch 12, batch 67: loss = 0.008702\n",
      "Epoch 12, batch 68: loss = 0.009990\n",
      "Epoch 12, batch 69: loss = 0.009728\n",
      "Epoch 12, batch 70: loss = 0.010095\n",
      "Epoch 12, batch 71: loss = 0.009113\n",
      "Epoch 12, batch 72: loss = 0.010178\n",
      "Epoch 12, batch 73: loss = 0.009001\n",
      "Epoch 12, batch 74: loss = 0.009712\n",
      "Epoch 12, batch 75: loss = 0.008687\n",
      "Epoch 12, batch 76: loss = 0.009598\n",
      "Epoch 12, batch 77: loss = 0.009287\n",
      "Epoch 12, batch 78: loss = 0.010655\n",
      "Epoch 12, batch 79: loss = 0.010257\n",
      "Epoch 12, batch 80: loss = 0.009697\n",
      "Epoch 12, batch 81: loss = 0.009796\n",
      "Epoch 12, batch 82: loss = 0.014685\n",
      "Validation\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 12: val_loss = 0.024205\n",
      "Epoch 13, batch 0: loss = 0.017491\n",
      "Epoch 13, batch 1: loss = 0.010160\n",
      "Epoch 13, batch 2: loss = 0.012473\n",
      "Epoch 13, batch 3: loss = 0.013392\n",
      "Epoch 13, batch 4: loss = 0.012951\n",
      "Epoch 13, batch 5: loss = 0.011352\n",
      "Epoch 13, batch 6: loss = 0.011393\n",
      "Epoch 13, batch 7: loss = 0.012944\n",
      "Epoch 13, batch 8: loss = 0.012125\n",
      "Epoch 13, batch 9: loss = 0.011881\n",
      "Epoch 13, batch 10: loss = 0.011043\n",
      "Epoch 13, batch 11: loss = 0.011186\n",
      "Epoch 13, batch 12: loss = 0.011541\n",
      "Epoch 13, batch 13: loss = 0.013267\n",
      "Epoch 13, batch 14: loss = 0.010707\n",
      "Epoch 13, batch 15: loss = 0.010899\n",
      "Epoch 13, batch 16: loss = 0.010803\n",
      "Epoch 13, batch 17: loss = 0.011022\n",
      "Epoch 13, batch 18: loss = 0.010997\n",
      "Epoch 13, batch 19: loss = 0.009592\n",
      "Epoch 13, batch 20: loss = 0.010221\n",
      "Epoch 13, batch 21: loss = 0.010543\n",
      "Epoch 13, batch 22: loss = 0.009538\n",
      "Epoch 13, batch 23: loss = 0.011734\n",
      "Epoch 13, batch 24: loss = 0.010651\n",
      "Epoch 13, batch 25: loss = 0.010465\n",
      "Epoch 13, batch 26: loss = 0.010730\n",
      "Epoch 13, batch 27: loss = 0.010554\n",
      "Epoch 13, batch 28: loss = 0.010983\n",
      "Epoch 13, batch 29: loss = 0.010452\n",
      "Epoch 13, batch 30: loss = 0.009877\n",
      "Epoch 13, batch 31: loss = 0.010473\n",
      "Epoch 13, batch 32: loss = 0.011047\n",
      "Epoch 13, batch 33: loss = 0.011225\n",
      "Epoch 13, batch 34: loss = 0.011267\n",
      "Epoch 13, batch 35: loss = 0.011143\n",
      "Epoch 13, batch 36: loss = 0.010358\n",
      "Epoch 13, batch 37: loss = 0.010943\n",
      "Epoch 13, batch 38: loss = 0.010781\n",
      "Epoch 13, batch 39: loss = 0.010051\n",
      "Epoch 13, batch 40: loss = 0.010418\n",
      "Epoch 13, batch 41: loss = 0.009475\n",
      "Epoch 13, batch 42: loss = 0.009926\n",
      "Epoch 13, batch 43: loss = 0.009925\n",
      "Epoch 13, batch 44: loss = 0.008657\n",
      "Epoch 13, batch 45: loss = 0.009816\n",
      "Epoch 13, batch 46: loss = 0.010715\n",
      "Epoch 13, batch 47: loss = 0.009932\n",
      "Epoch 13, batch 48: loss = 0.010955\n",
      "Epoch 13, batch 49: loss = 0.009838\n",
      "Epoch 13, batch 50: loss = 0.010871\n",
      "Epoch 13, batch 51: loss = 0.009682\n",
      "Epoch 13, batch 52: loss = 0.010164\n",
      "Epoch 13, batch 53: loss = 0.009763\n",
      "Epoch 13, batch 54: loss = 0.010143\n",
      "Epoch 13, batch 55: loss = 0.010231\n",
      "Epoch 13, batch 56: loss = 0.009040\n",
      "Epoch 13, batch 57: loss = 0.009552\n",
      "Epoch 13, batch 58: loss = 0.009406\n",
      "Epoch 13, batch 59: loss = 0.009762\n",
      "Epoch 13, batch 60: loss = 0.009239\n",
      "Epoch 13, batch 61: loss = 0.009729\n",
      "Epoch 13, batch 62: loss = 0.010328\n",
      "Epoch 13, batch 63: loss = 0.010193\n",
      "Epoch 13, batch 64: loss = 0.009438\n",
      "Epoch 13, batch 65: loss = 0.010348\n",
      "Epoch 13, batch 66: loss = 0.010915\n",
      "Epoch 13, batch 67: loss = 0.009908\n",
      "Epoch 13, batch 68: loss = 0.010014\n",
      "Epoch 13, batch 69: loss = 0.010345\n",
      "Epoch 13, batch 70: loss = 0.009855\n",
      "Epoch 13, batch 71: loss = 0.009998\n",
      "Epoch 13, batch 72: loss = 0.009409\n",
      "Epoch 13, batch 73: loss = 0.010654\n",
      "Epoch 13, batch 74: loss = 0.010222\n",
      "Epoch 13, batch 75: loss = 0.009383\n",
      "Epoch 13, batch 76: loss = 0.009917\n",
      "Epoch 13, batch 77: loss = 0.008554\n",
      "Epoch 13, batch 78: loss = 0.009902\n",
      "Epoch 13, batch 79: loss = 0.009491\n",
      "Epoch 13, batch 80: loss = 0.009322\n",
      "Epoch 13, batch 81: loss = 0.009154\n",
      "Epoch 13, batch 82: loss = 0.012679\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 13: val_loss = 0.011708\n",
      "Epoch 14, batch 0: loss = 0.009940\n",
      "Epoch 14, batch 1: loss = 0.010910\n",
      "Epoch 14, batch 2: loss = 0.009954\n",
      "Epoch 14, batch 3: loss = 0.010876\n",
      "Epoch 14, batch 4: loss = 0.010561\n",
      "Epoch 14, batch 5: loss = 0.011010\n",
      "Epoch 14, batch 6: loss = 0.010782\n",
      "Epoch 14, batch 7: loss = 0.010256\n",
      "Epoch 14, batch 8: loss = 0.009875\n",
      "Epoch 14, batch 9: loss = 0.009057\n",
      "Epoch 14, batch 10: loss = 0.011177\n",
      "Epoch 14, batch 11: loss = 0.009795\n",
      "Epoch 14, batch 12: loss = 0.009706\n",
      "Epoch 14, batch 13: loss = 0.010447\n",
      "Epoch 14, batch 14: loss = 0.009960\n",
      "Epoch 14, batch 15: loss = 0.009480\n",
      "Epoch 14, batch 16: loss = 0.009868\n",
      "Epoch 14, batch 17: loss = 0.009404\n",
      "Epoch 14, batch 18: loss = 0.010114\n",
      "Epoch 14, batch 19: loss = 0.009813\n",
      "Epoch 14, batch 20: loss = 0.009666\n",
      "Epoch 14, batch 21: loss = 0.010261\n",
      "Epoch 14, batch 22: loss = 0.010487\n",
      "Epoch 14, batch 23: loss = 0.009516\n",
      "Epoch 14, batch 24: loss = 0.009608\n",
      "Epoch 14, batch 25: loss = 0.009212\n",
      "Epoch 14, batch 26: loss = 0.009441\n",
      "Epoch 14, batch 27: loss = 0.011022\n",
      "Epoch 14, batch 28: loss = 0.010610\n",
      "Epoch 14, batch 29: loss = 0.009393\n",
      "Epoch 14, batch 30: loss = 0.010118\n",
      "Epoch 14, batch 31: loss = 0.009427\n",
      "Epoch 14, batch 32: loss = 0.010087\n",
      "Epoch 14, batch 33: loss = 0.009328\n",
      "Epoch 14, batch 34: loss = 0.009815\n",
      "Epoch 14, batch 35: loss = 0.009822\n",
      "Epoch 14, batch 36: loss = 0.009793\n",
      "Epoch 14, batch 37: loss = 0.009110\n",
      "Epoch 14, batch 38: loss = 0.009112\n",
      "Epoch 14, batch 39: loss = 0.009892\n",
      "Epoch 14, batch 40: loss = 0.009562\n",
      "Epoch 14, batch 41: loss = 0.009555\n",
      "Epoch 14, batch 42: loss = 0.009963\n",
      "Epoch 14, batch 43: loss = 0.009520\n",
      "Epoch 14, batch 44: loss = 0.010104\n",
      "Epoch 14, batch 45: loss = 0.009430\n",
      "Epoch 14, batch 46: loss = 0.009635\n",
      "Epoch 14, batch 47: loss = 0.009690\n",
      "Epoch 14, batch 48: loss = 0.009747\n",
      "Epoch 14, batch 49: loss = 0.009635\n",
      "Epoch 14, batch 50: loss = 0.009959\n",
      "Epoch 14, batch 51: loss = 0.009335\n",
      "Epoch 14, batch 52: loss = 0.009764\n",
      "Epoch 14, batch 53: loss = 0.009684\n",
      "Epoch 14, batch 54: loss = 0.009845\n",
      "Epoch 14, batch 55: loss = 0.009189\n",
      "Epoch 14, batch 56: loss = 0.009142\n",
      "Epoch 14, batch 57: loss = 0.010059\n",
      "Epoch 14, batch 58: loss = 0.009695\n",
      "Epoch 14, batch 59: loss = 0.009992\n",
      "Epoch 14, batch 60: loss = 0.009520\n",
      "Epoch 14, batch 61: loss = 0.009292\n",
      "Epoch 14, batch 62: loss = 0.008795\n",
      "Epoch 14, batch 63: loss = 0.010024\n",
      "Epoch 14, batch 64: loss = 0.009858\n",
      "Epoch 14, batch 65: loss = 0.009591\n",
      "Epoch 14, batch 66: loss = 0.009432\n",
      "Epoch 14, batch 67: loss = 0.009648\n",
      "Epoch 14, batch 68: loss = 0.008504\n",
      "Epoch 14, batch 69: loss = 0.010297\n",
      "Epoch 14, batch 70: loss = 0.009867\n",
      "Epoch 14, batch 71: loss = 0.009495\n",
      "Epoch 14, batch 72: loss = 0.009710\n",
      "Epoch 14, batch 73: loss = 0.008845\n",
      "Epoch 14, batch 74: loss = 0.009295\n",
      "Epoch 14, batch 75: loss = 0.009284\n",
      "Epoch 14, batch 76: loss = 0.008754\n",
      "Epoch 14, batch 77: loss = 0.009651\n",
      "Epoch 14, batch 78: loss = 0.010016\n",
      "Epoch 14, batch 79: loss = 0.009315\n",
      "Epoch 14, batch 80: loss = 0.009467\n",
      "Epoch 14, batch 81: loss = 0.010026\n",
      "Epoch 14, batch 82: loss = 0.008244\n",
      "Validation\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 14: val_loss = 0.012842\n",
      "Epoch 15, batch 0: loss = 0.011766\n",
      "Epoch 15, batch 1: loss = 0.009797\n",
      "Epoch 15, batch 2: loss = 0.009477\n",
      "Epoch 15, batch 3: loss = 0.009906\n",
      "Epoch 15, batch 4: loss = 0.009836\n",
      "Epoch 15, batch 5: loss = 0.010079\n",
      "Epoch 15, batch 6: loss = 0.009863\n",
      "Epoch 15, batch 7: loss = 0.008863\n",
      "Epoch 15, batch 8: loss = 0.010433\n",
      "Epoch 15, batch 9: loss = 0.009607\n",
      "Epoch 15, batch 10: loss = 0.010865\n",
      "Epoch 15, batch 11: loss = 0.010650\n",
      "Epoch 15, batch 12: loss = 0.009152\n",
      "Epoch 15, batch 13: loss = 0.009377\n",
      "Epoch 15, batch 14: loss = 0.009628\n",
      "Epoch 15, batch 15: loss = 0.009985\n",
      "Epoch 15, batch 16: loss = 0.009713\n",
      "Epoch 15, batch 17: loss = 0.009847\n",
      "Epoch 15, batch 18: loss = 0.009146\n",
      "Epoch 15, batch 19: loss = 0.010514\n",
      "Epoch 15, batch 20: loss = 0.008940\n",
      "Epoch 15, batch 21: loss = 0.009451\n",
      "Epoch 15, batch 22: loss = 0.009921\n",
      "Epoch 15, batch 23: loss = 0.009830\n",
      "Epoch 15, batch 24: loss = 0.010192\n",
      "Epoch 15, batch 25: loss = 0.008885\n",
      "Epoch 15, batch 26: loss = 0.011236\n",
      "Epoch 15, batch 27: loss = 0.009273\n",
      "Epoch 15, batch 28: loss = 0.009877\n",
      "Epoch 15, batch 29: loss = 0.009402\n",
      "Epoch 15, batch 30: loss = 0.009050\n",
      "Epoch 15, batch 31: loss = 0.009413\n",
      "Epoch 15, batch 32: loss = 0.009729\n",
      "Epoch 15, batch 33: loss = 0.009558\n",
      "Epoch 15, batch 34: loss = 0.008964\n",
      "Epoch 15, batch 35: loss = 0.009457\n",
      "Epoch 15, batch 36: loss = 0.009936\n",
      "Epoch 15, batch 37: loss = 0.008985\n",
      "Epoch 15, batch 38: loss = 0.009050\n",
      "Epoch 15, batch 39: loss = 0.009868\n",
      "Epoch 15, batch 40: loss = 0.008797\n",
      "Epoch 15, batch 41: loss = 0.010102\n",
      "Epoch 15, batch 42: loss = 0.009622\n",
      "Epoch 15, batch 43: loss = 0.009355\n",
      "Epoch 15, batch 44: loss = 0.009294\n",
      "Epoch 15, batch 45: loss = 0.009571\n",
      "Epoch 15, batch 46: loss = 0.009192\n",
      "Epoch 15, batch 47: loss = 0.010103\n",
      "Epoch 15, batch 48: loss = 0.009685\n",
      "Epoch 15, batch 49: loss = 0.009231\n",
      "Epoch 15, batch 50: loss = 0.009969\n",
      "Epoch 15, batch 51: loss = 0.009805\n",
      "Epoch 15, batch 52: loss = 0.009059\n",
      "Epoch 15, batch 53: loss = 0.009161\n",
      "Epoch 15, batch 54: loss = 0.009212\n",
      "Epoch 15, batch 55: loss = 0.009213\n",
      "Epoch 15, batch 56: loss = 0.008901\n",
      "Epoch 15, batch 57: loss = 0.009539\n",
      "Epoch 15, batch 58: loss = 0.008984\n",
      "Epoch 15, batch 59: loss = 0.008661\n",
      "Epoch 15, batch 60: loss = 0.008569\n",
      "Epoch 15, batch 61: loss = 0.009503\n",
      "Epoch 15, batch 62: loss = 0.010173\n",
      "Epoch 15, batch 63: loss = 0.008530\n",
      "Epoch 15, batch 64: loss = 0.009140\n",
      "Epoch 15, batch 65: loss = 0.010494\n",
      "Epoch 15, batch 66: loss = 0.009027\n",
      "Epoch 15, batch 67: loss = 0.008650\n",
      "Epoch 15, batch 68: loss = 0.009581\n",
      "Epoch 15, batch 69: loss = 0.009125\n",
      "Epoch 15, batch 70: loss = 0.009185\n",
      "Epoch 15, batch 71: loss = 0.009372\n",
      "Epoch 15, batch 72: loss = 0.009012\n",
      "Epoch 15, batch 73: loss = 0.009159\n",
      "Epoch 15, batch 74: loss = 0.009525\n",
      "Epoch 15, batch 75: loss = 0.008893\n",
      "Epoch 15, batch 76: loss = 0.009463\n",
      "Epoch 15, batch 77: loss = 0.009069\n",
      "Epoch 15, batch 78: loss = 0.009029\n",
      "Epoch 15, batch 79: loss = 0.009169\n",
      "Epoch 15, batch 80: loss = 0.010499\n",
      "Epoch 15, batch 81: loss = 0.008684\n",
      "Epoch 15, batch 82: loss = 0.012841\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 15: val_loss = 0.011609\n",
      "Epoch 16, batch 0: loss = 0.011053\n",
      "Epoch 16, batch 1: loss = 0.009740\n",
      "Epoch 16, batch 2: loss = 0.009520\n",
      "Epoch 16, batch 3: loss = 0.009620\n",
      "Epoch 16, batch 4: loss = 0.009462\n",
      "Epoch 16, batch 5: loss = 0.009157\n",
      "Epoch 16, batch 6: loss = 0.009348\n",
      "Epoch 16, batch 7: loss = 0.010275\n",
      "Epoch 16, batch 8: loss = 0.009366\n",
      "Epoch 16, batch 9: loss = 0.010083\n",
      "Epoch 16, batch 10: loss = 0.009930\n",
      "Epoch 16, batch 11: loss = 0.009727\n",
      "Epoch 16, batch 12: loss = 0.009293\n",
      "Epoch 16, batch 13: loss = 0.009778\n",
      "Epoch 16, batch 14: loss = 0.010303\n",
      "Epoch 16, batch 15: loss = 0.009324\n",
      "Epoch 16, batch 16: loss = 0.010455\n",
      "Epoch 16, batch 17: loss = 0.008910\n",
      "Epoch 16, batch 18: loss = 0.009087\n",
      "Epoch 16, batch 19: loss = 0.009905\n",
      "Epoch 16, batch 20: loss = 0.009310\n",
      "Epoch 16, batch 21: loss = 0.009458\n",
      "Epoch 16, batch 22: loss = 0.009419\n",
      "Epoch 16, batch 23: loss = 0.010002\n",
      "Epoch 16, batch 24: loss = 0.009096\n",
      "Epoch 16, batch 25: loss = 0.009328\n",
      "Epoch 16, batch 26: loss = 0.009493\n",
      "Epoch 16, batch 27: loss = 0.010692\n",
      "Epoch 16, batch 28: loss = 0.009504\n",
      "Epoch 16, batch 29: loss = 0.008681\n",
      "Epoch 16, batch 30: loss = 0.009417\n",
      "Epoch 16, batch 31: loss = 0.010133\n",
      "Epoch 16, batch 32: loss = 0.008799\n",
      "Epoch 16, batch 33: loss = 0.008900\n",
      "Epoch 16, batch 34: loss = 0.009216\n",
      "Epoch 16, batch 35: loss = 0.009144\n",
      "Epoch 16, batch 36: loss = 0.009891\n",
      "Epoch 16, batch 37: loss = 0.008428\n",
      "Epoch 16, batch 38: loss = 0.009497\n",
      "Epoch 16, batch 39: loss = 0.009483\n",
      "Epoch 16, batch 40: loss = 0.009496\n",
      "Epoch 16, batch 41: loss = 0.009145\n",
      "Epoch 16, batch 42: loss = 0.009343\n",
      "Epoch 16, batch 43: loss = 0.008841\n",
      "Epoch 16, batch 44: loss = 0.009040\n",
      "Epoch 16, batch 45: loss = 0.008589\n",
      "Epoch 16, batch 46: loss = 0.008909\n",
      "Epoch 16, batch 47: loss = 0.009514\n",
      "Epoch 16, batch 48: loss = 0.008690\n",
      "Epoch 16, batch 49: loss = 0.008876\n",
      "Epoch 16, batch 50: loss = 0.009338\n",
      "Epoch 16, batch 51: loss = 0.010158\n",
      "Epoch 16, batch 52: loss = 0.009720\n",
      "Epoch 16, batch 53: loss = 0.009135\n",
      "Epoch 16, batch 54: loss = 0.009303\n",
      "Epoch 16, batch 55: loss = 0.009675\n",
      "Epoch 16, batch 56: loss = 0.009333\n",
      "Epoch 16, batch 57: loss = 0.008403\n",
      "Epoch 16, batch 58: loss = 0.009656\n",
      "Epoch 16, batch 59: loss = 0.009561\n",
      "Epoch 16, batch 60: loss = 0.008606\n",
      "Epoch 16, batch 61: loss = 0.009307\n",
      "Epoch 16, batch 62: loss = 0.009541\n",
      "Epoch 16, batch 63: loss = 0.009141\n",
      "Epoch 16, batch 64: loss = 0.008911\n",
      "Epoch 16, batch 65: loss = 0.009442\n",
      "Epoch 16, batch 66: loss = 0.009716\n",
      "Epoch 16, batch 67: loss = 0.010277\n",
      "Epoch 16, batch 68: loss = 0.009515\n",
      "Epoch 16, batch 69: loss = 0.008638\n",
      "Epoch 16, batch 70: loss = 0.009283\n",
      "Epoch 16, batch 71: loss = 0.009156\n",
      "Epoch 16, batch 72: loss = 0.008741\n",
      "Epoch 16, batch 73: loss = 0.008938\n",
      "Epoch 16, batch 74: loss = 0.009339\n",
      "Epoch 16, batch 75: loss = 0.009447\n",
      "Epoch 16, batch 76: loss = 0.008916\n",
      "Epoch 16, batch 77: loss = 0.009840\n",
      "Epoch 16, batch 78: loss = 0.008642\n",
      "Epoch 16, batch 79: loss = 0.008937\n",
      "Epoch 16, batch 80: loss = 0.008713\n",
      "Epoch 16, batch 81: loss = 0.009588\n",
      "Epoch 16, batch 82: loss = 0.013762\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 16: val_loss = 0.012525\n",
      "Epoch 17, batch 0: loss = 0.009120\n",
      "Epoch 17, batch 1: loss = 0.009233\n",
      "Epoch 17, batch 2: loss = 0.010029\n",
      "Epoch 17, batch 3: loss = 0.009459\n",
      "Epoch 17, batch 4: loss = 0.009378\n",
      "Epoch 17, batch 5: loss = 0.009825\n",
      "Epoch 17, batch 6: loss = 0.010023\n",
      "Epoch 17, batch 7: loss = 0.008664\n",
      "Epoch 17, batch 8: loss = 0.009500\n",
      "Epoch 17, batch 9: loss = 0.009356\n",
      "Epoch 17, batch 10: loss = 0.009359\n",
      "Epoch 17, batch 11: loss = 0.009040\n",
      "Epoch 17, batch 12: loss = 0.009058\n",
      "Epoch 17, batch 13: loss = 0.009679\n",
      "Epoch 17, batch 14: loss = 0.009298\n",
      "Epoch 17, batch 15: loss = 0.010173\n",
      "Epoch 17, batch 16: loss = 0.009151\n",
      "Epoch 17, batch 17: loss = 0.009806\n",
      "Epoch 17, batch 18: loss = 0.009664\n",
      "Epoch 17, batch 19: loss = 0.008917\n",
      "Epoch 17, batch 20: loss = 0.008934\n",
      "Epoch 17, batch 21: loss = 0.009194\n",
      "Epoch 17, batch 22: loss = 0.009229\n",
      "Epoch 17, batch 23: loss = 0.009392\n",
      "Epoch 17, batch 24: loss = 0.009157\n",
      "Epoch 17, batch 25: loss = 0.008752\n",
      "Epoch 17, batch 26: loss = 0.009286\n",
      "Epoch 17, batch 27: loss = 0.008462\n",
      "Epoch 17, batch 28: loss = 0.009064\n",
      "Epoch 17, batch 29: loss = 0.009530\n",
      "Epoch 17, batch 30: loss = 0.009180\n",
      "Epoch 17, batch 31: loss = 0.009356\n",
      "Epoch 17, batch 32: loss = 0.008779\n",
      "Epoch 17, batch 33: loss = 0.010044\n",
      "Epoch 17, batch 34: loss = 0.009348\n",
      "Epoch 17, batch 35: loss = 0.009304\n",
      "Epoch 17, batch 36: loss = 0.009337\n",
      "Epoch 17, batch 37: loss = 0.009574\n",
      "Epoch 17, batch 38: loss = 0.009004\n",
      "Epoch 17, batch 39: loss = 0.009572\n",
      "Epoch 17, batch 40: loss = 0.009502\n",
      "Epoch 17, batch 41: loss = 0.009793\n",
      "Epoch 17, batch 42: loss = 0.009378\n",
      "Epoch 17, batch 43: loss = 0.008931\n",
      "Epoch 17, batch 44: loss = 0.009771\n",
      "Epoch 17, batch 45: loss = 0.009281\n",
      "Epoch 17, batch 46: loss = 0.009303\n",
      "Epoch 17, batch 47: loss = 0.009175\n",
      "Epoch 17, batch 48: loss = 0.008895\n",
      "Epoch 17, batch 49: loss = 0.009517\n",
      "Epoch 17, batch 50: loss = 0.008928\n",
      "Epoch 17, batch 51: loss = 0.009109\n",
      "Epoch 17, batch 52: loss = 0.008757\n",
      "Epoch 17, batch 53: loss = 0.008696\n",
      "Epoch 17, batch 54: loss = 0.008817\n",
      "Epoch 17, batch 55: loss = 0.009460\n",
      "Epoch 17, batch 56: loss = 0.008553\n",
      "Epoch 17, batch 57: loss = 0.009365\n",
      "Epoch 17, batch 58: loss = 0.009688\n",
      "Epoch 17, batch 59: loss = 0.009599\n",
      "Epoch 17, batch 60: loss = 0.008706\n",
      "Epoch 17, batch 61: loss = 0.008641\n",
      "Epoch 17, batch 62: loss = 0.009535\n",
      "Epoch 17, batch 63: loss = 0.009917\n",
      "Epoch 17, batch 64: loss = 0.008829\n",
      "Epoch 17, batch 65: loss = 0.008078\n",
      "Epoch 17, batch 66: loss = 0.009021\n",
      "Epoch 17, batch 67: loss = 0.009124\n",
      "Epoch 17, batch 68: loss = 0.008993\n",
      "Epoch 17, batch 69: loss = 0.009004\n",
      "Epoch 17, batch 70: loss = 0.008883\n",
      "Epoch 17, batch 71: loss = 0.009273\n",
      "Epoch 17, batch 72: loss = 0.009201\n",
      "Epoch 17, batch 73: loss = 0.008870\n",
      "Epoch 17, batch 74: loss = 0.008819\n",
      "Epoch 17, batch 75: loss = 0.008872\n",
      "Epoch 17, batch 76: loss = 0.008916\n",
      "Epoch 17, batch 77: loss = 0.010412\n",
      "Epoch 17, batch 78: loss = 0.008976\n",
      "Epoch 17, batch 79: loss = 0.008886\n",
      "Epoch 17, batch 80: loss = 0.008818\n",
      "Epoch 17, batch 81: loss = 0.009120\n",
      "Epoch 17, batch 82: loss = 0.011147\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 17: val_loss = 0.012293\n",
      "Epoch 18, batch 0: loss = 0.010195\n",
      "Epoch 18, batch 1: loss = 0.010383\n",
      "Epoch 18, batch 2: loss = 0.009278\n",
      "Epoch 18, batch 3: loss = 0.009675\n",
      "Epoch 18, batch 4: loss = 0.009991\n",
      "Epoch 18, batch 5: loss = 0.009054\n",
      "Epoch 18, batch 6: loss = 0.009496\n",
      "Epoch 18, batch 7: loss = 0.009843\n",
      "Epoch 18, batch 8: loss = 0.009093\n",
      "Epoch 18, batch 9: loss = 0.009917\n",
      "Epoch 18, batch 10: loss = 0.009190\n",
      "Epoch 18, batch 11: loss = 0.008930\n",
      "Epoch 18, batch 12: loss = 0.009211\n",
      "Epoch 18, batch 13: loss = 0.009406\n",
      "Epoch 18, batch 14: loss = 0.009346\n",
      "Epoch 18, batch 15: loss = 0.009202\n",
      "Epoch 18, batch 16: loss = 0.009191\n",
      "Epoch 18, batch 17: loss = 0.009710\n",
      "Epoch 18, batch 18: loss = 0.008542\n",
      "Epoch 18, batch 19: loss = 0.010191\n",
      "Epoch 18, batch 20: loss = 0.009124\n",
      "Epoch 18, batch 21: loss = 0.009475\n",
      "Epoch 18, batch 22: loss = 0.009447\n",
      "Epoch 18, batch 23: loss = 0.009262\n",
      "Epoch 18, batch 24: loss = 0.008793\n",
      "Epoch 18, batch 25: loss = 0.008476\n",
      "Epoch 18, batch 26: loss = 0.009275\n",
      "Epoch 18, batch 27: loss = 0.008451\n",
      "Epoch 18, batch 28: loss = 0.009019\n",
      "Epoch 18, batch 29: loss = 0.008535\n",
      "Epoch 18, batch 30: loss = 0.009642\n",
      "Epoch 18, batch 31: loss = 0.009045\n",
      "Epoch 18, batch 32: loss = 0.008997\n",
      "Epoch 18, batch 33: loss = 0.008925\n",
      "Epoch 18, batch 34: loss = 0.008669\n",
      "Epoch 18, batch 35: loss = 0.008921\n",
      "Epoch 18, batch 36: loss = 0.008673\n",
      "Epoch 18, batch 37: loss = 0.008402\n",
      "Epoch 18, batch 38: loss = 0.009451\n",
      "Epoch 18, batch 39: loss = 0.009594\n",
      "Epoch 18, batch 40: loss = 0.008866\n",
      "Epoch 18, batch 41: loss = 0.008737\n",
      "Epoch 18, batch 42: loss = 0.009202\n",
      "Epoch 18, batch 43: loss = 0.009388\n",
      "Epoch 18, batch 44: loss = 0.009329\n",
      "Epoch 18, batch 45: loss = 0.008893\n",
      "Epoch 18, batch 46: loss = 0.008687\n",
      "Epoch 18, batch 47: loss = 0.009126\n",
      "Epoch 18, batch 48: loss = 0.009271\n",
      "Epoch 18, batch 49: loss = 0.010109\n",
      "Epoch 18, batch 50: loss = 0.009006\n",
      "Epoch 18, batch 51: loss = 0.009238\n",
      "Epoch 18, batch 52: loss = 0.008966\n",
      "Epoch 18, batch 53: loss = 0.008985\n",
      "Epoch 18, batch 54: loss = 0.009413\n",
      "Epoch 18, batch 55: loss = 0.008948\n",
      "Epoch 18, batch 56: loss = 0.008775\n",
      "Epoch 18, batch 57: loss = 0.008631\n",
      "Epoch 18, batch 58: loss = 0.008367\n",
      "Epoch 18, batch 59: loss = 0.009722\n",
      "Epoch 18, batch 60: loss = 0.008892\n",
      "Epoch 18, batch 61: loss = 0.008638\n",
      "Epoch 18, batch 62: loss = 0.008881\n",
      "Epoch 18, batch 63: loss = 0.008804\n",
      "Epoch 18, batch 64: loss = 0.009320\n",
      "Epoch 18, batch 65: loss = 0.009468\n",
      "Epoch 18, batch 66: loss = 0.009309\n",
      "Epoch 18, batch 67: loss = 0.008589\n",
      "Epoch 18, batch 68: loss = 0.009161\n",
      "Epoch 18, batch 69: loss = 0.008739\n",
      "Epoch 18, batch 70: loss = 0.009657\n",
      "Epoch 18, batch 71: loss = 0.008490\n",
      "Epoch 18, batch 72: loss = 0.009001\n",
      "Epoch 18, batch 73: loss = 0.008551\n",
      "Epoch 18, batch 74: loss = 0.008877\n",
      "Epoch 18, batch 75: loss = 0.008804\n",
      "Epoch 18, batch 76: loss = 0.008484\n",
      "Epoch 18, batch 77: loss = 0.009288\n",
      "Epoch 18, batch 78: loss = 0.008330\n",
      "Epoch 18, batch 79: loss = 0.008603\n",
      "Epoch 18, batch 80: loss = 0.009474\n",
      "Epoch 18, batch 81: loss = 0.009031\n",
      "Epoch 18, batch 82: loss = 0.009377\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 18: val_loss = 0.011648\n",
      "Epoch 19, batch 0: loss = 0.009055\n",
      "Epoch 19, batch 1: loss = 0.009194\n",
      "Epoch 19, batch 2: loss = 0.009109\n",
      "Epoch 19, batch 3: loss = 0.009590\n",
      "Epoch 19, batch 4: loss = 0.009401\n",
      "Epoch 19, batch 5: loss = 0.008672\n",
      "Epoch 19, batch 6: loss = 0.009178\n",
      "Epoch 19, batch 7: loss = 0.009058\n",
      "Epoch 19, batch 8: loss = 0.008557\n",
      "Epoch 19, batch 9: loss = 0.009654\n",
      "Epoch 19, batch 10: loss = 0.009135\n",
      "Epoch 19, batch 11: loss = 0.008816\n",
      "Epoch 19, batch 12: loss = 0.009879\n",
      "Epoch 19, batch 13: loss = 0.009153\n",
      "Epoch 19, batch 14: loss = 0.008834\n",
      "Epoch 19, batch 15: loss = 0.009786\n",
      "Epoch 19, batch 16: loss = 0.008552\n",
      "Epoch 19, batch 17: loss = 0.009827\n",
      "Epoch 19, batch 18: loss = 0.009254\n",
      "Epoch 19, batch 19: loss = 0.009006\n",
      "Epoch 19, batch 20: loss = 0.010001\n",
      "Epoch 19, batch 21: loss = 0.009124\n",
      "Epoch 19, batch 22: loss = 0.008879\n",
      "Epoch 19, batch 23: loss = 0.009356\n",
      "Epoch 19, batch 24: loss = 0.008832\n",
      "Epoch 19, batch 25: loss = 0.009170\n",
      "Epoch 19, batch 26: loss = 0.009365\n",
      "Epoch 19, batch 27: loss = 0.009002\n",
      "Epoch 19, batch 28: loss = 0.009847\n",
      "Epoch 19, batch 29: loss = 0.009841\n",
      "Epoch 19, batch 30: loss = 0.008619\n",
      "Epoch 19, batch 31: loss = 0.009825\n",
      "Epoch 19, batch 32: loss = 0.008377\n",
      "Epoch 19, batch 33: loss = 0.009606\n",
      "Epoch 19, batch 34: loss = 0.009299\n",
      "Epoch 19, batch 35: loss = 0.008571\n",
      "Epoch 19, batch 36: loss = 0.009131\n",
      "Epoch 19, batch 37: loss = 0.008941\n",
      "Epoch 19, batch 38: loss = 0.009084\n",
      "Epoch 19, batch 39: loss = 0.009267\n",
      "Epoch 19, batch 40: loss = 0.008834\n",
      "Epoch 19, batch 41: loss = 0.008864\n",
      "Epoch 19, batch 42: loss = 0.009335\n",
      "Epoch 19, batch 43: loss = 0.009066\n",
      "Epoch 19, batch 44: loss = 0.008482\n",
      "Epoch 19, batch 45: loss = 0.008829\n",
      "Epoch 19, batch 46: loss = 0.008653\n",
      "Epoch 19, batch 47: loss = 0.008801\n",
      "Epoch 19, batch 48: loss = 0.009042\n",
      "Epoch 19, batch 49: loss = 0.009070\n",
      "Epoch 19, batch 50: loss = 0.009034\n",
      "Epoch 19, batch 51: loss = 0.008463\n",
      "Epoch 19, batch 52: loss = 0.009476\n",
      "Epoch 19, batch 53: loss = 0.008754\n",
      "Epoch 19, batch 54: loss = 0.009921\n",
      "Epoch 19, batch 55: loss = 0.009061\n",
      "Epoch 19, batch 56: loss = 0.008679\n",
      "Epoch 19, batch 57: loss = 0.009123\n",
      "Epoch 19, batch 58: loss = 0.008591\n",
      "Epoch 19, batch 59: loss = 0.008838\n",
      "Epoch 19, batch 60: loss = 0.008776\n",
      "Epoch 19, batch 61: loss = 0.008387\n",
      "Epoch 19, batch 62: loss = 0.008597\n",
      "Epoch 19, batch 63: loss = 0.008928\n",
      "Epoch 19, batch 64: loss = 0.008739\n",
      "Epoch 19, batch 65: loss = 0.008936\n",
      "Epoch 19, batch 66: loss = 0.008167\n",
      "Epoch 19, batch 67: loss = 0.008658\n",
      "Epoch 19, batch 68: loss = 0.009124\n",
      "Epoch 19, batch 69: loss = 0.008690\n",
      "Epoch 19, batch 70: loss = 0.009393\n",
      "Epoch 19, batch 71: loss = 0.008747\n",
      "Epoch 19, batch 72: loss = 0.009386\n",
      "Epoch 19, batch 73: loss = 0.008922\n",
      "Epoch 19, batch 74: loss = 0.008374\n",
      "Epoch 19, batch 75: loss = 0.008450\n",
      "Epoch 19, batch 76: loss = 0.008879\n",
      "Epoch 19, batch 77: loss = 0.008496\n",
      "Epoch 19, batch 78: loss = 0.008968\n",
      "Epoch 19, batch 79: loss = 0.008682\n",
      "Epoch 19, batch 80: loss = 0.008325\n",
      "Epoch 19, batch 81: loss = 0.008929\n",
      "Epoch 19, batch 82: loss = 0.009190\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 19: val_loss = 0.023723\n",
      "Epoch 20, batch 0: loss = 0.014431\n",
      "Epoch 20, batch 1: loss = 0.010616\n",
      "Epoch 20, batch 2: loss = 0.011948\n",
      "Epoch 20, batch 3: loss = 0.011492\n",
      "Epoch 20, batch 4: loss = 0.011092\n",
      "Epoch 20, batch 5: loss = 0.011599\n",
      "Epoch 20, batch 6: loss = 0.011010\n",
      "Epoch 20, batch 7: loss = 0.011350\n",
      "Epoch 20, batch 8: loss = 0.010404\n",
      "Epoch 20, batch 9: loss = 0.010114\n",
      "Epoch 20, batch 10: loss = 0.010817\n",
      "Epoch 20, batch 11: loss = 0.010036\n",
      "Epoch 20, batch 12: loss = 0.010582\n",
      "Epoch 20, batch 13: loss = 0.010406\n",
      "Epoch 20, batch 14: loss = 0.010467\n",
      "Epoch 20, batch 15: loss = 0.009578\n",
      "Epoch 20, batch 16: loss = 0.010829\n",
      "Epoch 20, batch 17: loss = 0.009909\n",
      "Epoch 20, batch 18: loss = 0.009875\n",
      "Epoch 20, batch 19: loss = 0.009629\n",
      "Epoch 20, batch 20: loss = 0.009800\n",
      "Epoch 20, batch 21: loss = 0.009911\n",
      "Epoch 20, batch 22: loss = 0.009159\n",
      "Epoch 20, batch 23: loss = 0.010018\n",
      "Epoch 20, batch 24: loss = 0.008690\n",
      "Epoch 20, batch 25: loss = 0.009848\n",
      "Epoch 20, batch 26: loss = 0.010021\n",
      "Epoch 20, batch 27: loss = 0.009861\n",
      "Epoch 20, batch 28: loss = 0.010015\n",
      "Epoch 20, batch 29: loss = 0.009975\n",
      "Epoch 20, batch 30: loss = 0.008779\n",
      "Epoch 20, batch 31: loss = 0.009792\n",
      "Epoch 20, batch 32: loss = 0.009420\n",
      "Epoch 20, batch 33: loss = 0.009667\n",
      "Epoch 20, batch 34: loss = 0.008309\n",
      "Epoch 20, batch 35: loss = 0.009453\n",
      "Epoch 20, batch 36: loss = 0.008635\n",
      "Epoch 20, batch 37: loss = 0.010250\n",
      "Epoch 20, batch 38: loss = 0.009676\n",
      "Epoch 20, batch 39: loss = 0.009541\n",
      "Epoch 20, batch 40: loss = 0.010013\n",
      "Epoch 20, batch 41: loss = 0.009887\n",
      "Epoch 20, batch 42: loss = 0.009526\n",
      "Epoch 20, batch 43: loss = 0.009522\n",
      "Epoch 20, batch 44: loss = 0.008986\n",
      "Epoch 20, batch 45: loss = 0.009380\n",
      "Epoch 20, batch 46: loss = 0.008693\n",
      "Epoch 20, batch 47: loss = 0.008397\n",
      "Epoch 20, batch 48: loss = 0.009797\n",
      "Epoch 20, batch 49: loss = 0.009702\n",
      "Epoch 20, batch 50: loss = 0.008569\n",
      "Epoch 20, batch 51: loss = 0.008877\n",
      "Epoch 20, batch 52: loss = 0.009063\n",
      "Epoch 20, batch 53: loss = 0.008419\n",
      "Epoch 20, batch 54: loss = 0.009051\n",
      "Epoch 20, batch 55: loss = 0.008614\n",
      "Epoch 20, batch 56: loss = 0.008547\n",
      "Epoch 20, batch 57: loss = 0.009045\n",
      "Epoch 20, batch 58: loss = 0.009439\n",
      "Epoch 20, batch 59: loss = 0.009018\n",
      "Epoch 20, batch 60: loss = 0.009089\n",
      "Epoch 20, batch 61: loss = 0.008837\n",
      "Epoch 20, batch 62: loss = 0.008575\n",
      "Epoch 20, batch 63: loss = 0.008392\n",
      "Epoch 20, batch 64: loss = 0.008810\n",
      "Epoch 20, batch 65: loss = 0.008742\n",
      "Epoch 20, batch 66: loss = 0.008852\n",
      "Epoch 20, batch 67: loss = 0.009019\n",
      "Epoch 20, batch 68: loss = 0.009033\n",
      "Epoch 20, batch 69: loss = 0.008963\n",
      "Epoch 20, batch 70: loss = 0.009513\n",
      "Epoch 20, batch 71: loss = 0.009050\n",
      "Epoch 20, batch 72: loss = 0.009687\n",
      "Epoch 20, batch 73: loss = 0.009387\n",
      "Epoch 20, batch 74: loss = 0.008590\n",
      "Epoch 20, batch 75: loss = 0.009118\n",
      "Epoch 20, batch 76: loss = 0.008636\n",
      "Epoch 20, batch 77: loss = 0.009527\n",
      "Epoch 20, batch 78: loss = 0.009265\n",
      "Epoch 20, batch 79: loss = 0.008820\n",
      "Epoch 20, batch 80: loss = 0.008879\n",
      "Epoch 20, batch 81: loss = 0.008426\n",
      "Epoch 20, batch 82: loss = 0.008587\n",
      "Validation\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 20: val_loss = 0.013185\n",
      "Epoch 21, batch 0: loss = 0.009120\n",
      "Epoch 21, batch 1: loss = 0.009519\n",
      "Epoch 21, batch 2: loss = 0.010331\n",
      "Epoch 21, batch 3: loss = 0.009013\n",
      "Epoch 21, batch 4: loss = 0.009623\n",
      "Epoch 21, batch 5: loss = 0.009276\n",
      "Epoch 21, batch 6: loss = 0.008701\n",
      "Epoch 21, batch 7: loss = 0.008558\n",
      "Epoch 21, batch 8: loss = 0.009420\n",
      "Epoch 21, batch 9: loss = 0.009167\n",
      "Epoch 21, batch 10: loss = 0.008215\n",
      "Epoch 21, batch 11: loss = 0.009030\n",
      "Epoch 21, batch 12: loss = 0.008658\n",
      "Epoch 21, batch 13: loss = 0.008970\n",
      "Epoch 21, batch 14: loss = 0.009386\n",
      "Epoch 21, batch 15: loss = 0.009041\n",
      "Epoch 21, batch 16: loss = 0.009117\n",
      "Epoch 21, batch 17: loss = 0.008610\n",
      "Epoch 21, batch 18: loss = 0.009016\n",
      "Epoch 21, batch 19: loss = 0.008623\n",
      "Epoch 21, batch 20: loss = 0.010396\n",
      "Epoch 21, batch 21: loss = 0.009038\n",
      "Epoch 21, batch 22: loss = 0.009689\n",
      "Epoch 21, batch 23: loss = 0.008310\n",
      "Epoch 21, batch 24: loss = 0.008965\n",
      "Epoch 21, batch 25: loss = 0.008793\n",
      "Epoch 21, batch 26: loss = 0.009501\n",
      "Epoch 21, batch 27: loss = 0.009276\n",
      "Epoch 21, batch 28: loss = 0.008836\n",
      "Epoch 21, batch 29: loss = 0.009640\n",
      "Epoch 21, batch 30: loss = 0.009299\n",
      "Epoch 21, batch 31: loss = 0.008671\n",
      "Epoch 21, batch 32: loss = 0.009206\n",
      "Epoch 21, batch 33: loss = 0.008915\n",
      "Epoch 21, batch 34: loss = 0.009232\n",
      "Epoch 21, batch 35: loss = 0.008767\n",
      "Epoch 21, batch 36: loss = 0.009274\n",
      "Epoch 21, batch 37: loss = 0.008936\n",
      "Epoch 21, batch 38: loss = 0.009011\n",
      "Epoch 21, batch 39: loss = 0.009387\n",
      "Epoch 21, batch 40: loss = 0.008494\n",
      "Epoch 21, batch 41: loss = 0.009160\n",
      "Epoch 21, batch 42: loss = 0.008824\n",
      "Epoch 21, batch 43: loss = 0.009681\n",
      "Epoch 21, batch 44: loss = 0.008937\n",
      "Epoch 21, batch 45: loss = 0.009221\n",
      "Epoch 21, batch 46: loss = 0.009727\n",
      "Epoch 21, batch 47: loss = 0.010840\n",
      "Epoch 21, batch 48: loss = 0.009206\n",
      "Epoch 21, batch 49: loss = 0.010104\n",
      "Epoch 21, batch 50: loss = 0.009291\n",
      "Epoch 21, batch 51: loss = 0.009397\n",
      "Epoch 21, batch 52: loss = 0.009292\n",
      "Epoch 21, batch 53: loss = 0.009719\n",
      "Epoch 21, batch 54: loss = 0.008867\n",
      "Epoch 21, batch 55: loss = 0.009914\n",
      "Epoch 21, batch 56: loss = 0.009614\n",
      "Epoch 21, batch 57: loss = 0.009694\n",
      "Epoch 21, batch 58: loss = 0.009334\n",
      "Epoch 21, batch 59: loss = 0.009042\n",
      "Epoch 21, batch 60: loss = 0.009201\n",
      "Epoch 21, batch 61: loss = 0.009312\n",
      "Epoch 21, batch 62: loss = 0.008735\n",
      "Epoch 21, batch 63: loss = 0.009811\n",
      "Epoch 21, batch 64: loss = 0.008736\n",
      "Epoch 21, batch 65: loss = 0.009261\n",
      "Epoch 21, batch 66: loss = 0.009443\n",
      "Epoch 21, batch 67: loss = 0.009019\n",
      "Epoch 21, batch 68: loss = 0.008726\n",
      "Epoch 21, batch 69: loss = 0.008843\n",
      "Epoch 21, batch 70: loss = 0.008879\n",
      "Epoch 21, batch 71: loss = 0.008861\n",
      "Epoch 21, batch 72: loss = 0.009957\n",
      "Epoch 21, batch 73: loss = 0.009489\n",
      "Epoch 21, batch 74: loss = 0.008941\n",
      "Epoch 21, batch 75: loss = 0.009437\n",
      "Epoch 21, batch 76: loss = 0.009143\n",
      "Epoch 21, batch 77: loss = 0.009125\n",
      "Epoch 21, batch 78: loss = 0.008613\n",
      "Epoch 21, batch 79: loss = 0.009037\n",
      "Epoch 21, batch 80: loss = 0.009196\n",
      "Epoch 21, batch 81: loss = 0.010270\n",
      "Epoch 21, batch 82: loss = 0.007560\n",
      "Validation\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 21: val_loss = 0.014190\n",
      "Epoch 22, batch 0: loss = 0.012602\n",
      "Epoch 22, batch 1: loss = 0.009552\n",
      "Epoch 22, batch 2: loss = 0.009745\n",
      "Epoch 22, batch 3: loss = 0.011015\n",
      "Epoch 22, batch 4: loss = 0.009679\n",
      "Epoch 22, batch 5: loss = 0.009453\n",
      "Epoch 22, batch 6: loss = 0.009778\n",
      "Epoch 22, batch 7: loss = 0.008819\n",
      "Epoch 22, batch 8: loss = 0.010760\n",
      "Epoch 22, batch 9: loss = 0.009310\n",
      "Epoch 22, batch 10: loss = 0.009274\n",
      "Epoch 22, batch 11: loss = 0.008794\n",
      "Epoch 22, batch 12: loss = 0.009342\n",
      "Epoch 22, batch 13: loss = 0.009302\n",
      "Epoch 22, batch 14: loss = 0.009458\n",
      "Epoch 22, batch 15: loss = 0.010195\n",
      "Epoch 22, batch 16: loss = 0.008549\n",
      "Epoch 22, batch 17: loss = 0.009710\n",
      "Epoch 22, batch 18: loss = 0.009099\n",
      "Epoch 22, batch 19: loss = 0.009322\n",
      "Epoch 22, batch 20: loss = 0.009191\n",
      "Epoch 22, batch 21: loss = 0.009899\n",
      "Epoch 22, batch 22: loss = 0.009650\n",
      "Epoch 22, batch 23: loss = 0.008707\n",
      "Epoch 22, batch 24: loss = 0.008974\n",
      "Epoch 22, batch 25: loss = 0.008522\n",
      "Epoch 22, batch 26: loss = 0.008502\n",
      "Epoch 22, batch 27: loss = 0.008744\n",
      "Epoch 22, batch 28: loss = 0.008887\n",
      "Epoch 22, batch 29: loss = 0.009018\n",
      "Epoch 22, batch 30: loss = 0.009240\n",
      "Epoch 22, batch 31: loss = 0.009051\n",
      "Epoch 22, batch 32: loss = 0.008314\n",
      "Epoch 22, batch 33: loss = 0.009176\n",
      "Epoch 22, batch 34: loss = 0.008465\n",
      "Epoch 22, batch 35: loss = 0.008879\n",
      "Epoch 22, batch 36: loss = 0.008960\n",
      "Epoch 22, batch 37: loss = 0.008687\n",
      "Epoch 22, batch 38: loss = 0.009318\n",
      "Epoch 22, batch 39: loss = 0.008432\n",
      "Epoch 22, batch 40: loss = 0.008601\n",
      "Epoch 22, batch 41: loss = 0.009871\n",
      "Epoch 22, batch 42: loss = 0.008692\n",
      "Epoch 22, batch 43: loss = 0.008634\n",
      "Epoch 22, batch 44: loss = 0.008805\n",
      "Epoch 22, batch 45: loss = 0.008327\n",
      "Epoch 22, batch 46: loss = 0.008587\n",
      "Epoch 22, batch 47: loss = 0.007906\n",
      "Epoch 22, batch 48: loss = 0.008897\n",
      "Epoch 22, batch 49: loss = 0.008420\n",
      "Epoch 22, batch 50: loss = 0.008569\n",
      "Epoch 22, batch 51: loss = 0.009127\n",
      "Epoch 22, batch 52: loss = 0.008318\n",
      "Epoch 22, batch 53: loss = 0.008189\n",
      "Epoch 22, batch 54: loss = 0.008979\n",
      "Epoch 22, batch 55: loss = 0.009030\n",
      "Epoch 22, batch 56: loss = 0.008830\n",
      "Epoch 22, batch 57: loss = 0.008289\n",
      "Epoch 22, batch 58: loss = 0.008543\n",
      "Epoch 22, batch 59: loss = 0.008447\n",
      "Epoch 22, batch 60: loss = 0.008100\n",
      "Epoch 22, batch 61: loss = 0.008445\n",
      "Epoch 22, batch 62: loss = 0.008520\n",
      "Epoch 22, batch 63: loss = 0.008466\n",
      "Epoch 22, batch 64: loss = 0.008942\n",
      "Epoch 22, batch 65: loss = 0.008245\n",
      "Epoch 22, batch 66: loss = 0.008954\n",
      "Epoch 22, batch 67: loss = 0.008372\n",
      "Epoch 22, batch 68: loss = 0.009007\n",
      "Epoch 22, batch 69: loss = 0.008048\n",
      "Epoch 22, batch 70: loss = 0.008521\n",
      "Epoch 22, batch 71: loss = 0.008107\n",
      "Epoch 22, batch 72: loss = 0.008510\n",
      "Epoch 22, batch 73: loss = 0.008549\n",
      "Epoch 22, batch 74: loss = 0.008780\n",
      "Epoch 22, batch 75: loss = 0.008818\n",
      "Epoch 22, batch 76: loss = 0.008751\n",
      "Epoch 22, batch 77: loss = 0.008596\n",
      "Epoch 22, batch 78: loss = 0.008786\n",
      "Epoch 22, batch 79: loss = 0.008679\n",
      "Epoch 22, batch 80: loss = 0.008128\n",
      "Epoch 22, batch 81: loss = 0.008879\n",
      "Epoch 22, batch 82: loss = 0.008953\n",
      "Validation\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 22: val_loss = 0.011772\n",
      "Epoch 23, batch 0: loss = 0.009198\n",
      "Epoch 23, batch 1: loss = 0.008909\n",
      "Epoch 23, batch 2: loss = 0.008648\n",
      "Epoch 23, batch 3: loss = 0.008808\n",
      "Epoch 23, batch 4: loss = 0.009437\n",
      "Epoch 23, batch 5: loss = 0.009555\n",
      "Epoch 23, batch 6: loss = 0.008495\n",
      "Epoch 23, batch 7: loss = 0.008330\n",
      "Epoch 23, batch 8: loss = 0.008705\n",
      "Epoch 23, batch 9: loss = 0.009761\n",
      "Epoch 23, batch 10: loss = 0.009440\n",
      "Epoch 23, batch 11: loss = 0.008582\n",
      "Epoch 23, batch 12: loss = 0.008509\n",
      "Epoch 23, batch 13: loss = 0.008909\n",
      "Epoch 23, batch 14: loss = 0.008950\n",
      "Epoch 23, batch 15: loss = 0.008540\n",
      "Epoch 23, batch 16: loss = 0.009259\n",
      "Epoch 23, batch 17: loss = 0.008761\n",
      "Epoch 23, batch 18: loss = 0.009709\n",
      "Epoch 23, batch 19: loss = 0.009100\n",
      "Epoch 23, batch 20: loss = 0.008355\n",
      "Epoch 23, batch 21: loss = 0.009334\n",
      "Epoch 23, batch 22: loss = 0.009234\n",
      "Epoch 23, batch 23: loss = 0.009631\n",
      "Epoch 23, batch 24: loss = 0.009126\n",
      "Epoch 23, batch 25: loss = 0.008560\n",
      "Epoch 23, batch 26: loss = 0.009008\n",
      "Epoch 23, batch 27: loss = 0.008386\n",
      "Epoch 23, batch 28: loss = 0.009307\n",
      "Epoch 23, batch 29: loss = 0.008803\n",
      "Epoch 23, batch 30: loss = 0.008374\n",
      "Epoch 23, batch 31: loss = 0.008555\n",
      "Epoch 23, batch 32: loss = 0.009150\n",
      "Epoch 23, batch 33: loss = 0.008667\n",
      "Epoch 23, batch 34: loss = 0.008688\n",
      "Epoch 23, batch 35: loss = 0.008693\n",
      "Epoch 23, batch 36: loss = 0.008796\n",
      "Epoch 23, batch 37: loss = 0.009459\n",
      "Epoch 23, batch 38: loss = 0.010212\n",
      "Epoch 23, batch 39: loss = 0.008759\n",
      "Epoch 23, batch 40: loss = 0.008801\n",
      "Epoch 23, batch 41: loss = 0.008929\n",
      "Epoch 23, batch 42: loss = 0.008947\n",
      "Epoch 23, batch 43: loss = 0.009598\n",
      "Epoch 23, batch 44: loss = 0.008195\n",
      "Epoch 23, batch 45: loss = 0.008526\n",
      "Epoch 23, batch 46: loss = 0.009247\n",
      "Epoch 23, batch 47: loss = 0.008592\n",
      "Epoch 23, batch 48: loss = 0.008612\n",
      "Epoch 23, batch 49: loss = 0.008582\n",
      "Epoch 23, batch 50: loss = 0.008737\n",
      "Epoch 23, batch 51: loss = 0.008666\n",
      "Epoch 23, batch 52: loss = 0.008786\n",
      "Epoch 23, batch 53: loss = 0.008125\n",
      "Epoch 23, batch 54: loss = 0.008541\n",
      "Epoch 23, batch 55: loss = 0.008265\n",
      "Epoch 23, batch 56: loss = 0.008274\n",
      "Epoch 23, batch 57: loss = 0.008564\n",
      "Epoch 23, batch 58: loss = 0.008615\n",
      "Epoch 23, batch 59: loss = 0.008877\n",
      "Epoch 23, batch 60: loss = 0.007788\n",
      "Epoch 23, batch 61: loss = 0.009301\n",
      "Epoch 23, batch 62: loss = 0.008289\n",
      "Epoch 23, batch 63: loss = 0.008918\n",
      "Epoch 23, batch 64: loss = 0.008336\n",
      "Epoch 23, batch 65: loss = 0.008645\n",
      "Epoch 23, batch 66: loss = 0.008968\n",
      "Epoch 23, batch 67: loss = 0.008148\n",
      "Epoch 23, batch 68: loss = 0.008760\n",
      "Epoch 23, batch 69: loss = 0.009080\n",
      "Epoch 23, batch 70: loss = 0.008895\n",
      "Epoch 23, batch 71: loss = 0.008589\n",
      "Epoch 23, batch 72: loss = 0.009112\n",
      "Epoch 23, batch 73: loss = 0.009464\n",
      "Epoch 23, batch 74: loss = 0.009009\n",
      "Epoch 23, batch 75: loss = 0.008074\n",
      "Epoch 23, batch 76: loss = 0.008711\n",
      "Epoch 23, batch 77: loss = 0.008337\n",
      "Epoch 23, batch 78: loss = 0.008584\n",
      "Epoch 23, batch 79: loss = 0.008162\n",
      "Epoch 23, batch 80: loss = 0.009296\n",
      "Epoch 23, batch 81: loss = 0.008290\n",
      "Epoch 23, batch 82: loss = 0.007405\n",
      "Validation\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 23: val_loss = 0.011946\n",
      "Epoch 24, batch 0: loss = 0.008278\n",
      "Epoch 24, batch 1: loss = 0.009316\n",
      "Epoch 24, batch 2: loss = 0.008788\n",
      "Epoch 24, batch 3: loss = 0.008493\n",
      "Epoch 24, batch 4: loss = 0.008520\n",
      "Epoch 24, batch 5: loss = 0.009058\n",
      "Epoch 24, batch 6: loss = 0.008965\n",
      "Epoch 24, batch 7: loss = 0.008591\n",
      "Epoch 24, batch 8: loss = 0.008580\n",
      "Epoch 24, batch 9: loss = 0.008421\n",
      "Epoch 24, batch 10: loss = 0.008799\n",
      "Epoch 24, batch 11: loss = 0.008898\n",
      "Epoch 24, batch 12: loss = 0.008824\n",
      "Epoch 24, batch 13: loss = 0.008189\n",
      "Epoch 24, batch 14: loss = 0.008992\n",
      "Epoch 24, batch 15: loss = 0.008432\n",
      "Epoch 24, batch 16: loss = 0.008475\n",
      "Epoch 24, batch 17: loss = 0.008386\n",
      "Epoch 24, batch 18: loss = 0.009065\n",
      "Epoch 24, batch 19: loss = 0.007902\n",
      "Epoch 24, batch 20: loss = 0.009228\n",
      "Epoch 24, batch 21: loss = 0.008618\n",
      "Epoch 24, batch 22: loss = 0.008628\n",
      "Epoch 24, batch 23: loss = 0.007928\n",
      "Epoch 24, batch 24: loss = 0.008270\n",
      "Epoch 24, batch 25: loss = 0.008475\n",
      "Epoch 24, batch 26: loss = 0.008423\n",
      "Epoch 24, batch 27: loss = 0.008399\n",
      "Epoch 24, batch 28: loss = 0.008905\n",
      "Epoch 24, batch 29: loss = 0.008652\n",
      "Epoch 24, batch 30: loss = 0.008166\n",
      "Epoch 24, batch 31: loss = 0.008336\n",
      "Epoch 24, batch 32: loss = 0.008289\n",
      "Epoch 24, batch 33: loss = 0.008498\n",
      "Epoch 24, batch 34: loss = 0.008637\n",
      "Epoch 24, batch 35: loss = 0.007908\n",
      "Epoch 24, batch 36: loss = 0.007499\n",
      "Epoch 24, batch 37: loss = 0.008553\n",
      "Epoch 24, batch 38: loss = 0.008063\n",
      "Epoch 24, batch 39: loss = 0.008412\n",
      "Epoch 24, batch 40: loss = 0.008584\n",
      "Epoch 24, batch 41: loss = 0.008178\n",
      "Epoch 24, batch 42: loss = 0.008593\n",
      "Epoch 24, batch 43: loss = 0.007602\n",
      "Epoch 24, batch 44: loss = 0.008061\n",
      "Epoch 24, batch 45: loss = 0.008494\n",
      "Epoch 24, batch 46: loss = 0.008287\n",
      "Epoch 24, batch 47: loss = 0.008391\n",
      "Epoch 24, batch 48: loss = 0.008963\n",
      "Epoch 24, batch 49: loss = 0.009304\n",
      "Epoch 24, batch 50: loss = 0.008413\n",
      "Epoch 24, batch 51: loss = 0.008677\n",
      "Epoch 24, batch 52: loss = 0.008776\n",
      "Epoch 24, batch 53: loss = 0.008371\n",
      "Epoch 24, batch 54: loss = 0.008224\n",
      "Epoch 24, batch 55: loss = 0.008370\n",
      "Epoch 24, batch 56: loss = 0.008278\n",
      "Epoch 24, batch 57: loss = 0.008541\n",
      "Epoch 24, batch 58: loss = 0.007937\n",
      "Epoch 24, batch 59: loss = 0.008768\n",
      "Epoch 24, batch 60: loss = 0.008310\n",
      "Epoch 24, batch 61: loss = 0.008052\n",
      "Epoch 24, batch 62: loss = 0.008609\n",
      "Epoch 24, batch 63: loss = 0.008325\n",
      "Epoch 24, batch 64: loss = 0.008076\n",
      "Epoch 24, batch 65: loss = 0.008844\n",
      "Epoch 24, batch 66: loss = 0.008651\n",
      "Epoch 24, batch 67: loss = 0.008404\n",
      "Epoch 24, batch 68: loss = 0.008099\n",
      "Epoch 24, batch 69: loss = 0.008531\n",
      "Epoch 24, batch 70: loss = 0.007756\n",
      "Epoch 24, batch 71: loss = 0.008399\n",
      "Epoch 24, batch 72: loss = 0.008267\n",
      "Epoch 24, batch 73: loss = 0.008879\n",
      "Epoch 24, batch 74: loss = 0.008251\n",
      "Epoch 24, batch 75: loss = 0.008989\n",
      "Epoch 24, batch 76: loss = 0.008520\n",
      "Epoch 24, batch 77: loss = 0.008895\n",
      "Epoch 24, batch 78: loss = 0.008189\n",
      "Epoch 24, batch 79: loss = 0.007729\n",
      "Epoch 24, batch 80: loss = 0.008189\n",
      "Epoch 24, batch 81: loss = 0.008383\n",
      "Epoch 24, batch 82: loss = 0.008385\n",
      "Validation\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 24: val_loss = 0.011889\n",
      "Epoch 25, batch 0: loss = 0.008419\n",
      "Epoch 25, batch 1: loss = 0.008894\n",
      "Epoch 25, batch 2: loss = 0.008057\n",
      "Epoch 25, batch 3: loss = 0.008468\n",
      "Epoch 25, batch 4: loss = 0.009341\n",
      "Epoch 25, batch 5: loss = 0.009096\n",
      "Epoch 25, batch 6: loss = 0.009739\n",
      "Epoch 25, batch 7: loss = 0.008963\n",
      "Epoch 25, batch 8: loss = 0.008751\n",
      "Epoch 25, batch 9: loss = 0.008360\n",
      "Epoch 25, batch 10: loss = 0.008848\n",
      "Epoch 25, batch 11: loss = 0.008261\n",
      "Epoch 25, batch 12: loss = 0.008347\n",
      "Epoch 25, batch 13: loss = 0.007925\n",
      "Epoch 25, batch 14: loss = 0.008533\n",
      "Epoch 25, batch 15: loss = 0.009350\n",
      "Epoch 25, batch 16: loss = 0.008159\n",
      "Epoch 25, batch 17: loss = 0.008828\n",
      "Epoch 25, batch 18: loss = 0.008065\n",
      "Epoch 25, batch 19: loss = 0.008231\n",
      "Epoch 25, batch 20: loss = 0.009087\n",
      "Epoch 25, batch 21: loss = 0.008835\n",
      "Epoch 25, batch 22: loss = 0.009033\n",
      "Epoch 25, batch 23: loss = 0.008316\n",
      "Epoch 25, batch 24: loss = 0.008442\n",
      "Epoch 25, batch 25: loss = 0.008336\n",
      "Epoch 25, batch 26: loss = 0.008581\n",
      "Epoch 25, batch 27: loss = 0.008456\n",
      "Epoch 25, batch 28: loss = 0.008943\n",
      "Epoch 25, batch 29: loss = 0.008742\n",
      "Epoch 25, batch 30: loss = 0.008071\n",
      "Epoch 25, batch 31: loss = 0.008138\n",
      "Epoch 25, batch 32: loss = 0.008397\n",
      "Epoch 25, batch 33: loss = 0.007551\n",
      "Epoch 25, batch 34: loss = 0.009294\n",
      "Epoch 25, batch 35: loss = 0.008638\n",
      "Epoch 25, batch 36: loss = 0.008329\n",
      "Epoch 25, batch 37: loss = 0.008510\n",
      "Epoch 25, batch 38: loss = 0.008473\n",
      "Epoch 25, batch 39: loss = 0.007868\n",
      "Epoch 25, batch 40: loss = 0.008202\n",
      "Epoch 25, batch 41: loss = 0.008781\n",
      "Epoch 25, batch 42: loss = 0.008433\n",
      "Epoch 25, batch 43: loss = 0.008414\n",
      "Epoch 25, batch 44: loss = 0.009051\n",
      "Epoch 25, batch 45: loss = 0.007743\n",
      "Epoch 25, batch 46: loss = 0.008143\n",
      "Epoch 25, batch 47: loss = 0.007928\n",
      "Epoch 25, batch 48: loss = 0.008520\n",
      "Epoch 25, batch 49: loss = 0.008208\n",
      "Epoch 25, batch 50: loss = 0.008479\n",
      "Epoch 25, batch 51: loss = 0.008505\n",
      "Epoch 25, batch 52: loss = 0.008087\n",
      "Epoch 25, batch 53: loss = 0.008382\n",
      "Epoch 25, batch 54: loss = 0.007804\n",
      "Epoch 25, batch 55: loss = 0.008216\n",
      "Epoch 25, batch 56: loss = 0.008491\n",
      "Epoch 25, batch 57: loss = 0.007813\n",
      "Epoch 25, batch 58: loss = 0.008430\n",
      "Epoch 25, batch 59: loss = 0.007943\n",
      "Epoch 25, batch 60: loss = 0.008852\n",
      "Epoch 25, batch 61: loss = 0.008242\n",
      "Epoch 25, batch 62: loss = 0.008381\n",
      "Epoch 25, batch 63: loss = 0.008294\n",
      "Epoch 25, batch 64: loss = 0.007973\n",
      "Epoch 25, batch 65: loss = 0.008205\n",
      "Epoch 25, batch 66: loss = 0.008145\n",
      "Epoch 25, batch 67: loss = 0.008974\n",
      "Epoch 25, batch 68: loss = 0.008507\n",
      "Epoch 25, batch 69: loss = 0.008408\n",
      "Epoch 25, batch 70: loss = 0.008488\n",
      "Epoch 25, batch 71: loss = 0.007756\n",
      "Epoch 25, batch 72: loss = 0.008407\n",
      "Epoch 25, batch 73: loss = 0.007731\n",
      "Epoch 25, batch 74: loss = 0.007920\n",
      "Epoch 25, batch 75: loss = 0.008781\n",
      "Epoch 25, batch 76: loss = 0.008031\n",
      "Epoch 25, batch 77: loss = 0.008641\n",
      "Epoch 25, batch 78: loss = 0.008482\n",
      "Epoch 25, batch 79: loss = 0.008230\n",
      "Epoch 25, batch 80: loss = 0.007637\n",
      "Epoch 25, batch 81: loss = 0.008766\n",
      "Epoch 25, batch 82: loss = 0.008659\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 25: val_loss = 0.011614\n",
      "Epoch 26, batch 0: loss = 0.008829\n",
      "Epoch 26, batch 1: loss = 0.008942\n",
      "Epoch 26, batch 2: loss = 0.008719\n",
      "Epoch 26, batch 3: loss = 0.008367\n",
      "Epoch 26, batch 4: loss = 0.008284\n",
      "Epoch 26, batch 5: loss = 0.008834\n",
      "Epoch 26, batch 6: loss = 0.008660\n",
      "Epoch 26, batch 7: loss = 0.008340\n",
      "Epoch 26, batch 8: loss = 0.008943\n",
      "Epoch 26, batch 9: loss = 0.008271\n",
      "Epoch 26, batch 10: loss = 0.008805\n",
      "Epoch 26, batch 11: loss = 0.008648\n",
      "Epoch 26, batch 12: loss = 0.008820\n",
      "Epoch 26, batch 13: loss = 0.009165\n",
      "Epoch 26, batch 14: loss = 0.008652\n",
      "Epoch 26, batch 15: loss = 0.008440\n",
      "Epoch 26, batch 16: loss = 0.008846\n",
      "Epoch 26, batch 17: loss = 0.008225\n",
      "Epoch 26, batch 18: loss = 0.008259\n",
      "Epoch 26, batch 19: loss = 0.008450\n",
      "Epoch 26, batch 20: loss = 0.008313\n",
      "Epoch 26, batch 21: loss = 0.008083\n",
      "Epoch 26, batch 22: loss = 0.008359\n",
      "Epoch 26, batch 23: loss = 0.008126\n",
      "Epoch 26, batch 24: loss = 0.008748\n",
      "Epoch 26, batch 25: loss = 0.008309\n",
      "Epoch 26, batch 26: loss = 0.008201\n",
      "Epoch 26, batch 27: loss = 0.008158\n",
      "Epoch 26, batch 28: loss = 0.008265\n",
      "Epoch 26, batch 29: loss = 0.008545\n",
      "Epoch 26, batch 30: loss = 0.008642\n",
      "Epoch 26, batch 31: loss = 0.008111\n",
      "Epoch 26, batch 32: loss = 0.008318\n",
      "Epoch 26, batch 33: loss = 0.008062\n",
      "Epoch 26, batch 34: loss = 0.008154\n",
      "Epoch 26, batch 35: loss = 0.008283\n",
      "Epoch 26, batch 36: loss = 0.008945\n",
      "Epoch 26, batch 37: loss = 0.008363\n",
      "Epoch 26, batch 38: loss = 0.008298\n",
      "Epoch 26, batch 39: loss = 0.008181\n",
      "Epoch 26, batch 40: loss = 0.007869\n",
      "Epoch 26, batch 41: loss = 0.008236\n",
      "Epoch 26, batch 42: loss = 0.008477\n",
      "Epoch 26, batch 43: loss = 0.008263\n",
      "Epoch 26, batch 44: loss = 0.007359\n",
      "Epoch 26, batch 45: loss = 0.008277\n",
      "Epoch 26, batch 46: loss = 0.008091\n",
      "Epoch 26, batch 47: loss = 0.008429\n",
      "Epoch 26, batch 48: loss = 0.007447\n",
      "Epoch 26, batch 49: loss = 0.007771\n",
      "Epoch 26, batch 50: loss = 0.008750\n",
      "Epoch 26, batch 51: loss = 0.009185\n",
      "Epoch 26, batch 52: loss = 0.007997\n",
      "Epoch 26, batch 53: loss = 0.008642\n",
      "Epoch 26, batch 54: loss = 0.008170\n",
      "Epoch 26, batch 55: loss = 0.007999\n",
      "Epoch 26, batch 56: loss = 0.008763\n",
      "Epoch 26, batch 57: loss = 0.008229\n",
      "Epoch 26, batch 58: loss = 0.007898\n",
      "Epoch 26, batch 59: loss = 0.008447\n",
      "Epoch 26, batch 60: loss = 0.008056\n",
      "Epoch 26, batch 61: loss = 0.008335\n",
      "Epoch 26, batch 62: loss = 0.007401\n",
      "Epoch 26, batch 63: loss = 0.008321\n",
      "Epoch 26, batch 64: loss = 0.008493\n",
      "Epoch 26, batch 65: loss = 0.008677\n",
      "Epoch 26, batch 66: loss = 0.008365\n",
      "Epoch 26, batch 67: loss = 0.008245\n",
      "Epoch 26, batch 68: loss = 0.008295\n",
      "Epoch 26, batch 69: loss = 0.008820\n",
      "Epoch 26, batch 70: loss = 0.008052\n",
      "Epoch 26, batch 71: loss = 0.007949\n",
      "Epoch 26, batch 72: loss = 0.007775\n",
      "Epoch 26, batch 73: loss = 0.008429\n",
      "Epoch 26, batch 74: loss = 0.008735\n",
      "Epoch 26, batch 75: loss = 0.008750\n",
      "Epoch 26, batch 76: loss = 0.008414\n",
      "Epoch 26, batch 77: loss = 0.008782\n",
      "Epoch 26, batch 78: loss = 0.008677\n",
      "Epoch 26, batch 79: loss = 0.008538\n",
      "Epoch 26, batch 80: loss = 0.009223\n",
      "Epoch 26, batch 81: loss = 0.008729\n",
      "Epoch 26, batch 82: loss = 0.008597\n",
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 26: val_loss = 0.012127\n",
      "Epoch 27, batch 0: loss = 0.009405\n",
      "Epoch 27, batch 1: loss = 0.009349\n",
      "Epoch 27, batch 2: loss = 0.008514\n",
      "Epoch 27, batch 3: loss = 0.008104\n",
      "Epoch 27, batch 4: loss = 0.007839\n",
      "Epoch 27, batch 5: loss = 0.008761\n",
      "Epoch 27, batch 6: loss = 0.008534\n",
      "Epoch 27, batch 7: loss = 0.008138\n",
      "Epoch 27, batch 8: loss = 0.008501\n",
      "Epoch 27, batch 9: loss = 0.008011\n",
      "Epoch 27, batch 10: loss = 0.008483\n",
      "Epoch 27, batch 11: loss = 0.008918\n",
      "Epoch 27, batch 12: loss = 0.008416\n",
      "Epoch 27, batch 13: loss = 0.008333\n",
      "Epoch 27, batch 14: loss = 0.007933\n",
      "Epoch 27, batch 15: loss = 0.008090\n",
      "Epoch 27, batch 16: loss = 0.008407\n",
      "Epoch 27, batch 17: loss = 0.008886\n",
      "Epoch 27, batch 18: loss = 0.007854\n",
      "Epoch 27, batch 19: loss = 0.008698\n",
      "Epoch 27, batch 20: loss = 0.008138\n",
      "Epoch 27, batch 21: loss = 0.008670\n",
      "Epoch 27, batch 22: loss = 0.008220\n",
      "Epoch 27, batch 23: loss = 0.007814\n",
      "Epoch 27, batch 24: loss = 0.008216\n",
      "Epoch 27, batch 25: loss = 0.008100\n",
      "Epoch 27, batch 26: loss = 0.008315\n",
      "Epoch 27, batch 27: loss = 0.008282\n",
      "Epoch 27, batch 28: loss = 0.007958\n",
      "Epoch 27, batch 29: loss = 0.008189\n",
      "Epoch 27, batch 30: loss = 0.008406\n",
      "Epoch 27, batch 31: loss = 0.008168\n",
      "Epoch 27, batch 32: loss = 0.008328\n",
      "Epoch 27, batch 33: loss = 0.008220\n",
      "Epoch 27, batch 34: loss = 0.008135\n",
      "Epoch 27, batch 35: loss = 0.008373\n",
      "Epoch 27, batch 36: loss = 0.007738\n",
      "Epoch 27, batch 37: loss = 0.008726\n",
      "Epoch 27, batch 38: loss = 0.007544\n",
      "Epoch 27, batch 39: loss = 0.008276\n",
      "Epoch 27, batch 40: loss = 0.008024\n",
      "Epoch 27, batch 41: loss = 0.008166\n",
      "Epoch 27, batch 42: loss = 0.008018\n",
      "Epoch 27, batch 43: loss = 0.008306\n",
      "Epoch 27, batch 44: loss = 0.008171\n",
      "Epoch 27, batch 45: loss = 0.007801\n",
      "Epoch 27, batch 46: loss = 0.008311\n",
      "Epoch 27, batch 47: loss = 0.007743\n",
      "Epoch 27, batch 48: loss = 0.008029\n",
      "Epoch 27, batch 49: loss = 0.007944\n",
      "Epoch 27, batch 50: loss = 0.008446\n",
      "Epoch 27, batch 51: loss = 0.007887\n",
      "Epoch 27, batch 52: loss = 0.008053\n",
      "Epoch 27, batch 53: loss = 0.007738\n",
      "Epoch 27, batch 54: loss = 0.007507\n",
      "Epoch 27, batch 55: loss = 0.008488\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # previous_output = torch.zeros(1, 512, 102).to(device)\n",
    "    losses = []\n",
    "    for i, (audio_batch, motion_batch) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        \n",
    "        audio_batch = audio_batch.to(device).float()\n",
    "        motion_batch = motion_batch.to(device).float()\n",
    "        # print(\"audio_batch\", audio_batch.shape)\n",
    "        # print(\"motion_batch\", motion_batch.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(audio_batch) #audio_batch\n",
    "        # print(\"output.shape\", output.shape)\n",
    "\n",
    "        # motion_ground_truth_padding = F.pad(motion_batch, (0,0,0,1), value = 1) #<eot>\n",
    "        \n",
    "        # loss =  F.mse_loss(output, motion_ground_truth_padding)\n",
    "        loss =  F.mse_loss(output, motion_batch)\n",
    "        # loss = customized_mse_loss(output, motion_ground_truth_padding, previous_output, midi_batch)\n",
    "        # loss = customized_mse_loss(output, motion_batch, previous_output, midi_batch)\n",
    "\n",
    "        # losses 累計lose\n",
    "        losses.append(loss.cpu().item())\n",
    "        all_loss_list.append(loss.cpu().item())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "\n",
    "        print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\")\n",
    "\n",
    "        # scheduler.step(1)\n",
    "        # previous_output = output\n",
    "\n",
    "        loc_dt = datetime.datetime.today()\n",
    "        loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    val_loss = evaluate_lstm(model, val_dataloader) #CUDA out of memory\n",
    "    val_loss_per_epoch_list.append(val_loss)\n",
    "    print(f\"Epoch {epoch}: val_loss = {val_loss:.6f}\")\n",
    "    # save_best_model(\n",
    "    #         val_loss, epoch, model, optimizer, loss, loc_dt_format, mean_loss\n",
    "    #     )\n",
    "    avg_loss_list.append(mean_loss)\n",
    "    loc_dt = datetime.datetime.today()\n",
    "    loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if (epoch+1)%100 == 0:\n",
    "        torch.save({\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),\n",
    "            'loss':loss\n",
    "        }, \"./model_save/[audio]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-18_20-18-33\n",
      "[0.014088256811969969, 0.012748566265386271, 0.012135430968489992, 0.011783327020884278, 0.011665332321840596, 0.011348000278763742, 0.011211590673101235, 0.01126363599695355, 0.010981195034032845, 0.011041705530271473, 0.010652564320129803, 0.010493768816701618, 0.010436136421399662, 0.010394138800182256, 0.010266933163785073, 0.010155179560274244, 0.010048930421022766, 0.009978100118866885, 0.009849181370697466, 0.009758815090789134, 0.009883428014904619, 0.00967351151966905, 0.00962024238184992, 0.009702010966657874, 0.009488175634339631, 0.0092398691249181, 0.009143874744873449, 0.009248467532536352, 0.009218326792210699, 0.009097143457865858, 0.009768575643110707, 0.009479412405067179, 0.009325702079986951, 0.008976236182119113, 0.008987353239432875, 0.008953133721398302, 0.010966492143560606, 0.009526901440807136, 0.009302870774394777, 0.009145709394241672, 0.009100556171622622, 0.008991728065512985, 0.00887559393577906, 0.008845821527921292, 0.008874942918857896, 0.008714025256684027, 0.00866576326247978, 0.008609346489994282, 0.008462396506444517, 0.00862086423481983, 0.008452712389898587, 0.008357532294354883, 0.00836835333134934, 0.008362646899129971, 0.008306471182100744, 0.008238311812102076, 0.008212381457707968, 0.008278413771101868, 0.008118434612785119, 0.008152230278061456, 0.008129165451749262, 0.008022671946919108, 0.008001188966389522, 0.008091263287891465, 0.007925072791481233, 0.007895248667168689, 0.008107084107686239, 0.007831114131104515, 0.007846745544573269, 0.007778555109917399, 0.00782428898410984, 0.007667424123599587, 0.007668853468115789, 0.007695864981421864, 0.008001946788056788, 0.008146181001316711, 0.008304473371749901, 0.010889162253364023, 0.009561570181724537, 0.009321228511272425, 0.009188297698386463, 0.0089952244917043, 0.00876316487654505, 0.008678013503731015, 0.008706914496619299, 0.009260843362075737, 0.00877367167632623, 0.008487243255802307, 0.00856666280383087, 0.008443230908947537, 0.008434072013450674, 0.008272712208689696, 0.008221394012132323, 0.008372612527560398, 0.008181025358253574, 0.008107293660875904, 0.008094822785940516, 0.008018234711005745, 0.00795654417296131, 0.007912229168711298]\n"
     ]
    }
   ],
   "source": [
    "print(loc_dt_format)\n",
    "print(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01278438325971365, 0.012452135793864727, 0.012619588524103165, 0.012583580799400806, 0.012676828540861607, 0.012934515252709389, 0.013072746805846691, 0.0120470579713583, 0.011598094366490841, 0.012044154107570648, 0.012224655598402023, 0.012943221256136894, 0.011343262158334255, 0.01114050392061472, 0.010922430083155632, 0.011694221757352352, 0.011601006612181664, 0.011959804221987724, 0.01255539245903492, 0.012239864096045494, 0.012193874455988407, 0.012043044902384281, 0.012772328220307827, 0.011544476263225079, 0.011981447227299213, 0.011674492619931698, 0.011470047757029533, 0.012049633078277111, 0.012382530607283115, 0.012579183094203472, 0.011807631701231003, 0.014613443985581398, 0.012081064283847809, 0.012330255471169949, 0.011556034907698631, 0.033256713300943375, 0.012245435267686844, 0.011719465255737305, 0.011602915823459625, 0.01261739432811737, 0.012613462284207344, 0.011865119449794292, 0.01175965927541256, 0.01231275126338005, 0.012440602295100689, 0.011565727181732655, 0.012038304470479488, 0.012144051492214203, 0.013280346989631653, 0.011942359618842602, 0.01198410615324974, 0.011832463555037975, 0.011701458133757114, 0.011762083508074284, 0.01186199951916933, 0.011945074424147606, 0.012092005461454391, 0.012013407424092293, 0.013873604126274586, 0.01164690125733614, 0.011499306187033653, 0.011670297011733055, 0.011667122133076191, 0.01227153092622757, 0.011528153903782368, 0.01321783009916544, 0.011688649654388428, 0.011914435774087906, 0.013560043647885323, 0.011790013872087002, 0.011861668899655342, 0.011606640182435513, 0.01203671284019947, 0.012268045917153358, 0.011607351712882519, 0.012172108516097069, 0.028247511014342308, 0.012615550309419632, 0.01218416914343834, 0.012678734958171844, 0.01254349760711193, 0.01322066131979227, 0.01218418963253498, 0.012356121093034744, 0.012790396809577942, 0.012864671647548676, 0.012179471552371979, 0.012493027374148369, 0.012625529430806637, 0.012184211052954197, 0.011979276314377785, 0.012451846152544022, 0.012520112097263336, 0.012400939129292965, 0.012175791896879673, 0.012036528438329697, 0.012121778912842274, 0.012442434206604958, 0.012401246465742588, 0.01275933813303709]\n"
     ]
    }
   ],
   "source": [
    "print(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d43dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_lambda(epoch):\n",
    "#     # LR to be 0.1 * (1/1+0.01*epoch)\n",
    "#     base_lr = 0.1\n",
    "#     factor = 0.01\n",
    "#     return base_lr/(1+factor*epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5982f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_loss_list))\n",
    "avg_loss_list_dataframe = pd.DataFrame(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.008095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.007957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.007912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.014088\n",
       "1   0.012749\n",
       "2   0.012135\n",
       "3   0.011783\n",
       "4   0.011665\n",
       "..       ...\n",
       "95  0.008107\n",
       "96  0.008095\n",
       "97  0.008018\n",
       "98  0.007957\n",
       "99  0.007912\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(avg_loss_list_dataframe.index), np.array(avg_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51793ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_dataframe = pd.DataFrame(all_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list_dataframe.index), np.array(loss_list_dataframe[0]))\n",
    "plt.savefig(\"training_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_per_epoch_list_dataframe = pd.DataFrame(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(val_loss_per_epoch_list_dataframe.index), np.array(val_loss_per_epoch_list_dataframe[0]))\n",
    "plt.savefig(\"training_val_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        # print(target.shape)\n",
    "        # target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        # TODO: target should be <sos>, should not random\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_preprocess(audio_path, specific_fps):\n",
    "    n_fft = 4096\n",
    "    hop = int(44000/specific_fps) #1102.5 -> 40fps #882 -> 50fps\n",
    "    y, sr = librosa.load(audio_path, sr=44000) #44000 for divide 40\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_fft=n_fft, hop_length=hop, n_mfcc=13)\n",
    "    y = np.where(y == 0, 1e-10, y)\n",
    "    energy = np.log(librosa.feature.rms(y=y, frame_length=n_fft, hop_length=hop, center=True))\n",
    "    mfcc_energy = np.vstack((mfcc, energy))\n",
    "    mfcc_delta = librosa.feature.delta(mfcc_energy)\n",
    "    aud = np.vstack((mfcc_energy, mfcc_delta)).T\n",
    "    \n",
    "    print(\"hop:\", hop)\n",
    "    print(\"aud:\", aud.shape)\n",
    "    return aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06620112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, specific_fps):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    piano_roll = midi_data.get_piano_roll(fs=specific_fps)  # 40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_name: ./BWV1001/vs1-1ada.wav\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.wav\n",
      "hop: 1100\n",
      "aud: (8172, 28)\n",
      "(8172, 28)\n",
      "str_name: ./BWV1001/vs1-3sic.wav\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.wav\n",
      "hop: 1100\n",
      "aud: (6989, 28)\n",
      "(6989, 28)\n",
      "str_name: ./BWV1001/vs1-2fug.wav\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.wav\n",
      "hop: 1100\n",
      "aud: (11534, 28)\n",
      "(11534, 28)\n",
      "str_name: ./BWV1001/vs1-4prs.wav\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.wav\n",
      "hop: 1100\n",
      "aud: (7898, 28)\n",
      "(7898, 28)\n",
      "str_name: ./BWV1001/vs1-1ada.mid\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.mid\n",
      "old len:  (8171, 128)\n",
      "new len:  (8172, 128)\n",
      "str_name: ./BWV1001/vs1-2fug.mid\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.mid\n",
      "old len:  (11537, 128)\n",
      "new len:  (11534, 128)\n",
      "str_name: ./BWV1001/vs1-3sic.mid\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.mid\n",
      "old len:  (6993, 128)\n",
      "new len:  (6989, 128)\n",
      "str_name: ./BWV1001/vs1-4prs.mid\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.mid\n",
      "old len:  (7897, 128)\n",
      "new len:  (7898, 128)\n",
      "['vs1-1ada', 'vs1-2fug', 'vs1-3sic', 'vs1-4prs']\n",
      "(8172, 156)\n",
      "(11534, 156)\n",
      "(6989, 156)\n",
      "(7898, 156)\n"
     ]
    }
   ],
   "source": [
    "test_datapath = \"./BWV1001/\"\n",
    "change_fps = 40\n",
    "test_audio_path_list = glob.glob(test_datapath + \"*.wav\")\n",
    "test_midi_path_list = glob.glob(test_datapath + \"*.mid\")\n",
    "test_audio_dict = {}\n",
    "test_midi_dict = {}\n",
    "test_data_list = []\n",
    "test_music_list = []\n",
    "\n",
    "test_audio_length = {}\n",
    "\n",
    "for test_audio in test_audio_path_list:\n",
    "    str_name = test_audio\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    # test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_audio)\n",
    "    # read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_audio = audio_preprocess(test_audio, change_fps)\n",
    "    # read_audio_transpose = read_audio\n",
    "    print(read_audio.shape)\n",
    "    test_audio_len = read_audio.shape[0]\n",
    "    test_audio_length[filecode] = test_audio_len\n",
    "    test_audio_dict[filecode] = read_audio\n",
    "\n",
    "for test_midi in test_midi_path_list:\n",
    "    str_name = test_midi\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_midi)\n",
    "    read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_piano_roll_transpose = read_piano_roll.T\n",
    "    print(\"old len: \", read_piano_roll_transpose.shape)\n",
    "\n",
    "    audio_len = test_audio_length[filecode]\n",
    "    midi_len = len(read_piano_roll_transpose)\n",
    "    if audio_len > midi_len:\n",
    "        #(top,bottom), (left,right)\n",
    "        read_piano_roll_transpose = np.pad(read_piano_roll_transpose,\n",
    "                                            pad_width=((0, audio_len - midi_len), (0, 0)))\n",
    "    if audio_len < midi_len:\n",
    "        n = midi_len - audio_len\n",
    "        read_piano_roll_transpose = read_piano_roll_transpose[:-n, :]\n",
    "        \n",
    "    test_midi_len = read_piano_roll_transpose.shape[0]\n",
    "    test_midi_dict[filecode] = read_piano_roll_transpose\n",
    "    print(\"new len: \", read_piano_roll_transpose.shape)\n",
    "\n",
    "\n",
    "print(test_music_list)\n",
    "\n",
    "for test_music in test_music_list:\n",
    "    combine_music = np.append(test_midi_dict[test_music], test_audio_dict[test_music], axis = 1)\n",
    "    test_data_list.append(combine_music)\n",
    "    print(combine_music.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 8172, 156)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction.shape (1, 8172, 102)\n",
      "full_prediction (8172, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.06355162  0.13356397  1.05939022]\n",
      "  [ 0.02451253  0.09293263  1.077633  ]\n",
      "  [ 0.12643632  0.05664559  1.05023298]\n",
      "  ...\n",
      "  [ 0.04668002  0.10732425  0.93162737]\n",
      "  [-0.1422101   0.08608773  1.03613845]\n",
      "  [ 0.08750859  0.2402505   0.73955188]]\n",
      "\n",
      " [[ 0.08414692  0.11390457  1.08929906]\n",
      "  [ 0.036357    0.09666923  1.09711764]\n",
      "  [ 0.15051877  0.04217945  1.09635202]\n",
      "  ...\n",
      "  [ 0.06092626  0.1131491   0.94641129]\n",
      "  [-0.12833472  0.08752057  1.04275451]\n",
      "  [ 0.12260811  0.21374393  0.77403579]]\n",
      "\n",
      " [[ 0.07429266  0.10394423  1.09531007]\n",
      "  [ 0.02439765  0.09194402  1.09812889]\n",
      "  [ 0.14384674  0.03564306  1.10306678]\n",
      "  ...\n",
      "  [ 0.05184722  0.11060955  0.95129052]\n",
      "  [-0.13783553  0.07621256  1.04014263]\n",
      "  [ 0.11655657  0.21114898  0.78239528]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.10110911  0.11616088  1.10146627]\n",
      "  [ 0.04462209  0.07892136  1.10632417]\n",
      "  [ 0.14449075  0.04203048  1.11012242]\n",
      "  ...\n",
      "  [ 0.05935774  0.09892346  0.96882555]\n",
      "  [-0.07586522  0.11583044  1.06106732]\n",
      "  [ 0.18907858  0.2346893   0.75186453]]\n",
      "\n",
      " [[ 0.10333198  0.11612798  1.10125003]\n",
      "  [ 0.04745825  0.07838163  1.10653851]\n",
      "  [ 0.14667906  0.04269257  1.10933588]\n",
      "  ...\n",
      "  [ 0.06221377  0.09772493  0.96872268]\n",
      "  [-0.07223009  0.11810856  1.06445692]\n",
      "  [ 0.19051725  0.2320143   0.74997894]]\n",
      "\n",
      " [[ 0.0997765   0.11305519  1.10049484]\n",
      "  [ 0.04339862  0.07568607  1.10603616]\n",
      "  [ 0.14366025  0.0417942   1.10767052]\n",
      "  ...\n",
      "  [ 0.05990519  0.09494078  0.96844397]\n",
      "  [-0.07383795  0.11816473  1.06539783]\n",
      "  [ 0.18427463  0.2242939   0.74700949]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-1ada.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-1ada.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 216 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 212 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-1ada.wav':\n",
      "  Duration: 00:03:24.29, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5568cef681c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5568cef681c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5568cef681c0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-1ada_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=439 q=-1.0 Lsize=    3737kB time=00:03:24.31 bitrate= 149.8kbits/s speed= 112x    \n",
      "video:483kB audio:3202kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.416812%\n",
      "[aac @ 0x5568cef66a80] Qavg: 182.785\n",
      "[libx264 @ 0x5568cef681c0] frame I:4     Avg QP:16.21  size: 13572\n",
      "[libx264 @ 0x5568cef681c0] frame P:213   Avg QP:23.27  size:  1253\n",
      "[libx264 @ 0x5568cef681c0] frame B:583   Avg QP:28.70  size:   296\n",
      "[libx264 @ 0x5568cef681c0] consecutive B-frames:  1.2%  3.5%  3.8% 91.5%\n",
      "[libx264 @ 0x5568cef681c0] mb I  I16..4: 26.6% 49.2% 24.2%\n",
      "[libx264 @ 0x5568cef681c0] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  0.9%  1.7%  2.0%  0.0%  0.0%    skip:95.2%\n",
      "[libx264 @ 0x5568cef681c0] mb B  I16..4:  0.0%  0.1%  0.0%  B16..8:  1.6%  1.6%  0.7%  direct: 0.2%  skip:95.7%  L0:44.8% L1:40.3% BI:14.9%\n",
      "[libx264 @ 0x5568cef681c0] 8x8 transform intra:52.9% inter:27.2%\n",
      "[libx264 @ 0x5568cef681c0] coded y,uvDC,uvAC intra: 17.2% 1.7% 1.4% inter: 1.1% 0.3% 0.3%\n",
      "[libx264 @ 0x5568cef681c0] i16 v,h,dc,p: 81%  7% 12%  0%\n",
      "[libx264 @ 0x5568cef681c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 37%  9% 54%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x5568cef681c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 31%  7%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x5568cef681c0] i8c dc,h,v,p: 99%  0%  0%  0%\n",
      "[libx264 @ 0x5568cef681c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5568cef681c0] ref P L0: 51.3%  8.0% 20.8% 20.0%\n",
      "[libx264 @ 0x5568cef681c0] ref B L0: 76.7% 15.0%  8.3%\n",
      "[libx264 @ 0x5568cef681c0] ref B L1: 92.4%  7.6%\n",
      "[libx264 @ 0x5568cef681c0] kb/s:197.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 11534, 156)\n",
      "prediction.shape (1, 11534, 102)\n",
      "full_prediction (11534, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.08070495  0.14534007  1.11399064]\n",
      "  [ 0.06805236  0.09855323  1.0968518 ]\n",
      "  [ 0.13246995  0.03517139  1.03133163]\n",
      "  ...\n",
      "  [ 0.00319252  0.12243085  0.96492354]\n",
      "  [-0.04189362  0.20937711  1.00741146]\n",
      "  [ 0.04500939  0.22100392  0.66683141]]\n",
      "\n",
      " [[ 0.05204338  0.18029329  1.15192351]\n",
      "  [ 0.02479108  0.1176395   1.13649688]\n",
      "  [ 0.11065398  0.06827161  1.10690877]\n",
      "  ...\n",
      "  [-0.04117206  0.13978781  1.00970546]\n",
      "  [-0.09507247  0.22575581  1.10915658]\n",
      "  [ 0.02460541  0.22122194  0.7199851 ]]\n",
      "\n",
      " [[ 0.04383961  0.19789372  1.15437171]\n",
      "  [ 0.01176155  0.13208453  1.14288435]\n",
      "  [ 0.10307933  0.08855149  1.12313328]\n",
      "  ...\n",
      "  [-0.04814007  0.14903975  1.0238103 ]\n",
      "  [-0.11726123  0.22779185  1.13596091]\n",
      "  [ 0.0087961   0.23648413  0.72666035]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.05046132  0.17993964  1.10056386]\n",
      "  [-0.00964692  0.14965498  1.11908648]\n",
      "  [ 0.0923114   0.10692465  1.12704203]\n",
      "  ...\n",
      "  [-0.00319973  0.13636009  0.99085162]\n",
      "  [-0.17612019  0.13243106  1.09580377]\n",
      "  [ 0.08112462  0.25421384  0.79052553]]\n",
      "\n",
      " [[ 0.05059092  0.17991172  1.10119293]\n",
      "  [-0.01032659  0.1496616   1.11878977]\n",
      "  [ 0.09087637  0.10468273  1.12565885]\n",
      "  ...\n",
      "  [-0.00513979  0.13731748  0.99109892]\n",
      "  [-0.17262816  0.1402082   1.09776399]\n",
      "  [ 0.08355206  0.25977898  0.77836636]]\n",
      "\n",
      " [[ 0.05358255  0.17644371  1.10155532]\n",
      "  [-0.00845527  0.14845735  1.11740587]\n",
      "  [ 0.09357123  0.10113283  1.12655578]\n",
      "  ...\n",
      "  [-0.00315293  0.13793541  0.98964909]\n",
      "  [-0.16848697  0.14269507  1.09157155]\n",
      "  [ 0.08808954  0.25747812  0.77605746]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-2fug.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-2fug.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 258 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 254 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-2fug.wav':\n",
      "  Duration: 00:04:48.34, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5638ac779ec0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5638ac779ec0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5638ac779ec0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-2fug_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=334 q=-1.0 Lsize=    5163kB time=00:04:48.34 bitrate= 146.7kbits/s speed= 120x    \n",
      "video:579kB audio:4518kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.301691%\n",
      "[aac @ 0x5638ac778780] Qavg: 260.041\n",
      "[libx264 @ 0x5638ac779ec0] frame I:4     Avg QP:16.90  size: 13611\n",
      "[libx264 @ 0x5638ac779ec0] frame P:221   Avg QP:23.12  size:  1480\n",
      "[libx264 @ 0x5638ac779ec0] frame B:575   Avg QP:29.14  size:   367\n",
      "[libx264 @ 0x5638ac779ec0] consecutive B-frames:  1.8%  6.2%  3.0% 89.0%\n",
      "[libx264 @ 0x5638ac779ec0] mb I  I16..4: 28.0% 47.3% 24.6%\n",
      "[libx264 @ 0x5638ac779ec0] mb P  I16..4:  0.0%  0.0%  0.1%  P16..4:  1.2%  1.9%  2.2%  0.0%  0.0%    skip:94.4%\n",
      "[libx264 @ 0x5638ac779ec0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  2.3%  1.6%  0.9%  direct: 0.2%  skip:94.9%  L0:42.9% L1:42.6% BI:14.5%\n",
      "[libx264 @ 0x5638ac779ec0] 8x8 transform intra:46.0% inter:23.6%\n",
      "[libx264 @ 0x5638ac779ec0] coded y,uvDC,uvAC intra: 20.5% 2.5% 2.1% inter: 1.4% 0.4% 0.4%\n",
      "[libx264 @ 0x5638ac779ec0] i16 v,h,dc,p: 83%  5% 12%  0%\n",
      "[libx264 @ 0x5638ac779ec0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 46%  8% 46%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x5638ac779ec0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 29% 11%  2%  5%  3%  4%  3%  3%\n",
      "[libx264 @ 0x5638ac779ec0] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x5638ac779ec0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5638ac779ec0] ref P L0: 56.6%  8.3% 18.7% 16.5%\n",
      "[libx264 @ 0x5638ac779ec0] ref B L0: 80.3% 14.4%  5.3%\n",
      "[libx264 @ 0x5638ac779ec0] ref B L1: 93.9%  6.1%\n",
      "[libx264 @ 0x5638ac779ec0] kb/s:236.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 6989, 156)\n",
      "prediction.shape (1, 6989, 102)\n",
      "full_prediction (6989, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.08093315  0.16217832  1.08257095]\n",
      "  [ 0.02813307  0.10430899  1.09326998]\n",
      "  [ 0.12145004  0.07571991  1.07382003]\n",
      "  ...\n",
      "  [ 0.04153442  0.11155283  0.95659081]\n",
      "  [-0.12720582  0.10311461  1.04320166]\n",
      "  [ 0.11097981  0.27614909  0.75573698]]\n",
      "\n",
      " [[ 0.08594778  0.14783636  1.10058997]\n",
      "  [ 0.0249481   0.10837639  1.1080421 ]\n",
      "  [ 0.12715413  0.0657869   1.10983608]\n",
      "  ...\n",
      "  [ 0.03546703  0.11836524  0.96746788]\n",
      "  [-0.12930612  0.09401795  1.05956051]\n",
      "  [ 0.14663424  0.27465183  0.79056177]]\n",
      "\n",
      " [[ 0.095667    0.13217275  1.10089192]\n",
      "  [ 0.03438616  0.09972148  1.10742543]\n",
      "  [ 0.13994768  0.05398431  1.11132989]\n",
      "  ...\n",
      "  [ 0.04686549  0.11235158  0.96742312]\n",
      "  [-0.11001059  0.09180865  1.04840288]\n",
      "  [ 0.16705954  0.27243337  0.78550074]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.09965208  0.11615978  1.1017879 ]\n",
      "  [ 0.04233343  0.07993923  1.10244629]\n",
      "  [ 0.1539481   0.04093921  1.11618612]\n",
      "  ...\n",
      "  [ 0.06512362  0.10353954  0.96665225]\n",
      "  [-0.0705415   0.11554565  1.05196348]\n",
      "  [ 0.1781408   0.21102451  0.74263022]]\n",
      "\n",
      " [[ 0.09980831  0.11757818  1.10238562]\n",
      "  [ 0.04155797  0.08109676  1.10213814]\n",
      "  [ 0.15538841  0.04243559  1.11682734]\n",
      "  ...\n",
      "  [ 0.06406652  0.10483658  0.96855   ]\n",
      "  [-0.07102694  0.11583868  1.05590007]\n",
      "  [ 0.17562391  0.21044247  0.73813269]]\n",
      "\n",
      " [[ 0.10028408  0.11552335  1.10278413]\n",
      "  [ 0.0425356   0.07907219  1.10259507]\n",
      "  [ 0.15594143  0.03957567  1.1149194 ]\n",
      "  ...\n",
      "  [ 0.06417934  0.10300688  0.97037301]\n",
      "  [-0.06769871  0.11658822  1.05990205]\n",
      "  [ 0.17430112  0.21022396  0.73320273]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-3sic.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-3sic.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 213 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 209 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-3sic.wav':\n",
      "  Duration: 00:02:54.71, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x56172f061280] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x56172f061280] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x56172f061280] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-3sic_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=491 q=-1.0 Lsize=    3264kB time=00:02:54.73 bitrate= 153.0kbits/s speed= 107x    \n",
      "video:478kB audio:2739kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.468278%\n",
      "[aac @ 0x56172f05fb40] Qavg: 180.446\n",
      "[libx264 @ 0x56172f061280] frame I:4     Avg QP:16.93  size: 13508\n",
      "[libx264 @ 0x56172f061280] frame P:217   Avg QP:23.08  size:  1246\n",
      "[libx264 @ 0x56172f061280] frame B:579   Avg QP:28.69  size:   284\n",
      "[libx264 @ 0x56172f061280] consecutive B-frames:  2.0%  3.5%  3.0% 91.5%\n",
      "[libx264 @ 0x56172f061280] mb I  I16..4: 26.9% 48.3% 24.8%\n",
      "[libx264 @ 0x56172f061280] mb P  I16..4:  0.0%  0.1%  0.0%  P16..4:  0.9%  1.8%  2.0%  0.0%  0.0%    skip:95.2%\n",
      "[libx264 @ 0x56172f061280] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.7%  1.6%  0.7%  direct: 0.2%  skip:95.8%  L0:43.7% L1:41.5% BI:14.9%\n",
      "[libx264 @ 0x56172f061280] 8x8 transform intra:47.4% inter:28.3%\n",
      "[libx264 @ 0x56172f061280] coded y,uvDC,uvAC intra: 18.9% 2.1% 1.8% inter: 1.1% 0.3% 0.3%\n",
      "[libx264 @ 0x56172f061280] i16 v,h,dc,p: 81%  7% 12%  0%\n",
      "[libx264 @ 0x56172f061280] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45%  9% 46%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x56172f061280] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 44% 31%  6%  2%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x56172f061280] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x56172f061280] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x56172f061280] ref P L0: 54.7%  8.7% 20.5% 16.1%\n",
      "[libx264 @ 0x56172f061280] ref B L0: 79.8% 13.7%  6.5%\n",
      "[libx264 @ 0x56172f061280] ref B L1: 91.9%  8.1%\n",
      "[libx264 @ 0x56172f061280] kb/s:195.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 7898, 156)\n",
      "prediction.shape (1, 7898, 102)\n",
      "full_prediction (7898, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.09799373  0.14396888  1.11264226]\n",
      "  [ 0.02599373  0.08567091  1.11100791]\n",
      "  [ 0.1360521   0.03611819  1.06715868]\n",
      "  ...\n",
      "  [ 0.03058271  0.12778926  0.95958928]\n",
      "  [-0.10334559  0.16407764  1.04709647]\n",
      "  [ 0.11493185  0.21483327  0.68059478]]\n",
      "\n",
      " [[ 0.06030766  0.13740326  1.1075351 ]\n",
      "  [ 0.00342417  0.10915142  1.1095067 ]\n",
      "  [ 0.1145698   0.05522706  1.10932848]\n",
      "  ...\n",
      "  [ 0.02013712  0.12653446  0.96561728]\n",
      "  [-0.16469252  0.11648785  1.11110768]\n",
      "  [ 0.09213534  0.21191293  0.78857819]]\n",
      "\n",
      " [[ 0.05830814  0.11862735  1.09925029]\n",
      "  [ 0.00577288  0.09314741  1.10155067]\n",
      "  [ 0.11214718  0.04878429  1.1079602 ]\n",
      "  ...\n",
      "  [ 0.02789533  0.11125202  0.95738063]\n",
      "  [-0.14720145  0.11713358  1.10546527]\n",
      "  [ 0.10149716  0.18553953  0.77859191]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.06514078  0.10743559  1.09854434]\n",
      "  [ 0.01258841  0.07519512  1.09770617]\n",
      "  [ 0.11424431  0.0304051   1.1052197 ]\n",
      "  ...\n",
      "  [ 0.02894011  0.10375525  0.95488617]\n",
      "  [-0.10035804  0.12886144  1.05786929]\n",
      "  [ 0.13409585  0.19358431  0.70424936]]\n",
      "\n",
      " [[ 0.06448636  0.10722178  1.09857646]\n",
      "  [ 0.01158288  0.07450141  1.09853814]\n",
      "  [ 0.11328307  0.0301951   1.10594103]\n",
      "  ...\n",
      "  [ 0.02808467  0.10421862  0.95494268]\n",
      "  [-0.1042936   0.12608895  1.05887864]\n",
      "  [ 0.13398051  0.19486722  0.70999632]]\n",
      "\n",
      " [[ 0.06505365  0.10700007  1.09840099]\n",
      "  [ 0.01148226  0.07450473  1.09946916]\n",
      "  [ 0.11353293  0.03100106  1.10646746]\n",
      "  ...\n",
      "  [ 0.02804401  0.10450193  0.95452855]\n",
      "  [-0.10719479  0.12254594  1.05774752]\n",
      "  [ 0.13560712  0.20017552  0.71754024]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-4prs.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-4prs.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 243 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 239 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-4prs.wav':\n",
      "  Duration: 00:03:17.43, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x564cb42ea180] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x564cb42ea180] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x564cb42ea180] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-4prs_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=449 q=-1.0 Lsize=    3691kB time=00:03:17.43 bitrate= 153.2kbits/s speed= 111x    \n",
      "video:545kB audio:3095kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.401183%\n",
      "[aac @ 0x564cb42e8a40] Qavg: 188.133\n",
      "[libx264 @ 0x564cb42ea180] frame I:4     Avg QP:16.70  size: 13396\n",
      "[libx264 @ 0x564cb42ea180] frame P:224   Avg QP:23.48  size:  1318\n",
      "[libx264 @ 0x564cb42ea180] frame B:572   Avg QP:29.09  size:   365\n",
      "[libx264 @ 0x564cb42ea180] consecutive B-frames:  2.2%  5.5%  5.2% 87.0%\n",
      "[libx264 @ 0x564cb42ea180] mb I  I16..4: 27.9% 47.7% 24.4%\n",
      "[libx264 @ 0x564cb42ea180] mb P  I16..4:  0.0%  0.1%  0.0%  P16..4:  0.9%  1.7%  2.1%  0.0%  0.0%    skip:95.2%\n",
      "[libx264 @ 0x564cb42ea180] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.5%  1.8%  0.8%  direct: 0.3%  skip:95.6%  L0:43.7% L1:41.6% BI:14.6%\n",
      "[libx264 @ 0x564cb42ea180] 8x8 transform intra:49.5% inter:27.5%\n",
      "[libx264 @ 0x564cb42ea180] coded y,uvDC,uvAC intra: 18.2% 2.2% 1.7% inter: 1.3% 0.4% 0.4%\n",
      "[libx264 @ 0x564cb42ea180] i16 v,h,dc,p: 80%  7% 14%  0%\n",
      "[libx264 @ 0x564cb42ea180] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 11% 47%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x564cb42ea180] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 44% 30%  7%  2%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x564cb42ea180] i8c dc,h,v,p: 99%  1%  1%  0%\n",
      "[libx264 @ 0x564cb42ea180] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x564cb42ea180] ref P L0: 51.7%  8.2% 20.7% 19.3%\n",
      "[libx264 @ 0x564cb42ea180] ref B L0: 81.0% 13.0%  6.0%\n",
      "[libx264 @ 0x564cb42ea180] ref B L1: 93.4%  6.6%\n",
      "[libx264 @ 0x564cb42ea180] kb/s:223.11\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        # first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        # print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        # test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        # print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        plot(test_datapath + test_music_list[num_count] + \".mid\", \"./video_\" + filecode + \"_test_predict.mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8172, 112])\n",
      "test_input (1, 8172, 156)\n",
      "test_target torch.Size([1, 8172, 112])\n",
      "prediction.shape (1, 8172, 102)\n",
      "full_prediction (8172, 102)\n",
      "torch.Size([11534, 112])\n",
      "test_input (1, 11534, 156)\n",
      "test_target torch.Size([1, 11534, 112])\n",
      "prediction.shape (1, 11534, 102)\n",
      "full_prediction (11534, 102)\n",
      "torch.Size([6989, 112])\n",
      "test_input (1, 6989, 156)\n",
      "test_target torch.Size([1, 6989, 112])\n",
      "prediction.shape (1, 6989, 102)\n",
      "full_prediction (6989, 102)\n",
      "torch.Size([7898, 112])\n",
      "test_input (1, 7898, 156)\n",
      "test_target torch.Size([1, 7898, 112])\n",
      "prediction.shape (1, 7898, 102)\n",
      "full_prediction (7898, 102)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        if not os.path.exists('./output_prediction/[all]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/'):\n",
    "            os.makedirs('./output_prediction/[all]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/')\n",
    "        midi_data_output = open('./output_prediction/[all]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/prediction_'+\n",
    "                                filecode +'.pkl', 'wb')\n",
    "        pickle.dump(prediction_arr, midi_data_output)\n",
    "        midi_data_output.close()\n",
    "        \n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bac6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n"
     ]
    }
   ],
   "source": [
    "final_val_loss = evaluate_lstm(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee221509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01275933813303709\n"
     ]
    }
   ],
   "source": [
    "print(final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation L1\n",
      "len(all_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(all_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(all_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(all_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(all_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 156])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "0.04442169889807701\n"
     ]
    }
   ],
   "source": [
    "final_l1_loss = evaluate_l1(model, val_dataloader)\n",
    "print(final_l1_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

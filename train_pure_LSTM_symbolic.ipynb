{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc6d36-fc6d-4916-b7b0-6a2dfaf9c4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder, Seq2Seq\n",
    "from data_loader import *\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pretty_midi\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import math\n",
    "matplotlib.use('Agg')\n",
    "# matplotlib.use(\"QtAgg\")\n",
    "import ffmpeg\n",
    "#conda install -c conda-forge ffmpeg-python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, writers\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/home/ilc/anaconda3/bin/ffmpeg'#'/usr/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b387469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26d6b8a-e8ec-4fa2-b14f-a45764fa7545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.piece_count:  105\n",
      "dataset_len:  10500\n",
      "val_dataset_len 5\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_name_path = f\"midi_list_symbolic.txt\" #f\"./midi_list.txt\"\n",
    "dataloader = get_dataloader(dataset_name_path, batch_size=128) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "val_dataset_name_path = f\"./midi_list_eval_symbolic.txt\" #f\"./midi_list_eval.txt\"\n",
    "val_dataloader = get_val_dataloader(val_dataset_name_path, batch_size=128) #[20, 512, 128], [20, 512, 102]\n",
    "\n",
    "learning_rate = 0.001#0.001\n",
    "\n",
    "input_size_encoder = 128 #129 #128\n",
    "input_size_decoder = 112 #102 #24\n",
    "output_size = 112#102 #24\n",
    "\n",
    "# encoder_embedding_size = 300\n",
    "# decoder_embedding_size = 300\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.\n",
    "step = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, output_dim, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.output_dim = output_dim #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, output_dim) #fully connected to determine output dim\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # h0, c0 no time information\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        # x is MIDI => [44, 512, 128]\n",
    "\n",
    "        # hn is final state, run over the sequence length\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        # print(\"output.shape\", output.shape)\n",
    "        # print(\"hn.shape\", hn.shape)\n",
    "        # out = self.relu(hn)\n",
    "        out = self.fc_1(output) #final\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23df2697-2943-4f69-89df-1f0c5cbf3343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_size = 128 #number of features\n",
    "hidden_size = 256 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "seq_len = 512\n",
    "output_dim = 112 #number of output classes\n",
    "\n",
    "# model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "# model = LSTM(embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "model = LSTM1(output_dim, input_size, hidden_size, num_layers, seq_len).to(device) #our lstm class\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "num_epochs = 100 #10\n",
    "avg_loss_list = []\n",
    "all_loss_list = []\n",
    "val_loss_per_epoch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fb7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_mse_loss(output, target, prev_output, midi_array):\n",
    "    # target = target.transpose(0, 1)\n",
    "    # print(\"output\", output)\n",
    "    # print(output.shape) #torch.Size([20, 513, 102])\n",
    "    # print(target.shape) #torch.Size([20, 513, 102])\n",
    "    mse_loss = F.mse_loss(output, target)\n",
    "    # print(\"mse_loss:\", mse_loss)\n",
    "\n",
    "    var_diff = torch.var(torch.squeeze(output), dim=1, keepdim=True)\n",
    "    mean_diff = torch.mean(var_diff)\n",
    "    \n",
    "    # Condition 1: Penalize if output is similar to previous output\n",
    "    if mean_diff < 1e-4: #threshold\n",
    "        #output [512, 1, 102] => [102] <-> [102] <-> [102] <-> ... <-> [102]\n",
    "        mse_loss *= 1000\n",
    "\n",
    "    # Condition 2: Stop movement if input is all zeros\n",
    "    # midi_transpose = midi_array.transpose(0, 1)\n",
    "    # midi_sum_row = torch.sum(midi_transpose, dim=-1)\n",
    "    # mask = midi_sum_row == 0\n",
    "    # mask = mask.unsqueeze(-1)\n",
    "    # mask = mask.to(device)\n",
    "    # # according to recorded index, make a mask [0, 1, 1, 0, ..., 0], true part will be omit(set value to 0).\n",
    "    # # before compute mse, use mask first to tensor, then caculate MES loss\n",
    "    # masked_output = output.masked_fill(mask, 0) #inplace function\n",
    "    # masked_target = target.masked_fill(mask, 0)\n",
    "    # mse_loss += F.mse_loss(masked_output, masked_target) * 100 #output 和 previous output 不像的話，增大 loss\n",
    "\n",
    "    # Condition 3: Penalize if right-hand movement is too different between outputs\n",
    "    # if output.shape[-1] == 21:  # Assumes hand joints are the last 21 dimensions\n",
    "    #     rh_indices = [i for i in range(12, 21)]  # Right-hand joint indices\n",
    "    #     rh_output = output[..., rh_indices]\n",
    "    #     rh_prev_output = prev_output[..., rh_indices]\n",
    "    #     rh_loss = nn.functional.mse_loss(rh_output, rh_prev_output)\n",
    "    #     if rh_loss > 0.1:\n",
    "    #         mse_loss *= 1000\n",
    "\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee089d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(model, val_dataloader):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    counter = 0\n",
    "    # previous_output = torch.zeros(512, 102).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_dataloader): #tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            counter += 1\n",
    "\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "            print(\"inputs.shape:\", inputs.shape)\n",
    "            print(\"targets.shape:\", targets.shape)\n",
    "            outputs = model(inputs)\n",
    "            print(\"outputs.shape:\", outputs.shape)\n",
    "\n",
    "            loss =  F.mse_loss(outputs, targets)\n",
    "            valid_running_loss += loss.cpu().item()\n",
    "            # previous_output = outputs\n",
    "\n",
    "    epoch_val_loss = valid_running_loss / counter\n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e92038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0: loss = 0.185788\n",
      "Epoch 0, batch 1: loss = 0.181267\n",
      "Epoch 0, batch 2: loss = 0.174472\n",
      "Epoch 0, batch 3: loss = 0.167693\n",
      "Epoch 0, batch 4: loss = 0.158342\n",
      "Epoch 0, batch 5: loss = 0.146799\n",
      "Epoch 0, batch 6: loss = 0.132753\n",
      "Epoch 0, batch 7: loss = 0.109730\n",
      "Epoch 0, batch 8: loss = 0.066779\n",
      "Epoch 0, batch 9: loss = 0.147527\n",
      "Epoch 0, batch 10: loss = 0.053333\n",
      "Epoch 0, batch 11: loss = 0.051527\n",
      "Epoch 0, batch 12: loss = 0.060552\n",
      "Epoch 0, batch 13: loss = 0.061877\n",
      "Epoch 0, batch 14: loss = 0.056914\n",
      "Epoch 0, batch 15: loss = 0.047171\n",
      "Epoch 0, batch 16: loss = 0.036223\n",
      "Epoch 0, batch 17: loss = 0.028663\n",
      "Epoch 0, batch 18: loss = 0.019750\n",
      "Epoch 0, batch 19: loss = 0.019938\n",
      "Epoch 0, batch 20: loss = 0.024164\n",
      "Epoch 0, batch 21: loss = 0.027480\n",
      "Epoch 0, batch 22: loss = 0.030184\n",
      "Epoch 0, batch 23: loss = 0.024068\n",
      "Epoch 0, batch 24: loss = 0.021902\n",
      "Epoch 0, batch 25: loss = 0.018091\n",
      "Epoch 0, batch 26: loss = 0.015868\n",
      "Epoch 0, batch 27: loss = 0.016843\n",
      "Epoch 0, batch 28: loss = 0.017173\n",
      "Epoch 0, batch 29: loss = 0.016748\n",
      "Epoch 0, batch 30: loss = 0.020077\n",
      "Epoch 0, batch 31: loss = 0.018302\n",
      "Epoch 0, batch 32: loss = 0.016893\n",
      "Epoch 0, batch 33: loss = 0.018236\n",
      "Epoch 0, batch 34: loss = 0.017043\n",
      "Epoch 0, batch 35: loss = 0.017632\n",
      "Epoch 0, batch 36: loss = 0.016463\n",
      "Epoch 0, batch 37: loss = 0.015223\n",
      "Epoch 0, batch 38: loss = 0.015883\n",
      "Epoch 0, batch 39: loss = 0.016285\n",
      "Epoch 0, batch 40: loss = 0.016200\n",
      "Epoch 0, batch 41: loss = 0.015321\n",
      "Epoch 0, batch 42: loss = 0.015417\n",
      "Epoch 0, batch 43: loss = 0.016406\n",
      "Epoch 0, batch 44: loss = 0.017231\n",
      "Epoch 0, batch 45: loss = 0.015299\n",
      "Epoch 0, batch 46: loss = 0.015711\n",
      "Epoch 0, batch 47: loss = 0.014853\n",
      "Epoch 0, batch 48: loss = 0.014723\n",
      "Epoch 0, batch 49: loss = 0.015407\n",
      "Epoch 0, batch 50: loss = 0.014784\n",
      "Epoch 0, batch 51: loss = 0.014650\n",
      "Epoch 0, batch 52: loss = 0.014563\n",
      "Epoch 0, batch 53: loss = 0.013835\n",
      "Epoch 0, batch 54: loss = 0.014608\n",
      "Epoch 0, batch 55: loss = 0.015010\n",
      "Epoch 0, batch 56: loss = 0.014897\n",
      "Epoch 0, batch 57: loss = 0.016119\n",
      "Epoch 0, batch 58: loss = 0.014251\n",
      "Epoch 0, batch 59: loss = 0.013573\n",
      "Epoch 0, batch 60: loss = 0.015127\n",
      "Epoch 0, batch 61: loss = 0.013990\n",
      "Epoch 0, batch 62: loss = 0.014929\n",
      "Epoch 0, batch 63: loss = 0.014498\n",
      "Epoch 0, batch 64: loss = 0.015561\n",
      "Epoch 0, batch 65: loss = 0.013656\n",
      "Epoch 0, batch 66: loss = 0.014605\n",
      "Epoch 0, batch 67: loss = 0.015213\n",
      "Epoch 0, batch 68: loss = 0.013523\n",
      "Epoch 0, batch 69: loss = 0.014137\n",
      "Epoch 0, batch 70: loss = 0.015200\n",
      "Epoch 0, batch 71: loss = 0.015152\n",
      "Epoch 0, batch 72: loss = 0.014287\n",
      "Epoch 0, batch 73: loss = 0.015134\n",
      "Epoch 0, batch 74: loss = 0.014665\n",
      "Epoch 0, batch 75: loss = 0.014294\n",
      "Epoch 0, batch 76: loss = 0.014559\n",
      "Epoch 0, batch 77: loss = 0.014526\n",
      "Epoch 0, batch 78: loss = 0.013649\n",
      "Epoch 0, batch 79: loss = 0.015443\n",
      "Epoch 0, batch 80: loss = 0.014569\n",
      "Epoch 0, batch 81: loss = 0.013613\n",
      "Epoch 0, batch 82: loss = 0.012619\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 0: val_loss = 0.034755\n",
      "Epoch 1, batch 0: loss = 0.014893\n",
      "Epoch 1, batch 1: loss = 0.013747\n",
      "Epoch 1, batch 2: loss = 0.014249\n",
      "Epoch 1, batch 3: loss = 0.013554\n",
      "Epoch 1, batch 4: loss = 0.014447\n",
      "Epoch 1, batch 5: loss = 0.014257\n",
      "Epoch 1, batch 6: loss = 0.013630\n",
      "Epoch 1, batch 7: loss = 0.015838\n",
      "Epoch 1, batch 8: loss = 0.014294\n",
      "Epoch 1, batch 9: loss = 0.014272\n",
      "Epoch 1, batch 10: loss = 0.015048\n",
      "Epoch 1, batch 11: loss = 0.014171\n",
      "Epoch 1, batch 12: loss = 0.015055\n",
      "Epoch 1, batch 13: loss = 0.014730\n",
      "Epoch 1, batch 14: loss = 0.014218\n",
      "Epoch 1, batch 15: loss = 0.015518\n",
      "Epoch 1, batch 16: loss = 0.014621\n",
      "Epoch 1, batch 17: loss = 0.014601\n",
      "Epoch 1, batch 18: loss = 0.014218\n",
      "Epoch 1, batch 19: loss = 0.014084\n",
      "Epoch 1, batch 20: loss = 0.014028\n",
      "Epoch 1, batch 21: loss = 0.014285\n",
      "Epoch 1, batch 22: loss = 0.014249\n",
      "Epoch 1, batch 23: loss = 0.015600\n",
      "Epoch 1, batch 24: loss = 0.013567\n",
      "Epoch 1, batch 25: loss = 0.016425\n",
      "Epoch 1, batch 26: loss = 0.014505\n",
      "Epoch 1, batch 27: loss = 0.013581\n",
      "Epoch 1, batch 28: loss = 0.014414\n",
      "Epoch 1, batch 29: loss = 0.012934\n",
      "Epoch 1, batch 30: loss = 0.014415\n",
      "Epoch 1, batch 31: loss = 0.013937\n",
      "Epoch 1, batch 32: loss = 0.014580\n",
      "Epoch 1, batch 33: loss = 0.013641\n",
      "Epoch 1, batch 34: loss = 0.014175\n",
      "Epoch 1, batch 35: loss = 0.013608\n",
      "Epoch 1, batch 36: loss = 0.014134\n",
      "Epoch 1, batch 37: loss = 0.014192\n",
      "Epoch 1, batch 38: loss = 0.014206\n",
      "Epoch 1, batch 39: loss = 0.014183\n",
      "Epoch 1, batch 40: loss = 0.013660\n",
      "Epoch 1, batch 41: loss = 0.015767\n",
      "Epoch 1, batch 42: loss = 0.014219\n",
      "Epoch 1, batch 43: loss = 0.015142\n",
      "Epoch 1, batch 44: loss = 0.013836\n",
      "Epoch 1, batch 45: loss = 0.014268\n",
      "Epoch 1, batch 46: loss = 0.014873\n",
      "Epoch 1, batch 47: loss = 0.014652\n",
      "Epoch 1, batch 48: loss = 0.014099\n",
      "Epoch 1, batch 49: loss = 0.014277\n",
      "Epoch 1, batch 50: loss = 0.014447\n",
      "Epoch 1, batch 51: loss = 0.014340\n",
      "Epoch 1, batch 52: loss = 0.013057\n",
      "Epoch 1, batch 53: loss = 0.015281\n",
      "Epoch 1, batch 54: loss = 0.015416\n",
      "Epoch 1, batch 55: loss = 0.015061\n",
      "Epoch 1, batch 56: loss = 0.014609\n",
      "Epoch 1, batch 57: loss = 0.014287\n",
      "Epoch 1, batch 58: loss = 0.014032\n",
      "Epoch 1, batch 59: loss = 0.013960\n",
      "Epoch 1, batch 60: loss = 0.013842\n",
      "Epoch 1, batch 61: loss = 0.013584\n",
      "Epoch 1, batch 62: loss = 0.014313\n",
      "Epoch 1, batch 63: loss = 0.014861\n",
      "Epoch 1, batch 64: loss = 0.014526\n",
      "Epoch 1, batch 65: loss = 0.014405\n",
      "Epoch 1, batch 66: loss = 0.014822\n",
      "Epoch 1, batch 67: loss = 0.013101\n",
      "Epoch 1, batch 68: loss = 0.013468\n",
      "Epoch 1, batch 69: loss = 0.014646\n",
      "Epoch 1, batch 70: loss = 0.014309\n",
      "Epoch 1, batch 71: loss = 0.013342\n",
      "Epoch 1, batch 72: loss = 0.013738\n",
      "Epoch 1, batch 73: loss = 0.013926\n",
      "Epoch 1, batch 74: loss = 0.014698\n",
      "Epoch 1, batch 75: loss = 0.013900\n",
      "Epoch 1, batch 76: loss = 0.014429\n",
      "Epoch 1, batch 77: loss = 0.012884\n",
      "Epoch 1, batch 78: loss = 0.014232\n",
      "Epoch 1, batch 79: loss = 0.014323\n",
      "Epoch 1, batch 80: loss = 0.014012\n",
      "Epoch 1, batch 81: loss = 0.014033\n",
      "Epoch 1, batch 82: loss = 0.013980\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 1: val_loss = 0.036021\n",
      "Epoch 2, batch 0: loss = 0.015182\n",
      "Epoch 2, batch 1: loss = 0.013287\n",
      "Epoch 2, batch 2: loss = 0.013600\n",
      "Epoch 2, batch 3: loss = 0.014411\n",
      "Epoch 2, batch 4: loss = 0.012941\n",
      "Epoch 2, batch 5: loss = 0.014639\n",
      "Epoch 2, batch 6: loss = 0.013794\n",
      "Epoch 2, batch 7: loss = 0.013874\n",
      "Epoch 2, batch 8: loss = 0.015750\n",
      "Epoch 2, batch 9: loss = 0.014861\n",
      "Epoch 2, batch 10: loss = 0.015438\n",
      "Epoch 2, batch 11: loss = 0.013773\n",
      "Epoch 2, batch 12: loss = 0.014636\n",
      "Epoch 2, batch 13: loss = 0.014189\n",
      "Epoch 2, batch 14: loss = 0.014164\n",
      "Epoch 2, batch 15: loss = 0.015155\n",
      "Epoch 2, batch 16: loss = 0.013342\n",
      "Epoch 2, batch 17: loss = 0.013512\n",
      "Epoch 2, batch 18: loss = 0.013534\n",
      "Epoch 2, batch 19: loss = 0.014243\n",
      "Epoch 2, batch 20: loss = 0.014801\n",
      "Epoch 2, batch 21: loss = 0.013203\n",
      "Epoch 2, batch 22: loss = 0.013951\n",
      "Epoch 2, batch 23: loss = 0.014157\n",
      "Epoch 2, batch 24: loss = 0.015372\n",
      "Epoch 2, batch 25: loss = 0.013885\n",
      "Epoch 2, batch 26: loss = 0.013392\n",
      "Epoch 2, batch 27: loss = 0.014177\n",
      "Epoch 2, batch 28: loss = 0.013986\n",
      "Epoch 2, batch 29: loss = 0.013376\n",
      "Epoch 2, batch 30: loss = 0.013514\n",
      "Epoch 2, batch 31: loss = 0.013637\n",
      "Epoch 2, batch 32: loss = 0.015436\n",
      "Epoch 2, batch 33: loss = 0.014299\n",
      "Epoch 2, batch 34: loss = 0.014631\n",
      "Epoch 2, batch 35: loss = 0.014150\n",
      "Epoch 2, batch 36: loss = 0.012320\n",
      "Epoch 2, batch 37: loss = 0.013893\n",
      "Epoch 2, batch 38: loss = 0.013864\n",
      "Epoch 2, batch 39: loss = 0.013678\n",
      "Epoch 2, batch 40: loss = 0.013434\n",
      "Epoch 2, batch 41: loss = 0.012875\n",
      "Epoch 2, batch 42: loss = 0.013776\n",
      "Epoch 2, batch 43: loss = 0.012848\n",
      "Epoch 2, batch 44: loss = 0.014092\n",
      "Epoch 2, batch 45: loss = 0.013566\n",
      "Epoch 2, batch 46: loss = 0.014304\n",
      "Epoch 2, batch 47: loss = 0.013665\n",
      "Epoch 2, batch 48: loss = 0.013039\n",
      "Epoch 2, batch 49: loss = 0.014048\n",
      "Epoch 2, batch 50: loss = 0.013137\n",
      "Epoch 2, batch 51: loss = 0.014170\n",
      "Epoch 2, batch 52: loss = 0.013473\n",
      "Epoch 2, batch 53: loss = 0.013043\n",
      "Epoch 2, batch 54: loss = 0.014248\n",
      "Epoch 2, batch 55: loss = 0.013577\n",
      "Epoch 2, batch 56: loss = 0.013852\n",
      "Epoch 2, batch 57: loss = 0.014195\n",
      "Epoch 2, batch 58: loss = 0.015322\n",
      "Epoch 2, batch 59: loss = 0.014175\n",
      "Epoch 2, batch 60: loss = 0.014445\n",
      "Epoch 2, batch 61: loss = 0.013695\n",
      "Epoch 2, batch 62: loss = 0.013584\n",
      "Epoch 2, batch 63: loss = 0.013955\n",
      "Epoch 2, batch 64: loss = 0.014236\n",
      "Epoch 2, batch 65: loss = 0.014594\n",
      "Epoch 2, batch 66: loss = 0.013786\n",
      "Epoch 2, batch 67: loss = 0.014551\n",
      "Epoch 2, batch 68: loss = 0.014070\n",
      "Epoch 2, batch 69: loss = 0.013489\n",
      "Epoch 2, batch 70: loss = 0.014437\n",
      "Epoch 2, batch 71: loss = 0.014428\n",
      "Epoch 2, batch 72: loss = 0.014315\n",
      "Epoch 2, batch 73: loss = 0.013057\n",
      "Epoch 2, batch 74: loss = 0.012691\n",
      "Epoch 2, batch 75: loss = 0.013639\n",
      "Epoch 2, batch 76: loss = 0.013225\n",
      "Epoch 2, batch 77: loss = 0.014519\n",
      "Epoch 2, batch 78: loss = 0.013931\n",
      "Epoch 2, batch 79: loss = 0.014438\n",
      "Epoch 2, batch 80: loss = 0.013929\n",
      "Epoch 2, batch 81: loss = 0.012767\n",
      "Epoch 2, batch 82: loss = 0.014627\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 2: val_loss = 0.036839\n",
      "Epoch 3, batch 0: loss = 0.014720\n",
      "Epoch 3, batch 1: loss = 0.013993\n",
      "Epoch 3, batch 2: loss = 0.013405\n",
      "Epoch 3, batch 3: loss = 0.013739\n",
      "Epoch 3, batch 4: loss = 0.013152\n",
      "Epoch 3, batch 5: loss = 0.014645\n",
      "Epoch 3, batch 6: loss = 0.013104\n",
      "Epoch 3, batch 7: loss = 0.012964\n",
      "Epoch 3, batch 8: loss = 0.013513\n",
      "Epoch 3, batch 9: loss = 0.013079\n",
      "Epoch 3, batch 10: loss = 0.015317\n",
      "Epoch 3, batch 11: loss = 0.013623\n",
      "Epoch 3, batch 12: loss = 0.014000\n",
      "Epoch 3, batch 13: loss = 0.014683\n",
      "Epoch 3, batch 14: loss = 0.013553\n",
      "Epoch 3, batch 15: loss = 0.013641\n",
      "Epoch 3, batch 16: loss = 0.013752\n",
      "Epoch 3, batch 17: loss = 0.013795\n",
      "Epoch 3, batch 18: loss = 0.014652\n",
      "Epoch 3, batch 19: loss = 0.014134\n",
      "Epoch 3, batch 20: loss = 0.013757\n",
      "Epoch 3, batch 21: loss = 0.014422\n",
      "Epoch 3, batch 22: loss = 0.013261\n",
      "Epoch 3, batch 23: loss = 0.013229\n",
      "Epoch 3, batch 24: loss = 0.014644\n",
      "Epoch 3, batch 25: loss = 0.013284\n",
      "Epoch 3, batch 26: loss = 0.015209\n",
      "Epoch 3, batch 27: loss = 0.014626\n",
      "Epoch 3, batch 28: loss = 0.013663\n",
      "Epoch 3, batch 29: loss = 0.013136\n",
      "Epoch 3, batch 30: loss = 0.012853\n",
      "Epoch 3, batch 31: loss = 0.013855\n",
      "Epoch 3, batch 32: loss = 0.013321\n",
      "Epoch 3, batch 33: loss = 0.013746\n",
      "Epoch 3, batch 34: loss = 0.013364\n",
      "Epoch 3, batch 35: loss = 0.013350\n",
      "Epoch 3, batch 36: loss = 0.015426\n",
      "Epoch 3, batch 37: loss = 0.012657\n",
      "Epoch 3, batch 38: loss = 0.013900\n",
      "Epoch 3, batch 39: loss = 0.013265\n",
      "Epoch 3, batch 40: loss = 0.012639\n",
      "Epoch 3, batch 41: loss = 0.014700\n",
      "Epoch 3, batch 42: loss = 0.012454\n",
      "Epoch 3, batch 43: loss = 0.013038\n",
      "Epoch 3, batch 44: loss = 0.015512\n",
      "Epoch 3, batch 45: loss = 0.013165\n",
      "Epoch 3, batch 46: loss = 0.013572\n",
      "Epoch 3, batch 47: loss = 0.013220\n",
      "Epoch 3, batch 48: loss = 0.014514\n",
      "Epoch 3, batch 49: loss = 0.012455\n",
      "Epoch 3, batch 50: loss = 0.013005\n",
      "Epoch 3, batch 51: loss = 0.014905\n",
      "Epoch 3, batch 52: loss = 0.013938\n",
      "Epoch 3, batch 53: loss = 0.014619\n",
      "Epoch 3, batch 54: loss = 0.013704\n",
      "Epoch 3, batch 55: loss = 0.014050\n",
      "Epoch 3, batch 56: loss = 0.013317\n",
      "Epoch 3, batch 57: loss = 0.013609\n",
      "Epoch 3, batch 58: loss = 0.013296\n",
      "Epoch 3, batch 59: loss = 0.013574\n",
      "Epoch 3, batch 60: loss = 0.013829\n",
      "Epoch 3, batch 61: loss = 0.013458\n",
      "Epoch 3, batch 62: loss = 0.012651\n",
      "Epoch 3, batch 63: loss = 0.013055\n",
      "Epoch 3, batch 64: loss = 0.014558\n",
      "Epoch 3, batch 65: loss = 0.012738\n",
      "Epoch 3, batch 66: loss = 0.013886\n",
      "Epoch 3, batch 67: loss = 0.013418\n",
      "Epoch 3, batch 68: loss = 0.013904\n",
      "Epoch 3, batch 69: loss = 0.013364\n",
      "Epoch 3, batch 70: loss = 0.013643\n",
      "Epoch 3, batch 71: loss = 0.014029\n",
      "Epoch 3, batch 72: loss = 0.014007\n",
      "Epoch 3, batch 73: loss = 0.013227\n",
      "Epoch 3, batch 74: loss = 0.011982\n",
      "Epoch 3, batch 75: loss = 0.013715\n",
      "Epoch 3, batch 76: loss = 0.014592\n",
      "Epoch 3, batch 77: loss = 0.012519\n",
      "Epoch 3, batch 78: loss = 0.013746\n",
      "Epoch 3, batch 79: loss = 0.012728\n",
      "Epoch 3, batch 80: loss = 0.013598\n",
      "Epoch 3, batch 81: loss = 0.012163\n",
      "Epoch 3, batch 82: loss = 0.011403\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 3: val_loss = 0.037261\n",
      "Epoch 4, batch 0: loss = 0.012895\n",
      "Epoch 4, batch 1: loss = 0.013227\n",
      "Epoch 4, batch 2: loss = 0.014429\n",
      "Epoch 4, batch 3: loss = 0.014193\n",
      "Epoch 4, batch 4: loss = 0.014596\n",
      "Epoch 4, batch 5: loss = 0.014112\n",
      "Epoch 4, batch 6: loss = 0.013139\n",
      "Epoch 4, batch 7: loss = 0.013226\n",
      "Epoch 4, batch 8: loss = 0.014341\n",
      "Epoch 4, batch 9: loss = 0.013080\n",
      "Epoch 4, batch 10: loss = 0.013610\n",
      "Epoch 4, batch 11: loss = 0.013797\n",
      "Epoch 4, batch 12: loss = 0.013172\n",
      "Epoch 4, batch 13: loss = 0.012225\n",
      "Epoch 4, batch 14: loss = 0.013225\n",
      "Epoch 4, batch 15: loss = 0.014213\n",
      "Epoch 4, batch 16: loss = 0.013485\n",
      "Epoch 4, batch 17: loss = 0.013736\n",
      "Epoch 4, batch 18: loss = 0.012402\n",
      "Epoch 4, batch 19: loss = 0.012779\n",
      "Epoch 4, batch 20: loss = 0.013128\n",
      "Epoch 4, batch 21: loss = 0.014537\n",
      "Epoch 4, batch 22: loss = 0.013771\n",
      "Epoch 4, batch 23: loss = 0.012757\n",
      "Epoch 4, batch 24: loss = 0.013917\n",
      "Epoch 4, batch 25: loss = 0.013384\n",
      "Epoch 4, batch 26: loss = 0.013445\n",
      "Epoch 4, batch 27: loss = 0.012803\n",
      "Epoch 4, batch 28: loss = 0.014038\n",
      "Epoch 4, batch 29: loss = 0.013511\n",
      "Epoch 4, batch 30: loss = 0.012642\n",
      "Epoch 4, batch 31: loss = 0.013071\n",
      "Epoch 4, batch 32: loss = 0.014848\n",
      "Epoch 4, batch 33: loss = 0.013587\n",
      "Epoch 4, batch 34: loss = 0.013105\n",
      "Epoch 4, batch 35: loss = 0.013505\n",
      "Epoch 4, batch 36: loss = 0.013954\n",
      "Epoch 4, batch 37: loss = 0.014412\n",
      "Epoch 4, batch 38: loss = 0.012963\n",
      "Epoch 4, batch 39: loss = 0.012768\n",
      "Epoch 4, batch 40: loss = 0.012360\n",
      "Epoch 4, batch 41: loss = 0.013123\n",
      "Epoch 4, batch 42: loss = 0.013045\n",
      "Epoch 4, batch 43: loss = 0.012501\n",
      "Epoch 4, batch 44: loss = 0.013575\n",
      "Epoch 4, batch 45: loss = 0.013300\n",
      "Epoch 4, batch 46: loss = 0.013293\n",
      "Epoch 4, batch 47: loss = 0.012688\n",
      "Epoch 4, batch 48: loss = 0.012896\n",
      "Epoch 4, batch 49: loss = 0.013354\n",
      "Epoch 4, batch 50: loss = 0.014142\n",
      "Epoch 4, batch 51: loss = 0.013465\n",
      "Epoch 4, batch 52: loss = 0.012935\n",
      "Epoch 4, batch 53: loss = 0.012945\n",
      "Epoch 4, batch 54: loss = 0.013904\n",
      "Epoch 4, batch 55: loss = 0.012622\n",
      "Epoch 4, batch 56: loss = 0.012700\n",
      "Epoch 4, batch 57: loss = 0.012120\n",
      "Epoch 4, batch 58: loss = 0.014127\n",
      "Epoch 4, batch 59: loss = 0.012509\n",
      "Epoch 4, batch 60: loss = 0.013160\n",
      "Epoch 4, batch 61: loss = 0.013785\n",
      "Epoch 4, batch 62: loss = 0.013670\n",
      "Epoch 4, batch 63: loss = 0.012829\n",
      "Epoch 4, batch 64: loss = 0.012385\n",
      "Epoch 4, batch 65: loss = 0.013264\n",
      "Epoch 4, batch 66: loss = 0.012891\n",
      "Epoch 4, batch 67: loss = 0.014109\n",
      "Epoch 4, batch 68: loss = 0.012659\n",
      "Epoch 4, batch 69: loss = 0.014294\n",
      "Epoch 4, batch 70: loss = 0.013709\n",
      "Epoch 4, batch 71: loss = 0.013571\n",
      "Epoch 4, batch 72: loss = 0.011629\n",
      "Epoch 4, batch 73: loss = 0.013356\n",
      "Epoch 4, batch 74: loss = 0.013575\n",
      "Epoch 4, batch 75: loss = 0.013220\n",
      "Epoch 4, batch 76: loss = 0.014141\n",
      "Epoch 4, batch 77: loss = 0.013287\n",
      "Epoch 4, batch 78: loss = 0.012401\n",
      "Epoch 4, batch 79: loss = 0.012361\n",
      "Epoch 4, batch 80: loss = 0.013751\n",
      "Epoch 4, batch 81: loss = 0.012634\n",
      "Epoch 4, batch 82: loss = 0.011288\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 4: val_loss = 0.037167\n",
      "Epoch 5, batch 0: loss = 0.015325\n",
      "Epoch 5, batch 1: loss = 0.013772\n",
      "Epoch 5, batch 2: loss = 0.012504\n",
      "Epoch 5, batch 3: loss = 0.013710\n",
      "Epoch 5, batch 4: loss = 0.013647\n",
      "Epoch 5, batch 5: loss = 0.013218\n",
      "Epoch 5, batch 6: loss = 0.013101\n",
      "Epoch 5, batch 7: loss = 0.013888\n",
      "Epoch 5, batch 8: loss = 0.013797\n",
      "Epoch 5, batch 9: loss = 0.012676\n",
      "Epoch 5, batch 10: loss = 0.013221\n",
      "Epoch 5, batch 11: loss = 0.012699\n",
      "Epoch 5, batch 12: loss = 0.013679\n",
      "Epoch 5, batch 13: loss = 0.012010\n",
      "Epoch 5, batch 14: loss = 0.013788\n",
      "Epoch 5, batch 15: loss = 0.012939\n",
      "Epoch 5, batch 16: loss = 0.012626\n",
      "Epoch 5, batch 17: loss = 0.012457\n",
      "Epoch 5, batch 18: loss = 0.013435\n",
      "Epoch 5, batch 19: loss = 0.012976\n",
      "Epoch 5, batch 20: loss = 0.012072\n",
      "Epoch 5, batch 21: loss = 0.013281\n",
      "Epoch 5, batch 22: loss = 0.013543\n",
      "Epoch 5, batch 23: loss = 0.012730\n",
      "Epoch 5, batch 24: loss = 0.012430\n",
      "Epoch 5, batch 25: loss = 0.013544\n",
      "Epoch 5, batch 26: loss = 0.013032\n",
      "Epoch 5, batch 27: loss = 0.013239\n",
      "Epoch 5, batch 28: loss = 0.012961\n",
      "Epoch 5, batch 29: loss = 0.013193\n",
      "Epoch 5, batch 30: loss = 0.013393\n",
      "Epoch 5, batch 31: loss = 0.012934\n",
      "Epoch 5, batch 32: loss = 0.012371\n",
      "Epoch 5, batch 33: loss = 0.012228\n",
      "Epoch 5, batch 34: loss = 0.012626\n",
      "Epoch 5, batch 35: loss = 0.013075\n",
      "Epoch 5, batch 36: loss = 0.013015\n",
      "Epoch 5, batch 37: loss = 0.013918\n",
      "Epoch 5, batch 38: loss = 0.013336\n",
      "Epoch 5, batch 39: loss = 0.012762\n",
      "Epoch 5, batch 40: loss = 0.013085\n",
      "Epoch 5, batch 41: loss = 0.012795\n",
      "Epoch 5, batch 42: loss = 0.013228\n",
      "Epoch 5, batch 43: loss = 0.012577\n",
      "Epoch 5, batch 44: loss = 0.012275\n",
      "Epoch 5, batch 45: loss = 0.012132\n",
      "Epoch 5, batch 46: loss = 0.013423\n",
      "Epoch 5, batch 47: loss = 0.012526\n",
      "Epoch 5, batch 48: loss = 0.011700\n",
      "Epoch 5, batch 49: loss = 0.013598\n",
      "Epoch 5, batch 50: loss = 0.014057\n",
      "Epoch 5, batch 51: loss = 0.012000\n",
      "Epoch 5, batch 52: loss = 0.012402\n",
      "Epoch 5, batch 53: loss = 0.013624\n",
      "Epoch 5, batch 54: loss = 0.012443\n",
      "Epoch 5, batch 55: loss = 0.012472\n",
      "Epoch 5, batch 56: loss = 0.013479\n",
      "Epoch 5, batch 57: loss = 0.013482\n",
      "Epoch 5, batch 58: loss = 0.011994\n",
      "Epoch 5, batch 59: loss = 0.012954\n",
      "Epoch 5, batch 60: loss = 0.013463\n",
      "Epoch 5, batch 61: loss = 0.012625\n",
      "Epoch 5, batch 62: loss = 0.012941\n",
      "Epoch 5, batch 63: loss = 0.013078\n",
      "Epoch 5, batch 64: loss = 0.013176\n",
      "Epoch 5, batch 65: loss = 0.012333\n",
      "Epoch 5, batch 66: loss = 0.012373\n",
      "Epoch 5, batch 67: loss = 0.012581\n",
      "Epoch 5, batch 68: loss = 0.012204\n",
      "Epoch 5, batch 69: loss = 0.014369\n",
      "Epoch 5, batch 70: loss = 0.011997\n",
      "Epoch 5, batch 71: loss = 0.012769\n",
      "Epoch 5, batch 72: loss = 0.011479\n",
      "Epoch 5, batch 73: loss = 0.013980\n",
      "Epoch 5, batch 74: loss = 0.012175\n",
      "Epoch 5, batch 75: loss = 0.012861\n",
      "Epoch 5, batch 76: loss = 0.012429\n",
      "Epoch 5, batch 77: loss = 0.011201\n",
      "Epoch 5, batch 78: loss = 0.013388\n",
      "Epoch 5, batch 79: loss = 0.012895\n",
      "Epoch 5, batch 80: loss = 0.012752\n",
      "Epoch 5, batch 81: loss = 0.012442\n",
      "Epoch 5, batch 82: loss = 0.014153\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 5: val_loss = 0.036368\n",
      "Epoch 6, batch 0: loss = 0.012786\n",
      "Epoch 6, batch 1: loss = 0.013072\n",
      "Epoch 6, batch 2: loss = 0.013024\n",
      "Epoch 6, batch 3: loss = 0.012183\n",
      "Epoch 6, batch 4: loss = 0.013858\n",
      "Epoch 6, batch 5: loss = 0.012940\n",
      "Epoch 6, batch 6: loss = 0.013261\n",
      "Epoch 6, batch 7: loss = 0.012211\n",
      "Epoch 6, batch 8: loss = 0.012648\n",
      "Epoch 6, batch 9: loss = 0.012208\n",
      "Epoch 6, batch 10: loss = 0.013399\n",
      "Epoch 6, batch 11: loss = 0.013019\n",
      "Epoch 6, batch 12: loss = 0.014280\n",
      "Epoch 6, batch 13: loss = 0.012578\n",
      "Epoch 6, batch 14: loss = 0.013137\n",
      "Epoch 6, batch 15: loss = 0.013200\n",
      "Epoch 6, batch 16: loss = 0.011769\n",
      "Epoch 6, batch 17: loss = 0.012292\n",
      "Epoch 6, batch 18: loss = 0.012041\n",
      "Epoch 6, batch 19: loss = 0.013405\n",
      "Epoch 6, batch 20: loss = 0.011987\n",
      "Epoch 6, batch 21: loss = 0.013356\n",
      "Epoch 6, batch 22: loss = 0.012930\n",
      "Epoch 6, batch 23: loss = 0.012963\n",
      "Epoch 6, batch 24: loss = 0.013104\n",
      "Epoch 6, batch 25: loss = 0.012269\n",
      "Epoch 6, batch 26: loss = 0.013531\n",
      "Epoch 6, batch 27: loss = 0.012096\n",
      "Epoch 6, batch 28: loss = 0.011744\n",
      "Epoch 6, batch 29: loss = 0.011935\n",
      "Epoch 6, batch 30: loss = 0.011938\n",
      "Epoch 6, batch 31: loss = 0.013087\n",
      "Epoch 6, batch 32: loss = 0.012652\n",
      "Epoch 6, batch 33: loss = 0.012375\n",
      "Epoch 6, batch 34: loss = 0.014555\n",
      "Epoch 6, batch 35: loss = 0.013551\n",
      "Epoch 6, batch 36: loss = 0.012741\n",
      "Epoch 6, batch 37: loss = 0.012434\n",
      "Epoch 6, batch 38: loss = 0.012754\n",
      "Epoch 6, batch 39: loss = 0.012632\n",
      "Epoch 6, batch 40: loss = 0.012588\n",
      "Epoch 6, batch 41: loss = 0.012482\n",
      "Epoch 6, batch 42: loss = 0.012744\n",
      "Epoch 6, batch 43: loss = 0.012895\n",
      "Epoch 6, batch 44: loss = 0.013076\n",
      "Epoch 6, batch 45: loss = 0.013399\n",
      "Epoch 6, batch 46: loss = 0.013068\n",
      "Epoch 6, batch 47: loss = 0.012609\n",
      "Epoch 6, batch 48: loss = 0.013394\n",
      "Epoch 6, batch 49: loss = 0.011835\n",
      "Epoch 6, batch 50: loss = 0.012423\n",
      "Epoch 6, batch 51: loss = 0.012422\n",
      "Epoch 6, batch 52: loss = 0.011428\n",
      "Epoch 6, batch 53: loss = 0.012872\n",
      "Epoch 6, batch 54: loss = 0.012500\n",
      "Epoch 6, batch 55: loss = 0.012145\n",
      "Epoch 6, batch 56: loss = 0.012266\n",
      "Epoch 6, batch 57: loss = 0.012826\n",
      "Epoch 6, batch 58: loss = 0.012858\n",
      "Epoch 6, batch 59: loss = 0.012471\n",
      "Epoch 6, batch 60: loss = 0.012085\n",
      "Epoch 6, batch 61: loss = 0.012740\n",
      "Epoch 6, batch 62: loss = 0.011922\n",
      "Epoch 6, batch 63: loss = 0.014033\n",
      "Epoch 6, batch 64: loss = 0.011408\n",
      "Epoch 6, batch 65: loss = 0.012541\n",
      "Epoch 6, batch 66: loss = 0.012150\n",
      "Epoch 6, batch 67: loss = 0.013415\n",
      "Epoch 6, batch 68: loss = 0.012510\n",
      "Epoch 6, batch 69: loss = 0.012610\n",
      "Epoch 6, batch 70: loss = 0.012708\n",
      "Epoch 6, batch 71: loss = 0.012149\n",
      "Epoch 6, batch 72: loss = 0.014071\n",
      "Epoch 6, batch 73: loss = 0.012350\n",
      "Epoch 6, batch 74: loss = 0.012483\n",
      "Epoch 6, batch 75: loss = 0.011998\n",
      "Epoch 6, batch 76: loss = 0.013045\n",
      "Epoch 6, batch 77: loss = 0.012405\n",
      "Epoch 6, batch 78: loss = 0.012144\n",
      "Epoch 6, batch 79: loss = 0.012006\n",
      "Epoch 6, batch 80: loss = 0.012539\n",
      "Epoch 6, batch 81: loss = 0.011873\n",
      "Epoch 6, batch 82: loss = 0.011322\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 6: val_loss = 0.035459\n",
      "Epoch 7, batch 0: loss = 0.012276\n",
      "Epoch 7, batch 1: loss = 0.012255\n",
      "Epoch 7, batch 2: loss = 0.013982\n",
      "Epoch 7, batch 3: loss = 0.011864\n",
      "Epoch 7, batch 4: loss = 0.012323\n",
      "Epoch 7, batch 5: loss = 0.012488\n",
      "Epoch 7, batch 6: loss = 0.012021\n",
      "Epoch 7, batch 7: loss = 0.013650\n",
      "Epoch 7, batch 8: loss = 0.013081\n",
      "Epoch 7, batch 9: loss = 0.012719\n",
      "Epoch 7, batch 10: loss = 0.011991\n",
      "Epoch 7, batch 11: loss = 0.011546\n",
      "Epoch 7, batch 12: loss = 0.013439\n",
      "Epoch 7, batch 13: loss = 0.012963\n",
      "Epoch 7, batch 14: loss = 0.012639\n",
      "Epoch 7, batch 15: loss = 0.012426\n",
      "Epoch 7, batch 16: loss = 0.011943\n",
      "Epoch 7, batch 17: loss = 0.012519\n",
      "Epoch 7, batch 18: loss = 0.012140\n",
      "Epoch 7, batch 19: loss = 0.012800\n",
      "Epoch 7, batch 20: loss = 0.012158\n",
      "Epoch 7, batch 21: loss = 0.012705\n",
      "Epoch 7, batch 22: loss = 0.011751\n",
      "Epoch 7, batch 23: loss = 0.013087\n",
      "Epoch 7, batch 24: loss = 0.011638\n",
      "Epoch 7, batch 25: loss = 0.011496\n",
      "Epoch 7, batch 26: loss = 0.011201\n",
      "Epoch 7, batch 27: loss = 0.012070\n",
      "Epoch 7, batch 28: loss = 0.013128\n",
      "Epoch 7, batch 29: loss = 0.011833\n",
      "Epoch 7, batch 30: loss = 0.012766\n",
      "Epoch 7, batch 31: loss = 0.012971\n",
      "Epoch 7, batch 32: loss = 0.012026\n",
      "Epoch 7, batch 33: loss = 0.012177\n",
      "Epoch 7, batch 34: loss = 0.011760\n",
      "Epoch 7, batch 35: loss = 0.011459\n",
      "Epoch 7, batch 36: loss = 0.012504\n",
      "Epoch 7, batch 37: loss = 0.013871\n",
      "Epoch 7, batch 38: loss = 0.012470\n",
      "Epoch 7, batch 39: loss = 0.013190\n",
      "Epoch 7, batch 40: loss = 0.013963\n",
      "Epoch 7, batch 41: loss = 0.013503\n",
      "Epoch 7, batch 42: loss = 0.012418\n",
      "Epoch 7, batch 43: loss = 0.013176\n",
      "Epoch 7, batch 44: loss = 0.012077\n",
      "Epoch 7, batch 45: loss = 0.012435\n",
      "Epoch 7, batch 46: loss = 0.011954\n",
      "Epoch 7, batch 47: loss = 0.013249\n",
      "Epoch 7, batch 48: loss = 0.012494\n",
      "Epoch 7, batch 49: loss = 0.011886\n",
      "Epoch 7, batch 50: loss = 0.013441\n",
      "Epoch 7, batch 51: loss = 0.013473\n",
      "Epoch 7, batch 52: loss = 0.012420\n",
      "Epoch 7, batch 53: loss = 0.013280\n",
      "Epoch 7, batch 54: loss = 0.011617\n",
      "Epoch 7, batch 55: loss = 0.012452\n",
      "Epoch 7, batch 56: loss = 0.013059\n",
      "Epoch 7, batch 57: loss = 0.013721\n",
      "Epoch 7, batch 58: loss = 0.013596\n",
      "Epoch 7, batch 59: loss = 0.012229\n",
      "Epoch 7, batch 60: loss = 0.012023\n",
      "Epoch 7, batch 61: loss = 0.013119\n",
      "Epoch 7, batch 62: loss = 0.012744\n",
      "Epoch 7, batch 63: loss = 0.011720\n",
      "Epoch 7, batch 64: loss = 0.012729\n",
      "Epoch 7, batch 65: loss = 0.011559\n",
      "Epoch 7, batch 66: loss = 0.011350\n",
      "Epoch 7, batch 67: loss = 0.012147\n",
      "Epoch 7, batch 68: loss = 0.012549\n",
      "Epoch 7, batch 69: loss = 0.012693\n",
      "Epoch 7, batch 70: loss = 0.013255\n",
      "Epoch 7, batch 71: loss = 0.011161\n",
      "Epoch 7, batch 72: loss = 0.012617\n",
      "Epoch 7, batch 73: loss = 0.011895\n",
      "Epoch 7, batch 74: loss = 0.012908\n",
      "Epoch 7, batch 75: loss = 0.012299\n",
      "Epoch 7, batch 76: loss = 0.011891\n",
      "Epoch 7, batch 77: loss = 0.012119\n",
      "Epoch 7, batch 78: loss = 0.012173\n",
      "Epoch 7, batch 79: loss = 0.013417\n",
      "Epoch 7, batch 80: loss = 0.011606\n",
      "Epoch 7, batch 81: loss = 0.013291\n",
      "Epoch 7, batch 82: loss = 0.015762\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 7: val_loss = 0.036681\n",
      "Epoch 8, batch 0: loss = 0.013096\n",
      "Epoch 8, batch 1: loss = 0.013090\n",
      "Epoch 8, batch 2: loss = 0.012833\n",
      "Epoch 8, batch 3: loss = 0.011578\n",
      "Epoch 8, batch 4: loss = 0.012860\n",
      "Epoch 8, batch 5: loss = 0.012785\n",
      "Epoch 8, batch 6: loss = 0.013763\n",
      "Epoch 8, batch 7: loss = 0.012673\n",
      "Epoch 8, batch 8: loss = 0.011778\n",
      "Epoch 8, batch 9: loss = 0.012079\n",
      "Epoch 8, batch 10: loss = 0.012592\n",
      "Epoch 8, batch 11: loss = 0.012795\n",
      "Epoch 8, batch 12: loss = 0.012567\n",
      "Epoch 8, batch 13: loss = 0.013292\n",
      "Epoch 8, batch 14: loss = 0.011734\n",
      "Epoch 8, batch 15: loss = 0.012857\n",
      "Epoch 8, batch 16: loss = 0.012318\n",
      "Epoch 8, batch 17: loss = 0.012459\n",
      "Epoch 8, batch 18: loss = 0.012762\n",
      "Epoch 8, batch 19: loss = 0.011707\n",
      "Epoch 8, batch 20: loss = 0.012749\n",
      "Epoch 8, batch 21: loss = 0.013519\n",
      "Epoch 8, batch 22: loss = 0.014435\n",
      "Epoch 8, batch 23: loss = 0.012822\n",
      "Epoch 8, batch 24: loss = 0.011804\n",
      "Epoch 8, batch 25: loss = 0.012301\n",
      "Epoch 8, batch 26: loss = 0.011614\n",
      "Epoch 8, batch 27: loss = 0.012336\n",
      "Epoch 8, batch 28: loss = 0.011918\n",
      "Epoch 8, batch 29: loss = 0.013072\n",
      "Epoch 8, batch 30: loss = 0.012229\n",
      "Epoch 8, batch 31: loss = 0.012494\n",
      "Epoch 8, batch 32: loss = 0.013485\n",
      "Epoch 8, batch 33: loss = 0.011938\n",
      "Epoch 8, batch 34: loss = 0.013541\n",
      "Epoch 8, batch 35: loss = 0.012661\n",
      "Epoch 8, batch 36: loss = 0.012962\n",
      "Epoch 8, batch 37: loss = 0.012565\n",
      "Epoch 8, batch 38: loss = 0.012855\n",
      "Epoch 8, batch 39: loss = 0.013063\n",
      "Epoch 8, batch 40: loss = 0.012587\n",
      "Epoch 8, batch 41: loss = 0.014217\n",
      "Epoch 8, batch 42: loss = 0.011644\n",
      "Epoch 8, batch 43: loss = 0.012173\n",
      "Epoch 8, batch 44: loss = 0.011998\n",
      "Epoch 8, batch 45: loss = 0.012181\n",
      "Epoch 8, batch 46: loss = 0.014009\n",
      "Epoch 8, batch 47: loss = 0.012228\n",
      "Epoch 8, batch 48: loss = 0.011721\n",
      "Epoch 8, batch 49: loss = 0.011451\n",
      "Epoch 8, batch 50: loss = 0.012551\n",
      "Epoch 8, batch 51: loss = 0.012898\n",
      "Epoch 8, batch 52: loss = 0.011483\n",
      "Epoch 8, batch 53: loss = 0.012160\n",
      "Epoch 8, batch 54: loss = 0.011685\n",
      "Epoch 8, batch 55: loss = 0.012399\n",
      "Epoch 8, batch 56: loss = 0.012173\n",
      "Epoch 8, batch 57: loss = 0.012668\n",
      "Epoch 8, batch 58: loss = 0.012349\n",
      "Epoch 8, batch 59: loss = 0.012089\n",
      "Epoch 8, batch 60: loss = 0.012972\n",
      "Epoch 8, batch 61: loss = 0.011918\n",
      "Epoch 8, batch 62: loss = 0.011657\n",
      "Epoch 8, batch 63: loss = 0.011800\n",
      "Epoch 8, batch 64: loss = 0.011807\n",
      "Epoch 8, batch 65: loss = 0.011562\n",
      "Epoch 8, batch 66: loss = 0.012764\n",
      "Epoch 8, batch 67: loss = 0.013316\n",
      "Epoch 8, batch 68: loss = 0.011934\n",
      "Epoch 8, batch 69: loss = 0.012172\n",
      "Epoch 8, batch 70: loss = 0.014190\n",
      "Epoch 8, batch 71: loss = 0.013712\n",
      "Epoch 8, batch 72: loss = 0.011581\n",
      "Epoch 8, batch 73: loss = 0.011015\n",
      "Epoch 8, batch 74: loss = 0.012588\n",
      "Epoch 8, batch 75: loss = 0.011443\n",
      "Epoch 8, batch 76: loss = 0.012231\n",
      "Epoch 8, batch 77: loss = 0.011686\n",
      "Epoch 8, batch 78: loss = 0.011701\n",
      "Epoch 8, batch 79: loss = 0.012063\n",
      "Epoch 8, batch 80: loss = 0.013022\n",
      "Epoch 8, batch 81: loss = 0.011264\n",
      "Epoch 8, batch 82: loss = 0.011860\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 8: val_loss = 0.035214\n",
      "Epoch 9, batch 0: loss = 0.011796\n",
      "Epoch 9, batch 1: loss = 0.012339\n",
      "Epoch 9, batch 2: loss = 0.012065\n",
      "Epoch 9, batch 3: loss = 0.011683\n",
      "Epoch 9, batch 4: loss = 0.012959\n",
      "Epoch 9, batch 5: loss = 0.012400\n",
      "Epoch 9, batch 6: loss = 0.012629\n",
      "Epoch 9, batch 7: loss = 0.012753\n",
      "Epoch 9, batch 8: loss = 0.012330\n",
      "Epoch 9, batch 9: loss = 0.012018\n",
      "Epoch 9, batch 10: loss = 0.012399\n",
      "Epoch 9, batch 11: loss = 0.013115\n",
      "Epoch 9, batch 12: loss = 0.012945\n",
      "Epoch 9, batch 13: loss = 0.011907\n",
      "Epoch 9, batch 14: loss = 0.012168\n",
      "Epoch 9, batch 15: loss = 0.011419\n",
      "Epoch 9, batch 16: loss = 0.010720\n",
      "Epoch 9, batch 17: loss = 0.012597\n",
      "Epoch 9, batch 18: loss = 0.013471\n",
      "Epoch 9, batch 19: loss = 0.012519\n",
      "Epoch 9, batch 20: loss = 0.012033\n",
      "Epoch 9, batch 21: loss = 0.012042\n",
      "Epoch 9, batch 22: loss = 0.012927\n",
      "Epoch 9, batch 23: loss = 0.011670\n",
      "Epoch 9, batch 24: loss = 0.012070\n",
      "Epoch 9, batch 25: loss = 0.012534\n",
      "Epoch 9, batch 26: loss = 0.011664\n",
      "Epoch 9, batch 27: loss = 0.011957\n",
      "Epoch 9, batch 28: loss = 0.011560\n",
      "Epoch 9, batch 29: loss = 0.012583\n",
      "Epoch 9, batch 30: loss = 0.012241\n",
      "Epoch 9, batch 31: loss = 0.012302\n",
      "Epoch 9, batch 32: loss = 0.011501\n",
      "Epoch 9, batch 33: loss = 0.011949\n",
      "Epoch 9, batch 34: loss = 0.012303\n",
      "Epoch 9, batch 35: loss = 0.012299\n",
      "Epoch 9, batch 36: loss = 0.012272\n",
      "Epoch 9, batch 37: loss = 0.011538\n",
      "Epoch 9, batch 38: loss = 0.012898\n",
      "Epoch 9, batch 39: loss = 0.013250\n",
      "Epoch 9, batch 40: loss = 0.012499\n",
      "Epoch 9, batch 41: loss = 0.012724\n",
      "Epoch 9, batch 42: loss = 0.012325\n",
      "Epoch 9, batch 43: loss = 0.012483\n",
      "Epoch 9, batch 44: loss = 0.012195\n",
      "Epoch 9, batch 45: loss = 0.012279\n",
      "Epoch 9, batch 46: loss = 0.011559\n",
      "Epoch 9, batch 47: loss = 0.012309\n",
      "Epoch 9, batch 48: loss = 0.012053\n",
      "Epoch 9, batch 49: loss = 0.012136\n",
      "Epoch 9, batch 50: loss = 0.012105\n",
      "Epoch 9, batch 51: loss = 0.011230\n",
      "Epoch 9, batch 52: loss = 0.012025\n",
      "Epoch 9, batch 53: loss = 0.011914\n",
      "Epoch 9, batch 54: loss = 0.012055\n",
      "Epoch 9, batch 55: loss = 0.012615\n",
      "Epoch 9, batch 56: loss = 0.011506\n",
      "Epoch 9, batch 57: loss = 0.012291\n",
      "Epoch 9, batch 58: loss = 0.011388\n",
      "Epoch 9, batch 59: loss = 0.011826\n",
      "Epoch 9, batch 60: loss = 0.012307\n",
      "Epoch 9, batch 61: loss = 0.011480\n",
      "Epoch 9, batch 62: loss = 0.011865\n",
      "Epoch 9, batch 63: loss = 0.011940\n",
      "Epoch 9, batch 64: loss = 0.012273\n",
      "Epoch 9, batch 65: loss = 0.013071\n",
      "Epoch 9, batch 66: loss = 0.012489\n",
      "Epoch 9, batch 67: loss = 0.011587\n",
      "Epoch 9, batch 68: loss = 0.012278\n",
      "Epoch 9, batch 69: loss = 0.012205\n",
      "Epoch 9, batch 70: loss = 0.012418\n",
      "Epoch 9, batch 71: loss = 0.012102\n",
      "Epoch 9, batch 72: loss = 0.011631\n",
      "Epoch 9, batch 73: loss = 0.011954\n",
      "Epoch 9, batch 74: loss = 0.011175\n",
      "Epoch 9, batch 75: loss = 0.013183\n",
      "Epoch 9, batch 76: loss = 0.011707\n",
      "Epoch 9, batch 77: loss = 0.012047\n",
      "Epoch 9, batch 78: loss = 0.012306\n",
      "Epoch 9, batch 79: loss = 0.012740\n",
      "Epoch 9, batch 80: loss = 0.011721\n",
      "Epoch 9, batch 81: loss = 0.012408\n",
      "Epoch 9, batch 82: loss = 0.013431\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 9: val_loss = 0.036202\n",
      "Epoch 10, batch 0: loss = 0.011788\n",
      "Epoch 10, batch 1: loss = 0.012027\n",
      "Epoch 10, batch 2: loss = 0.012880\n",
      "Epoch 10, batch 3: loss = 0.012840\n",
      "Epoch 10, batch 4: loss = 0.012091\n",
      "Epoch 10, batch 5: loss = 0.011712\n",
      "Epoch 10, batch 6: loss = 0.012332\n",
      "Epoch 10, batch 7: loss = 0.012457\n",
      "Epoch 10, batch 8: loss = 0.012455\n",
      "Epoch 10, batch 9: loss = 0.012005\n",
      "Epoch 10, batch 10: loss = 0.012242\n",
      "Epoch 10, batch 11: loss = 0.012330\n",
      "Epoch 10, batch 12: loss = 0.011388\n",
      "Epoch 10, batch 13: loss = 0.011534\n",
      "Epoch 10, batch 14: loss = 0.012228\n",
      "Epoch 10, batch 15: loss = 0.013366\n",
      "Epoch 10, batch 16: loss = 0.012401\n",
      "Epoch 10, batch 17: loss = 0.013989\n",
      "Epoch 10, batch 18: loss = 0.012538\n",
      "Epoch 10, batch 19: loss = 0.011824\n",
      "Epoch 10, batch 20: loss = 0.011998\n",
      "Epoch 10, batch 21: loss = 0.011598\n",
      "Epoch 10, batch 22: loss = 0.011708\n",
      "Epoch 10, batch 23: loss = 0.012583\n",
      "Epoch 10, batch 24: loss = 0.011863\n",
      "Epoch 10, batch 25: loss = 0.012146\n",
      "Epoch 10, batch 26: loss = 0.011945\n",
      "Epoch 10, batch 27: loss = 0.011899\n",
      "Epoch 10, batch 28: loss = 0.012172\n",
      "Epoch 10, batch 29: loss = 0.011670\n",
      "Epoch 10, batch 30: loss = 0.012122\n",
      "Epoch 10, batch 31: loss = 0.012215\n",
      "Epoch 10, batch 32: loss = 0.012288\n",
      "Epoch 10, batch 33: loss = 0.011682\n",
      "Epoch 10, batch 34: loss = 0.011890\n",
      "Epoch 10, batch 35: loss = 0.012829\n",
      "Epoch 10, batch 36: loss = 0.012799\n",
      "Epoch 10, batch 37: loss = 0.013280\n",
      "Epoch 10, batch 38: loss = 0.012111\n",
      "Epoch 10, batch 39: loss = 0.012257\n",
      "Epoch 10, batch 40: loss = 0.011453\n",
      "Epoch 10, batch 41: loss = 0.012450\n",
      "Epoch 10, batch 42: loss = 0.012265\n",
      "Epoch 10, batch 43: loss = 0.012343\n",
      "Epoch 10, batch 44: loss = 0.012503\n",
      "Epoch 10, batch 45: loss = 0.011594\n",
      "Epoch 10, batch 46: loss = 0.012234\n",
      "Epoch 10, batch 47: loss = 0.012154\n",
      "Epoch 10, batch 48: loss = 0.012141\n",
      "Epoch 10, batch 49: loss = 0.011706\n",
      "Epoch 10, batch 50: loss = 0.012220\n",
      "Epoch 10, batch 51: loss = 0.011734\n",
      "Epoch 10, batch 52: loss = 0.011988\n",
      "Epoch 10, batch 53: loss = 0.012725\n",
      "Epoch 10, batch 54: loss = 0.011868\n",
      "Epoch 10, batch 55: loss = 0.012157\n",
      "Epoch 10, batch 56: loss = 0.011846\n",
      "Epoch 10, batch 57: loss = 0.012984\n",
      "Epoch 10, batch 58: loss = 0.011196\n",
      "Epoch 10, batch 59: loss = 0.012487\n",
      "Epoch 10, batch 60: loss = 0.011922\n",
      "Epoch 10, batch 61: loss = 0.012273\n",
      "Epoch 10, batch 62: loss = 0.012478\n",
      "Epoch 10, batch 63: loss = 0.010972\n",
      "Epoch 10, batch 64: loss = 0.011998\n",
      "Epoch 10, batch 65: loss = 0.012115\n",
      "Epoch 10, batch 66: loss = 0.012322\n",
      "Epoch 10, batch 67: loss = 0.012920\n",
      "Epoch 10, batch 68: loss = 0.012403\n",
      "Epoch 10, batch 69: loss = 0.012573\n",
      "Epoch 10, batch 70: loss = 0.011916\n",
      "Epoch 10, batch 71: loss = 0.011557\n",
      "Epoch 10, batch 72: loss = 0.011649\n",
      "Epoch 10, batch 73: loss = 0.011088\n",
      "Epoch 10, batch 74: loss = 0.011783\n",
      "Epoch 10, batch 75: loss = 0.011483\n",
      "Epoch 10, batch 76: loss = 0.011803\n",
      "Epoch 10, batch 77: loss = 0.011865\n",
      "Epoch 10, batch 78: loss = 0.012930\n",
      "Epoch 10, batch 79: loss = 0.011973\n",
      "Epoch 10, batch 80: loss = 0.012830\n",
      "Epoch 10, batch 81: loss = 0.011523\n",
      "Epoch 10, batch 82: loss = 0.008096\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 10: val_loss = 0.035650\n",
      "Epoch 11, batch 0: loss = 0.012070\n",
      "Epoch 11, batch 1: loss = 0.010914\n",
      "Epoch 11, batch 2: loss = 0.013355\n",
      "Epoch 11, batch 3: loss = 0.011773\n",
      "Epoch 11, batch 4: loss = 0.011770\n",
      "Epoch 11, batch 5: loss = 0.012590\n",
      "Epoch 11, batch 6: loss = 0.012236\n",
      "Epoch 11, batch 7: loss = 0.012008\n",
      "Epoch 11, batch 8: loss = 0.011680\n",
      "Epoch 11, batch 9: loss = 0.012420\n",
      "Epoch 11, batch 10: loss = 0.011777\n",
      "Epoch 11, batch 11: loss = 0.012155\n",
      "Epoch 11, batch 12: loss = 0.011784\n",
      "Epoch 11, batch 13: loss = 0.011464\n",
      "Epoch 11, batch 14: loss = 0.011765\n",
      "Epoch 11, batch 15: loss = 0.012310\n",
      "Epoch 11, batch 16: loss = 0.013175\n",
      "Epoch 11, batch 17: loss = 0.011047\n",
      "Epoch 11, batch 18: loss = 0.012253\n",
      "Epoch 11, batch 19: loss = 0.012369\n",
      "Epoch 11, batch 20: loss = 0.012128\n",
      "Epoch 11, batch 21: loss = 0.012330\n",
      "Epoch 11, batch 22: loss = 0.012155\n",
      "Epoch 11, batch 23: loss = 0.012305\n",
      "Epoch 11, batch 24: loss = 0.011584\n",
      "Epoch 11, batch 25: loss = 0.011994\n",
      "Epoch 11, batch 26: loss = 0.012063\n",
      "Epoch 11, batch 27: loss = 0.012128\n",
      "Epoch 11, batch 28: loss = 0.012218\n",
      "Epoch 11, batch 29: loss = 0.012338\n",
      "Epoch 11, batch 30: loss = 0.011404\n",
      "Epoch 11, batch 31: loss = 0.013044\n",
      "Epoch 11, batch 32: loss = 0.011949\n",
      "Epoch 11, batch 33: loss = 0.011904\n",
      "Epoch 11, batch 34: loss = 0.012999\n",
      "Epoch 11, batch 35: loss = 0.011940\n",
      "Epoch 11, batch 36: loss = 0.012051\n",
      "Epoch 11, batch 37: loss = 0.011690\n",
      "Epoch 11, batch 38: loss = 0.011889\n",
      "Epoch 11, batch 39: loss = 0.011751\n",
      "Epoch 11, batch 40: loss = 0.011570\n",
      "Epoch 11, batch 41: loss = 0.011627\n",
      "Epoch 11, batch 42: loss = 0.010561\n",
      "Epoch 11, batch 43: loss = 0.012867\n",
      "Epoch 11, batch 44: loss = 0.012895\n",
      "Epoch 11, batch 45: loss = 0.011476\n",
      "Epoch 11, batch 46: loss = 0.012505\n",
      "Epoch 11, batch 47: loss = 0.011827\n",
      "Epoch 11, batch 48: loss = 0.012708\n",
      "Epoch 11, batch 49: loss = 0.011984\n",
      "Epoch 11, batch 50: loss = 0.011263\n",
      "Epoch 11, batch 51: loss = 0.011514\n",
      "Epoch 11, batch 52: loss = 0.011847\n",
      "Epoch 11, batch 53: loss = 0.011917\n",
      "Epoch 11, batch 54: loss = 0.011976\n",
      "Epoch 11, batch 55: loss = 0.010916\n",
      "Epoch 11, batch 56: loss = 0.012628\n",
      "Epoch 11, batch 57: loss = 0.010828\n",
      "Epoch 11, batch 58: loss = 0.011906\n",
      "Epoch 11, batch 59: loss = 0.012969\n",
      "Epoch 11, batch 60: loss = 0.011308\n",
      "Epoch 11, batch 61: loss = 0.012583\n",
      "Epoch 11, batch 62: loss = 0.012213\n",
      "Epoch 11, batch 63: loss = 0.011689\n",
      "Epoch 11, batch 64: loss = 0.011662\n",
      "Epoch 11, batch 65: loss = 0.012524\n",
      "Epoch 11, batch 66: loss = 0.012053\n",
      "Epoch 11, batch 67: loss = 0.011727\n",
      "Epoch 11, batch 68: loss = 0.011749\n",
      "Epoch 11, batch 69: loss = 0.011573\n",
      "Epoch 11, batch 70: loss = 0.011825\n",
      "Epoch 11, batch 71: loss = 0.011866\n",
      "Epoch 11, batch 72: loss = 0.011302\n",
      "Epoch 11, batch 73: loss = 0.012191\n",
      "Epoch 11, batch 74: loss = 0.011440\n",
      "Epoch 11, batch 75: loss = 0.013086\n",
      "Epoch 11, batch 76: loss = 0.010928\n",
      "Epoch 11, batch 77: loss = 0.011044\n",
      "Epoch 11, batch 78: loss = 0.012127\n",
      "Epoch 11, batch 79: loss = 0.011684\n",
      "Epoch 11, batch 80: loss = 0.012613\n",
      "Epoch 11, batch 81: loss = 0.011587\n",
      "Epoch 11, batch 82: loss = 0.017830\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 11: val_loss = 0.037614\n",
      "Epoch 12, batch 0: loss = 0.014286\n",
      "Epoch 12, batch 1: loss = 0.013778\n",
      "Epoch 12, batch 2: loss = 0.011382\n",
      "Epoch 12, batch 3: loss = 0.012705\n",
      "Epoch 12, batch 4: loss = 0.011973\n",
      "Epoch 12, batch 5: loss = 0.012690\n",
      "Epoch 12, batch 6: loss = 0.013024\n",
      "Epoch 12, batch 7: loss = 0.012164\n",
      "Epoch 12, batch 8: loss = 0.013408\n",
      "Epoch 12, batch 9: loss = 0.012605\n",
      "Epoch 12, batch 10: loss = 0.011890\n",
      "Epoch 12, batch 11: loss = 0.012946\n",
      "Epoch 12, batch 12: loss = 0.011214\n",
      "Epoch 12, batch 13: loss = 0.013188\n",
      "Epoch 12, batch 14: loss = 0.012718\n",
      "Epoch 12, batch 15: loss = 0.012632\n",
      "Epoch 12, batch 16: loss = 0.012170\n",
      "Epoch 12, batch 17: loss = 0.011074\n",
      "Epoch 12, batch 18: loss = 0.010856\n",
      "Epoch 12, batch 19: loss = 0.011863\n",
      "Epoch 12, batch 20: loss = 0.011106\n",
      "Epoch 12, batch 21: loss = 0.011491\n",
      "Epoch 12, batch 22: loss = 0.011804\n",
      "Epoch 12, batch 23: loss = 0.012388\n",
      "Epoch 12, batch 24: loss = 0.012106\n",
      "Epoch 12, batch 25: loss = 0.012297\n",
      "Epoch 12, batch 26: loss = 0.012948\n",
      "Epoch 12, batch 27: loss = 0.012562\n",
      "Epoch 12, batch 28: loss = 0.012217\n",
      "Epoch 12, batch 29: loss = 0.012027\n",
      "Epoch 12, batch 30: loss = 0.011203\n",
      "Epoch 12, batch 31: loss = 0.011661\n",
      "Epoch 12, batch 32: loss = 0.011342\n",
      "Epoch 12, batch 33: loss = 0.011724\n",
      "Epoch 12, batch 34: loss = 0.011105\n",
      "Epoch 12, batch 35: loss = 0.012153\n",
      "Epoch 12, batch 36: loss = 0.012050\n",
      "Epoch 12, batch 37: loss = 0.011936\n",
      "Epoch 12, batch 38: loss = 0.012549\n",
      "Epoch 12, batch 39: loss = 0.011752\n",
      "Epoch 12, batch 40: loss = 0.011597\n",
      "Epoch 12, batch 41: loss = 0.012626\n",
      "Epoch 12, batch 42: loss = 0.011745\n",
      "Epoch 12, batch 43: loss = 0.011651\n",
      "Epoch 12, batch 44: loss = 0.011772\n",
      "Epoch 12, batch 45: loss = 0.011747\n",
      "Epoch 12, batch 46: loss = 0.011595\n",
      "Epoch 12, batch 47: loss = 0.012241\n",
      "Epoch 12, batch 48: loss = 0.012101\n",
      "Epoch 12, batch 49: loss = 0.012489\n",
      "Epoch 12, batch 50: loss = 0.012504\n",
      "Epoch 12, batch 51: loss = 0.013654\n",
      "Epoch 12, batch 52: loss = 0.012378\n",
      "Epoch 12, batch 53: loss = 0.011826\n",
      "Epoch 12, batch 54: loss = 0.012071\n",
      "Epoch 12, batch 55: loss = 0.010799\n",
      "Epoch 12, batch 56: loss = 0.011396\n",
      "Epoch 12, batch 57: loss = 0.012456\n",
      "Epoch 12, batch 58: loss = 0.011384\n",
      "Epoch 12, batch 59: loss = 0.011521\n",
      "Epoch 12, batch 60: loss = 0.011613\n",
      "Epoch 12, batch 61: loss = 0.011747\n",
      "Epoch 12, batch 62: loss = 0.012108\n",
      "Epoch 12, batch 63: loss = 0.011547\n",
      "Epoch 12, batch 64: loss = 0.011142\n",
      "Epoch 12, batch 65: loss = 0.011776\n",
      "Epoch 12, batch 66: loss = 0.011733\n",
      "Epoch 12, batch 67: loss = 0.011750\n",
      "Epoch 12, batch 68: loss = 0.011953\n",
      "Epoch 12, batch 69: loss = 0.012354\n",
      "Epoch 12, batch 70: loss = 0.011158\n",
      "Epoch 12, batch 71: loss = 0.010882\n",
      "Epoch 12, batch 72: loss = 0.012075\n",
      "Epoch 12, batch 73: loss = 0.011727\n",
      "Epoch 12, batch 74: loss = 0.011169\n",
      "Epoch 12, batch 75: loss = 0.012183\n",
      "Epoch 12, batch 76: loss = 0.011541\n",
      "Epoch 12, batch 77: loss = 0.011149\n",
      "Epoch 12, batch 78: loss = 0.011120\n",
      "Epoch 12, batch 79: loss = 0.011563\n",
      "Epoch 12, batch 80: loss = 0.010710\n",
      "Epoch 12, batch 81: loss = 0.011731\n",
      "Epoch 12, batch 82: loss = 0.008601\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 12: val_loss = 0.036197\n",
      "Epoch 13, batch 0: loss = 0.011940\n",
      "Epoch 13, batch 1: loss = 0.010463\n",
      "Epoch 13, batch 2: loss = 0.011387\n",
      "Epoch 13, batch 3: loss = 0.012306\n",
      "Epoch 13, batch 4: loss = 0.012578\n",
      "Epoch 13, batch 5: loss = 0.011862\n",
      "Epoch 13, batch 6: loss = 0.011011\n",
      "Epoch 13, batch 7: loss = 0.011363\n",
      "Epoch 13, batch 8: loss = 0.011495\n",
      "Epoch 13, batch 9: loss = 0.011672\n",
      "Epoch 13, batch 10: loss = 0.011707\n",
      "Epoch 13, batch 11: loss = 0.012367\n",
      "Epoch 13, batch 12: loss = 0.012155\n",
      "Epoch 13, batch 13: loss = 0.012117\n",
      "Epoch 13, batch 14: loss = 0.011712\n",
      "Epoch 13, batch 15: loss = 0.012315\n",
      "Epoch 13, batch 16: loss = 0.011938\n",
      "Epoch 13, batch 17: loss = 0.011954\n",
      "Epoch 13, batch 18: loss = 0.011609\n",
      "Epoch 13, batch 19: loss = 0.011798\n",
      "Epoch 13, batch 20: loss = 0.012095\n",
      "Epoch 13, batch 21: loss = 0.011335\n",
      "Epoch 13, batch 22: loss = 0.011311\n",
      "Epoch 13, batch 23: loss = 0.011129\n",
      "Epoch 13, batch 24: loss = 0.011267\n",
      "Epoch 13, batch 25: loss = 0.012134\n",
      "Epoch 13, batch 26: loss = 0.011507\n",
      "Epoch 13, batch 27: loss = 0.011793\n",
      "Epoch 13, batch 28: loss = 0.011919\n",
      "Epoch 13, batch 29: loss = 0.011125\n",
      "Epoch 13, batch 30: loss = 0.010956\n",
      "Epoch 13, batch 31: loss = 0.011996\n",
      "Epoch 13, batch 32: loss = 0.010287\n",
      "Epoch 13, batch 33: loss = 0.011311\n",
      "Epoch 13, batch 34: loss = 0.012399\n",
      "Epoch 13, batch 35: loss = 0.012024\n",
      "Epoch 13, batch 36: loss = 0.010929\n",
      "Epoch 13, batch 37: loss = 0.010817\n",
      "Epoch 13, batch 38: loss = 0.011371\n",
      "Epoch 13, batch 39: loss = 0.011744\n",
      "Epoch 13, batch 40: loss = 0.011000\n",
      "Epoch 13, batch 41: loss = 0.011965\n",
      "Epoch 13, batch 42: loss = 0.011139\n",
      "Epoch 13, batch 43: loss = 0.011927\n",
      "Epoch 13, batch 44: loss = 0.011787\n",
      "Epoch 13, batch 45: loss = 0.010687\n",
      "Epoch 13, batch 46: loss = 0.011199\n",
      "Epoch 13, batch 47: loss = 0.010807\n",
      "Epoch 13, batch 48: loss = 0.011657\n",
      "Epoch 13, batch 49: loss = 0.010919\n",
      "Epoch 13, batch 50: loss = 0.011791\n",
      "Epoch 13, batch 51: loss = 0.012172\n",
      "Epoch 13, batch 52: loss = 0.011763\n",
      "Epoch 13, batch 53: loss = 0.011563\n",
      "Epoch 13, batch 54: loss = 0.012355\n",
      "Epoch 13, batch 55: loss = 0.010892\n",
      "Epoch 13, batch 56: loss = 0.011400\n",
      "Epoch 13, batch 57: loss = 0.010411\n",
      "Epoch 13, batch 58: loss = 0.012324\n",
      "Epoch 13, batch 59: loss = 0.011933\n",
      "Epoch 13, batch 60: loss = 0.012118\n",
      "Epoch 13, batch 61: loss = 0.011983\n",
      "Epoch 13, batch 62: loss = 0.011588\n",
      "Epoch 13, batch 63: loss = 0.011718\n",
      "Epoch 13, batch 64: loss = 0.011895\n",
      "Epoch 13, batch 65: loss = 0.011343\n",
      "Epoch 13, batch 66: loss = 0.011305\n",
      "Epoch 13, batch 67: loss = 0.012213\n",
      "Epoch 13, batch 68: loss = 0.011649\n",
      "Epoch 13, batch 69: loss = 0.011227\n",
      "Epoch 13, batch 70: loss = 0.011628\n",
      "Epoch 13, batch 71: loss = 0.011976\n",
      "Epoch 13, batch 72: loss = 0.011100\n",
      "Epoch 13, batch 73: loss = 0.010804\n",
      "Epoch 13, batch 74: loss = 0.011880\n",
      "Epoch 13, batch 75: loss = 0.011678\n",
      "Epoch 13, batch 76: loss = 0.011795\n",
      "Epoch 13, batch 77: loss = 0.012057\n",
      "Epoch 13, batch 78: loss = 0.011429\n",
      "Epoch 13, batch 79: loss = 0.010819\n",
      "Epoch 13, batch 80: loss = 0.011426\n",
      "Epoch 13, batch 81: loss = 0.012041\n",
      "Epoch 13, batch 82: loss = 0.008254\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 13: val_loss = 0.035054\n",
      "Epoch 14, batch 0: loss = 0.012164\n",
      "Epoch 14, batch 1: loss = 0.011751\n",
      "Epoch 14, batch 2: loss = 0.011724\n",
      "Epoch 14, batch 3: loss = 0.011552\n",
      "Epoch 14, batch 4: loss = 0.011343\n",
      "Epoch 14, batch 5: loss = 0.011352\n",
      "Epoch 14, batch 6: loss = 0.011829\n",
      "Epoch 14, batch 7: loss = 0.011088\n",
      "Epoch 14, batch 8: loss = 0.011267\n",
      "Epoch 14, batch 9: loss = 0.011309\n",
      "Epoch 14, batch 10: loss = 0.011577\n",
      "Epoch 14, batch 11: loss = 0.011870\n",
      "Epoch 14, batch 12: loss = 0.011093\n",
      "Epoch 14, batch 13: loss = 0.012017\n",
      "Epoch 14, batch 14: loss = 0.011647\n",
      "Epoch 14, batch 15: loss = 0.011853\n",
      "Epoch 14, batch 16: loss = 0.011181\n",
      "Epoch 14, batch 17: loss = 0.011441\n",
      "Epoch 14, batch 18: loss = 0.011905\n",
      "Epoch 14, batch 19: loss = 0.011888\n",
      "Epoch 14, batch 20: loss = 0.011727\n",
      "Epoch 14, batch 21: loss = 0.011054\n",
      "Epoch 14, batch 22: loss = 0.011241\n",
      "Epoch 14, batch 23: loss = 0.011116\n",
      "Epoch 14, batch 24: loss = 0.011433\n",
      "Epoch 14, batch 25: loss = 0.010672\n",
      "Epoch 14, batch 26: loss = 0.010755\n",
      "Epoch 14, batch 27: loss = 0.011585\n",
      "Epoch 14, batch 28: loss = 0.012666\n",
      "Epoch 14, batch 29: loss = 0.012030\n",
      "Epoch 14, batch 30: loss = 0.012291\n",
      "Epoch 14, batch 31: loss = 0.012298\n",
      "Epoch 14, batch 32: loss = 0.012168\n",
      "Epoch 14, batch 33: loss = 0.012238\n",
      "Epoch 14, batch 34: loss = 0.011763\n",
      "Epoch 14, batch 35: loss = 0.012467\n",
      "Epoch 14, batch 36: loss = 0.012154\n",
      "Epoch 14, batch 37: loss = 0.012059\n",
      "Epoch 14, batch 38: loss = 0.011927\n",
      "Epoch 14, batch 39: loss = 0.011727\n",
      "Epoch 14, batch 40: loss = 0.012095\n",
      "Epoch 14, batch 41: loss = 0.012036\n",
      "Epoch 14, batch 42: loss = 0.010956\n",
      "Epoch 14, batch 43: loss = 0.011372\n",
      "Epoch 14, batch 44: loss = 0.012368\n",
      "Epoch 14, batch 45: loss = 0.012990\n",
      "Epoch 14, batch 46: loss = 0.012112\n",
      "Epoch 14, batch 47: loss = 0.011738\n",
      "Epoch 14, batch 48: loss = 0.012754\n",
      "Epoch 14, batch 49: loss = 0.011384\n",
      "Epoch 14, batch 50: loss = 0.011549\n",
      "Epoch 14, batch 51: loss = 0.011873\n",
      "Epoch 14, batch 52: loss = 0.011165\n",
      "Epoch 14, batch 53: loss = 0.011107\n",
      "Epoch 14, batch 54: loss = 0.010761\n",
      "Epoch 14, batch 55: loss = 0.011557\n",
      "Epoch 14, batch 56: loss = 0.013452\n",
      "Epoch 14, batch 57: loss = 0.010969\n",
      "Epoch 14, batch 58: loss = 0.010774\n",
      "Epoch 14, batch 59: loss = 0.011528\n",
      "Epoch 14, batch 60: loss = 0.011787\n",
      "Epoch 14, batch 61: loss = 0.011194\n",
      "Epoch 14, batch 62: loss = 0.011535\n",
      "Epoch 14, batch 63: loss = 0.011499\n",
      "Epoch 14, batch 64: loss = 0.012009\n",
      "Epoch 14, batch 65: loss = 0.011825\n",
      "Epoch 14, batch 66: loss = 0.012115\n",
      "Epoch 14, batch 67: loss = 0.012239\n",
      "Epoch 14, batch 68: loss = 0.011524\n",
      "Epoch 14, batch 69: loss = 0.011806\n",
      "Epoch 14, batch 70: loss = 0.011846\n",
      "Epoch 14, batch 71: loss = 0.011202\n",
      "Epoch 14, batch 72: loss = 0.011946\n",
      "Epoch 14, batch 73: loss = 0.011534\n",
      "Epoch 14, batch 74: loss = 0.011494\n",
      "Epoch 14, batch 75: loss = 0.011399\n",
      "Epoch 14, batch 76: loss = 0.011858\n",
      "Epoch 14, batch 77: loss = 0.012854\n",
      "Epoch 14, batch 78: loss = 0.011498\n",
      "Epoch 14, batch 79: loss = 0.011506\n",
      "Epoch 14, batch 80: loss = 0.011723\n",
      "Epoch 14, batch 81: loss = 0.010928\n",
      "Epoch 14, batch 82: loss = 0.010248\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 14: val_loss = 0.035326\n",
      "Epoch 15, batch 0: loss = 0.011131\n",
      "Epoch 15, batch 1: loss = 0.011284\n",
      "Epoch 15, batch 2: loss = 0.011784\n",
      "Epoch 15, batch 3: loss = 0.010624\n",
      "Epoch 15, batch 4: loss = 0.010945\n",
      "Epoch 15, batch 5: loss = 0.012023\n",
      "Epoch 15, batch 6: loss = 0.011590\n",
      "Epoch 15, batch 7: loss = 0.011524\n",
      "Epoch 15, batch 8: loss = 0.011467\n",
      "Epoch 15, batch 9: loss = 0.010656\n",
      "Epoch 15, batch 10: loss = 0.011651\n",
      "Epoch 15, batch 11: loss = 0.011840\n",
      "Epoch 15, batch 12: loss = 0.011986\n",
      "Epoch 15, batch 13: loss = 0.012425\n",
      "Epoch 15, batch 14: loss = 0.011292\n",
      "Epoch 15, batch 15: loss = 0.011763\n",
      "Epoch 15, batch 16: loss = 0.011787\n",
      "Epoch 15, batch 17: loss = 0.011000\n",
      "Epoch 15, batch 18: loss = 0.012128\n",
      "Epoch 15, batch 19: loss = 0.011887\n",
      "Epoch 15, batch 20: loss = 0.011638\n",
      "Epoch 15, batch 21: loss = 0.012419\n",
      "Epoch 15, batch 22: loss = 0.010798\n",
      "Epoch 15, batch 23: loss = 0.012258\n",
      "Epoch 15, batch 24: loss = 0.010679\n",
      "Epoch 15, batch 25: loss = 0.011457\n",
      "Epoch 15, batch 26: loss = 0.012110\n",
      "Epoch 15, batch 27: loss = 0.011178\n",
      "Epoch 15, batch 28: loss = 0.011313\n",
      "Epoch 15, batch 29: loss = 0.011402\n",
      "Epoch 15, batch 30: loss = 0.011419\n",
      "Epoch 15, batch 31: loss = 0.011049\n",
      "Epoch 15, batch 32: loss = 0.011700\n",
      "Epoch 15, batch 33: loss = 0.011883\n",
      "Epoch 15, batch 34: loss = 0.011675\n",
      "Epoch 15, batch 35: loss = 0.012928\n",
      "Epoch 15, batch 36: loss = 0.011521\n",
      "Epoch 15, batch 37: loss = 0.012228\n",
      "Epoch 15, batch 38: loss = 0.010675\n",
      "Epoch 15, batch 39: loss = 0.011320\n",
      "Epoch 15, batch 40: loss = 0.011503\n",
      "Epoch 15, batch 41: loss = 0.011629\n",
      "Epoch 15, batch 42: loss = 0.010977\n",
      "Epoch 15, batch 43: loss = 0.012041\n",
      "Epoch 15, batch 44: loss = 0.011382\n",
      "Epoch 15, batch 45: loss = 0.011231\n",
      "Epoch 15, batch 46: loss = 0.011719\n",
      "Epoch 15, batch 47: loss = 0.010679\n",
      "Epoch 15, batch 48: loss = 0.010683\n",
      "Epoch 15, batch 49: loss = 0.011580\n",
      "Epoch 15, batch 50: loss = 0.010413\n",
      "Epoch 15, batch 51: loss = 0.010631\n",
      "Epoch 15, batch 52: loss = 0.011441\n",
      "Epoch 15, batch 53: loss = 0.011770\n",
      "Epoch 15, batch 54: loss = 0.011130\n",
      "Epoch 15, batch 55: loss = 0.011172\n",
      "Epoch 15, batch 56: loss = 0.011720\n",
      "Epoch 15, batch 57: loss = 0.011525\n",
      "Epoch 15, batch 58: loss = 0.011389\n",
      "Epoch 15, batch 59: loss = 0.011169\n",
      "Epoch 15, batch 60: loss = 0.011372\n",
      "Epoch 15, batch 61: loss = 0.011060\n",
      "Epoch 15, batch 62: loss = 0.011371\n",
      "Epoch 15, batch 63: loss = 0.012256\n",
      "Epoch 15, batch 64: loss = 0.011867\n",
      "Epoch 15, batch 65: loss = 0.012205\n",
      "Epoch 15, batch 66: loss = 0.012225\n",
      "Epoch 15, batch 67: loss = 0.011861\n",
      "Epoch 15, batch 68: loss = 0.010485\n",
      "Epoch 15, batch 69: loss = 0.010996\n",
      "Epoch 15, batch 70: loss = 0.010976\n",
      "Epoch 15, batch 71: loss = 0.011012\n",
      "Epoch 15, batch 72: loss = 0.011080\n",
      "Epoch 15, batch 73: loss = 0.011462\n",
      "Epoch 15, batch 74: loss = 0.011344\n",
      "Epoch 15, batch 75: loss = 0.011284\n",
      "Epoch 15, batch 76: loss = 0.011108\n",
      "Epoch 15, batch 77: loss = 0.010701\n",
      "Epoch 15, batch 78: loss = 0.011942\n",
      "Epoch 15, batch 79: loss = 0.011195\n",
      "Epoch 15, batch 80: loss = 0.011450\n",
      "Epoch 15, batch 81: loss = 0.011375\n",
      "Epoch 15, batch 82: loss = 0.015224\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 15: val_loss = 0.035669\n",
      "Epoch 16, batch 0: loss = 0.011387\n",
      "Epoch 16, batch 1: loss = 0.011783\n",
      "Epoch 16, batch 2: loss = 0.011888\n",
      "Epoch 16, batch 3: loss = 0.012452\n",
      "Epoch 16, batch 4: loss = 0.011596\n",
      "Epoch 16, batch 5: loss = 0.012129\n",
      "Epoch 16, batch 6: loss = 0.012272\n",
      "Epoch 16, batch 7: loss = 0.011285\n",
      "Epoch 16, batch 8: loss = 0.011623\n",
      "Epoch 16, batch 9: loss = 0.011092\n",
      "Epoch 16, batch 10: loss = 0.011054\n",
      "Epoch 16, batch 11: loss = 0.011891\n",
      "Epoch 16, batch 12: loss = 0.011151\n",
      "Epoch 16, batch 13: loss = 0.011271\n",
      "Epoch 16, batch 14: loss = 0.012282\n",
      "Epoch 16, batch 15: loss = 0.011231\n",
      "Epoch 16, batch 16: loss = 0.011525\n",
      "Epoch 16, batch 17: loss = 0.010872\n",
      "Epoch 16, batch 18: loss = 0.010921\n",
      "Epoch 16, batch 19: loss = 0.011826\n",
      "Epoch 16, batch 20: loss = 0.011672\n",
      "Epoch 16, batch 21: loss = 0.011621\n",
      "Epoch 16, batch 22: loss = 0.011322\n",
      "Epoch 16, batch 23: loss = 0.011108\n",
      "Epoch 16, batch 24: loss = 0.010327\n",
      "Epoch 16, batch 25: loss = 0.011696\n",
      "Epoch 16, batch 26: loss = 0.011586\n",
      "Epoch 16, batch 27: loss = 0.011467\n",
      "Epoch 16, batch 28: loss = 0.011117\n",
      "Epoch 16, batch 29: loss = 0.011546\n",
      "Epoch 16, batch 30: loss = 0.011174\n",
      "Epoch 16, batch 31: loss = 0.011933\n",
      "Epoch 16, batch 32: loss = 0.011933\n",
      "Epoch 16, batch 33: loss = 0.010319\n",
      "Epoch 16, batch 34: loss = 0.011954\n",
      "Epoch 16, batch 35: loss = 0.010707\n",
      "Epoch 16, batch 36: loss = 0.011245\n",
      "Epoch 16, batch 37: loss = 0.011210\n",
      "Epoch 16, batch 38: loss = 0.012002\n",
      "Epoch 16, batch 39: loss = 0.011902\n",
      "Epoch 16, batch 40: loss = 0.010818\n",
      "Epoch 16, batch 41: loss = 0.011389\n",
      "Epoch 16, batch 42: loss = 0.011684\n",
      "Epoch 16, batch 43: loss = 0.010811\n",
      "Epoch 16, batch 44: loss = 0.011182\n",
      "Epoch 16, batch 45: loss = 0.010615\n",
      "Epoch 16, batch 46: loss = 0.012530\n",
      "Epoch 16, batch 47: loss = 0.011524\n",
      "Epoch 16, batch 48: loss = 0.011212\n",
      "Epoch 16, batch 49: loss = 0.011183\n",
      "Epoch 16, batch 50: loss = 0.011161\n",
      "Epoch 16, batch 51: loss = 0.011113\n",
      "Epoch 16, batch 52: loss = 0.010361\n",
      "Epoch 16, batch 53: loss = 0.010929\n",
      "Epoch 16, batch 54: loss = 0.011466\n",
      "Epoch 16, batch 55: loss = 0.011888\n",
      "Epoch 16, batch 56: loss = 0.012042\n",
      "Epoch 16, batch 57: loss = 0.010871\n",
      "Epoch 16, batch 58: loss = 0.010915\n",
      "Epoch 16, batch 59: loss = 0.011578\n",
      "Epoch 16, batch 60: loss = 0.011444\n",
      "Epoch 16, batch 61: loss = 0.011070\n",
      "Epoch 16, batch 62: loss = 0.009848\n",
      "Epoch 16, batch 63: loss = 0.010852\n",
      "Epoch 16, batch 64: loss = 0.011954\n",
      "Epoch 16, batch 65: loss = 0.011429\n",
      "Epoch 16, batch 66: loss = 0.011554\n",
      "Epoch 16, batch 67: loss = 0.011494\n",
      "Epoch 16, batch 68: loss = 0.011777\n",
      "Epoch 16, batch 69: loss = 0.011120\n",
      "Epoch 16, batch 70: loss = 0.010727\n",
      "Epoch 16, batch 71: loss = 0.011258\n",
      "Epoch 16, batch 72: loss = 0.011833\n",
      "Epoch 16, batch 73: loss = 0.011114\n",
      "Epoch 16, batch 74: loss = 0.011435\n",
      "Epoch 16, batch 75: loss = 0.010234\n",
      "Epoch 16, batch 76: loss = 0.010844\n",
      "Epoch 16, batch 77: loss = 0.011453\n",
      "Epoch 16, batch 78: loss = 0.011201\n",
      "Epoch 16, batch 79: loss = 0.011268\n",
      "Epoch 16, batch 80: loss = 0.010765\n",
      "Epoch 16, batch 81: loss = 0.010596\n",
      "Epoch 16, batch 82: loss = 0.012854\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 16: val_loss = 0.036304\n",
      "Epoch 17, batch 0: loss = 0.011154\n",
      "Epoch 17, batch 1: loss = 0.011380\n",
      "Epoch 17, batch 2: loss = 0.011018\n",
      "Epoch 17, batch 3: loss = 0.011591\n",
      "Epoch 17, batch 4: loss = 0.010419\n",
      "Epoch 17, batch 5: loss = 0.012090\n",
      "Epoch 17, batch 6: loss = 0.011017\n",
      "Epoch 17, batch 7: loss = 0.010625\n",
      "Epoch 17, batch 8: loss = 0.011306\n",
      "Epoch 17, batch 9: loss = 0.010601\n",
      "Epoch 17, batch 10: loss = 0.011489\n",
      "Epoch 17, batch 11: loss = 0.011357\n",
      "Epoch 17, batch 12: loss = 0.011026\n",
      "Epoch 17, batch 13: loss = 0.010488\n",
      "Epoch 17, batch 14: loss = 0.011714\n",
      "Epoch 17, batch 15: loss = 0.011224\n",
      "Epoch 17, batch 16: loss = 0.011060\n",
      "Epoch 17, batch 17: loss = 0.011181\n",
      "Epoch 17, batch 18: loss = 0.010715\n",
      "Epoch 17, batch 19: loss = 0.011689\n",
      "Epoch 17, batch 20: loss = 0.012170\n",
      "Epoch 17, batch 21: loss = 0.011444\n",
      "Epoch 17, batch 22: loss = 0.012196\n",
      "Epoch 17, batch 23: loss = 0.011832\n",
      "Epoch 17, batch 24: loss = 0.011516\n",
      "Epoch 17, batch 25: loss = 0.011415\n",
      "Epoch 17, batch 26: loss = 0.012158\n",
      "Epoch 17, batch 27: loss = 0.011662\n",
      "Epoch 17, batch 28: loss = 0.011489\n",
      "Epoch 17, batch 29: loss = 0.011820\n",
      "Epoch 17, batch 30: loss = 0.010431\n",
      "Epoch 17, batch 31: loss = 0.011003\n",
      "Epoch 17, batch 32: loss = 0.010756\n",
      "Epoch 17, batch 33: loss = 0.011106\n",
      "Epoch 17, batch 34: loss = 0.011767\n",
      "Epoch 17, batch 35: loss = 0.011399\n",
      "Epoch 17, batch 36: loss = 0.011458\n",
      "Epoch 17, batch 37: loss = 0.011384\n",
      "Epoch 17, batch 38: loss = 0.011514\n",
      "Epoch 17, batch 39: loss = 0.011341\n",
      "Epoch 17, batch 40: loss = 0.011068\n",
      "Epoch 17, batch 41: loss = 0.011768\n",
      "Epoch 17, batch 42: loss = 0.011835\n",
      "Epoch 17, batch 43: loss = 0.011462\n",
      "Epoch 17, batch 44: loss = 0.010601\n",
      "Epoch 17, batch 45: loss = 0.011682\n",
      "Epoch 17, batch 46: loss = 0.011030\n",
      "Epoch 17, batch 47: loss = 0.010990\n",
      "Epoch 17, batch 48: loss = 0.011626\n",
      "Epoch 17, batch 49: loss = 0.011385\n",
      "Epoch 17, batch 50: loss = 0.010901\n",
      "Epoch 17, batch 51: loss = 0.011315\n",
      "Epoch 17, batch 52: loss = 0.010953\n",
      "Epoch 17, batch 53: loss = 0.011334\n",
      "Epoch 17, batch 54: loss = 0.010512\n",
      "Epoch 17, batch 55: loss = 0.011595\n",
      "Epoch 17, batch 56: loss = 0.012109\n",
      "Epoch 17, batch 57: loss = 0.010398\n",
      "Epoch 17, batch 58: loss = 0.011041\n",
      "Epoch 17, batch 59: loss = 0.011153\n",
      "Epoch 17, batch 60: loss = 0.011081\n",
      "Epoch 17, batch 61: loss = 0.011994\n",
      "Epoch 17, batch 62: loss = 0.011701\n",
      "Epoch 17, batch 63: loss = 0.010784\n",
      "Epoch 17, batch 64: loss = 0.010505\n",
      "Epoch 17, batch 65: loss = 0.011110\n",
      "Epoch 17, batch 66: loss = 0.010418\n",
      "Epoch 17, batch 67: loss = 0.011015\n",
      "Epoch 17, batch 68: loss = 0.011550\n",
      "Epoch 17, batch 69: loss = 0.010372\n",
      "Epoch 17, batch 70: loss = 0.011201\n",
      "Epoch 17, batch 71: loss = 0.011432\n",
      "Epoch 17, batch 72: loss = 0.011156\n",
      "Epoch 17, batch 73: loss = 0.010353\n",
      "Epoch 17, batch 74: loss = 0.011203\n",
      "Epoch 17, batch 75: loss = 0.011414\n",
      "Epoch 17, batch 76: loss = 0.011046\n",
      "Epoch 17, batch 77: loss = 0.010732\n",
      "Epoch 17, batch 78: loss = 0.011361\n",
      "Epoch 17, batch 79: loss = 0.010664\n",
      "Epoch 17, batch 80: loss = 0.011070\n",
      "Epoch 17, batch 81: loss = 0.010863\n",
      "Epoch 17, batch 82: loss = 0.009938\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 17: val_loss = 0.035339\n",
      "Epoch 18, batch 0: loss = 0.011488\n",
      "Epoch 18, batch 1: loss = 0.010865\n",
      "Epoch 18, batch 2: loss = 0.011422\n",
      "Epoch 18, batch 3: loss = 0.010832\n",
      "Epoch 18, batch 4: loss = 0.010569\n",
      "Epoch 18, batch 5: loss = 0.011344\n",
      "Epoch 18, batch 6: loss = 0.010637\n",
      "Epoch 18, batch 7: loss = 0.011800\n",
      "Epoch 18, batch 8: loss = 0.010614\n",
      "Epoch 18, batch 9: loss = 0.010660\n",
      "Epoch 18, batch 10: loss = 0.011182\n",
      "Epoch 18, batch 11: loss = 0.010668\n",
      "Epoch 18, batch 12: loss = 0.012710\n",
      "Epoch 18, batch 13: loss = 0.011728\n",
      "Epoch 18, batch 14: loss = 0.011220\n",
      "Epoch 18, batch 15: loss = 0.011133\n",
      "Epoch 18, batch 16: loss = 0.011096\n",
      "Epoch 18, batch 17: loss = 0.010770\n",
      "Epoch 18, batch 18: loss = 0.010744\n",
      "Epoch 18, batch 19: loss = 0.010803\n",
      "Epoch 18, batch 20: loss = 0.010734\n",
      "Epoch 18, batch 21: loss = 0.011094\n",
      "Epoch 18, batch 22: loss = 0.010231\n",
      "Epoch 18, batch 23: loss = 0.010366\n",
      "Epoch 18, batch 24: loss = 0.011045\n",
      "Epoch 18, batch 25: loss = 0.010433\n",
      "Epoch 18, batch 26: loss = 0.010418\n",
      "Epoch 18, batch 27: loss = 0.010097\n",
      "Epoch 18, batch 28: loss = 0.011387\n",
      "Epoch 18, batch 29: loss = 0.010950\n",
      "Epoch 18, batch 30: loss = 0.010867\n",
      "Epoch 18, batch 31: loss = 0.010865\n",
      "Epoch 18, batch 32: loss = 0.011019\n",
      "Epoch 18, batch 33: loss = 0.011152\n",
      "Epoch 18, batch 34: loss = 0.010970\n",
      "Epoch 18, batch 35: loss = 0.010845\n",
      "Epoch 18, batch 36: loss = 0.011184\n",
      "Epoch 18, batch 37: loss = 0.010810\n",
      "Epoch 18, batch 38: loss = 0.011170\n",
      "Epoch 18, batch 39: loss = 0.010754\n",
      "Epoch 18, batch 40: loss = 0.010865\n",
      "Epoch 18, batch 41: loss = 0.010919\n",
      "Epoch 18, batch 42: loss = 0.010880\n",
      "Epoch 18, batch 43: loss = 0.011268\n",
      "Epoch 18, batch 44: loss = 0.011152\n",
      "Epoch 18, batch 45: loss = 0.010514\n",
      "Epoch 18, batch 46: loss = 0.011545\n",
      "Epoch 18, batch 47: loss = 0.011148\n",
      "Epoch 18, batch 48: loss = 0.010908\n",
      "Epoch 18, batch 49: loss = 0.012308\n",
      "Epoch 18, batch 50: loss = 0.011118\n",
      "Epoch 18, batch 51: loss = 0.010086\n",
      "Epoch 18, batch 52: loss = 0.010607\n",
      "Epoch 18, batch 53: loss = 0.011322\n",
      "Epoch 18, batch 54: loss = 0.011363\n",
      "Epoch 18, batch 55: loss = 0.011575\n",
      "Epoch 18, batch 56: loss = 0.010504\n",
      "Epoch 18, batch 57: loss = 0.010667\n",
      "Epoch 18, batch 58: loss = 0.011090\n",
      "Epoch 18, batch 59: loss = 0.011154\n",
      "Epoch 18, batch 60: loss = 0.010690\n",
      "Epoch 18, batch 61: loss = 0.010714\n",
      "Epoch 18, batch 62: loss = 0.010077\n",
      "Epoch 18, batch 63: loss = 0.010534\n",
      "Epoch 18, batch 64: loss = 0.011094\n",
      "Epoch 18, batch 65: loss = 0.011165\n",
      "Epoch 18, batch 66: loss = 0.010527\n",
      "Epoch 18, batch 67: loss = 0.010545\n",
      "Epoch 18, batch 68: loss = 0.011048\n",
      "Epoch 18, batch 69: loss = 0.012354\n",
      "Epoch 18, batch 70: loss = 0.011104\n",
      "Epoch 18, batch 71: loss = 0.010890\n",
      "Epoch 18, batch 72: loss = 0.010836\n",
      "Epoch 18, batch 73: loss = 0.010419\n",
      "Epoch 18, batch 74: loss = 0.011112\n",
      "Epoch 18, batch 75: loss = 0.011034\n",
      "Epoch 18, batch 76: loss = 0.011204\n",
      "Epoch 18, batch 77: loss = 0.010705\n",
      "Epoch 18, batch 78: loss = 0.010514\n",
      "Epoch 18, batch 79: loss = 0.010779\n",
      "Epoch 18, batch 80: loss = 0.011044\n",
      "Epoch 18, batch 81: loss = 0.011567\n",
      "Epoch 18, batch 82: loss = 0.009417\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 18: val_loss = 0.034703\n",
      "Epoch 19, batch 0: loss = 0.010662\n",
      "Epoch 19, batch 1: loss = 0.011002\n",
      "Epoch 19, batch 2: loss = 0.010314\n",
      "Epoch 19, batch 3: loss = 0.011000\n",
      "Epoch 19, batch 4: loss = 0.011066\n",
      "Epoch 19, batch 5: loss = 0.011286\n",
      "Epoch 19, batch 6: loss = 0.011228\n",
      "Epoch 19, batch 7: loss = 0.010920\n",
      "Epoch 19, batch 8: loss = 0.010761\n",
      "Epoch 19, batch 9: loss = 0.011400\n",
      "Epoch 19, batch 10: loss = 0.011471\n",
      "Epoch 19, batch 11: loss = 0.010850\n",
      "Epoch 19, batch 12: loss = 0.011066\n",
      "Epoch 19, batch 13: loss = 0.010834\n",
      "Epoch 19, batch 14: loss = 0.010742\n",
      "Epoch 19, batch 15: loss = 0.010709\n",
      "Epoch 19, batch 16: loss = 0.009968\n",
      "Epoch 19, batch 17: loss = 0.010682\n",
      "Epoch 19, batch 18: loss = 0.011476\n",
      "Epoch 19, batch 19: loss = 0.010893\n",
      "Epoch 19, batch 20: loss = 0.010307\n",
      "Epoch 19, batch 21: loss = 0.010821\n",
      "Epoch 19, batch 22: loss = 0.009891\n",
      "Epoch 19, batch 23: loss = 0.011524\n",
      "Epoch 19, batch 24: loss = 0.010647\n",
      "Epoch 19, batch 25: loss = 0.011653\n",
      "Epoch 19, batch 26: loss = 0.011148\n",
      "Epoch 19, batch 27: loss = 0.010654\n",
      "Epoch 19, batch 28: loss = 0.010747\n",
      "Epoch 19, batch 29: loss = 0.010779\n",
      "Epoch 19, batch 30: loss = 0.011290\n",
      "Epoch 19, batch 31: loss = 0.010157\n",
      "Epoch 19, batch 32: loss = 0.010912\n",
      "Epoch 19, batch 33: loss = 0.010608\n",
      "Epoch 19, batch 34: loss = 0.011300\n",
      "Epoch 19, batch 35: loss = 0.011125\n",
      "Epoch 19, batch 36: loss = 0.011109\n",
      "Epoch 19, batch 37: loss = 0.010774\n",
      "Epoch 19, batch 38: loss = 0.011199\n",
      "Epoch 19, batch 39: loss = 0.010901\n",
      "Epoch 19, batch 40: loss = 0.011127\n",
      "Epoch 19, batch 41: loss = 0.012070\n",
      "Epoch 19, batch 42: loss = 0.011447\n",
      "Epoch 19, batch 43: loss = 0.011029\n",
      "Epoch 19, batch 44: loss = 0.010662\n",
      "Epoch 19, batch 45: loss = 0.010820\n",
      "Epoch 19, batch 46: loss = 0.010615\n",
      "Epoch 19, batch 47: loss = 0.009729\n",
      "Epoch 19, batch 48: loss = 0.010504\n",
      "Epoch 19, batch 49: loss = 0.010533\n",
      "Epoch 19, batch 50: loss = 0.011121\n",
      "Epoch 19, batch 51: loss = 0.011935\n",
      "Epoch 19, batch 52: loss = 0.010647\n",
      "Epoch 19, batch 53: loss = 0.010714\n",
      "Epoch 19, batch 54: loss = 0.010496\n",
      "Epoch 19, batch 55: loss = 0.010437\n",
      "Epoch 19, batch 56: loss = 0.010392\n",
      "Epoch 19, batch 57: loss = 0.010906\n",
      "Epoch 19, batch 58: loss = 0.011527\n",
      "Epoch 19, batch 59: loss = 0.010172\n",
      "Epoch 19, batch 60: loss = 0.010635\n",
      "Epoch 19, batch 61: loss = 0.011533\n",
      "Epoch 19, batch 62: loss = 0.010358\n",
      "Epoch 19, batch 63: loss = 0.010664\n",
      "Epoch 19, batch 64: loss = 0.011109\n",
      "Epoch 19, batch 65: loss = 0.010510\n",
      "Epoch 19, batch 66: loss = 0.011353\n",
      "Epoch 19, batch 67: loss = 0.010522\n",
      "Epoch 19, batch 68: loss = 0.010641\n",
      "Epoch 19, batch 69: loss = 0.011180\n",
      "Epoch 19, batch 70: loss = 0.011277\n",
      "Epoch 19, batch 71: loss = 0.011087\n",
      "Epoch 19, batch 72: loss = 0.010617\n",
      "Epoch 19, batch 73: loss = 0.010793\n",
      "Epoch 19, batch 74: loss = 0.010420\n",
      "Epoch 19, batch 75: loss = 0.011806\n",
      "Epoch 19, batch 76: loss = 0.010607\n",
      "Epoch 19, batch 77: loss = 0.011108\n",
      "Epoch 19, batch 78: loss = 0.010265\n",
      "Epoch 19, batch 79: loss = 0.010242\n",
      "Epoch 19, batch 80: loss = 0.010463\n",
      "Epoch 19, batch 81: loss = 0.009764\n",
      "Epoch 19, batch 82: loss = 0.007292\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 19: val_loss = 0.035447\n",
      "Epoch 20, batch 0: loss = 0.010568\n",
      "Epoch 20, batch 1: loss = 0.010504\n",
      "Epoch 20, batch 2: loss = 0.010278\n",
      "Epoch 20, batch 3: loss = 0.010262\n",
      "Epoch 20, batch 4: loss = 0.010782\n",
      "Epoch 20, batch 5: loss = 0.010485\n",
      "Epoch 20, batch 6: loss = 0.010950\n",
      "Epoch 20, batch 7: loss = 0.010913\n",
      "Epoch 20, batch 8: loss = 0.010015\n",
      "Epoch 20, batch 9: loss = 0.010042\n",
      "Epoch 20, batch 10: loss = 0.010360\n",
      "Epoch 20, batch 11: loss = 0.010439\n",
      "Epoch 20, batch 12: loss = 0.011350\n",
      "Epoch 20, batch 13: loss = 0.010504\n",
      "Epoch 20, batch 14: loss = 0.010963\n",
      "Epoch 20, batch 15: loss = 0.011462\n",
      "Epoch 20, batch 16: loss = 0.011099\n",
      "Epoch 20, batch 17: loss = 0.011194\n",
      "Epoch 20, batch 18: loss = 0.010061\n",
      "Epoch 20, batch 19: loss = 0.010369\n",
      "Epoch 20, batch 20: loss = 0.010819\n",
      "Epoch 20, batch 21: loss = 0.011420\n",
      "Epoch 20, batch 22: loss = 0.010665\n",
      "Epoch 20, batch 23: loss = 0.010782\n",
      "Epoch 20, batch 24: loss = 0.010776\n",
      "Epoch 20, batch 25: loss = 0.011233\n",
      "Epoch 20, batch 26: loss = 0.011885\n",
      "Epoch 20, batch 27: loss = 0.011113\n",
      "Epoch 20, batch 28: loss = 0.010760\n",
      "Epoch 20, batch 29: loss = 0.009990\n",
      "Epoch 20, batch 30: loss = 0.011333\n",
      "Epoch 20, batch 31: loss = 0.010307\n",
      "Epoch 20, batch 32: loss = 0.011482\n",
      "Epoch 20, batch 33: loss = 0.010290\n",
      "Epoch 20, batch 34: loss = 0.011313\n",
      "Epoch 20, batch 35: loss = 0.011330\n",
      "Epoch 20, batch 36: loss = 0.010573\n",
      "Epoch 20, batch 37: loss = 0.011276\n",
      "Epoch 20, batch 38: loss = 0.010800\n",
      "Epoch 20, batch 39: loss = 0.010383\n",
      "Epoch 20, batch 40: loss = 0.010763\n",
      "Epoch 20, batch 41: loss = 0.010899\n",
      "Epoch 20, batch 42: loss = 0.010637\n",
      "Epoch 20, batch 43: loss = 0.010177\n",
      "Epoch 20, batch 44: loss = 0.011603\n",
      "Epoch 20, batch 45: loss = 0.010616\n",
      "Epoch 20, batch 46: loss = 0.010116\n",
      "Epoch 20, batch 47: loss = 0.010103\n",
      "Epoch 20, batch 48: loss = 0.011503\n",
      "Epoch 20, batch 49: loss = 0.011030\n",
      "Epoch 20, batch 50: loss = 0.009861\n",
      "Epoch 20, batch 51: loss = 0.010193\n",
      "Epoch 20, batch 52: loss = 0.010051\n",
      "Epoch 20, batch 53: loss = 0.010953\n",
      "Epoch 20, batch 54: loss = 0.012007\n",
      "Epoch 20, batch 55: loss = 0.011313\n",
      "Epoch 20, batch 56: loss = 0.010568\n",
      "Epoch 20, batch 57: loss = 0.009977\n",
      "Epoch 20, batch 58: loss = 0.010747\n",
      "Epoch 20, batch 59: loss = 0.010872\n",
      "Epoch 20, batch 60: loss = 0.011345\n",
      "Epoch 20, batch 61: loss = 0.010224\n",
      "Epoch 20, batch 62: loss = 0.010860\n",
      "Epoch 20, batch 63: loss = 0.010566\n",
      "Epoch 20, batch 64: loss = 0.010319\n",
      "Epoch 20, batch 65: loss = 0.010167\n",
      "Epoch 20, batch 66: loss = 0.011683\n",
      "Epoch 20, batch 67: loss = 0.010681\n",
      "Epoch 20, batch 68: loss = 0.011380\n",
      "Epoch 20, batch 69: loss = 0.011757\n",
      "Epoch 20, batch 70: loss = 0.010789\n",
      "Epoch 20, batch 71: loss = 0.010642\n",
      "Epoch 20, batch 72: loss = 0.010671\n",
      "Epoch 20, batch 73: loss = 0.011504\n",
      "Epoch 20, batch 74: loss = 0.011143\n",
      "Epoch 20, batch 75: loss = 0.011435\n",
      "Epoch 20, batch 76: loss = 0.010512\n",
      "Epoch 20, batch 77: loss = 0.010835\n",
      "Epoch 20, batch 78: loss = 0.010299\n",
      "Epoch 20, batch 79: loss = 0.010376\n",
      "Epoch 20, batch 80: loss = 0.010514\n",
      "Epoch 20, batch 81: loss = 0.010013\n",
      "Epoch 20, batch 82: loss = 0.008171\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 20: val_loss = 0.035248\n",
      "Epoch 21, batch 0: loss = 0.010937\n",
      "Epoch 21, batch 1: loss = 0.011431\n",
      "Epoch 21, batch 2: loss = 0.010536\n",
      "Epoch 21, batch 3: loss = 0.011175\n",
      "Epoch 21, batch 4: loss = 0.009724\n",
      "Epoch 21, batch 5: loss = 0.011152\n",
      "Epoch 21, batch 6: loss = 0.010225\n",
      "Epoch 21, batch 7: loss = 0.011534\n",
      "Epoch 21, batch 8: loss = 0.010736\n",
      "Epoch 21, batch 9: loss = 0.012068\n",
      "Epoch 21, batch 10: loss = 0.011435\n",
      "Epoch 21, batch 11: loss = 0.010429\n",
      "Epoch 21, batch 12: loss = 0.010634\n",
      "Epoch 21, batch 13: loss = 0.010529\n",
      "Epoch 21, batch 14: loss = 0.010687\n",
      "Epoch 21, batch 15: loss = 0.009793\n",
      "Epoch 21, batch 16: loss = 0.010162\n",
      "Epoch 21, batch 17: loss = 0.011325\n",
      "Epoch 21, batch 18: loss = 0.010537\n",
      "Epoch 21, batch 19: loss = 0.011256\n",
      "Epoch 21, batch 20: loss = 0.010340\n",
      "Epoch 21, batch 21: loss = 0.010823\n",
      "Epoch 21, batch 22: loss = 0.010491\n",
      "Epoch 21, batch 23: loss = 0.010326\n",
      "Epoch 21, batch 24: loss = 0.011745\n",
      "Epoch 21, batch 25: loss = 0.010265\n",
      "Epoch 21, batch 26: loss = 0.010260\n",
      "Epoch 21, batch 27: loss = 0.010544\n",
      "Epoch 21, batch 28: loss = 0.010996\n",
      "Epoch 21, batch 29: loss = 0.010563\n",
      "Epoch 21, batch 30: loss = 0.010230\n",
      "Epoch 21, batch 31: loss = 0.010767\n",
      "Epoch 21, batch 32: loss = 0.010039\n",
      "Epoch 21, batch 33: loss = 0.009763\n",
      "Epoch 21, batch 34: loss = 0.010815\n",
      "Epoch 21, batch 35: loss = 0.010068\n",
      "Epoch 21, batch 36: loss = 0.011008\n",
      "Epoch 21, batch 37: loss = 0.010615\n",
      "Epoch 21, batch 38: loss = 0.011236\n",
      "Epoch 21, batch 39: loss = 0.009724\n",
      "Epoch 21, batch 40: loss = 0.010549\n",
      "Epoch 21, batch 41: loss = 0.010359\n",
      "Epoch 21, batch 42: loss = 0.010517\n",
      "Epoch 21, batch 43: loss = 0.010354\n",
      "Epoch 21, batch 44: loss = 0.010079\n",
      "Epoch 21, batch 45: loss = 0.010532\n",
      "Epoch 21, batch 46: loss = 0.010174\n",
      "Epoch 21, batch 47: loss = 0.010076\n",
      "Epoch 21, batch 48: loss = 0.010023\n",
      "Epoch 21, batch 49: loss = 0.009888\n",
      "Epoch 21, batch 50: loss = 0.010315\n",
      "Epoch 21, batch 51: loss = 0.010927\n",
      "Epoch 21, batch 52: loss = 0.011048\n",
      "Epoch 21, batch 53: loss = 0.010360\n",
      "Epoch 21, batch 54: loss = 0.011394\n",
      "Epoch 21, batch 55: loss = 0.010348\n",
      "Epoch 21, batch 56: loss = 0.010128\n",
      "Epoch 21, batch 57: loss = 0.010605\n",
      "Epoch 21, batch 58: loss = 0.010512\n",
      "Epoch 21, batch 59: loss = 0.010488\n",
      "Epoch 21, batch 60: loss = 0.010482\n",
      "Epoch 21, batch 61: loss = 0.010204\n",
      "Epoch 21, batch 62: loss = 0.010693\n",
      "Epoch 21, batch 63: loss = 0.010663\n",
      "Epoch 21, batch 64: loss = 0.011538\n",
      "Epoch 21, batch 65: loss = 0.010243\n",
      "Epoch 21, batch 66: loss = 0.010875\n",
      "Epoch 21, batch 67: loss = 0.010120\n",
      "Epoch 21, batch 68: loss = 0.010710\n",
      "Epoch 21, batch 69: loss = 0.010672\n",
      "Epoch 21, batch 70: loss = 0.010148\n",
      "Epoch 21, batch 71: loss = 0.010314\n",
      "Epoch 21, batch 72: loss = 0.010617\n",
      "Epoch 21, batch 73: loss = 0.010101\n",
      "Epoch 21, batch 74: loss = 0.010442\n",
      "Epoch 21, batch 75: loss = 0.010933\n",
      "Epoch 21, batch 76: loss = 0.011206\n",
      "Epoch 21, batch 77: loss = 0.010954\n",
      "Epoch 21, batch 78: loss = 0.010432\n",
      "Epoch 21, batch 79: loss = 0.010146\n",
      "Epoch 21, batch 80: loss = 0.010297\n",
      "Epoch 21, batch 81: loss = 0.010804\n",
      "Epoch 21, batch 82: loss = 0.009416\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 21: val_loss = 0.035342\n",
      "Epoch 22, batch 0: loss = 0.010550\n",
      "Epoch 22, batch 1: loss = 0.010701\n",
      "Epoch 22, batch 2: loss = 0.011179\n",
      "Epoch 22, batch 3: loss = 0.010797\n",
      "Epoch 22, batch 4: loss = 0.010795\n",
      "Epoch 22, batch 5: loss = 0.011776\n",
      "Epoch 22, batch 6: loss = 0.011831\n",
      "Epoch 22, batch 7: loss = 0.010964\n",
      "Epoch 22, batch 8: loss = 0.012157\n",
      "Epoch 22, batch 9: loss = 0.013222\n",
      "Epoch 22, batch 10: loss = 0.011230\n",
      "Epoch 22, batch 11: loss = 0.011796\n",
      "Epoch 22, batch 12: loss = 0.012409\n",
      "Epoch 22, batch 13: loss = 0.011128\n",
      "Epoch 22, batch 14: loss = 0.011192\n",
      "Epoch 22, batch 15: loss = 0.011344\n",
      "Epoch 22, batch 16: loss = 0.011258\n",
      "Epoch 22, batch 17: loss = 0.011141\n",
      "Epoch 22, batch 18: loss = 0.010945\n",
      "Epoch 22, batch 19: loss = 0.011521\n",
      "Epoch 22, batch 20: loss = 0.011279\n",
      "Epoch 22, batch 21: loss = 0.011515\n",
      "Epoch 22, batch 22: loss = 0.011321\n",
      "Epoch 22, batch 23: loss = 0.011535\n",
      "Epoch 22, batch 24: loss = 0.011298\n",
      "Epoch 22, batch 25: loss = 0.011203\n",
      "Epoch 22, batch 26: loss = 0.011128\n",
      "Epoch 22, batch 27: loss = 0.011643\n",
      "Epoch 22, batch 28: loss = 0.012081\n",
      "Epoch 22, batch 29: loss = 0.010655\n",
      "Epoch 22, batch 30: loss = 0.010719\n",
      "Epoch 22, batch 31: loss = 0.010522\n",
      "Epoch 22, batch 32: loss = 0.011329\n",
      "Epoch 22, batch 33: loss = 0.011147\n",
      "Epoch 22, batch 34: loss = 0.011723\n",
      "Epoch 22, batch 35: loss = 0.011123\n",
      "Epoch 22, batch 36: loss = 0.011194\n",
      "Epoch 22, batch 37: loss = 0.011854\n",
      "Epoch 22, batch 38: loss = 0.011103\n",
      "Epoch 22, batch 39: loss = 0.010668\n",
      "Epoch 22, batch 40: loss = 0.011363\n",
      "Epoch 22, batch 41: loss = 0.010770\n",
      "Epoch 22, batch 42: loss = 0.011178\n",
      "Epoch 22, batch 43: loss = 0.010857\n",
      "Epoch 22, batch 44: loss = 0.010868\n",
      "Epoch 22, batch 45: loss = 0.010728\n",
      "Epoch 22, batch 46: loss = 0.010542\n",
      "Epoch 22, batch 47: loss = 0.011132\n",
      "Epoch 22, batch 48: loss = 0.010975\n",
      "Epoch 22, batch 49: loss = 0.011514\n",
      "Epoch 22, batch 50: loss = 0.011151\n",
      "Epoch 22, batch 51: loss = 0.011014\n",
      "Epoch 22, batch 52: loss = 0.010867\n",
      "Epoch 22, batch 53: loss = 0.011300\n",
      "Epoch 22, batch 54: loss = 0.010740\n",
      "Epoch 22, batch 55: loss = 0.010530\n",
      "Epoch 22, batch 56: loss = 0.011003\n",
      "Epoch 22, batch 57: loss = 0.011158\n",
      "Epoch 22, batch 58: loss = 0.010504\n",
      "Epoch 22, batch 59: loss = 0.010710\n",
      "Epoch 22, batch 60: loss = 0.010487\n",
      "Epoch 22, batch 61: loss = 0.009833\n",
      "Epoch 22, batch 62: loss = 0.009996\n",
      "Epoch 22, batch 63: loss = 0.010584\n",
      "Epoch 22, batch 64: loss = 0.010904\n",
      "Epoch 22, batch 65: loss = 0.010008\n",
      "Epoch 22, batch 66: loss = 0.010043\n",
      "Epoch 22, batch 67: loss = 0.010151\n",
      "Epoch 22, batch 68: loss = 0.010757\n",
      "Epoch 22, batch 69: loss = 0.010412\n",
      "Epoch 22, batch 70: loss = 0.010001\n",
      "Epoch 22, batch 71: loss = 0.011589\n",
      "Epoch 22, batch 72: loss = 0.010674\n",
      "Epoch 22, batch 73: loss = 0.009770\n",
      "Epoch 22, batch 74: loss = 0.010078\n",
      "Epoch 22, batch 75: loss = 0.011037\n",
      "Epoch 22, batch 76: loss = 0.010483\n",
      "Epoch 22, batch 77: loss = 0.010853\n",
      "Epoch 22, batch 78: loss = 0.010920\n",
      "Epoch 22, batch 79: loss = 0.010602\n",
      "Epoch 22, batch 80: loss = 0.010989\n",
      "Epoch 22, batch 81: loss = 0.010193\n",
      "Epoch 22, batch 82: loss = 0.010223\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 22: val_loss = 0.035630\n",
      "Epoch 23, batch 0: loss = 0.009907\n",
      "Epoch 23, batch 1: loss = 0.010676\n",
      "Epoch 23, batch 2: loss = 0.010469\n",
      "Epoch 23, batch 3: loss = 0.010402\n",
      "Epoch 23, batch 4: loss = 0.009730\n",
      "Epoch 23, batch 5: loss = 0.010083\n",
      "Epoch 23, batch 6: loss = 0.010162\n",
      "Epoch 23, batch 7: loss = 0.010169\n",
      "Epoch 23, batch 8: loss = 0.010414\n",
      "Epoch 23, batch 9: loss = 0.010179\n",
      "Epoch 23, batch 10: loss = 0.010579\n",
      "Epoch 23, batch 11: loss = 0.010817\n",
      "Epoch 23, batch 12: loss = 0.010357\n",
      "Epoch 23, batch 13: loss = 0.010691\n",
      "Epoch 23, batch 14: loss = 0.010761\n",
      "Epoch 23, batch 15: loss = 0.012144\n",
      "Epoch 23, batch 16: loss = 0.010761\n",
      "Epoch 23, batch 17: loss = 0.010436\n",
      "Epoch 23, batch 18: loss = 0.010450\n",
      "Epoch 23, batch 19: loss = 0.010327\n",
      "Epoch 23, batch 20: loss = 0.010903\n",
      "Epoch 23, batch 21: loss = 0.010359\n",
      "Epoch 23, batch 22: loss = 0.009894\n",
      "Epoch 23, batch 23: loss = 0.011057\n",
      "Epoch 23, batch 24: loss = 0.010304\n",
      "Epoch 23, batch 25: loss = 0.010502\n",
      "Epoch 23, batch 26: loss = 0.010357\n",
      "Epoch 23, batch 27: loss = 0.010114\n",
      "Epoch 23, batch 28: loss = 0.010507\n",
      "Epoch 23, batch 29: loss = 0.009349\n",
      "Epoch 23, batch 30: loss = 0.010283\n",
      "Epoch 23, batch 31: loss = 0.010219\n",
      "Epoch 23, batch 32: loss = 0.011235\n",
      "Epoch 23, batch 33: loss = 0.010802\n",
      "Epoch 23, batch 34: loss = 0.009710\n",
      "Epoch 23, batch 35: loss = 0.010922\n",
      "Epoch 23, batch 36: loss = 0.010710\n",
      "Epoch 23, batch 37: loss = 0.009995\n",
      "Epoch 23, batch 38: loss = 0.011039\n",
      "Epoch 23, batch 39: loss = 0.010537\n",
      "Epoch 23, batch 40: loss = 0.010294\n",
      "Epoch 23, batch 41: loss = 0.010493\n",
      "Epoch 23, batch 42: loss = 0.009939\n",
      "Epoch 23, batch 43: loss = 0.010198\n",
      "Epoch 23, batch 44: loss = 0.010165\n",
      "Epoch 23, batch 45: loss = 0.010973\n",
      "Epoch 23, batch 46: loss = 0.009818\n",
      "Epoch 23, batch 47: loss = 0.010181\n",
      "Epoch 23, batch 48: loss = 0.011073\n",
      "Epoch 23, batch 49: loss = 0.010407\n",
      "Epoch 23, batch 50: loss = 0.010107\n",
      "Epoch 23, batch 51: loss = 0.011054\n",
      "Epoch 23, batch 52: loss = 0.010340\n",
      "Epoch 23, batch 53: loss = 0.010778\n",
      "Epoch 23, batch 54: loss = 0.010136\n",
      "Epoch 23, batch 55: loss = 0.010919\n",
      "Epoch 23, batch 56: loss = 0.010748\n",
      "Epoch 23, batch 57: loss = 0.011075\n",
      "Epoch 23, batch 58: loss = 0.011101\n",
      "Epoch 23, batch 59: loss = 0.011046\n",
      "Epoch 23, batch 60: loss = 0.010738\n",
      "Epoch 23, batch 61: loss = 0.009995\n",
      "Epoch 23, batch 62: loss = 0.010634\n",
      "Epoch 23, batch 63: loss = 0.010367\n",
      "Epoch 23, batch 64: loss = 0.010576\n",
      "Epoch 23, batch 65: loss = 0.010409\n",
      "Epoch 23, batch 66: loss = 0.010314\n",
      "Epoch 23, batch 67: loss = 0.010699\n",
      "Epoch 23, batch 68: loss = 0.010740\n",
      "Epoch 23, batch 69: loss = 0.010368\n",
      "Epoch 23, batch 70: loss = 0.010232\n",
      "Epoch 23, batch 71: loss = 0.011028\n",
      "Epoch 23, batch 72: loss = 0.010589\n",
      "Epoch 23, batch 73: loss = 0.009853\n",
      "Epoch 23, batch 74: loss = 0.009728\n",
      "Epoch 23, batch 75: loss = 0.009810\n",
      "Epoch 23, batch 76: loss = 0.010914\n",
      "Epoch 23, batch 77: loss = 0.009518\n",
      "Epoch 23, batch 78: loss = 0.010192\n",
      "Epoch 23, batch 79: loss = 0.010702\n",
      "Epoch 23, batch 80: loss = 0.010512\n",
      "Epoch 23, batch 81: loss = 0.009693\n",
      "Epoch 23, batch 82: loss = 0.010455\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 23: val_loss = 0.035195\n",
      "Epoch 24, batch 0: loss = 0.010299\n",
      "Epoch 24, batch 1: loss = 0.010351\n",
      "Epoch 24, batch 2: loss = 0.011056\n",
      "Epoch 24, batch 3: loss = 0.010129\n",
      "Epoch 24, batch 4: loss = 0.010989\n",
      "Epoch 24, batch 5: loss = 0.010769\n",
      "Epoch 24, batch 6: loss = 0.010148\n",
      "Epoch 24, batch 7: loss = 0.010602\n",
      "Epoch 24, batch 8: loss = 0.010580\n",
      "Epoch 24, batch 9: loss = 0.010822\n",
      "Epoch 24, batch 10: loss = 0.010638\n",
      "Epoch 24, batch 11: loss = 0.009651\n",
      "Epoch 24, batch 12: loss = 0.010917\n",
      "Epoch 24, batch 13: loss = 0.010671\n",
      "Epoch 24, batch 14: loss = 0.010378\n",
      "Epoch 24, batch 15: loss = 0.011105\n",
      "Epoch 24, batch 16: loss = 0.010147\n",
      "Epoch 24, batch 17: loss = 0.010452\n",
      "Epoch 24, batch 18: loss = 0.011134\n",
      "Epoch 24, batch 19: loss = 0.010342\n",
      "Epoch 24, batch 20: loss = 0.009881\n",
      "Epoch 24, batch 21: loss = 0.010210\n",
      "Epoch 24, batch 22: loss = 0.010411\n",
      "Epoch 24, batch 23: loss = 0.010057\n",
      "Epoch 24, batch 24: loss = 0.010631\n",
      "Epoch 24, batch 25: loss = 0.010411\n",
      "Epoch 24, batch 26: loss = 0.010627\n",
      "Epoch 24, batch 27: loss = 0.010568\n",
      "Epoch 24, batch 28: loss = 0.011357\n",
      "Epoch 24, batch 29: loss = 0.010903\n",
      "Epoch 24, batch 30: loss = 0.010411\n",
      "Epoch 24, batch 31: loss = 0.010655\n",
      "Epoch 24, batch 32: loss = 0.010779\n",
      "Epoch 24, batch 33: loss = 0.009805\n",
      "Epoch 24, batch 34: loss = 0.010166\n",
      "Epoch 24, batch 35: loss = 0.010421\n",
      "Epoch 24, batch 36: loss = 0.009981\n",
      "Epoch 24, batch 37: loss = 0.009962\n",
      "Epoch 24, batch 38: loss = 0.009765\n",
      "Epoch 24, batch 39: loss = 0.009935\n",
      "Epoch 24, batch 40: loss = 0.010098\n",
      "Epoch 24, batch 41: loss = 0.010810\n",
      "Epoch 24, batch 42: loss = 0.010174\n",
      "Epoch 24, batch 43: loss = 0.010036\n",
      "Epoch 24, batch 44: loss = 0.010036\n",
      "Epoch 24, batch 45: loss = 0.010079\n",
      "Epoch 24, batch 46: loss = 0.010607\n",
      "Epoch 24, batch 47: loss = 0.010372\n",
      "Epoch 24, batch 48: loss = 0.010976\n",
      "Epoch 24, batch 49: loss = 0.009660\n",
      "Epoch 24, batch 50: loss = 0.009680\n",
      "Epoch 24, batch 51: loss = 0.010179\n",
      "Epoch 24, batch 52: loss = 0.011016\n",
      "Epoch 24, batch 53: loss = 0.010983\n",
      "Epoch 24, batch 54: loss = 0.010541\n",
      "Epoch 24, batch 55: loss = 0.010495\n",
      "Epoch 24, batch 56: loss = 0.010020\n",
      "Epoch 24, batch 57: loss = 0.010276\n",
      "Epoch 24, batch 58: loss = 0.010320\n",
      "Epoch 24, batch 59: loss = 0.010603\n",
      "Epoch 24, batch 60: loss = 0.010483\n",
      "Epoch 24, batch 61: loss = 0.010082\n",
      "Epoch 24, batch 62: loss = 0.010950\n",
      "Epoch 24, batch 63: loss = 0.011005\n",
      "Epoch 24, batch 64: loss = 0.010085\n",
      "Epoch 24, batch 65: loss = 0.010221\n",
      "Epoch 24, batch 66: loss = 0.010204\n",
      "Epoch 24, batch 67: loss = 0.009691\n",
      "Epoch 24, batch 68: loss = 0.010349\n",
      "Epoch 24, batch 69: loss = 0.010350\n",
      "Epoch 24, batch 70: loss = 0.010174\n",
      "Epoch 24, batch 71: loss = 0.010504\n",
      "Epoch 24, batch 72: loss = 0.009944\n",
      "Epoch 24, batch 73: loss = 0.010748\n",
      "Epoch 24, batch 74: loss = 0.010083\n",
      "Epoch 24, batch 75: loss = 0.010154\n",
      "Epoch 24, batch 76: loss = 0.010332\n",
      "Epoch 24, batch 77: loss = 0.010357\n",
      "Epoch 24, batch 78: loss = 0.009978\n",
      "Epoch 24, batch 79: loss = 0.010184\n",
      "Epoch 24, batch 80: loss = 0.010219\n",
      "Epoch 24, batch 81: loss = 0.010932\n",
      "Epoch 24, batch 82: loss = 0.008897\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 24: val_loss = 0.035142\n",
      "Epoch 25, batch 0: loss = 0.010184\n",
      "Epoch 25, batch 1: loss = 0.010177\n",
      "Epoch 25, batch 2: loss = 0.009839\n",
      "Epoch 25, batch 3: loss = 0.010043\n",
      "Epoch 25, batch 4: loss = 0.009763\n",
      "Epoch 25, batch 5: loss = 0.009874\n",
      "Epoch 25, batch 6: loss = 0.010920\n",
      "Epoch 25, batch 7: loss = 0.010059\n",
      "Epoch 25, batch 8: loss = 0.010565\n",
      "Epoch 25, batch 9: loss = 0.010437\n",
      "Epoch 25, batch 10: loss = 0.010293\n",
      "Epoch 25, batch 11: loss = 0.009377\n",
      "Epoch 25, batch 12: loss = 0.009822\n",
      "Epoch 25, batch 13: loss = 0.009973\n",
      "Epoch 25, batch 14: loss = 0.010357\n",
      "Epoch 25, batch 15: loss = 0.010108\n",
      "Epoch 25, batch 16: loss = 0.010507\n",
      "Epoch 25, batch 17: loss = 0.009857\n",
      "Epoch 25, batch 18: loss = 0.010032\n",
      "Epoch 25, batch 19: loss = 0.010052\n",
      "Epoch 25, batch 20: loss = 0.010376\n",
      "Epoch 25, batch 21: loss = 0.010597\n",
      "Epoch 25, batch 22: loss = 0.010087\n",
      "Epoch 25, batch 23: loss = 0.010406\n",
      "Epoch 25, batch 24: loss = 0.009528\n",
      "Epoch 25, batch 25: loss = 0.010417\n",
      "Epoch 25, batch 26: loss = 0.009923\n",
      "Epoch 25, batch 27: loss = 0.010473\n",
      "Epoch 25, batch 28: loss = 0.009583\n",
      "Epoch 25, batch 29: loss = 0.010638\n",
      "Epoch 25, batch 30: loss = 0.010352\n",
      "Epoch 25, batch 31: loss = 0.009902\n",
      "Epoch 25, batch 32: loss = 0.010289\n",
      "Epoch 25, batch 33: loss = 0.010024\n",
      "Epoch 25, batch 34: loss = 0.010206\n",
      "Epoch 25, batch 35: loss = 0.009162\n",
      "Epoch 25, batch 36: loss = 0.010473\n",
      "Epoch 25, batch 37: loss = 0.010896\n",
      "Epoch 25, batch 38: loss = 0.011504\n",
      "Epoch 25, batch 39: loss = 0.010422\n",
      "Epoch 25, batch 40: loss = 0.010607\n",
      "Epoch 25, batch 41: loss = 0.009504\n",
      "Epoch 25, batch 42: loss = 0.009648\n",
      "Epoch 25, batch 43: loss = 0.009995\n",
      "Epoch 25, batch 44: loss = 0.009866\n",
      "Epoch 25, batch 45: loss = 0.009847\n",
      "Epoch 25, batch 46: loss = 0.010428\n",
      "Epoch 25, batch 47: loss = 0.010175\n",
      "Epoch 25, batch 48: loss = 0.009911\n",
      "Epoch 25, batch 49: loss = 0.010251\n",
      "Epoch 25, batch 50: loss = 0.010811\n",
      "Epoch 25, batch 51: loss = 0.009936\n",
      "Epoch 25, batch 52: loss = 0.010136\n",
      "Epoch 25, batch 53: loss = 0.010425\n",
      "Epoch 25, batch 54: loss = 0.009774\n",
      "Epoch 25, batch 55: loss = 0.009988\n",
      "Epoch 25, batch 56: loss = 0.010435\n",
      "Epoch 25, batch 57: loss = 0.010283\n",
      "Epoch 25, batch 58: loss = 0.011330\n",
      "Epoch 25, batch 59: loss = 0.009920\n",
      "Epoch 25, batch 60: loss = 0.010255\n",
      "Epoch 25, batch 61: loss = 0.011153\n",
      "Epoch 25, batch 62: loss = 0.010414\n",
      "Epoch 25, batch 63: loss = 0.009667\n",
      "Epoch 25, batch 64: loss = 0.010284\n",
      "Epoch 25, batch 65: loss = 0.009668\n",
      "Epoch 25, batch 66: loss = 0.009552\n",
      "Epoch 25, batch 67: loss = 0.010376\n",
      "Epoch 25, batch 68: loss = 0.009533\n",
      "Epoch 25, batch 69: loss = 0.010190\n",
      "Epoch 25, batch 70: loss = 0.010871\n",
      "Epoch 25, batch 71: loss = 0.009687\n",
      "Epoch 25, batch 72: loss = 0.010959\n",
      "Epoch 25, batch 73: loss = 0.010000\n",
      "Epoch 25, batch 74: loss = 0.010174\n",
      "Epoch 25, batch 75: loss = 0.009869\n",
      "Epoch 25, batch 76: loss = 0.010338\n",
      "Epoch 25, batch 77: loss = 0.009951\n",
      "Epoch 25, batch 78: loss = 0.009672\n",
      "Epoch 25, batch 79: loss = 0.009712\n",
      "Epoch 25, batch 80: loss = 0.010416\n",
      "Epoch 25, batch 81: loss = 0.010003\n",
      "Epoch 25, batch 82: loss = 0.011516\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 25: val_loss = 0.034506\n",
      "Epoch 26, batch 0: loss = 0.011052\n",
      "Epoch 26, batch 1: loss = 0.010863\n",
      "Epoch 26, batch 2: loss = 0.011462\n",
      "Epoch 26, batch 3: loss = 0.012106\n",
      "Epoch 26, batch 4: loss = 0.012489\n",
      "Epoch 26, batch 5: loss = 0.010265\n",
      "Epoch 26, batch 6: loss = 0.011165\n",
      "Epoch 26, batch 7: loss = 0.010560\n",
      "Epoch 26, batch 8: loss = 0.011084\n",
      "Epoch 26, batch 9: loss = 0.010812\n",
      "Epoch 26, batch 10: loss = 0.010766\n",
      "Epoch 26, batch 11: loss = 0.010694\n",
      "Epoch 26, batch 12: loss = 0.010648\n",
      "Epoch 26, batch 13: loss = 0.010248\n",
      "Epoch 26, batch 14: loss = 0.010926\n",
      "Epoch 26, batch 15: loss = 0.010134\n",
      "Epoch 26, batch 16: loss = 0.010593\n",
      "Epoch 26, batch 17: loss = 0.010667\n",
      "Epoch 26, batch 18: loss = 0.010608\n",
      "Epoch 26, batch 19: loss = 0.010240\n",
      "Epoch 26, batch 20: loss = 0.010451\n",
      "Epoch 26, batch 21: loss = 0.010895\n",
      "Epoch 26, batch 22: loss = 0.010895\n",
      "Epoch 26, batch 23: loss = 0.009981\n",
      "Epoch 26, batch 24: loss = 0.010215\n",
      "Epoch 26, batch 25: loss = 0.010008\n",
      "Epoch 26, batch 26: loss = 0.010612\n",
      "Epoch 26, batch 27: loss = 0.010668\n",
      "Epoch 26, batch 28: loss = 0.009927\n",
      "Epoch 26, batch 29: loss = 0.009772\n",
      "Epoch 26, batch 30: loss = 0.010019\n",
      "Epoch 26, batch 31: loss = 0.011321\n",
      "Epoch 26, batch 32: loss = 0.010230\n",
      "Epoch 26, batch 33: loss = 0.011077\n",
      "Epoch 26, batch 34: loss = 0.010489\n",
      "Epoch 26, batch 35: loss = 0.011047\n",
      "Epoch 26, batch 36: loss = 0.010842\n",
      "Epoch 26, batch 37: loss = 0.010862\n",
      "Epoch 26, batch 38: loss = 0.010032\n",
      "Epoch 26, batch 39: loss = 0.009787\n",
      "Epoch 26, batch 40: loss = 0.011060\n",
      "Epoch 26, batch 41: loss = 0.009758\n",
      "Epoch 26, batch 42: loss = 0.010853\n",
      "Epoch 26, batch 43: loss = 0.010004\n",
      "Epoch 26, batch 44: loss = 0.009581\n",
      "Epoch 26, batch 45: loss = 0.010370\n",
      "Epoch 26, batch 46: loss = 0.009893\n",
      "Epoch 26, batch 47: loss = 0.009965\n",
      "Epoch 26, batch 48: loss = 0.010777\n",
      "Epoch 26, batch 49: loss = 0.010553\n",
      "Epoch 26, batch 50: loss = 0.009630\n",
      "Epoch 26, batch 51: loss = 0.010080\n",
      "Epoch 26, batch 52: loss = 0.010267\n",
      "Epoch 26, batch 53: loss = 0.009867\n",
      "Epoch 26, batch 54: loss = 0.010871\n",
      "Epoch 26, batch 55: loss = 0.010184\n",
      "Epoch 26, batch 56: loss = 0.010032\n",
      "Epoch 26, batch 57: loss = 0.010120\n",
      "Epoch 26, batch 58: loss = 0.010528\n",
      "Epoch 26, batch 59: loss = 0.010749\n",
      "Epoch 26, batch 60: loss = 0.009677\n",
      "Epoch 26, batch 61: loss = 0.010256\n",
      "Epoch 26, batch 62: loss = 0.009383\n",
      "Epoch 26, batch 63: loss = 0.010167\n",
      "Epoch 26, batch 64: loss = 0.009430\n",
      "Epoch 26, batch 65: loss = 0.010090\n",
      "Epoch 26, batch 66: loss = 0.010371\n",
      "Epoch 26, batch 67: loss = 0.010130\n",
      "Epoch 26, batch 68: loss = 0.009546\n",
      "Epoch 26, batch 69: loss = 0.009329\n",
      "Epoch 26, batch 70: loss = 0.010304\n",
      "Epoch 26, batch 71: loss = 0.009788\n",
      "Epoch 26, batch 72: loss = 0.010011\n",
      "Epoch 26, batch 73: loss = 0.009508\n",
      "Epoch 26, batch 74: loss = 0.009756\n",
      "Epoch 26, batch 75: loss = 0.010139\n",
      "Epoch 26, batch 76: loss = 0.010366\n",
      "Epoch 26, batch 77: loss = 0.009919\n",
      "Epoch 26, batch 78: loss = 0.010420\n",
      "Epoch 26, batch 79: loss = 0.010072\n",
      "Epoch 26, batch 80: loss = 0.009903\n",
      "Epoch 26, batch 81: loss = 0.009405\n",
      "Epoch 26, batch 82: loss = 0.007364\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 26: val_loss = 0.034926\n",
      "Epoch 27, batch 0: loss = 0.010034\n",
      "Epoch 27, batch 1: loss = 0.009629\n",
      "Epoch 27, batch 2: loss = 0.010516\n",
      "Epoch 27, batch 3: loss = 0.010057\n",
      "Epoch 27, batch 4: loss = 0.010883\n",
      "Epoch 27, batch 5: loss = 0.009916\n",
      "Epoch 27, batch 6: loss = 0.010236\n",
      "Epoch 27, batch 7: loss = 0.010350\n",
      "Epoch 27, batch 8: loss = 0.010583\n",
      "Epoch 27, batch 9: loss = 0.010174\n",
      "Epoch 27, batch 10: loss = 0.009122\n",
      "Epoch 27, batch 11: loss = 0.010091\n",
      "Epoch 27, batch 12: loss = 0.009799\n",
      "Epoch 27, batch 13: loss = 0.009481\n",
      "Epoch 27, batch 14: loss = 0.010017\n",
      "Epoch 27, batch 15: loss = 0.009836\n",
      "Epoch 27, batch 16: loss = 0.010303\n",
      "Epoch 27, batch 17: loss = 0.009766\n",
      "Epoch 27, batch 18: loss = 0.009842\n",
      "Epoch 27, batch 19: loss = 0.010433\n",
      "Epoch 27, batch 20: loss = 0.010308\n",
      "Epoch 27, batch 21: loss = 0.009295\n",
      "Epoch 27, batch 22: loss = 0.010257\n",
      "Epoch 27, batch 23: loss = 0.009827\n",
      "Epoch 27, batch 24: loss = 0.010089\n",
      "Epoch 27, batch 25: loss = 0.010615\n",
      "Epoch 27, batch 26: loss = 0.010582\n",
      "Epoch 27, batch 27: loss = 0.009346\n",
      "Epoch 27, batch 28: loss = 0.010121\n",
      "Epoch 27, batch 29: loss = 0.010307\n",
      "Epoch 27, batch 30: loss = 0.009808\n",
      "Epoch 27, batch 31: loss = 0.009980\n",
      "Epoch 27, batch 32: loss = 0.010206\n",
      "Epoch 27, batch 33: loss = 0.009705\n",
      "Epoch 27, batch 34: loss = 0.009963\n",
      "Epoch 27, batch 35: loss = 0.010565\n",
      "Epoch 27, batch 36: loss = 0.009985\n",
      "Epoch 27, batch 37: loss = 0.010616\n",
      "Epoch 27, batch 38: loss = 0.010688\n",
      "Epoch 27, batch 39: loss = 0.009821\n",
      "Epoch 27, batch 40: loss = 0.010479\n",
      "Epoch 27, batch 41: loss = 0.010093\n",
      "Epoch 27, batch 42: loss = 0.010137\n",
      "Epoch 27, batch 43: loss = 0.009714\n",
      "Epoch 27, batch 44: loss = 0.010667\n",
      "Epoch 27, batch 45: loss = 0.009946\n",
      "Epoch 27, batch 46: loss = 0.010448\n",
      "Epoch 27, batch 47: loss = 0.009310\n",
      "Epoch 27, batch 48: loss = 0.009793\n",
      "Epoch 27, batch 49: loss = 0.010459\n",
      "Epoch 27, batch 50: loss = 0.010262\n",
      "Epoch 27, batch 51: loss = 0.010025\n",
      "Epoch 27, batch 52: loss = 0.010169\n",
      "Epoch 27, batch 53: loss = 0.009563\n",
      "Epoch 27, batch 54: loss = 0.010046\n",
      "Epoch 27, batch 55: loss = 0.009464\n",
      "Epoch 27, batch 56: loss = 0.010798\n",
      "Epoch 27, batch 57: loss = 0.009354\n",
      "Epoch 27, batch 58: loss = 0.009885\n",
      "Epoch 27, batch 59: loss = 0.009967\n",
      "Epoch 27, batch 60: loss = 0.009654\n",
      "Epoch 27, batch 61: loss = 0.009612\n",
      "Epoch 27, batch 62: loss = 0.009797\n",
      "Epoch 27, batch 63: loss = 0.009921\n",
      "Epoch 27, batch 64: loss = 0.010094\n",
      "Epoch 27, batch 65: loss = 0.010095\n",
      "Epoch 27, batch 66: loss = 0.009380\n",
      "Epoch 27, batch 67: loss = 0.009862\n",
      "Epoch 27, batch 68: loss = 0.009633\n",
      "Epoch 27, batch 69: loss = 0.009856\n",
      "Epoch 27, batch 70: loss = 0.009598\n",
      "Epoch 27, batch 71: loss = 0.009363\n",
      "Epoch 27, batch 72: loss = 0.009344\n",
      "Epoch 27, batch 73: loss = 0.009915\n",
      "Epoch 27, batch 74: loss = 0.009740\n",
      "Epoch 27, batch 75: loss = 0.010476\n",
      "Epoch 27, batch 76: loss = 0.009982\n",
      "Epoch 27, batch 77: loss = 0.010021\n",
      "Epoch 27, batch 78: loss = 0.009618\n",
      "Epoch 27, batch 79: loss = 0.009842\n",
      "Epoch 27, batch 80: loss = 0.009851\n",
      "Epoch 27, batch 81: loss = 0.009517\n",
      "Epoch 27, batch 82: loss = 0.009565\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 27: val_loss = 0.035335\n",
      "Epoch 28, batch 0: loss = 0.009570\n",
      "Epoch 28, batch 1: loss = 0.009885\n",
      "Epoch 28, batch 2: loss = 0.009602\n",
      "Epoch 28, batch 3: loss = 0.010479\n",
      "Epoch 28, batch 4: loss = 0.009945\n",
      "Epoch 28, batch 5: loss = 0.010360\n",
      "Epoch 28, batch 6: loss = 0.010373\n",
      "Epoch 28, batch 7: loss = 0.009839\n",
      "Epoch 28, batch 8: loss = 0.010660\n",
      "Epoch 28, batch 9: loss = 0.010153\n",
      "Epoch 28, batch 10: loss = 0.010462\n",
      "Epoch 28, batch 11: loss = 0.010309\n",
      "Epoch 28, batch 12: loss = 0.010330\n",
      "Epoch 28, batch 13: loss = 0.009701\n",
      "Epoch 28, batch 14: loss = 0.010734\n",
      "Epoch 28, batch 15: loss = 0.010036\n",
      "Epoch 28, batch 16: loss = 0.009974\n",
      "Epoch 28, batch 17: loss = 0.010467\n",
      "Epoch 28, batch 18: loss = 0.009210\n",
      "Epoch 28, batch 19: loss = 0.009990\n",
      "Epoch 28, batch 20: loss = 0.010225\n",
      "Epoch 28, batch 21: loss = 0.009554\n",
      "Epoch 28, batch 22: loss = 0.009852\n",
      "Epoch 28, batch 23: loss = 0.009695\n",
      "Epoch 28, batch 24: loss = 0.009891\n",
      "Epoch 28, batch 25: loss = 0.009335\n",
      "Epoch 28, batch 26: loss = 0.009446\n",
      "Epoch 28, batch 27: loss = 0.009661\n",
      "Epoch 28, batch 28: loss = 0.008879\n",
      "Epoch 28, batch 29: loss = 0.009398\n",
      "Epoch 28, batch 30: loss = 0.010697\n",
      "Epoch 28, batch 31: loss = 0.010166\n",
      "Epoch 28, batch 32: loss = 0.010033\n",
      "Epoch 28, batch 33: loss = 0.010479\n",
      "Epoch 28, batch 34: loss = 0.010079\n",
      "Epoch 28, batch 35: loss = 0.009075\n",
      "Epoch 28, batch 36: loss = 0.009646\n",
      "Epoch 28, batch 37: loss = 0.010334\n",
      "Epoch 28, batch 38: loss = 0.009773\n",
      "Epoch 28, batch 39: loss = 0.010293\n",
      "Epoch 28, batch 40: loss = 0.009583\n",
      "Epoch 28, batch 41: loss = 0.010116\n",
      "Epoch 28, batch 42: loss = 0.010929\n",
      "Epoch 28, batch 43: loss = 0.009974\n",
      "Epoch 28, batch 44: loss = 0.009531\n",
      "Epoch 28, batch 45: loss = 0.009600\n",
      "Epoch 28, batch 46: loss = 0.009684\n",
      "Epoch 28, batch 47: loss = 0.009377\n",
      "Epoch 28, batch 48: loss = 0.009728\n",
      "Epoch 28, batch 49: loss = 0.009869\n",
      "Epoch 28, batch 50: loss = 0.010501\n",
      "Epoch 28, batch 51: loss = 0.010615\n",
      "Epoch 28, batch 52: loss = 0.010777\n",
      "Epoch 28, batch 53: loss = 0.010314\n",
      "Epoch 28, batch 54: loss = 0.010161\n",
      "Epoch 28, batch 55: loss = 0.010186\n",
      "Epoch 28, batch 56: loss = 0.011234\n",
      "Epoch 28, batch 57: loss = 0.010401\n",
      "Epoch 28, batch 58: loss = 0.011062\n",
      "Epoch 28, batch 59: loss = 0.010684\n",
      "Epoch 28, batch 60: loss = 0.009858\n",
      "Epoch 28, batch 61: loss = 0.010609\n",
      "Epoch 28, batch 62: loss = 0.010828\n",
      "Epoch 28, batch 63: loss = 0.010666\n",
      "Epoch 28, batch 64: loss = 0.009566\n",
      "Epoch 28, batch 65: loss = 0.011536\n",
      "Epoch 28, batch 66: loss = 0.010352\n",
      "Epoch 28, batch 67: loss = 0.010352\n",
      "Epoch 28, batch 68: loss = 0.010848\n",
      "Epoch 28, batch 69: loss = 0.010058\n",
      "Epoch 28, batch 70: loss = 0.010813\n",
      "Epoch 28, batch 71: loss = 0.010185\n",
      "Epoch 28, batch 72: loss = 0.010063\n",
      "Epoch 28, batch 73: loss = 0.010283\n",
      "Epoch 28, batch 74: loss = 0.009914\n",
      "Epoch 28, batch 75: loss = 0.011217\n",
      "Epoch 28, batch 76: loss = 0.009626\n",
      "Epoch 28, batch 77: loss = 0.010530\n",
      "Epoch 28, batch 78: loss = 0.010285\n",
      "Epoch 28, batch 79: loss = 0.009836\n",
      "Epoch 28, batch 80: loss = 0.010380\n",
      "Epoch 28, batch 81: loss = 0.010588\n",
      "Epoch 28, batch 82: loss = 0.013898\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 28: val_loss = 0.034376\n",
      "Epoch 29, batch 0: loss = 0.012082\n",
      "Epoch 29, batch 1: loss = 0.009671\n",
      "Epoch 29, batch 2: loss = 0.009861\n",
      "Epoch 29, batch 3: loss = 0.010087\n",
      "Epoch 29, batch 4: loss = 0.010703\n",
      "Epoch 29, batch 5: loss = 0.010233\n",
      "Epoch 29, batch 6: loss = 0.009928\n",
      "Epoch 29, batch 7: loss = 0.010292\n",
      "Epoch 29, batch 8: loss = 0.009943\n",
      "Epoch 29, batch 9: loss = 0.009928\n",
      "Epoch 29, batch 10: loss = 0.010204\n",
      "Epoch 29, batch 11: loss = 0.009254\n",
      "Epoch 29, batch 12: loss = 0.009731\n",
      "Epoch 29, batch 13: loss = 0.010356\n",
      "Epoch 29, batch 14: loss = 0.009584\n",
      "Epoch 29, batch 15: loss = 0.009864\n",
      "Epoch 29, batch 16: loss = 0.009716\n",
      "Epoch 29, batch 17: loss = 0.009227\n",
      "Epoch 29, batch 18: loss = 0.010246\n",
      "Epoch 29, batch 19: loss = 0.009633\n",
      "Epoch 29, batch 20: loss = 0.009869\n",
      "Epoch 29, batch 21: loss = 0.009596\n",
      "Epoch 29, batch 22: loss = 0.009389\n",
      "Epoch 29, batch 23: loss = 0.010304\n",
      "Epoch 29, batch 24: loss = 0.009803\n",
      "Epoch 29, batch 25: loss = 0.009703\n",
      "Epoch 29, batch 26: loss = 0.011067\n",
      "Epoch 29, batch 27: loss = 0.010378\n",
      "Epoch 29, batch 28: loss = 0.009889\n",
      "Epoch 29, batch 29: loss = 0.009723\n",
      "Epoch 29, batch 30: loss = 0.009296\n",
      "Epoch 29, batch 31: loss = 0.009864\n",
      "Epoch 29, batch 32: loss = 0.010422\n",
      "Epoch 29, batch 33: loss = 0.009544\n",
      "Epoch 29, batch 34: loss = 0.009287\n",
      "Epoch 29, batch 35: loss = 0.010618\n",
      "Epoch 29, batch 36: loss = 0.010054\n",
      "Epoch 29, batch 37: loss = 0.010235\n",
      "Epoch 29, batch 38: loss = 0.009932\n",
      "Epoch 29, batch 39: loss = 0.010076\n",
      "Epoch 29, batch 40: loss = 0.010803\n",
      "Epoch 29, batch 41: loss = 0.010091\n",
      "Epoch 29, batch 42: loss = 0.010018\n",
      "Epoch 29, batch 43: loss = 0.009666\n",
      "Epoch 29, batch 44: loss = 0.009785\n",
      "Epoch 29, batch 45: loss = 0.009799\n",
      "Epoch 29, batch 46: loss = 0.010023\n",
      "Epoch 29, batch 47: loss = 0.009603\n",
      "Epoch 29, batch 48: loss = 0.010243\n",
      "Epoch 29, batch 49: loss = 0.009882\n",
      "Epoch 29, batch 50: loss = 0.009737\n",
      "Epoch 29, batch 51: loss = 0.009892\n",
      "Epoch 29, batch 52: loss = 0.009750\n",
      "Epoch 29, batch 53: loss = 0.009286\n",
      "Epoch 29, batch 54: loss = 0.008895\n",
      "Epoch 29, batch 55: loss = 0.010403\n",
      "Epoch 29, batch 56: loss = 0.009776\n",
      "Epoch 29, batch 57: loss = 0.008928\n",
      "Epoch 29, batch 58: loss = 0.009139\n",
      "Epoch 29, batch 59: loss = 0.009859\n",
      "Epoch 29, batch 60: loss = 0.010421\n",
      "Epoch 29, batch 61: loss = 0.009772\n",
      "Epoch 29, batch 62: loss = 0.010038\n",
      "Epoch 29, batch 63: loss = 0.009199\n",
      "Epoch 29, batch 64: loss = 0.009482\n",
      "Epoch 29, batch 65: loss = 0.009791\n",
      "Epoch 29, batch 66: loss = 0.009590\n",
      "Epoch 29, batch 67: loss = 0.010048\n",
      "Epoch 29, batch 68: loss = 0.009744\n",
      "Epoch 29, batch 69: loss = 0.009656\n",
      "Epoch 29, batch 70: loss = 0.009421\n",
      "Epoch 29, batch 71: loss = 0.009793\n",
      "Epoch 29, batch 72: loss = 0.010312\n",
      "Epoch 29, batch 73: loss = 0.010168\n",
      "Epoch 29, batch 74: loss = 0.009180\n",
      "Epoch 29, batch 75: loss = 0.009359\n",
      "Epoch 29, batch 76: loss = 0.009425\n",
      "Epoch 29, batch 77: loss = 0.009537\n",
      "Epoch 29, batch 78: loss = 0.008625\n",
      "Epoch 29, batch 79: loss = 0.009502\n",
      "Epoch 29, batch 80: loss = 0.009732\n",
      "Epoch 29, batch 81: loss = 0.010120\n",
      "Epoch 29, batch 82: loss = 0.018803\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 29: val_loss = 0.038355\n",
      "Epoch 30, batch 0: loss = 0.011993\n",
      "Epoch 30, batch 1: loss = 0.011824\n",
      "Epoch 30, batch 2: loss = 0.010456\n",
      "Epoch 30, batch 3: loss = 0.010540\n",
      "Epoch 30, batch 4: loss = 0.011800\n",
      "Epoch 30, batch 5: loss = 0.010806\n",
      "Epoch 30, batch 6: loss = 0.010679\n",
      "Epoch 30, batch 7: loss = 0.011400\n",
      "Epoch 30, batch 8: loss = 0.011708\n",
      "Epoch 30, batch 9: loss = 0.010916\n",
      "Epoch 30, batch 10: loss = 0.009992\n",
      "Epoch 30, batch 11: loss = 0.010664\n",
      "Epoch 30, batch 12: loss = 0.010304\n",
      "Epoch 30, batch 13: loss = 0.010977\n",
      "Epoch 30, batch 14: loss = 0.010344\n",
      "Epoch 30, batch 15: loss = 0.010758\n",
      "Epoch 30, batch 16: loss = 0.010803\n",
      "Epoch 30, batch 17: loss = 0.011175\n",
      "Epoch 30, batch 18: loss = 0.010197\n",
      "Epoch 30, batch 19: loss = 0.010670\n",
      "Epoch 30, batch 20: loss = 0.010432\n",
      "Epoch 30, batch 21: loss = 0.011656\n",
      "Epoch 30, batch 22: loss = 0.011017\n",
      "Epoch 30, batch 23: loss = 0.010853\n",
      "Epoch 30, batch 24: loss = 0.010289\n",
      "Epoch 30, batch 25: loss = 0.011399\n",
      "Epoch 30, batch 26: loss = 0.009581\n",
      "Epoch 30, batch 27: loss = 0.010902\n",
      "Epoch 30, batch 28: loss = 0.009484\n",
      "Epoch 30, batch 29: loss = 0.010402\n",
      "Epoch 30, batch 30: loss = 0.009985\n",
      "Epoch 30, batch 31: loss = 0.010708\n",
      "Epoch 30, batch 32: loss = 0.009375\n",
      "Epoch 30, batch 33: loss = 0.010245\n",
      "Epoch 30, batch 34: loss = 0.010666\n",
      "Epoch 30, batch 35: loss = 0.010680\n",
      "Epoch 30, batch 36: loss = 0.010643\n",
      "Epoch 30, batch 37: loss = 0.010700\n",
      "Epoch 30, batch 38: loss = 0.010716\n",
      "Epoch 30, batch 39: loss = 0.011102\n",
      "Epoch 30, batch 40: loss = 0.009956\n",
      "Epoch 30, batch 41: loss = 0.010563\n",
      "Epoch 30, batch 42: loss = 0.010447\n",
      "Epoch 30, batch 43: loss = 0.010099\n",
      "Epoch 30, batch 44: loss = 0.010439\n",
      "Epoch 30, batch 45: loss = 0.009727\n",
      "Epoch 30, batch 46: loss = 0.010352\n",
      "Epoch 30, batch 47: loss = 0.009889\n",
      "Epoch 30, batch 48: loss = 0.009663\n",
      "Epoch 30, batch 49: loss = 0.010056\n",
      "Epoch 30, batch 50: loss = 0.009830\n",
      "Epoch 30, batch 51: loss = 0.009794\n",
      "Epoch 30, batch 52: loss = 0.010049\n",
      "Epoch 30, batch 53: loss = 0.010374\n",
      "Epoch 30, batch 54: loss = 0.010614\n",
      "Epoch 30, batch 55: loss = 0.009881\n",
      "Epoch 30, batch 56: loss = 0.009472\n",
      "Epoch 30, batch 57: loss = 0.009564\n",
      "Epoch 30, batch 58: loss = 0.009980\n",
      "Epoch 30, batch 59: loss = 0.009798\n",
      "Epoch 30, batch 60: loss = 0.009942\n",
      "Epoch 30, batch 61: loss = 0.010281\n",
      "Epoch 30, batch 62: loss = 0.009922\n",
      "Epoch 30, batch 63: loss = 0.010148\n",
      "Epoch 30, batch 64: loss = 0.009495\n",
      "Epoch 30, batch 65: loss = 0.009657\n",
      "Epoch 30, batch 66: loss = 0.009847\n",
      "Epoch 30, batch 67: loss = 0.010043\n",
      "Epoch 30, batch 68: loss = 0.010630\n",
      "Epoch 30, batch 69: loss = 0.010762\n",
      "Epoch 30, batch 70: loss = 0.010487\n",
      "Epoch 30, batch 71: loss = 0.010207\n",
      "Epoch 30, batch 72: loss = 0.009464\n",
      "Epoch 30, batch 73: loss = 0.009399\n",
      "Epoch 30, batch 74: loss = 0.009800\n",
      "Epoch 30, batch 75: loss = 0.010481\n",
      "Epoch 30, batch 76: loss = 0.010873\n",
      "Epoch 30, batch 77: loss = 0.009587\n",
      "Epoch 30, batch 78: loss = 0.009931\n",
      "Epoch 30, batch 79: loss = 0.010261\n",
      "Epoch 30, batch 80: loss = 0.009842\n",
      "Epoch 30, batch 81: loss = 0.009422\n",
      "Epoch 30, batch 82: loss = 0.010462\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 30: val_loss = 0.034546\n",
      "Epoch 31, batch 0: loss = 0.010047\n",
      "Epoch 31, batch 1: loss = 0.009996\n",
      "Epoch 31, batch 2: loss = 0.010511\n",
      "Epoch 31, batch 3: loss = 0.009650\n",
      "Epoch 31, batch 4: loss = 0.010605\n",
      "Epoch 31, batch 5: loss = 0.009751\n",
      "Epoch 31, batch 6: loss = 0.011824\n",
      "Epoch 31, batch 7: loss = 0.009998\n",
      "Epoch 31, batch 8: loss = 0.010311\n",
      "Epoch 31, batch 9: loss = 0.010275\n",
      "Epoch 31, batch 10: loss = 0.009599\n",
      "Epoch 31, batch 11: loss = 0.009612\n",
      "Epoch 31, batch 12: loss = 0.009209\n",
      "Epoch 31, batch 13: loss = 0.010236\n",
      "Epoch 31, batch 14: loss = 0.009954\n",
      "Epoch 31, batch 15: loss = 0.010234\n",
      "Epoch 31, batch 16: loss = 0.009786\n",
      "Epoch 31, batch 17: loss = 0.009994\n",
      "Epoch 31, batch 18: loss = 0.010195\n",
      "Epoch 31, batch 19: loss = 0.010100\n",
      "Epoch 31, batch 20: loss = 0.009621\n",
      "Epoch 31, batch 21: loss = 0.010141\n",
      "Epoch 31, batch 22: loss = 0.010303\n",
      "Epoch 31, batch 23: loss = 0.009165\n",
      "Epoch 31, batch 24: loss = 0.010208\n",
      "Epoch 31, batch 25: loss = 0.009571\n",
      "Epoch 31, batch 26: loss = 0.009659\n",
      "Epoch 31, batch 27: loss = 0.009779\n",
      "Epoch 31, batch 28: loss = 0.009781\n",
      "Epoch 31, batch 29: loss = 0.009449\n",
      "Epoch 31, batch 30: loss = 0.009973\n",
      "Epoch 31, batch 31: loss = 0.009152\n",
      "Epoch 31, batch 32: loss = 0.009923\n",
      "Epoch 31, batch 33: loss = 0.009806\n",
      "Epoch 31, batch 34: loss = 0.009785\n",
      "Epoch 31, batch 35: loss = 0.009954\n",
      "Epoch 31, batch 36: loss = 0.010666\n",
      "Epoch 31, batch 37: loss = 0.009586\n",
      "Epoch 31, batch 38: loss = 0.010197\n",
      "Epoch 31, batch 39: loss = 0.009351\n",
      "Epoch 31, batch 40: loss = 0.009591\n",
      "Epoch 31, batch 41: loss = 0.009466\n",
      "Epoch 31, batch 42: loss = 0.009868\n",
      "Epoch 31, batch 43: loss = 0.009404\n",
      "Epoch 31, batch 44: loss = 0.009176\n",
      "Epoch 31, batch 45: loss = 0.009482\n",
      "Epoch 31, batch 46: loss = 0.010184\n",
      "Epoch 31, batch 47: loss = 0.010018\n",
      "Epoch 31, batch 48: loss = 0.009360\n",
      "Epoch 31, batch 49: loss = 0.009112\n",
      "Epoch 31, batch 50: loss = 0.009413\n",
      "Epoch 31, batch 51: loss = 0.008851\n",
      "Epoch 31, batch 52: loss = 0.009253\n",
      "Epoch 31, batch 53: loss = 0.009483\n",
      "Epoch 31, batch 54: loss = 0.009891\n",
      "Epoch 31, batch 55: loss = 0.010204\n",
      "Epoch 31, batch 56: loss = 0.009708\n",
      "Epoch 31, batch 57: loss = 0.010161\n",
      "Epoch 31, batch 58: loss = 0.009367\n",
      "Epoch 31, batch 59: loss = 0.009663\n",
      "Epoch 31, batch 60: loss = 0.009950\n",
      "Epoch 31, batch 61: loss = 0.009573\n",
      "Epoch 31, batch 62: loss = 0.009506\n",
      "Epoch 31, batch 63: loss = 0.009692\n",
      "Epoch 31, batch 64: loss = 0.010056\n",
      "Epoch 31, batch 65: loss = 0.009703\n",
      "Epoch 31, batch 66: loss = 0.009965\n",
      "Epoch 31, batch 67: loss = 0.009499\n",
      "Epoch 31, batch 68: loss = 0.010221\n",
      "Epoch 31, batch 69: loss = 0.010072\n",
      "Epoch 31, batch 70: loss = 0.009928\n",
      "Epoch 31, batch 71: loss = 0.009068\n",
      "Epoch 31, batch 72: loss = 0.010281\n",
      "Epoch 31, batch 73: loss = 0.009905\n",
      "Epoch 31, batch 74: loss = 0.009890\n",
      "Epoch 31, batch 75: loss = 0.010098\n",
      "Epoch 31, batch 76: loss = 0.009282\n",
      "Epoch 31, batch 77: loss = 0.009439\n",
      "Epoch 31, batch 78: loss = 0.009351\n",
      "Epoch 31, batch 79: loss = 0.010053\n",
      "Epoch 31, batch 80: loss = 0.009637\n",
      "Epoch 31, batch 81: loss = 0.009743\n",
      "Epoch 31, batch 82: loss = 0.010941\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 31: val_loss = 0.034832\n",
      "Epoch 32, batch 0: loss = 0.010422\n",
      "Epoch 32, batch 1: loss = 0.010442\n",
      "Epoch 32, batch 2: loss = 0.010615\n",
      "Epoch 32, batch 3: loss = 0.010209\n",
      "Epoch 32, batch 4: loss = 0.009374\n",
      "Epoch 32, batch 5: loss = 0.011399\n",
      "Epoch 32, batch 6: loss = 0.010699\n",
      "Epoch 32, batch 7: loss = 0.010083\n",
      "Epoch 32, batch 8: loss = 0.009146\n",
      "Epoch 32, batch 9: loss = 0.010300\n",
      "Epoch 32, batch 10: loss = 0.009662\n",
      "Epoch 32, batch 11: loss = 0.009529\n",
      "Epoch 32, batch 12: loss = 0.009880\n",
      "Epoch 32, batch 13: loss = 0.010126\n",
      "Epoch 32, batch 14: loss = 0.009015\n",
      "Epoch 32, batch 15: loss = 0.010114\n",
      "Epoch 32, batch 16: loss = 0.009258\n",
      "Epoch 32, batch 17: loss = 0.009995\n",
      "Epoch 32, batch 18: loss = 0.009766\n",
      "Epoch 32, batch 19: loss = 0.009988\n",
      "Epoch 32, batch 20: loss = 0.009563\n",
      "Epoch 32, batch 21: loss = 0.009316\n",
      "Epoch 32, batch 22: loss = 0.009085\n",
      "Epoch 32, batch 23: loss = 0.009663\n",
      "Epoch 32, batch 24: loss = 0.009588\n",
      "Epoch 32, batch 25: loss = 0.010222\n",
      "Epoch 32, batch 26: loss = 0.009674\n",
      "Epoch 32, batch 27: loss = 0.009770\n",
      "Epoch 32, batch 28: loss = 0.009561\n",
      "Epoch 32, batch 29: loss = 0.009533\n",
      "Epoch 32, batch 30: loss = 0.009948\n",
      "Epoch 32, batch 31: loss = 0.009974\n",
      "Epoch 32, batch 32: loss = 0.009407\n",
      "Epoch 32, batch 33: loss = 0.009569\n",
      "Epoch 32, batch 34: loss = 0.009566\n",
      "Epoch 32, batch 35: loss = 0.010084\n",
      "Epoch 32, batch 36: loss = 0.009983\n",
      "Epoch 32, batch 37: loss = 0.009546\n",
      "Epoch 32, batch 38: loss = 0.008845\n",
      "Epoch 32, batch 39: loss = 0.009443\n",
      "Epoch 32, batch 40: loss = 0.009449\n",
      "Epoch 32, batch 41: loss = 0.008799\n",
      "Epoch 32, batch 42: loss = 0.009151\n",
      "Epoch 32, batch 43: loss = 0.009796\n",
      "Epoch 32, batch 44: loss = 0.009537\n",
      "Epoch 32, batch 45: loss = 0.009582\n",
      "Epoch 32, batch 46: loss = 0.009659\n",
      "Epoch 32, batch 47: loss = 0.009778\n",
      "Epoch 32, batch 48: loss = 0.009909\n",
      "Epoch 32, batch 49: loss = 0.009733\n",
      "Epoch 32, batch 50: loss = 0.009777\n",
      "Epoch 32, batch 51: loss = 0.009424\n",
      "Epoch 32, batch 52: loss = 0.009508\n",
      "Epoch 32, batch 53: loss = 0.009331\n",
      "Epoch 32, batch 54: loss = 0.009646\n",
      "Epoch 32, batch 55: loss = 0.009218\n",
      "Epoch 32, batch 56: loss = 0.009838\n",
      "Epoch 32, batch 57: loss = 0.009135\n",
      "Epoch 32, batch 58: loss = 0.009260\n",
      "Epoch 32, batch 59: loss = 0.009207\n",
      "Epoch 32, batch 60: loss = 0.009097\n",
      "Epoch 32, batch 61: loss = 0.009410\n",
      "Epoch 32, batch 62: loss = 0.009233\n",
      "Epoch 32, batch 63: loss = 0.009580\n",
      "Epoch 32, batch 64: loss = 0.009444\n",
      "Epoch 32, batch 65: loss = 0.009382\n",
      "Epoch 32, batch 66: loss = 0.009351\n",
      "Epoch 32, batch 67: loss = 0.009426\n",
      "Epoch 32, batch 68: loss = 0.009906\n",
      "Epoch 32, batch 69: loss = 0.009488\n",
      "Epoch 32, batch 70: loss = 0.010259\n",
      "Epoch 32, batch 71: loss = 0.010591\n",
      "Epoch 32, batch 72: loss = 0.009688\n",
      "Epoch 32, batch 73: loss = 0.009420\n",
      "Epoch 32, batch 74: loss = 0.009491\n",
      "Epoch 32, batch 75: loss = 0.009463\n",
      "Epoch 32, batch 76: loss = 0.009497\n",
      "Epoch 32, batch 77: loss = 0.010392\n",
      "Epoch 32, batch 78: loss = 0.009679\n",
      "Epoch 32, batch 79: loss = 0.009466\n",
      "Epoch 32, batch 80: loss = 0.009115\n",
      "Epoch 32, batch 81: loss = 0.009582\n",
      "Epoch 32, batch 82: loss = 0.008261\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 32: val_loss = 0.034855\n",
      "Epoch 33, batch 0: loss = 0.009482\n",
      "Epoch 33, batch 1: loss = 0.010948\n",
      "Epoch 33, batch 2: loss = 0.009691\n",
      "Epoch 33, batch 3: loss = 0.010116\n",
      "Epoch 33, batch 4: loss = 0.009655\n",
      "Epoch 33, batch 5: loss = 0.009836\n",
      "Epoch 33, batch 6: loss = 0.009398\n",
      "Epoch 33, batch 7: loss = 0.010243\n",
      "Epoch 33, batch 8: loss = 0.009281\n",
      "Epoch 33, batch 9: loss = 0.009722\n",
      "Epoch 33, batch 10: loss = 0.009185\n",
      "Epoch 33, batch 11: loss = 0.009875\n",
      "Epoch 33, batch 12: loss = 0.009946\n",
      "Epoch 33, batch 13: loss = 0.009649\n",
      "Epoch 33, batch 14: loss = 0.009624\n",
      "Epoch 33, batch 15: loss = 0.009426\n",
      "Epoch 33, batch 16: loss = 0.009598\n",
      "Epoch 33, batch 17: loss = 0.008989\n",
      "Epoch 33, batch 18: loss = 0.009884\n",
      "Epoch 33, batch 19: loss = 0.009599\n",
      "Epoch 33, batch 20: loss = 0.009165\n",
      "Epoch 33, batch 21: loss = 0.009936\n",
      "Epoch 33, batch 22: loss = 0.008928\n",
      "Epoch 33, batch 23: loss = 0.010016\n",
      "Epoch 33, batch 24: loss = 0.009397\n",
      "Epoch 33, batch 25: loss = 0.009422\n",
      "Epoch 33, batch 26: loss = 0.010096\n",
      "Epoch 33, batch 27: loss = 0.010512\n",
      "Epoch 33, batch 28: loss = 0.009521\n",
      "Epoch 33, batch 29: loss = 0.009102\n",
      "Epoch 33, batch 30: loss = 0.010085\n",
      "Epoch 33, batch 31: loss = 0.008870\n",
      "Epoch 33, batch 32: loss = 0.009097\n",
      "Epoch 33, batch 33: loss = 0.010306\n",
      "Epoch 33, batch 34: loss = 0.010127\n",
      "Epoch 33, batch 35: loss = 0.010068\n",
      "Epoch 33, batch 36: loss = 0.009581\n",
      "Epoch 33, batch 37: loss = 0.009653\n",
      "Epoch 33, batch 38: loss = 0.009935\n",
      "Epoch 33, batch 39: loss = 0.010374\n",
      "Epoch 33, batch 40: loss = 0.010285\n",
      "Epoch 33, batch 41: loss = 0.009504\n",
      "Epoch 33, batch 42: loss = 0.009252\n",
      "Epoch 33, batch 43: loss = 0.009569\n",
      "Epoch 33, batch 44: loss = 0.009139\n",
      "Epoch 33, batch 45: loss = 0.008987\n",
      "Epoch 33, batch 46: loss = 0.009512\n",
      "Epoch 33, batch 47: loss = 0.010004\n",
      "Epoch 33, batch 48: loss = 0.009467\n",
      "Epoch 33, batch 49: loss = 0.009094\n",
      "Epoch 33, batch 50: loss = 0.009356\n",
      "Epoch 33, batch 51: loss = 0.009904\n",
      "Epoch 33, batch 52: loss = 0.009513\n",
      "Epoch 33, batch 53: loss = 0.009996\n",
      "Epoch 33, batch 54: loss = 0.009664\n",
      "Epoch 33, batch 55: loss = 0.009080\n",
      "Epoch 33, batch 56: loss = 0.009776\n",
      "Epoch 33, batch 57: loss = 0.009110\n",
      "Epoch 33, batch 58: loss = 0.009346\n",
      "Epoch 33, batch 59: loss = 0.008749\n",
      "Epoch 33, batch 60: loss = 0.008954\n",
      "Epoch 33, batch 61: loss = 0.009536\n",
      "Epoch 33, batch 62: loss = 0.009552\n",
      "Epoch 33, batch 63: loss = 0.009560\n",
      "Epoch 33, batch 64: loss = 0.008947\n",
      "Epoch 33, batch 65: loss = 0.009752\n",
      "Epoch 33, batch 66: loss = 0.009595\n",
      "Epoch 33, batch 67: loss = 0.009337\n",
      "Epoch 33, batch 68: loss = 0.009135\n",
      "Epoch 33, batch 69: loss = 0.009015\n",
      "Epoch 33, batch 70: loss = 0.010070\n",
      "Epoch 33, batch 71: loss = 0.009300\n",
      "Epoch 33, batch 72: loss = 0.009727\n",
      "Epoch 33, batch 73: loss = 0.008751\n",
      "Epoch 33, batch 74: loss = 0.009115\n",
      "Epoch 33, batch 75: loss = 0.009356\n",
      "Epoch 33, batch 76: loss = 0.009480\n",
      "Epoch 33, batch 77: loss = 0.009209\n",
      "Epoch 33, batch 78: loss = 0.009955\n",
      "Epoch 33, batch 79: loss = 0.009081\n",
      "Epoch 33, batch 80: loss = 0.009285\n",
      "Epoch 33, batch 81: loss = 0.009265\n",
      "Epoch 33, batch 82: loss = 0.008051\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 33: val_loss = 0.035018\n",
      "Epoch 34, batch 0: loss = 0.009692\n",
      "Epoch 34, batch 1: loss = 0.009734\n",
      "Epoch 34, batch 2: loss = 0.008998\n",
      "Epoch 34, batch 3: loss = 0.009445\n",
      "Epoch 34, batch 4: loss = 0.009617\n",
      "Epoch 34, batch 5: loss = 0.009590\n",
      "Epoch 34, batch 6: loss = 0.009659\n",
      "Epoch 34, batch 7: loss = 0.009433\n",
      "Epoch 34, batch 8: loss = 0.009310\n",
      "Epoch 34, batch 9: loss = 0.009484\n",
      "Epoch 34, batch 10: loss = 0.009595\n",
      "Epoch 34, batch 11: loss = 0.009383\n",
      "Epoch 34, batch 12: loss = 0.009729\n",
      "Epoch 34, batch 13: loss = 0.010402\n",
      "Epoch 34, batch 14: loss = 0.009060\n",
      "Epoch 34, batch 15: loss = 0.009072\n",
      "Epoch 34, batch 16: loss = 0.009490\n",
      "Epoch 34, batch 17: loss = 0.009710\n",
      "Epoch 34, batch 18: loss = 0.009356\n",
      "Epoch 34, batch 19: loss = 0.010044\n",
      "Epoch 34, batch 20: loss = 0.009466\n",
      "Epoch 34, batch 21: loss = 0.009945\n",
      "Epoch 34, batch 22: loss = 0.009986\n",
      "Epoch 34, batch 23: loss = 0.009274\n",
      "Epoch 34, batch 24: loss = 0.009668\n",
      "Epoch 34, batch 25: loss = 0.009930\n",
      "Epoch 34, batch 26: loss = 0.009906\n",
      "Epoch 34, batch 27: loss = 0.009189\n",
      "Epoch 34, batch 28: loss = 0.009313\n",
      "Epoch 34, batch 29: loss = 0.009784\n",
      "Epoch 34, batch 30: loss = 0.009089\n",
      "Epoch 34, batch 31: loss = 0.009632\n",
      "Epoch 34, batch 32: loss = 0.009611\n",
      "Epoch 34, batch 33: loss = 0.009920\n",
      "Epoch 34, batch 34: loss = 0.009549\n",
      "Epoch 34, batch 35: loss = 0.009090\n",
      "Epoch 34, batch 36: loss = 0.009047\n",
      "Epoch 34, batch 37: loss = 0.009100\n",
      "Epoch 34, batch 38: loss = 0.009836\n",
      "Epoch 34, batch 39: loss = 0.009456\n",
      "Epoch 34, batch 40: loss = 0.009617\n",
      "Epoch 34, batch 41: loss = 0.008881\n",
      "Epoch 34, batch 42: loss = 0.009156\n",
      "Epoch 34, batch 43: loss = 0.010043\n",
      "Epoch 34, batch 44: loss = 0.008772\n",
      "Epoch 34, batch 45: loss = 0.009456\n",
      "Epoch 34, batch 46: loss = 0.009247\n",
      "Epoch 34, batch 47: loss = 0.009566\n",
      "Epoch 34, batch 48: loss = 0.009351\n",
      "Epoch 34, batch 49: loss = 0.009401\n",
      "Epoch 34, batch 50: loss = 0.009480\n",
      "Epoch 34, batch 51: loss = 0.009703\n",
      "Epoch 34, batch 52: loss = 0.009385\n",
      "Epoch 34, batch 53: loss = 0.010164\n",
      "Epoch 34, batch 54: loss = 0.009572\n",
      "Epoch 34, batch 55: loss = 0.009319\n",
      "Epoch 34, batch 56: loss = 0.009171\n",
      "Epoch 34, batch 57: loss = 0.009205\n",
      "Epoch 34, batch 58: loss = 0.009449\n",
      "Epoch 34, batch 59: loss = 0.009357\n",
      "Epoch 34, batch 60: loss = 0.009275\n",
      "Epoch 34, batch 61: loss = 0.009418\n",
      "Epoch 34, batch 62: loss = 0.009403\n",
      "Epoch 34, batch 63: loss = 0.009239\n",
      "Epoch 34, batch 64: loss = 0.009563\n",
      "Epoch 34, batch 65: loss = 0.009743\n",
      "Epoch 34, batch 66: loss = 0.009166\n",
      "Epoch 34, batch 67: loss = 0.010001\n",
      "Epoch 34, batch 68: loss = 0.008722\n",
      "Epoch 34, batch 69: loss = 0.009083\n",
      "Epoch 34, batch 70: loss = 0.009302\n",
      "Epoch 34, batch 71: loss = 0.009596\n",
      "Epoch 34, batch 72: loss = 0.009673\n",
      "Epoch 34, batch 73: loss = 0.009814\n",
      "Epoch 34, batch 74: loss = 0.010017\n",
      "Epoch 34, batch 75: loss = 0.009277\n",
      "Epoch 34, batch 76: loss = 0.009511\n",
      "Epoch 34, batch 77: loss = 0.010211\n",
      "Epoch 34, batch 78: loss = 0.009029\n",
      "Epoch 34, batch 79: loss = 0.009204\n",
      "Epoch 34, batch 80: loss = 0.009234\n",
      "Epoch 34, batch 81: loss = 0.009866\n",
      "Epoch 34, batch 82: loss = 0.010985\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 34: val_loss = 0.035392\n",
      "Epoch 35, batch 0: loss = 0.009542\n",
      "Epoch 35, batch 1: loss = 0.010009\n",
      "Epoch 35, batch 2: loss = 0.008957\n",
      "Epoch 35, batch 3: loss = 0.009909\n",
      "Epoch 35, batch 4: loss = 0.008989\n",
      "Epoch 35, batch 5: loss = 0.009927\n",
      "Epoch 35, batch 6: loss = 0.010042\n",
      "Epoch 35, batch 7: loss = 0.010242\n",
      "Epoch 35, batch 8: loss = 0.009759\n",
      "Epoch 35, batch 9: loss = 0.010473\n",
      "Epoch 35, batch 10: loss = 0.009947\n",
      "Epoch 35, batch 11: loss = 0.009177\n",
      "Epoch 35, batch 12: loss = 0.010143\n",
      "Epoch 35, batch 13: loss = 0.010033\n",
      "Epoch 35, batch 14: loss = 0.009019\n",
      "Epoch 35, batch 15: loss = 0.009430\n",
      "Epoch 35, batch 16: loss = 0.010038\n",
      "Epoch 35, batch 17: loss = 0.008890\n",
      "Epoch 35, batch 18: loss = 0.009672\n",
      "Epoch 35, batch 19: loss = 0.009807\n",
      "Epoch 35, batch 20: loss = 0.009613\n",
      "Epoch 35, batch 21: loss = 0.009156\n",
      "Epoch 35, batch 22: loss = 0.010235\n",
      "Epoch 35, batch 23: loss = 0.010156\n",
      "Epoch 35, batch 24: loss = 0.009854\n",
      "Epoch 35, batch 25: loss = 0.009386\n",
      "Epoch 35, batch 26: loss = 0.009868\n",
      "Epoch 35, batch 27: loss = 0.009568\n",
      "Epoch 35, batch 28: loss = 0.009573\n",
      "Epoch 35, batch 29: loss = 0.009511\n",
      "Epoch 35, batch 30: loss = 0.010448\n",
      "Epoch 35, batch 31: loss = 0.009757\n",
      "Epoch 35, batch 32: loss = 0.009330\n",
      "Epoch 35, batch 33: loss = 0.009904\n",
      "Epoch 35, batch 34: loss = 0.009820\n",
      "Epoch 35, batch 35: loss = 0.008575\n",
      "Epoch 35, batch 36: loss = 0.009302\n",
      "Epoch 35, batch 37: loss = 0.010347\n",
      "Epoch 35, batch 38: loss = 0.009158\n",
      "Epoch 35, batch 39: loss = 0.009580\n",
      "Epoch 35, batch 40: loss = 0.009154\n",
      "Epoch 35, batch 41: loss = 0.009070\n",
      "Epoch 35, batch 42: loss = 0.008907\n",
      "Epoch 35, batch 43: loss = 0.009361\n",
      "Epoch 35, batch 44: loss = 0.009597\n",
      "Epoch 35, batch 45: loss = 0.009206\n",
      "Epoch 35, batch 46: loss = 0.008968\n",
      "Epoch 35, batch 47: loss = 0.009259\n",
      "Epoch 35, batch 48: loss = 0.009645\n",
      "Epoch 35, batch 49: loss = 0.009067\n",
      "Epoch 35, batch 50: loss = 0.009499\n",
      "Epoch 35, batch 51: loss = 0.008925\n",
      "Epoch 35, batch 52: loss = 0.009312\n",
      "Epoch 35, batch 53: loss = 0.009258\n",
      "Epoch 35, batch 54: loss = 0.009796\n",
      "Epoch 35, batch 55: loss = 0.009458\n",
      "Epoch 35, batch 56: loss = 0.009238\n",
      "Epoch 35, batch 57: loss = 0.009006\n",
      "Epoch 35, batch 58: loss = 0.009101\n",
      "Epoch 35, batch 59: loss = 0.009912\n",
      "Epoch 35, batch 60: loss = 0.008588\n",
      "Epoch 35, batch 61: loss = 0.009555\n",
      "Epoch 35, batch 62: loss = 0.009512\n",
      "Epoch 35, batch 63: loss = 0.008446\n",
      "Epoch 35, batch 64: loss = 0.009461\n",
      "Epoch 35, batch 65: loss = 0.009508\n",
      "Epoch 35, batch 66: loss = 0.008909\n",
      "Epoch 35, batch 67: loss = 0.009003\n",
      "Epoch 35, batch 68: loss = 0.008576\n",
      "Epoch 35, batch 69: loss = 0.009406\n",
      "Epoch 35, batch 70: loss = 0.009410\n",
      "Epoch 35, batch 71: loss = 0.008977\n",
      "Epoch 35, batch 72: loss = 0.008866\n",
      "Epoch 35, batch 73: loss = 0.009179\n",
      "Epoch 35, batch 74: loss = 0.009785\n",
      "Epoch 35, batch 75: loss = 0.009362\n",
      "Epoch 35, batch 76: loss = 0.008879\n",
      "Epoch 35, batch 77: loss = 0.009272\n",
      "Epoch 35, batch 78: loss = 0.009235\n",
      "Epoch 35, batch 79: loss = 0.008774\n",
      "Epoch 35, batch 80: loss = 0.009455\n",
      "Epoch 35, batch 81: loss = 0.009390\n",
      "Epoch 35, batch 82: loss = 0.010303\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 35: val_loss = 0.035133\n",
      "Epoch 36, batch 0: loss = 0.009303\n",
      "Epoch 36, batch 1: loss = 0.009884\n",
      "Epoch 36, batch 2: loss = 0.009545\n",
      "Epoch 36, batch 3: loss = 0.010025\n",
      "Epoch 36, batch 4: loss = 0.009089\n",
      "Epoch 36, batch 5: loss = 0.010103\n",
      "Epoch 36, batch 6: loss = 0.009382\n",
      "Epoch 36, batch 7: loss = 0.009091\n",
      "Epoch 36, batch 8: loss = 0.010112\n",
      "Epoch 36, batch 9: loss = 0.009871\n",
      "Epoch 36, batch 10: loss = 0.009988\n",
      "Epoch 36, batch 11: loss = 0.009518\n",
      "Epoch 36, batch 12: loss = 0.009847\n",
      "Epoch 36, batch 13: loss = 0.009936\n",
      "Epoch 36, batch 14: loss = 0.009544\n",
      "Epoch 36, batch 15: loss = 0.009262\n",
      "Epoch 36, batch 16: loss = 0.009542\n",
      "Epoch 36, batch 17: loss = 0.009143\n",
      "Epoch 36, batch 18: loss = 0.009186\n",
      "Epoch 36, batch 19: loss = 0.009158\n",
      "Epoch 36, batch 20: loss = 0.008945\n",
      "Epoch 36, batch 21: loss = 0.009167\n",
      "Epoch 36, batch 22: loss = 0.009581\n",
      "Epoch 36, batch 23: loss = 0.009843\n",
      "Epoch 36, batch 24: loss = 0.009149\n",
      "Epoch 36, batch 25: loss = 0.008943\n",
      "Epoch 36, batch 26: loss = 0.008999\n",
      "Epoch 36, batch 27: loss = 0.010425\n",
      "Epoch 36, batch 28: loss = 0.009460\n",
      "Epoch 36, batch 29: loss = 0.008971\n",
      "Epoch 36, batch 30: loss = 0.009862\n",
      "Epoch 36, batch 31: loss = 0.009222\n",
      "Epoch 36, batch 32: loss = 0.010050\n",
      "Epoch 36, batch 33: loss = 0.008903\n",
      "Epoch 36, batch 34: loss = 0.009957\n",
      "Epoch 36, batch 35: loss = 0.009207\n",
      "Epoch 36, batch 36: loss = 0.010054\n",
      "Epoch 36, batch 37: loss = 0.009324\n",
      "Epoch 36, batch 38: loss = 0.009077\n",
      "Epoch 36, batch 39: loss = 0.009125\n",
      "Epoch 36, batch 40: loss = 0.008878\n",
      "Epoch 36, batch 41: loss = 0.008719\n",
      "Epoch 36, batch 42: loss = 0.009332\n",
      "Epoch 36, batch 43: loss = 0.009631\n",
      "Epoch 36, batch 44: loss = 0.008992\n",
      "Epoch 36, batch 45: loss = 0.008892\n",
      "Epoch 36, batch 46: loss = 0.009102\n",
      "Epoch 36, batch 47: loss = 0.009610\n",
      "Epoch 36, batch 48: loss = 0.009295\n",
      "Epoch 36, batch 49: loss = 0.008613\n",
      "Epoch 36, batch 50: loss = 0.008875\n",
      "Epoch 36, batch 51: loss = 0.009041\n",
      "Epoch 36, batch 52: loss = 0.009282\n",
      "Epoch 36, batch 53: loss = 0.010109\n",
      "Epoch 36, batch 54: loss = 0.008550\n",
      "Epoch 36, batch 55: loss = 0.008998\n",
      "Epoch 36, batch 56: loss = 0.008591\n",
      "Epoch 36, batch 57: loss = 0.008848\n",
      "Epoch 36, batch 58: loss = 0.009265\n",
      "Epoch 36, batch 59: loss = 0.009769\n",
      "Epoch 36, batch 60: loss = 0.009692\n",
      "Epoch 36, batch 61: loss = 0.008653\n",
      "Epoch 36, batch 62: loss = 0.008779\n",
      "Epoch 36, batch 63: loss = 0.008838\n",
      "Epoch 36, batch 64: loss = 0.009240\n",
      "Epoch 36, batch 65: loss = 0.008640\n",
      "Epoch 36, batch 66: loss = 0.008773\n",
      "Epoch 36, batch 67: loss = 0.009470\n",
      "Epoch 36, batch 68: loss = 0.009308\n",
      "Epoch 36, batch 69: loss = 0.009323\n",
      "Epoch 36, batch 70: loss = 0.009346\n",
      "Epoch 36, batch 71: loss = 0.008976\n",
      "Epoch 36, batch 72: loss = 0.009725\n",
      "Epoch 36, batch 73: loss = 0.009175\n",
      "Epoch 36, batch 74: loss = 0.009328\n",
      "Epoch 36, batch 75: loss = 0.008572\n",
      "Epoch 36, batch 76: loss = 0.008948\n",
      "Epoch 36, batch 77: loss = 0.009473\n",
      "Epoch 36, batch 78: loss = 0.009036\n",
      "Epoch 36, batch 79: loss = 0.009242\n",
      "Epoch 36, batch 80: loss = 0.009673\n",
      "Epoch 36, batch 81: loss = 0.009092\n",
      "Epoch 36, batch 82: loss = 0.014284\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 36: val_loss = 0.034408\n",
      "Epoch 37, batch 0: loss = 0.010489\n",
      "Epoch 37, batch 1: loss = 0.009245\n",
      "Epoch 37, batch 2: loss = 0.009912\n",
      "Epoch 37, batch 3: loss = 0.009975\n",
      "Epoch 37, batch 4: loss = 0.009869\n",
      "Epoch 37, batch 5: loss = 0.009544\n",
      "Epoch 37, batch 6: loss = 0.009549\n",
      "Epoch 37, batch 7: loss = 0.009603\n",
      "Epoch 37, batch 8: loss = 0.008960\n",
      "Epoch 37, batch 9: loss = 0.009786\n",
      "Epoch 37, batch 10: loss = 0.009411\n",
      "Epoch 37, batch 11: loss = 0.009104\n",
      "Epoch 37, batch 12: loss = 0.009685\n",
      "Epoch 37, batch 13: loss = 0.009967\n",
      "Epoch 37, batch 14: loss = 0.009461\n",
      "Epoch 37, batch 15: loss = 0.009312\n",
      "Epoch 37, batch 16: loss = 0.009468\n",
      "Epoch 37, batch 17: loss = 0.009294\n",
      "Epoch 37, batch 18: loss = 0.008700\n",
      "Epoch 37, batch 19: loss = 0.009582\n",
      "Epoch 37, batch 20: loss = 0.008629\n",
      "Epoch 37, batch 21: loss = 0.009153\n",
      "Epoch 37, batch 22: loss = 0.009856\n",
      "Epoch 37, batch 23: loss = 0.009285\n",
      "Epoch 37, batch 24: loss = 0.009181\n",
      "Epoch 37, batch 25: loss = 0.009254\n",
      "Epoch 37, batch 26: loss = 0.009370\n",
      "Epoch 37, batch 27: loss = 0.009254\n",
      "Epoch 37, batch 28: loss = 0.009337\n",
      "Epoch 37, batch 29: loss = 0.008538\n",
      "Epoch 37, batch 30: loss = 0.009301\n",
      "Epoch 37, batch 31: loss = 0.009445\n",
      "Epoch 37, batch 32: loss = 0.009351\n",
      "Epoch 37, batch 33: loss = 0.008844\n",
      "Epoch 37, batch 34: loss = 0.008754\n",
      "Epoch 37, batch 35: loss = 0.009537\n",
      "Epoch 37, batch 36: loss = 0.008843\n",
      "Epoch 37, batch 37: loss = 0.009197\n",
      "Epoch 37, batch 38: loss = 0.009634\n",
      "Epoch 37, batch 39: loss = 0.009471\n",
      "Epoch 37, batch 40: loss = 0.009558\n",
      "Epoch 37, batch 41: loss = 0.010003\n",
      "Epoch 37, batch 42: loss = 0.009443\n",
      "Epoch 37, batch 43: loss = 0.008806\n",
      "Epoch 37, batch 44: loss = 0.009867\n",
      "Epoch 37, batch 45: loss = 0.009057\n",
      "Epoch 37, batch 46: loss = 0.008962\n",
      "Epoch 37, batch 47: loss = 0.009553\n",
      "Epoch 37, batch 48: loss = 0.009928\n",
      "Epoch 37, batch 49: loss = 0.009349\n",
      "Epoch 37, batch 50: loss = 0.009385\n",
      "Epoch 37, batch 51: loss = 0.009079\n",
      "Epoch 37, batch 52: loss = 0.008715\n",
      "Epoch 37, batch 53: loss = 0.009053\n",
      "Epoch 37, batch 54: loss = 0.009906\n",
      "Epoch 37, batch 55: loss = 0.008578\n",
      "Epoch 37, batch 56: loss = 0.009563\n",
      "Epoch 37, batch 57: loss = 0.009342\n",
      "Epoch 37, batch 58: loss = 0.009486\n",
      "Epoch 37, batch 59: loss = 0.009510\n",
      "Epoch 37, batch 60: loss = 0.008737\n",
      "Epoch 37, batch 61: loss = 0.009350\n",
      "Epoch 37, batch 62: loss = 0.009419\n",
      "Epoch 37, batch 63: loss = 0.009596\n",
      "Epoch 37, batch 64: loss = 0.009192\n",
      "Epoch 37, batch 65: loss = 0.008904\n",
      "Epoch 37, batch 66: loss = 0.009035\n",
      "Epoch 37, batch 67: loss = 0.009434\n",
      "Epoch 37, batch 68: loss = 0.008850\n",
      "Epoch 37, batch 69: loss = 0.010085\n",
      "Epoch 37, batch 70: loss = 0.008993\n",
      "Epoch 37, batch 71: loss = 0.009009\n",
      "Epoch 37, batch 72: loss = 0.009668\n",
      "Epoch 37, batch 73: loss = 0.008987\n",
      "Epoch 37, batch 74: loss = 0.008590\n",
      "Epoch 37, batch 75: loss = 0.009771\n",
      "Epoch 37, batch 76: loss = 0.009699\n",
      "Epoch 37, batch 77: loss = 0.009682\n",
      "Epoch 37, batch 78: loss = 0.008751\n",
      "Epoch 37, batch 79: loss = 0.009385\n",
      "Epoch 37, batch 80: loss = 0.008944\n",
      "Epoch 37, batch 81: loss = 0.009823\n",
      "Epoch 37, batch 82: loss = 0.009852\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 37: val_loss = 0.034421\n",
      "Epoch 38, batch 0: loss = 0.009767\n",
      "Epoch 38, batch 1: loss = 0.009139\n",
      "Epoch 38, batch 2: loss = 0.009263\n",
      "Epoch 38, batch 3: loss = 0.008477\n",
      "Epoch 38, batch 4: loss = 0.008630\n",
      "Epoch 38, batch 5: loss = 0.009405\n",
      "Epoch 38, batch 6: loss = 0.010055\n",
      "Epoch 38, batch 7: loss = 0.009108\n",
      "Epoch 38, batch 8: loss = 0.008968\n",
      "Epoch 38, batch 9: loss = 0.009024\n",
      "Epoch 38, batch 10: loss = 0.008868\n",
      "Epoch 38, batch 11: loss = 0.008813\n",
      "Epoch 38, batch 12: loss = 0.009209\n",
      "Epoch 38, batch 13: loss = 0.009277\n",
      "Epoch 38, batch 14: loss = 0.008994\n",
      "Epoch 38, batch 15: loss = 0.008950\n",
      "Epoch 38, batch 16: loss = 0.009845\n",
      "Epoch 38, batch 17: loss = 0.009700\n",
      "Epoch 38, batch 18: loss = 0.009070\n",
      "Epoch 38, batch 19: loss = 0.008816\n",
      "Epoch 38, batch 20: loss = 0.008965\n",
      "Epoch 38, batch 21: loss = 0.008544\n",
      "Epoch 38, batch 22: loss = 0.008891\n",
      "Epoch 38, batch 23: loss = 0.009140\n",
      "Epoch 38, batch 24: loss = 0.008213\n",
      "Epoch 38, batch 25: loss = 0.009109\n",
      "Epoch 38, batch 26: loss = 0.009206\n",
      "Epoch 38, batch 27: loss = 0.009503\n",
      "Epoch 38, batch 28: loss = 0.009414\n",
      "Epoch 38, batch 29: loss = 0.008944\n",
      "Epoch 38, batch 30: loss = 0.009000\n",
      "Epoch 38, batch 31: loss = 0.008986\n",
      "Epoch 38, batch 32: loss = 0.008883\n",
      "Epoch 38, batch 33: loss = 0.009140\n",
      "Epoch 38, batch 34: loss = 0.009048\n",
      "Epoch 38, batch 35: loss = 0.009423\n",
      "Epoch 38, batch 36: loss = 0.009982\n",
      "Epoch 38, batch 37: loss = 0.009274\n",
      "Epoch 38, batch 38: loss = 0.009333\n",
      "Epoch 38, batch 39: loss = 0.009150\n",
      "Epoch 38, batch 40: loss = 0.009290\n",
      "Epoch 38, batch 41: loss = 0.009627\n",
      "Epoch 38, batch 42: loss = 0.008302\n",
      "Epoch 38, batch 43: loss = 0.009095\n",
      "Epoch 38, batch 44: loss = 0.009131\n",
      "Epoch 38, batch 45: loss = 0.009264\n",
      "Epoch 38, batch 46: loss = 0.009075\n",
      "Epoch 38, batch 47: loss = 0.009254\n",
      "Epoch 38, batch 48: loss = 0.008900\n",
      "Epoch 38, batch 49: loss = 0.008976\n",
      "Epoch 38, batch 50: loss = 0.008486\n",
      "Epoch 38, batch 51: loss = 0.008989\n",
      "Epoch 38, batch 52: loss = 0.008936\n",
      "Epoch 38, batch 53: loss = 0.009147\n",
      "Epoch 38, batch 54: loss = 0.008652\n",
      "Epoch 38, batch 55: loss = 0.009799\n",
      "Epoch 38, batch 56: loss = 0.009756\n",
      "Epoch 38, batch 57: loss = 0.009306\n",
      "Epoch 38, batch 58: loss = 0.008988\n",
      "Epoch 38, batch 59: loss = 0.009003\n",
      "Epoch 38, batch 60: loss = 0.008889\n",
      "Epoch 38, batch 61: loss = 0.009039\n",
      "Epoch 38, batch 62: loss = 0.009543\n",
      "Epoch 38, batch 63: loss = 0.009533\n",
      "Epoch 38, batch 64: loss = 0.009051\n",
      "Epoch 38, batch 65: loss = 0.008971\n",
      "Epoch 38, batch 66: loss = 0.009024\n",
      "Epoch 38, batch 67: loss = 0.008552\n",
      "Epoch 38, batch 68: loss = 0.008922\n",
      "Epoch 38, batch 69: loss = 0.009582\n",
      "Epoch 38, batch 70: loss = 0.008691\n",
      "Epoch 38, batch 71: loss = 0.008502\n",
      "Epoch 38, batch 72: loss = 0.008667\n",
      "Epoch 38, batch 73: loss = 0.009036\n",
      "Epoch 38, batch 74: loss = 0.008924\n",
      "Epoch 38, batch 75: loss = 0.009489\n",
      "Epoch 38, batch 76: loss = 0.008632\n",
      "Epoch 38, batch 77: loss = 0.008908\n",
      "Epoch 38, batch 78: loss = 0.008958\n",
      "Epoch 38, batch 79: loss = 0.009134\n",
      "Epoch 38, batch 80: loss = 0.009003\n",
      "Epoch 38, batch 81: loss = 0.008934\n",
      "Epoch 38, batch 82: loss = 0.011837\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 38: val_loss = 0.034104\n",
      "Epoch 39, batch 0: loss = 0.009225\n",
      "Epoch 39, batch 1: loss = 0.008841\n",
      "Epoch 39, batch 2: loss = 0.009397\n",
      "Epoch 39, batch 3: loss = 0.009386\n",
      "Epoch 39, batch 4: loss = 0.009872\n",
      "Epoch 39, batch 5: loss = 0.009202\n",
      "Epoch 39, batch 6: loss = 0.009204\n",
      "Epoch 39, batch 7: loss = 0.009686\n",
      "Epoch 39, batch 8: loss = 0.008855\n",
      "Epoch 39, batch 9: loss = 0.008771\n",
      "Epoch 39, batch 10: loss = 0.008700\n",
      "Epoch 39, batch 11: loss = 0.009320\n",
      "Epoch 39, batch 12: loss = 0.008891\n",
      "Epoch 39, batch 13: loss = 0.009243\n",
      "Epoch 39, batch 14: loss = 0.008722\n",
      "Epoch 39, batch 15: loss = 0.008965\n",
      "Epoch 39, batch 16: loss = 0.008806\n",
      "Epoch 39, batch 17: loss = 0.008570\n",
      "Epoch 39, batch 18: loss = 0.009290\n",
      "Epoch 39, batch 19: loss = 0.009308\n",
      "Epoch 39, batch 20: loss = 0.009197\n",
      "Epoch 39, batch 21: loss = 0.008638\n",
      "Epoch 39, batch 22: loss = 0.008928\n",
      "Epoch 39, batch 23: loss = 0.009152\n",
      "Epoch 39, batch 24: loss = 0.008538\n",
      "Epoch 39, batch 25: loss = 0.009086\n",
      "Epoch 39, batch 26: loss = 0.008876\n",
      "Epoch 39, batch 27: loss = 0.008564\n",
      "Epoch 39, batch 28: loss = 0.008674\n",
      "Epoch 39, batch 29: loss = 0.008770\n",
      "Epoch 39, batch 30: loss = 0.009099\n",
      "Epoch 39, batch 31: loss = 0.009558\n",
      "Epoch 39, batch 32: loss = 0.008916\n",
      "Epoch 39, batch 33: loss = 0.009196\n",
      "Epoch 39, batch 34: loss = 0.008832\n",
      "Epoch 39, batch 35: loss = 0.008332\n",
      "Epoch 39, batch 36: loss = 0.008293\n",
      "Epoch 39, batch 37: loss = 0.009300\n",
      "Epoch 39, batch 38: loss = 0.008863\n",
      "Epoch 39, batch 39: loss = 0.009767\n",
      "Epoch 39, batch 40: loss = 0.008690\n",
      "Epoch 39, batch 41: loss = 0.009069\n",
      "Epoch 39, batch 42: loss = 0.009211\n",
      "Epoch 39, batch 43: loss = 0.009279\n",
      "Epoch 39, batch 44: loss = 0.008639\n",
      "Epoch 39, batch 45: loss = 0.008423\n",
      "Epoch 39, batch 46: loss = 0.008484\n",
      "Epoch 39, batch 47: loss = 0.008809\n",
      "Epoch 39, batch 48: loss = 0.009296\n",
      "Epoch 39, batch 49: loss = 0.008568\n",
      "Epoch 39, batch 50: loss = 0.008707\n",
      "Epoch 39, batch 51: loss = 0.008632\n",
      "Epoch 39, batch 52: loss = 0.009652\n",
      "Epoch 39, batch 53: loss = 0.008844\n",
      "Epoch 39, batch 54: loss = 0.008579\n",
      "Epoch 39, batch 55: loss = 0.008944\n",
      "Epoch 39, batch 56: loss = 0.008933\n",
      "Epoch 39, batch 57: loss = 0.009331\n",
      "Epoch 39, batch 58: loss = 0.009103\n",
      "Epoch 39, batch 59: loss = 0.008587\n",
      "Epoch 39, batch 60: loss = 0.009793\n",
      "Epoch 39, batch 61: loss = 0.009685\n",
      "Epoch 39, batch 62: loss = 0.008975\n",
      "Epoch 39, batch 63: loss = 0.008619\n",
      "Epoch 39, batch 64: loss = 0.008745\n",
      "Epoch 39, batch 65: loss = 0.008406\n",
      "Epoch 39, batch 66: loss = 0.008761\n",
      "Epoch 39, batch 67: loss = 0.009363\n",
      "Epoch 39, batch 68: loss = 0.008348\n",
      "Epoch 39, batch 69: loss = 0.008679\n",
      "Epoch 39, batch 70: loss = 0.008764\n",
      "Epoch 39, batch 71: loss = 0.008861\n",
      "Epoch 39, batch 72: loss = 0.008458\n",
      "Epoch 39, batch 73: loss = 0.008713\n",
      "Epoch 39, batch 74: loss = 0.010037\n",
      "Epoch 39, batch 75: loss = 0.008852\n",
      "Epoch 39, batch 76: loss = 0.008985\n",
      "Epoch 39, batch 77: loss = 0.009134\n",
      "Epoch 39, batch 78: loss = 0.008852\n",
      "Epoch 39, batch 79: loss = 0.009172\n",
      "Epoch 39, batch 80: loss = 0.009648\n",
      "Epoch 39, batch 81: loss = 0.008547\n",
      "Epoch 39, batch 82: loss = 0.005866\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 39: val_loss = 0.033657\n",
      "Epoch 40, batch 0: loss = 0.009178\n",
      "Epoch 40, batch 1: loss = 0.009117\n",
      "Epoch 40, batch 2: loss = 0.009078\n",
      "Epoch 40, batch 3: loss = 0.008935\n",
      "Epoch 40, batch 4: loss = 0.008840\n",
      "Epoch 40, batch 5: loss = 0.008773\n",
      "Epoch 40, batch 6: loss = 0.009375\n",
      "Epoch 40, batch 7: loss = 0.009783\n",
      "Epoch 40, batch 8: loss = 0.009855\n",
      "Epoch 40, batch 9: loss = 0.009224\n",
      "Epoch 40, batch 10: loss = 0.008640\n",
      "Epoch 40, batch 11: loss = 0.008642\n",
      "Epoch 40, batch 12: loss = 0.009497\n",
      "Epoch 40, batch 13: loss = 0.009131\n",
      "Epoch 40, batch 14: loss = 0.008746\n",
      "Epoch 40, batch 15: loss = 0.008710\n",
      "Epoch 40, batch 16: loss = 0.008690\n",
      "Epoch 40, batch 17: loss = 0.008529\n",
      "Epoch 40, batch 18: loss = 0.008690\n",
      "Epoch 40, batch 19: loss = 0.009023\n",
      "Epoch 40, batch 20: loss = 0.008759\n",
      "Epoch 40, batch 21: loss = 0.009335\n",
      "Epoch 40, batch 22: loss = 0.008263\n",
      "Epoch 40, batch 23: loss = 0.008962\n",
      "Epoch 40, batch 24: loss = 0.009207\n",
      "Epoch 40, batch 25: loss = 0.009908\n",
      "Epoch 40, batch 26: loss = 0.009021\n",
      "Epoch 40, batch 27: loss = 0.008767\n",
      "Epoch 40, batch 28: loss = 0.008887\n",
      "Epoch 40, batch 29: loss = 0.008607\n",
      "Epoch 40, batch 30: loss = 0.009346\n",
      "Epoch 40, batch 31: loss = 0.009208\n",
      "Epoch 40, batch 32: loss = 0.008628\n",
      "Epoch 40, batch 33: loss = 0.009140\n",
      "Epoch 40, batch 34: loss = 0.009045\n",
      "Epoch 40, batch 35: loss = 0.009098\n",
      "Epoch 40, batch 36: loss = 0.008685\n",
      "Epoch 40, batch 37: loss = 0.008516\n",
      "Epoch 40, batch 38: loss = 0.009125\n",
      "Epoch 40, batch 39: loss = 0.008703\n",
      "Epoch 40, batch 40: loss = 0.008743\n",
      "Epoch 40, batch 41: loss = 0.008615\n",
      "Epoch 40, batch 42: loss = 0.008673\n",
      "Epoch 40, batch 43: loss = 0.008791\n",
      "Epoch 40, batch 44: loss = 0.009728\n",
      "Epoch 40, batch 45: loss = 0.009048\n",
      "Epoch 40, batch 46: loss = 0.009758\n",
      "Epoch 40, batch 47: loss = 0.008749\n",
      "Epoch 40, batch 48: loss = 0.009070\n",
      "Epoch 40, batch 49: loss = 0.008978\n",
      "Epoch 40, batch 50: loss = 0.008844\n",
      "Epoch 40, batch 51: loss = 0.008550\n",
      "Epoch 40, batch 52: loss = 0.008046\n",
      "Epoch 40, batch 53: loss = 0.008165\n",
      "Epoch 40, batch 54: loss = 0.009010\n",
      "Epoch 40, batch 55: loss = 0.009145\n",
      "Epoch 40, batch 56: loss = 0.008267\n",
      "Epoch 40, batch 57: loss = 0.009335\n",
      "Epoch 40, batch 58: loss = 0.008504\n",
      "Epoch 40, batch 59: loss = 0.008598\n",
      "Epoch 40, batch 60: loss = 0.009015\n",
      "Epoch 40, batch 61: loss = 0.008580\n",
      "Epoch 40, batch 62: loss = 0.008394\n",
      "Epoch 40, batch 63: loss = 0.009073\n",
      "Epoch 40, batch 64: loss = 0.008698\n",
      "Epoch 40, batch 65: loss = 0.007844\n",
      "Epoch 40, batch 66: loss = 0.008642\n",
      "Epoch 40, batch 67: loss = 0.008533\n",
      "Epoch 40, batch 68: loss = 0.009036\n",
      "Epoch 40, batch 69: loss = 0.008428\n",
      "Epoch 40, batch 70: loss = 0.008677\n",
      "Epoch 40, batch 71: loss = 0.008834\n",
      "Epoch 40, batch 72: loss = 0.008453\n",
      "Epoch 40, batch 73: loss = 0.008726\n",
      "Epoch 40, batch 74: loss = 0.008442\n",
      "Epoch 40, batch 75: loss = 0.009267\n",
      "Epoch 40, batch 76: loss = 0.009198\n",
      "Epoch 40, batch 77: loss = 0.008587\n",
      "Epoch 40, batch 78: loss = 0.008784\n",
      "Epoch 40, batch 79: loss = 0.008595\n",
      "Epoch 40, batch 80: loss = 0.009092\n",
      "Epoch 40, batch 81: loss = 0.008377\n",
      "Epoch 40, batch 82: loss = 0.007056\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 40: val_loss = 0.034284\n",
      "Epoch 41, batch 0: loss = 0.009280\n",
      "Epoch 41, batch 1: loss = 0.009023\n",
      "Epoch 41, batch 2: loss = 0.009142\n",
      "Epoch 41, batch 3: loss = 0.009519\n",
      "Epoch 41, batch 4: loss = 0.008391\n",
      "Epoch 41, batch 5: loss = 0.009146\n",
      "Epoch 41, batch 6: loss = 0.008943\n",
      "Epoch 41, batch 7: loss = 0.008909\n",
      "Epoch 41, batch 8: loss = 0.009103\n",
      "Epoch 41, batch 9: loss = 0.009058\n",
      "Epoch 41, batch 10: loss = 0.009016\n",
      "Epoch 41, batch 11: loss = 0.009258\n",
      "Epoch 41, batch 12: loss = 0.009103\n",
      "Epoch 41, batch 13: loss = 0.008634\n",
      "Epoch 41, batch 14: loss = 0.009054\n",
      "Epoch 41, batch 15: loss = 0.008529\n",
      "Epoch 41, batch 16: loss = 0.008554\n",
      "Epoch 41, batch 17: loss = 0.008977\n",
      "Epoch 41, batch 18: loss = 0.008597\n",
      "Epoch 41, batch 19: loss = 0.009086\n",
      "Epoch 41, batch 20: loss = 0.009106\n",
      "Epoch 41, batch 21: loss = 0.008873\n",
      "Epoch 41, batch 22: loss = 0.008863\n",
      "Epoch 41, batch 23: loss = 0.009188\n",
      "Epoch 41, batch 24: loss = 0.009420\n",
      "Epoch 41, batch 25: loss = 0.009732\n",
      "Epoch 41, batch 26: loss = 0.009512\n",
      "Epoch 41, batch 27: loss = 0.009374\n",
      "Epoch 41, batch 28: loss = 0.009160\n",
      "Epoch 41, batch 29: loss = 0.009239\n",
      "Epoch 41, batch 30: loss = 0.009688\n",
      "Epoch 41, batch 31: loss = 0.008852\n",
      "Epoch 41, batch 32: loss = 0.009321\n",
      "Epoch 41, batch 33: loss = 0.009452\n",
      "Epoch 41, batch 34: loss = 0.008912\n",
      "Epoch 41, batch 35: loss = 0.008851\n",
      "Epoch 41, batch 36: loss = 0.009041\n",
      "Epoch 41, batch 37: loss = 0.008753\n",
      "Epoch 41, batch 38: loss = 0.009147\n",
      "Epoch 41, batch 39: loss = 0.009387\n",
      "Epoch 41, batch 40: loss = 0.008618\n",
      "Epoch 41, batch 41: loss = 0.008368\n",
      "Epoch 41, batch 42: loss = 0.009266\n",
      "Epoch 41, batch 43: loss = 0.009724\n",
      "Epoch 41, batch 44: loss = 0.009186\n",
      "Epoch 41, batch 45: loss = 0.008508\n",
      "Epoch 41, batch 46: loss = 0.009129\n",
      "Epoch 41, batch 47: loss = 0.008672\n",
      "Epoch 41, batch 48: loss = 0.008972\n",
      "Epoch 41, batch 49: loss = 0.008951\n",
      "Epoch 41, batch 50: loss = 0.008621\n",
      "Epoch 41, batch 51: loss = 0.009240\n",
      "Epoch 41, batch 52: loss = 0.008760\n",
      "Epoch 41, batch 53: loss = 0.009382\n",
      "Epoch 41, batch 54: loss = 0.009422\n",
      "Epoch 41, batch 55: loss = 0.008787\n",
      "Epoch 41, batch 56: loss = 0.008841\n",
      "Epoch 41, batch 57: loss = 0.008913\n",
      "Epoch 41, batch 58: loss = 0.008770\n",
      "Epoch 41, batch 59: loss = 0.009274\n",
      "Epoch 41, batch 60: loss = 0.008705\n",
      "Epoch 41, batch 61: loss = 0.008726\n",
      "Epoch 41, batch 62: loss = 0.008835\n",
      "Epoch 41, batch 63: loss = 0.008633\n",
      "Epoch 41, batch 64: loss = 0.009145\n",
      "Epoch 41, batch 65: loss = 0.008852\n",
      "Epoch 41, batch 66: loss = 0.008926\n",
      "Epoch 41, batch 67: loss = 0.008809\n",
      "Epoch 41, batch 68: loss = 0.008458\n",
      "Epoch 41, batch 69: loss = 0.008925\n",
      "Epoch 41, batch 70: loss = 0.008839\n",
      "Epoch 41, batch 71: loss = 0.008725\n",
      "Epoch 41, batch 72: loss = 0.008767\n",
      "Epoch 41, batch 73: loss = 0.009139\n",
      "Epoch 41, batch 74: loss = 0.009422\n",
      "Epoch 41, batch 75: loss = 0.008122\n",
      "Epoch 41, batch 76: loss = 0.009284\n",
      "Epoch 41, batch 77: loss = 0.008280\n",
      "Epoch 41, batch 78: loss = 0.008451\n",
      "Epoch 41, batch 79: loss = 0.009092\n",
      "Epoch 41, batch 80: loss = 0.009158\n",
      "Epoch 41, batch 81: loss = 0.008516\n",
      "Epoch 41, batch 82: loss = 0.008662\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 41: val_loss = 0.034016\n",
      "Epoch 42, batch 0: loss = 0.008493\n",
      "Epoch 42, batch 1: loss = 0.008837\n",
      "Epoch 42, batch 2: loss = 0.008895\n",
      "Epoch 42, batch 3: loss = 0.008987\n",
      "Epoch 42, batch 4: loss = 0.008895\n",
      "Epoch 42, batch 5: loss = 0.008834\n",
      "Epoch 42, batch 6: loss = 0.008668\n",
      "Epoch 42, batch 7: loss = 0.009006\n",
      "Epoch 42, batch 8: loss = 0.008592\n",
      "Epoch 42, batch 9: loss = 0.009126\n",
      "Epoch 42, batch 10: loss = 0.008441\n",
      "Epoch 42, batch 11: loss = 0.008789\n",
      "Epoch 42, batch 12: loss = 0.008905\n",
      "Epoch 42, batch 13: loss = 0.008731\n",
      "Epoch 42, batch 14: loss = 0.008724\n",
      "Epoch 42, batch 15: loss = 0.008972\n",
      "Epoch 42, batch 16: loss = 0.008922\n",
      "Epoch 42, batch 17: loss = 0.008809\n",
      "Epoch 42, batch 18: loss = 0.008083\n",
      "Epoch 42, batch 19: loss = 0.009254\n",
      "Epoch 42, batch 20: loss = 0.009318\n",
      "Epoch 42, batch 21: loss = 0.008968\n",
      "Epoch 42, batch 22: loss = 0.008635\n",
      "Epoch 42, batch 23: loss = 0.008626\n",
      "Epoch 42, batch 24: loss = 0.008957\n",
      "Epoch 42, batch 25: loss = 0.008596\n",
      "Epoch 42, batch 26: loss = 0.008851\n",
      "Epoch 42, batch 27: loss = 0.008650\n",
      "Epoch 42, batch 28: loss = 0.008592\n",
      "Epoch 42, batch 29: loss = 0.008728\n",
      "Epoch 42, batch 30: loss = 0.008839\n",
      "Epoch 42, batch 31: loss = 0.008352\n",
      "Epoch 42, batch 32: loss = 0.008820\n",
      "Epoch 42, batch 33: loss = 0.008557\n",
      "Epoch 42, batch 34: loss = 0.008817\n",
      "Epoch 42, batch 35: loss = 0.009015\n",
      "Epoch 42, batch 36: loss = 0.008218\n",
      "Epoch 42, batch 37: loss = 0.008439\n",
      "Epoch 42, batch 38: loss = 0.008336\n",
      "Epoch 42, batch 39: loss = 0.008571\n",
      "Epoch 42, batch 40: loss = 0.008692\n",
      "Epoch 42, batch 41: loss = 0.008642\n",
      "Epoch 42, batch 42: loss = 0.008627\n",
      "Epoch 42, batch 43: loss = 0.008919\n",
      "Epoch 42, batch 44: loss = 0.008754\n",
      "Epoch 42, batch 45: loss = 0.008220\n",
      "Epoch 42, batch 46: loss = 0.008782\n",
      "Epoch 42, batch 47: loss = 0.008409\n",
      "Epoch 42, batch 48: loss = 0.008059\n",
      "Epoch 42, batch 49: loss = 0.008398\n",
      "Epoch 42, batch 50: loss = 0.008408\n",
      "Epoch 42, batch 51: loss = 0.008543\n",
      "Epoch 42, batch 52: loss = 0.008356\n",
      "Epoch 42, batch 53: loss = 0.008185\n",
      "Epoch 42, batch 54: loss = 0.008083\n",
      "Epoch 42, batch 55: loss = 0.008913\n",
      "Epoch 42, batch 56: loss = 0.008634\n",
      "Epoch 42, batch 57: loss = 0.008816\n",
      "Epoch 42, batch 58: loss = 0.009223\n",
      "Epoch 42, batch 59: loss = 0.008392\n",
      "Epoch 42, batch 60: loss = 0.008455\n",
      "Epoch 42, batch 61: loss = 0.009145\n",
      "Epoch 42, batch 62: loss = 0.008837\n",
      "Epoch 42, batch 63: loss = 0.008735\n",
      "Epoch 42, batch 64: loss = 0.008663\n",
      "Epoch 42, batch 65: loss = 0.008664\n",
      "Epoch 42, batch 66: loss = 0.008864\n",
      "Epoch 42, batch 67: loss = 0.008599\n",
      "Epoch 42, batch 68: loss = 0.008736\n",
      "Epoch 42, batch 69: loss = 0.008399\n",
      "Epoch 42, batch 70: loss = 0.008422\n",
      "Epoch 42, batch 71: loss = 0.008904\n",
      "Epoch 42, batch 72: loss = 0.008733\n",
      "Epoch 42, batch 73: loss = 0.008569\n",
      "Epoch 42, batch 74: loss = 0.008265\n",
      "Epoch 42, batch 75: loss = 0.008729\n",
      "Epoch 42, batch 76: loss = 0.008727\n",
      "Epoch 42, batch 77: loss = 0.009099\n",
      "Epoch 42, batch 78: loss = 0.008464\n",
      "Epoch 42, batch 79: loss = 0.008947\n",
      "Epoch 42, batch 80: loss = 0.009039\n",
      "Epoch 42, batch 81: loss = 0.009006\n",
      "Epoch 42, batch 82: loss = 0.009159\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 42: val_loss = 0.035315\n",
      "Epoch 43, batch 0: loss = 0.008165\n",
      "Epoch 43, batch 1: loss = 0.008821\n",
      "Epoch 43, batch 2: loss = 0.009131\n",
      "Epoch 43, batch 3: loss = 0.008773\n",
      "Epoch 43, batch 4: loss = 0.008783\n",
      "Epoch 43, batch 5: loss = 0.008682\n",
      "Epoch 43, batch 6: loss = 0.009197\n",
      "Epoch 43, batch 7: loss = 0.008675\n",
      "Epoch 43, batch 8: loss = 0.008960\n",
      "Epoch 43, batch 9: loss = 0.008968\n",
      "Epoch 43, batch 10: loss = 0.009093\n",
      "Epoch 43, batch 11: loss = 0.009473\n",
      "Epoch 43, batch 12: loss = 0.009171\n",
      "Epoch 43, batch 13: loss = 0.008274\n",
      "Epoch 43, batch 14: loss = 0.008545\n",
      "Epoch 43, batch 15: loss = 0.009749\n",
      "Epoch 43, batch 16: loss = 0.008820\n",
      "Epoch 43, batch 17: loss = 0.009203\n",
      "Epoch 43, batch 18: loss = 0.009022\n",
      "Epoch 43, batch 19: loss = 0.010192\n",
      "Epoch 43, batch 20: loss = 0.009348\n",
      "Epoch 43, batch 21: loss = 0.009260\n",
      "Epoch 43, batch 22: loss = 0.010240\n",
      "Epoch 43, batch 23: loss = 0.009228\n",
      "Epoch 43, batch 24: loss = 0.009356\n",
      "Epoch 43, batch 25: loss = 0.009252\n",
      "Epoch 43, batch 26: loss = 0.009254\n",
      "Epoch 43, batch 27: loss = 0.008980\n",
      "Epoch 43, batch 28: loss = 0.009295\n",
      "Epoch 43, batch 29: loss = 0.009532\n",
      "Epoch 43, batch 30: loss = 0.009300\n",
      "Epoch 43, batch 31: loss = 0.009140\n",
      "Epoch 43, batch 32: loss = 0.009724\n",
      "Epoch 43, batch 33: loss = 0.009917\n",
      "Epoch 43, batch 34: loss = 0.009538\n",
      "Epoch 43, batch 35: loss = 0.008790\n",
      "Epoch 43, batch 36: loss = 0.008805\n",
      "Epoch 43, batch 37: loss = 0.009346\n",
      "Epoch 43, batch 38: loss = 0.008641\n",
      "Epoch 43, batch 39: loss = 0.010376\n",
      "Epoch 43, batch 40: loss = 0.009365\n",
      "Epoch 43, batch 41: loss = 0.009297\n",
      "Epoch 43, batch 42: loss = 0.009354\n",
      "Epoch 43, batch 43: loss = 0.009727\n",
      "Epoch 43, batch 44: loss = 0.008922\n",
      "Epoch 43, batch 45: loss = 0.008699\n",
      "Epoch 43, batch 46: loss = 0.009044\n",
      "Epoch 43, batch 47: loss = 0.008891\n",
      "Epoch 43, batch 48: loss = 0.008942\n",
      "Epoch 43, batch 49: loss = 0.009255\n",
      "Epoch 43, batch 50: loss = 0.008937\n",
      "Epoch 43, batch 51: loss = 0.008968\n",
      "Epoch 43, batch 52: loss = 0.008826\n",
      "Epoch 43, batch 53: loss = 0.009703\n",
      "Epoch 43, batch 54: loss = 0.008670\n",
      "Epoch 43, batch 55: loss = 0.009094\n",
      "Epoch 43, batch 56: loss = 0.008357\n",
      "Epoch 43, batch 57: loss = 0.008846\n",
      "Epoch 43, batch 58: loss = 0.009411\n",
      "Epoch 43, batch 59: loss = 0.008992\n",
      "Epoch 43, batch 60: loss = 0.007995\n",
      "Epoch 43, batch 61: loss = 0.009044\n",
      "Epoch 43, batch 62: loss = 0.008516\n",
      "Epoch 43, batch 63: loss = 0.008963\n",
      "Epoch 43, batch 64: loss = 0.008742\n",
      "Epoch 43, batch 65: loss = 0.008782\n",
      "Epoch 43, batch 66: loss = 0.008395\n",
      "Epoch 43, batch 67: loss = 0.009064\n",
      "Epoch 43, batch 68: loss = 0.008741\n",
      "Epoch 43, batch 69: loss = 0.009263\n",
      "Epoch 43, batch 70: loss = 0.008853\n",
      "Epoch 43, batch 71: loss = 0.008523\n",
      "Epoch 43, batch 72: loss = 0.008496\n",
      "Epoch 43, batch 73: loss = 0.008756\n",
      "Epoch 43, batch 74: loss = 0.008871\n",
      "Epoch 43, batch 75: loss = 0.009652\n",
      "Epoch 43, batch 76: loss = 0.009378\n",
      "Epoch 43, batch 77: loss = 0.008277\n",
      "Epoch 43, batch 78: loss = 0.009199\n",
      "Epoch 43, batch 79: loss = 0.008270\n",
      "Epoch 43, batch 80: loss = 0.008326\n",
      "Epoch 43, batch 81: loss = 0.008523\n",
      "Epoch 43, batch 82: loss = 0.010844\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 43: val_loss = 0.034407\n",
      "Epoch 44, batch 0: loss = 0.009017\n",
      "Epoch 44, batch 1: loss = 0.008848\n",
      "Epoch 44, batch 2: loss = 0.008524\n",
      "Epoch 44, batch 3: loss = 0.009394\n",
      "Epoch 44, batch 4: loss = 0.008727\n",
      "Epoch 44, batch 5: loss = 0.008584\n",
      "Epoch 44, batch 6: loss = 0.008918\n",
      "Epoch 44, batch 7: loss = 0.008680\n",
      "Epoch 44, batch 8: loss = 0.008914\n",
      "Epoch 44, batch 9: loss = 0.008238\n",
      "Epoch 44, batch 10: loss = 0.008139\n",
      "Epoch 44, batch 11: loss = 0.008100\n",
      "Epoch 44, batch 12: loss = 0.009402\n",
      "Epoch 44, batch 13: loss = 0.009182\n",
      "Epoch 44, batch 14: loss = 0.008319\n",
      "Epoch 44, batch 15: loss = 0.008765\n",
      "Epoch 44, batch 16: loss = 0.008288\n",
      "Epoch 44, batch 17: loss = 0.008618\n",
      "Epoch 44, batch 18: loss = 0.008566\n",
      "Epoch 44, batch 19: loss = 0.008224\n",
      "Epoch 44, batch 20: loss = 0.008436\n",
      "Epoch 44, batch 21: loss = 0.008791\n",
      "Epoch 44, batch 22: loss = 0.008655\n",
      "Epoch 44, batch 23: loss = 0.008823\n",
      "Epoch 44, batch 24: loss = 0.008946\n",
      "Epoch 44, batch 25: loss = 0.008032\n",
      "Epoch 44, batch 26: loss = 0.008701\n",
      "Epoch 44, batch 27: loss = 0.008707\n",
      "Epoch 44, batch 28: loss = 0.008179\n",
      "Epoch 44, batch 29: loss = 0.008532\n",
      "Epoch 44, batch 30: loss = 0.008975\n",
      "Epoch 44, batch 31: loss = 0.008454\n",
      "Epoch 44, batch 32: loss = 0.007974\n",
      "Epoch 44, batch 33: loss = 0.008630\n",
      "Epoch 44, batch 34: loss = 0.008577\n",
      "Epoch 44, batch 35: loss = 0.009340\n",
      "Epoch 44, batch 36: loss = 0.008438\n",
      "Epoch 44, batch 37: loss = 0.008446\n",
      "Epoch 44, batch 38: loss = 0.008689\n",
      "Epoch 44, batch 39: loss = 0.009780\n",
      "Epoch 44, batch 40: loss = 0.009074\n",
      "Epoch 44, batch 41: loss = 0.008404\n",
      "Epoch 44, batch 42: loss = 0.008458\n",
      "Epoch 44, batch 43: loss = 0.008765\n",
      "Epoch 44, batch 44: loss = 0.008677\n",
      "Epoch 44, batch 45: loss = 0.008240\n",
      "Epoch 44, batch 46: loss = 0.008771\n",
      "Epoch 44, batch 47: loss = 0.008327\n",
      "Epoch 44, batch 48: loss = 0.008215\n",
      "Epoch 44, batch 49: loss = 0.008027\n",
      "Epoch 44, batch 50: loss = 0.008947\n",
      "Epoch 44, batch 51: loss = 0.008071\n",
      "Epoch 44, batch 52: loss = 0.008923\n",
      "Epoch 44, batch 53: loss = 0.008936\n",
      "Epoch 44, batch 54: loss = 0.008420\n",
      "Epoch 44, batch 55: loss = 0.008276\n",
      "Epoch 44, batch 56: loss = 0.008392\n",
      "Epoch 44, batch 57: loss = 0.009251\n",
      "Epoch 44, batch 58: loss = 0.008934\n",
      "Epoch 44, batch 59: loss = 0.008750\n",
      "Epoch 44, batch 60: loss = 0.009009\n",
      "Epoch 44, batch 61: loss = 0.008883\n",
      "Epoch 44, batch 62: loss = 0.009082\n",
      "Epoch 44, batch 63: loss = 0.008660\n",
      "Epoch 44, batch 64: loss = 0.009120\n",
      "Epoch 44, batch 65: loss = 0.008397\n",
      "Epoch 44, batch 66: loss = 0.007977\n",
      "Epoch 44, batch 67: loss = 0.008856\n",
      "Epoch 44, batch 68: loss = 0.008626\n",
      "Epoch 44, batch 69: loss = 0.008196\n",
      "Epoch 44, batch 70: loss = 0.008734\n",
      "Epoch 44, batch 71: loss = 0.008135\n",
      "Epoch 44, batch 72: loss = 0.008586\n",
      "Epoch 44, batch 73: loss = 0.008303\n",
      "Epoch 44, batch 74: loss = 0.008902\n",
      "Epoch 44, batch 75: loss = 0.008674\n",
      "Epoch 44, batch 76: loss = 0.008432\n",
      "Epoch 44, batch 77: loss = 0.008186\n",
      "Epoch 44, batch 78: loss = 0.008321\n",
      "Epoch 44, batch 79: loss = 0.008938\n",
      "Epoch 44, batch 80: loss = 0.008551\n",
      "Epoch 44, batch 81: loss = 0.008371\n",
      "Epoch 44, batch 82: loss = 0.006366\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 44: val_loss = 0.034258\n",
      "Epoch 45, batch 0: loss = 0.008098\n",
      "Epoch 45, batch 1: loss = 0.008799\n",
      "Epoch 45, batch 2: loss = 0.007986\n",
      "Epoch 45, batch 3: loss = 0.009204\n",
      "Epoch 45, batch 4: loss = 0.008536\n",
      "Epoch 45, batch 5: loss = 0.009254\n",
      "Epoch 45, batch 6: loss = 0.007988\n",
      "Epoch 45, batch 7: loss = 0.008158\n",
      "Epoch 45, batch 8: loss = 0.008371\n",
      "Epoch 45, batch 9: loss = 0.008701\n",
      "Epoch 45, batch 10: loss = 0.008365\n",
      "Epoch 45, batch 11: loss = 0.008498\n",
      "Epoch 45, batch 12: loss = 0.009209\n",
      "Epoch 45, batch 13: loss = 0.008638\n",
      "Epoch 45, batch 14: loss = 0.008591\n",
      "Epoch 45, batch 15: loss = 0.008810\n",
      "Epoch 45, batch 16: loss = 0.008848\n",
      "Epoch 45, batch 17: loss = 0.008085\n",
      "Epoch 45, batch 18: loss = 0.008351\n",
      "Epoch 45, batch 19: loss = 0.008705\n",
      "Epoch 45, batch 20: loss = 0.008436\n",
      "Epoch 45, batch 21: loss = 0.008289\n",
      "Epoch 45, batch 22: loss = 0.008396\n",
      "Epoch 45, batch 23: loss = 0.008405\n",
      "Epoch 45, batch 24: loss = 0.008853\n",
      "Epoch 45, batch 25: loss = 0.008345\n",
      "Epoch 45, batch 26: loss = 0.008150\n",
      "Epoch 45, batch 27: loss = 0.008264\n",
      "Epoch 45, batch 28: loss = 0.008416\n",
      "Epoch 45, batch 29: loss = 0.008305\n",
      "Epoch 45, batch 30: loss = 0.008689\n",
      "Epoch 45, batch 31: loss = 0.009328\n",
      "Epoch 45, batch 32: loss = 0.008416\n",
      "Epoch 45, batch 33: loss = 0.008127\n",
      "Epoch 45, batch 34: loss = 0.007420\n",
      "Epoch 45, batch 35: loss = 0.008387\n",
      "Epoch 45, batch 36: loss = 0.008719\n",
      "Epoch 45, batch 37: loss = 0.009103\n",
      "Epoch 45, batch 38: loss = 0.008424\n",
      "Epoch 45, batch 39: loss = 0.008385\n",
      "Epoch 45, batch 40: loss = 0.008707\n",
      "Epoch 45, batch 41: loss = 0.008488\n",
      "Epoch 45, batch 42: loss = 0.008662\n",
      "Epoch 45, batch 43: loss = 0.008177\n",
      "Epoch 45, batch 44: loss = 0.008474\n",
      "Epoch 45, batch 45: loss = 0.008509\n",
      "Epoch 45, batch 46: loss = 0.007926\n",
      "Epoch 45, batch 47: loss = 0.008342\n",
      "Epoch 45, batch 48: loss = 0.008238\n",
      "Epoch 45, batch 49: loss = 0.008123\n",
      "Epoch 45, batch 50: loss = 0.008746\n",
      "Epoch 45, batch 51: loss = 0.007958\n",
      "Epoch 45, batch 52: loss = 0.008906\n",
      "Epoch 45, batch 53: loss = 0.007909\n",
      "Epoch 45, batch 54: loss = 0.008646\n",
      "Epoch 45, batch 55: loss = 0.008442\n",
      "Epoch 45, batch 56: loss = 0.008268\n",
      "Epoch 45, batch 57: loss = 0.008363\n",
      "Epoch 45, batch 58: loss = 0.008079\n",
      "Epoch 45, batch 59: loss = 0.008551\n",
      "Epoch 45, batch 60: loss = 0.008099\n",
      "Epoch 45, batch 61: loss = 0.008686\n",
      "Epoch 45, batch 62: loss = 0.008687\n",
      "Epoch 45, batch 63: loss = 0.007909\n",
      "Epoch 45, batch 64: loss = 0.008492\n",
      "Epoch 45, batch 65: loss = 0.008329\n",
      "Epoch 45, batch 66: loss = 0.008059\n",
      "Epoch 45, batch 67: loss = 0.008378\n",
      "Epoch 45, batch 68: loss = 0.008896\n",
      "Epoch 45, batch 69: loss = 0.008550\n",
      "Epoch 45, batch 70: loss = 0.008163\n",
      "Epoch 45, batch 71: loss = 0.008774\n",
      "Epoch 45, batch 72: loss = 0.008952\n",
      "Epoch 45, batch 73: loss = 0.008270\n",
      "Epoch 45, batch 74: loss = 0.008543\n",
      "Epoch 45, batch 75: loss = 0.008316\n",
      "Epoch 45, batch 76: loss = 0.008978\n",
      "Epoch 45, batch 77: loss = 0.008771\n",
      "Epoch 45, batch 78: loss = 0.008378\n",
      "Epoch 45, batch 79: loss = 0.008290\n",
      "Epoch 45, batch 80: loss = 0.008264\n",
      "Epoch 45, batch 81: loss = 0.008449\n",
      "Epoch 45, batch 82: loss = 0.008338\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 45: val_loss = 0.035415\n",
      "Epoch 46, batch 0: loss = 0.008683\n",
      "Epoch 46, batch 1: loss = 0.008434\n",
      "Epoch 46, batch 2: loss = 0.008771\n",
      "Epoch 46, batch 3: loss = 0.008338\n",
      "Epoch 46, batch 4: loss = 0.009302\n",
      "Epoch 46, batch 5: loss = 0.008367\n",
      "Epoch 46, batch 6: loss = 0.008879\n",
      "Epoch 46, batch 7: loss = 0.008850\n",
      "Epoch 46, batch 8: loss = 0.008818\n",
      "Epoch 46, batch 9: loss = 0.008259\n",
      "Epoch 46, batch 10: loss = 0.008947\n",
      "Epoch 46, batch 11: loss = 0.008513\n",
      "Epoch 46, batch 12: loss = 0.007824\n",
      "Epoch 46, batch 13: loss = 0.008488\n",
      "Epoch 46, batch 14: loss = 0.008459\n",
      "Epoch 46, batch 15: loss = 0.008441\n",
      "Epoch 46, batch 16: loss = 0.008910\n",
      "Epoch 46, batch 17: loss = 0.008649\n",
      "Epoch 46, batch 18: loss = 0.009122\n",
      "Epoch 46, batch 19: loss = 0.008867\n",
      "Epoch 46, batch 20: loss = 0.008453\n",
      "Epoch 46, batch 21: loss = 0.008167\n",
      "Epoch 46, batch 22: loss = 0.008788\n",
      "Epoch 46, batch 23: loss = 0.009030\n",
      "Epoch 46, batch 24: loss = 0.009246\n",
      "Epoch 46, batch 25: loss = 0.009062\n",
      "Epoch 46, batch 26: loss = 0.008222\n",
      "Epoch 46, batch 27: loss = 0.008394\n",
      "Epoch 46, batch 28: loss = 0.008960\n",
      "Epoch 46, batch 29: loss = 0.008750\n",
      "Epoch 46, batch 30: loss = 0.008413\n",
      "Epoch 46, batch 31: loss = 0.008100\n",
      "Epoch 46, batch 32: loss = 0.008835\n",
      "Epoch 46, batch 33: loss = 0.008282\n",
      "Epoch 46, batch 34: loss = 0.008413\n",
      "Epoch 46, batch 35: loss = 0.008506\n",
      "Epoch 46, batch 36: loss = 0.008369\n",
      "Epoch 46, batch 37: loss = 0.008947\n",
      "Epoch 46, batch 38: loss = 0.008079\n",
      "Epoch 46, batch 39: loss = 0.008780\n",
      "Epoch 46, batch 40: loss = 0.008597\n",
      "Epoch 46, batch 41: loss = 0.008565\n",
      "Epoch 46, batch 42: loss = 0.008368\n",
      "Epoch 46, batch 43: loss = 0.008259\n",
      "Epoch 46, batch 44: loss = 0.007862\n",
      "Epoch 46, batch 45: loss = 0.007869\n",
      "Epoch 46, batch 46: loss = 0.008345\n",
      "Epoch 46, batch 47: loss = 0.008607\n",
      "Epoch 46, batch 48: loss = 0.007730\n",
      "Epoch 46, batch 49: loss = 0.008626\n",
      "Epoch 46, batch 50: loss = 0.008409\n",
      "Epoch 46, batch 51: loss = 0.008273\n",
      "Epoch 46, batch 52: loss = 0.008547\n",
      "Epoch 46, batch 53: loss = 0.009289\n",
      "Epoch 46, batch 54: loss = 0.008639\n",
      "Epoch 46, batch 55: loss = 0.008466\n",
      "Epoch 46, batch 56: loss = 0.008179\n",
      "Epoch 46, batch 57: loss = 0.007990\n",
      "Epoch 46, batch 58: loss = 0.007812\n",
      "Epoch 46, batch 59: loss = 0.007806\n",
      "Epoch 46, batch 60: loss = 0.008989\n",
      "Epoch 46, batch 61: loss = 0.008614\n",
      "Epoch 46, batch 62: loss = 0.008972\n",
      "Epoch 46, batch 63: loss = 0.007714\n",
      "Epoch 46, batch 64: loss = 0.008616\n",
      "Epoch 46, batch 65: loss = 0.007801\n",
      "Epoch 46, batch 66: loss = 0.007696\n",
      "Epoch 46, batch 67: loss = 0.008466\n",
      "Epoch 46, batch 68: loss = 0.008357\n",
      "Epoch 46, batch 69: loss = 0.008264\n",
      "Epoch 46, batch 70: loss = 0.008847\n",
      "Epoch 46, batch 71: loss = 0.007995\n",
      "Epoch 46, batch 72: loss = 0.007982\n",
      "Epoch 46, batch 73: loss = 0.008910\n",
      "Epoch 46, batch 74: loss = 0.008189\n",
      "Epoch 46, batch 75: loss = 0.008320\n",
      "Epoch 46, batch 76: loss = 0.008064\n",
      "Epoch 46, batch 77: loss = 0.008760\n",
      "Epoch 46, batch 78: loss = 0.008635\n",
      "Epoch 46, batch 79: loss = 0.007535\n",
      "Epoch 46, batch 80: loss = 0.008388\n",
      "Epoch 46, batch 81: loss = 0.008537\n",
      "Epoch 46, batch 82: loss = 0.008644\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 46: val_loss = 0.035024\n",
      "Epoch 47, batch 0: loss = 0.008853\n",
      "Epoch 47, batch 1: loss = 0.008328\n",
      "Epoch 47, batch 2: loss = 0.008818\n",
      "Epoch 47, batch 3: loss = 0.008194\n",
      "Epoch 47, batch 4: loss = 0.008291\n",
      "Epoch 47, batch 5: loss = 0.008387\n",
      "Epoch 47, batch 6: loss = 0.008368\n",
      "Epoch 47, batch 7: loss = 0.008584\n",
      "Epoch 47, batch 8: loss = 0.008809\n",
      "Epoch 47, batch 9: loss = 0.008566\n",
      "Epoch 47, batch 10: loss = 0.008378\n",
      "Epoch 47, batch 11: loss = 0.008190\n",
      "Epoch 47, batch 12: loss = 0.008663\n",
      "Epoch 47, batch 13: loss = 0.008378\n",
      "Epoch 47, batch 14: loss = 0.008555\n",
      "Epoch 47, batch 15: loss = 0.008043\n",
      "Epoch 47, batch 16: loss = 0.008016\n",
      "Epoch 47, batch 17: loss = 0.008361\n",
      "Epoch 47, batch 18: loss = 0.007884\n",
      "Epoch 47, batch 19: loss = 0.007804\n",
      "Epoch 47, batch 20: loss = 0.008248\n",
      "Epoch 47, batch 21: loss = 0.008298\n",
      "Epoch 47, batch 22: loss = 0.007923\n",
      "Epoch 47, batch 23: loss = 0.007946\n",
      "Epoch 47, batch 24: loss = 0.008147\n",
      "Epoch 47, batch 25: loss = 0.008816\n",
      "Epoch 47, batch 26: loss = 0.008158\n",
      "Epoch 47, batch 27: loss = 0.008834\n",
      "Epoch 47, batch 28: loss = 0.007760\n",
      "Epoch 47, batch 29: loss = 0.008477\n",
      "Epoch 47, batch 30: loss = 0.008347\n",
      "Epoch 47, batch 31: loss = 0.008923\n",
      "Epoch 47, batch 32: loss = 0.008049\n",
      "Epoch 47, batch 33: loss = 0.008724\n",
      "Epoch 47, batch 34: loss = 0.009068\n",
      "Epoch 47, batch 35: loss = 0.008265\n",
      "Epoch 47, batch 36: loss = 0.008473\n",
      "Epoch 47, batch 37: loss = 0.008120\n",
      "Epoch 47, batch 38: loss = 0.008492\n",
      "Epoch 47, batch 39: loss = 0.008501\n",
      "Epoch 47, batch 40: loss = 0.008564\n",
      "Epoch 47, batch 41: loss = 0.009043\n",
      "Epoch 47, batch 42: loss = 0.008368\n",
      "Epoch 47, batch 43: loss = 0.009028\n",
      "Epoch 47, batch 44: loss = 0.007854\n",
      "Epoch 47, batch 45: loss = 0.008323\n",
      "Epoch 47, batch 46: loss = 0.008572\n",
      "Epoch 47, batch 47: loss = 0.008154\n",
      "Epoch 47, batch 48: loss = 0.008433\n",
      "Epoch 47, batch 49: loss = 0.008191\n",
      "Epoch 47, batch 50: loss = 0.007791\n",
      "Epoch 47, batch 51: loss = 0.008077\n",
      "Epoch 47, batch 52: loss = 0.008163\n",
      "Epoch 47, batch 53: loss = 0.008418\n",
      "Epoch 47, batch 54: loss = 0.008439\n",
      "Epoch 47, batch 55: loss = 0.008049\n",
      "Epoch 47, batch 56: loss = 0.008456\n",
      "Epoch 47, batch 57: loss = 0.007740\n",
      "Epoch 47, batch 58: loss = 0.008180\n",
      "Epoch 47, batch 59: loss = 0.007871\n",
      "Epoch 47, batch 60: loss = 0.007878\n",
      "Epoch 47, batch 61: loss = 0.008231\n",
      "Epoch 47, batch 62: loss = 0.008329\n",
      "Epoch 47, batch 63: loss = 0.008179\n",
      "Epoch 47, batch 64: loss = 0.008281\n",
      "Epoch 47, batch 65: loss = 0.007636\n",
      "Epoch 47, batch 66: loss = 0.008087\n",
      "Epoch 47, batch 67: loss = 0.007905\n",
      "Epoch 47, batch 68: loss = 0.008248\n",
      "Epoch 47, batch 69: loss = 0.008005\n",
      "Epoch 47, batch 70: loss = 0.008139\n",
      "Epoch 47, batch 71: loss = 0.007634\n",
      "Epoch 47, batch 72: loss = 0.007987\n",
      "Epoch 47, batch 73: loss = 0.007913\n",
      "Epoch 47, batch 74: loss = 0.007971\n",
      "Epoch 47, batch 75: loss = 0.007891\n",
      "Epoch 47, batch 76: loss = 0.008586\n",
      "Epoch 47, batch 77: loss = 0.008021\n",
      "Epoch 47, batch 78: loss = 0.008171\n",
      "Epoch 47, batch 79: loss = 0.008207\n",
      "Epoch 47, batch 80: loss = 0.008490\n",
      "Epoch 47, batch 81: loss = 0.008300\n",
      "Epoch 47, batch 82: loss = 0.008474\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 47: val_loss = 0.034628\n",
      "Epoch 48, batch 0: loss = 0.008496\n",
      "Epoch 48, batch 1: loss = 0.008276\n",
      "Epoch 48, batch 2: loss = 0.008142\n",
      "Epoch 48, batch 3: loss = 0.008163\n",
      "Epoch 48, batch 4: loss = 0.008686\n",
      "Epoch 48, batch 5: loss = 0.008304\n",
      "Epoch 48, batch 6: loss = 0.009346\n",
      "Epoch 48, batch 7: loss = 0.007991\n",
      "Epoch 48, batch 8: loss = 0.008743\n",
      "Epoch 48, batch 9: loss = 0.008582\n",
      "Epoch 48, batch 10: loss = 0.008815\n",
      "Epoch 48, batch 11: loss = 0.007328\n",
      "Epoch 48, batch 12: loss = 0.008423\n",
      "Epoch 48, batch 13: loss = 0.009018\n",
      "Epoch 48, batch 14: loss = 0.009138\n",
      "Epoch 48, batch 15: loss = 0.008106\n",
      "Epoch 48, batch 16: loss = 0.008036\n",
      "Epoch 48, batch 17: loss = 0.008638\n",
      "Epoch 48, batch 18: loss = 0.008335\n",
      "Epoch 48, batch 19: loss = 0.008505\n",
      "Epoch 48, batch 20: loss = 0.008108\n",
      "Epoch 48, batch 21: loss = 0.008135\n",
      "Epoch 48, batch 22: loss = 0.008090\n",
      "Epoch 48, batch 23: loss = 0.007883\n",
      "Epoch 48, batch 24: loss = 0.007950\n",
      "Epoch 48, batch 25: loss = 0.008438\n",
      "Epoch 48, batch 26: loss = 0.008613\n",
      "Epoch 48, batch 27: loss = 0.008224\n",
      "Epoch 48, batch 28: loss = 0.007895\n",
      "Epoch 48, batch 29: loss = 0.007884\n",
      "Epoch 48, batch 30: loss = 0.007450\n",
      "Epoch 48, batch 31: loss = 0.008262\n",
      "Epoch 48, batch 32: loss = 0.008146\n",
      "Epoch 48, batch 33: loss = 0.008588\n",
      "Epoch 48, batch 34: loss = 0.008521\n",
      "Epoch 48, batch 35: loss = 0.008434\n",
      "Epoch 48, batch 36: loss = 0.008061\n",
      "Epoch 48, batch 37: loss = 0.008196\n",
      "Epoch 48, batch 38: loss = 0.008434\n",
      "Epoch 48, batch 39: loss = 0.008371\n",
      "Epoch 48, batch 40: loss = 0.008092\n",
      "Epoch 48, batch 41: loss = 0.008924\n",
      "Epoch 48, batch 42: loss = 0.008925\n",
      "Epoch 48, batch 43: loss = 0.008570\n",
      "Epoch 48, batch 44: loss = 0.008319\n",
      "Epoch 48, batch 45: loss = 0.008127\n",
      "Epoch 48, batch 46: loss = 0.007933\n",
      "Epoch 48, batch 47: loss = 0.008410\n",
      "Epoch 48, batch 48: loss = 0.009144\n",
      "Epoch 48, batch 49: loss = 0.008451\n",
      "Epoch 48, batch 50: loss = 0.008257\n",
      "Epoch 48, batch 51: loss = 0.008511\n",
      "Epoch 48, batch 52: loss = 0.008630\n",
      "Epoch 48, batch 53: loss = 0.008974\n",
      "Epoch 48, batch 54: loss = 0.007637\n",
      "Epoch 48, batch 55: loss = 0.008250\n",
      "Epoch 48, batch 56: loss = 0.007920\n",
      "Epoch 48, batch 57: loss = 0.008156\n",
      "Epoch 48, batch 58: loss = 0.008287\n",
      "Epoch 48, batch 59: loss = 0.008478\n",
      "Epoch 48, batch 60: loss = 0.008251\n",
      "Epoch 48, batch 61: loss = 0.008063\n",
      "Epoch 48, batch 62: loss = 0.007973\n",
      "Epoch 48, batch 63: loss = 0.008293\n",
      "Epoch 48, batch 64: loss = 0.008403\n",
      "Epoch 48, batch 65: loss = 0.008314\n",
      "Epoch 48, batch 66: loss = 0.008291\n",
      "Epoch 48, batch 67: loss = 0.008557\n",
      "Epoch 48, batch 68: loss = 0.008563\n",
      "Epoch 48, batch 69: loss = 0.008486\n",
      "Epoch 48, batch 70: loss = 0.008525\n",
      "Epoch 48, batch 71: loss = 0.008831\n",
      "Epoch 48, batch 72: loss = 0.008943\n",
      "Epoch 48, batch 73: loss = 0.008610\n",
      "Epoch 48, batch 74: loss = 0.008350\n",
      "Epoch 48, batch 75: loss = 0.008366\n",
      "Epoch 48, batch 76: loss = 0.008104\n",
      "Epoch 48, batch 77: loss = 0.008070\n",
      "Epoch 48, batch 78: loss = 0.007945\n",
      "Epoch 48, batch 79: loss = 0.008823\n",
      "Epoch 48, batch 80: loss = 0.007882\n",
      "Epoch 48, batch 81: loss = 0.008466\n",
      "Epoch 48, batch 82: loss = 0.009241\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 48: val_loss = 0.035715\n",
      "Epoch 49, batch 0: loss = 0.008479\n",
      "Epoch 49, batch 1: loss = 0.008146\n",
      "Epoch 49, batch 2: loss = 0.008603\n",
      "Epoch 49, batch 3: loss = 0.008178\n",
      "Epoch 49, batch 4: loss = 0.008183\n",
      "Epoch 49, batch 5: loss = 0.008195\n",
      "Epoch 49, batch 6: loss = 0.008347\n",
      "Epoch 49, batch 7: loss = 0.008741\n",
      "Epoch 49, batch 8: loss = 0.008340\n",
      "Epoch 49, batch 9: loss = 0.008312\n",
      "Epoch 49, batch 10: loss = 0.009064\n",
      "Epoch 49, batch 11: loss = 0.008488\n",
      "Epoch 49, batch 12: loss = 0.007631\n",
      "Epoch 49, batch 13: loss = 0.008653\n",
      "Epoch 49, batch 14: loss = 0.008653\n",
      "Epoch 49, batch 15: loss = 0.008276\n",
      "Epoch 49, batch 16: loss = 0.007984\n",
      "Epoch 49, batch 17: loss = 0.008398\n",
      "Epoch 49, batch 18: loss = 0.008761\n",
      "Epoch 49, batch 19: loss = 0.008571\n",
      "Epoch 49, batch 20: loss = 0.008032\n",
      "Epoch 49, batch 21: loss = 0.008427\n",
      "Epoch 49, batch 22: loss = 0.008285\n",
      "Epoch 49, batch 23: loss = 0.008445\n",
      "Epoch 49, batch 24: loss = 0.008208\n",
      "Epoch 49, batch 25: loss = 0.007939\n",
      "Epoch 49, batch 26: loss = 0.007931\n",
      "Epoch 49, batch 27: loss = 0.008660\n",
      "Epoch 49, batch 28: loss = 0.007974\n",
      "Epoch 49, batch 29: loss = 0.009263\n",
      "Epoch 49, batch 30: loss = 0.008407\n",
      "Epoch 49, batch 31: loss = 0.008609\n",
      "Epoch 49, batch 32: loss = 0.008414\n",
      "Epoch 49, batch 33: loss = 0.008019\n",
      "Epoch 49, batch 34: loss = 0.008400\n",
      "Epoch 49, batch 35: loss = 0.008493\n",
      "Epoch 49, batch 36: loss = 0.007645\n",
      "Epoch 49, batch 37: loss = 0.008127\n",
      "Epoch 49, batch 38: loss = 0.008472\n",
      "Epoch 49, batch 39: loss = 0.008549\n",
      "Epoch 49, batch 40: loss = 0.008303\n",
      "Epoch 49, batch 41: loss = 0.007693\n",
      "Epoch 49, batch 42: loss = 0.008206\n",
      "Epoch 49, batch 43: loss = 0.008566\n",
      "Epoch 49, batch 44: loss = 0.008064\n",
      "Epoch 49, batch 45: loss = 0.008168\n",
      "Epoch 49, batch 46: loss = 0.008074\n",
      "Epoch 49, batch 47: loss = 0.007909\n",
      "Epoch 49, batch 48: loss = 0.008480\n",
      "Epoch 49, batch 49: loss = 0.008362\n",
      "Epoch 49, batch 50: loss = 0.007977\n",
      "Epoch 49, batch 51: loss = 0.008517\n",
      "Epoch 49, batch 52: loss = 0.007824\n",
      "Epoch 49, batch 53: loss = 0.008407\n",
      "Epoch 49, batch 54: loss = 0.008260\n",
      "Epoch 49, batch 55: loss = 0.008079\n",
      "Epoch 49, batch 56: loss = 0.008301\n",
      "Epoch 49, batch 57: loss = 0.008264\n",
      "Epoch 49, batch 58: loss = 0.008502\n",
      "Epoch 49, batch 59: loss = 0.008108\n",
      "Epoch 49, batch 60: loss = 0.008217\n",
      "Epoch 49, batch 61: loss = 0.007852\n",
      "Epoch 49, batch 62: loss = 0.007875\n",
      "Epoch 49, batch 63: loss = 0.008066\n",
      "Epoch 49, batch 64: loss = 0.008378\n",
      "Epoch 49, batch 65: loss = 0.008581\n",
      "Epoch 49, batch 66: loss = 0.007740\n",
      "Epoch 49, batch 67: loss = 0.007994\n",
      "Epoch 49, batch 68: loss = 0.008610\n",
      "Epoch 49, batch 69: loss = 0.008273\n",
      "Epoch 49, batch 70: loss = 0.008406\n",
      "Epoch 49, batch 71: loss = 0.008043\n",
      "Epoch 49, batch 72: loss = 0.008117\n",
      "Epoch 49, batch 73: loss = 0.007875\n",
      "Epoch 49, batch 74: loss = 0.008247\n",
      "Epoch 49, batch 75: loss = 0.007837\n",
      "Epoch 49, batch 76: loss = 0.008150\n",
      "Epoch 49, batch 77: loss = 0.008868\n",
      "Epoch 49, batch 78: loss = 0.008093\n",
      "Epoch 49, batch 79: loss = 0.008055\n",
      "Epoch 49, batch 80: loss = 0.007829\n",
      "Epoch 49, batch 81: loss = 0.008350\n",
      "Epoch 49, batch 82: loss = 0.009914\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 49: val_loss = 0.035059\n",
      "Epoch 50, batch 0: loss = 0.008182\n",
      "Epoch 50, batch 1: loss = 0.008762\n",
      "Epoch 50, batch 2: loss = 0.008020\n",
      "Epoch 50, batch 3: loss = 0.008090\n",
      "Epoch 50, batch 4: loss = 0.008429\n",
      "Epoch 50, batch 5: loss = 0.008899\n",
      "Epoch 50, batch 6: loss = 0.008515\n",
      "Epoch 50, batch 7: loss = 0.008968\n",
      "Epoch 50, batch 8: loss = 0.007940\n",
      "Epoch 50, batch 9: loss = 0.008280\n",
      "Epoch 50, batch 10: loss = 0.007942\n",
      "Epoch 50, batch 11: loss = 0.008268\n",
      "Epoch 50, batch 12: loss = 0.008081\n",
      "Epoch 50, batch 13: loss = 0.008247\n",
      "Epoch 50, batch 14: loss = 0.008175\n",
      "Epoch 50, batch 15: loss = 0.008578\n",
      "Epoch 50, batch 16: loss = 0.008293\n",
      "Epoch 50, batch 17: loss = 0.008650\n",
      "Epoch 50, batch 18: loss = 0.008033\n",
      "Epoch 50, batch 19: loss = 0.007949\n",
      "Epoch 50, batch 20: loss = 0.007857\n",
      "Epoch 50, batch 21: loss = 0.008214\n",
      "Epoch 50, batch 22: loss = 0.007776\n",
      "Epoch 50, batch 23: loss = 0.008474\n",
      "Epoch 50, batch 24: loss = 0.008349\n",
      "Epoch 50, batch 25: loss = 0.007787\n",
      "Epoch 50, batch 26: loss = 0.007734\n",
      "Epoch 50, batch 27: loss = 0.008605\n",
      "Epoch 50, batch 28: loss = 0.007931\n",
      "Epoch 50, batch 29: loss = 0.007710\n",
      "Epoch 50, batch 30: loss = 0.008228\n",
      "Epoch 50, batch 31: loss = 0.008302\n",
      "Epoch 50, batch 32: loss = 0.009512\n",
      "Epoch 50, batch 33: loss = 0.007858\n",
      "Epoch 50, batch 34: loss = 0.008178\n",
      "Epoch 50, batch 35: loss = 0.008441\n",
      "Epoch 50, batch 36: loss = 0.008109\n",
      "Epoch 50, batch 37: loss = 0.008694\n",
      "Epoch 50, batch 38: loss = 0.008526\n",
      "Epoch 50, batch 39: loss = 0.008311\n",
      "Epoch 50, batch 40: loss = 0.008137\n",
      "Epoch 50, batch 41: loss = 0.008852\n",
      "Epoch 50, batch 42: loss = 0.008613\n",
      "Epoch 50, batch 43: loss = 0.008745\n",
      "Epoch 50, batch 44: loss = 0.008560\n",
      "Epoch 50, batch 45: loss = 0.008305\n",
      "Epoch 50, batch 46: loss = 0.008641\n",
      "Epoch 50, batch 47: loss = 0.008544\n",
      "Epoch 50, batch 48: loss = 0.008208\n",
      "Epoch 50, batch 49: loss = 0.008409\n",
      "Epoch 50, batch 50: loss = 0.007979\n",
      "Epoch 50, batch 51: loss = 0.008710\n",
      "Epoch 50, batch 52: loss = 0.007755\n",
      "Epoch 50, batch 53: loss = 0.008587\n",
      "Epoch 50, batch 54: loss = 0.008143\n",
      "Epoch 50, batch 55: loss = 0.008289\n",
      "Epoch 50, batch 56: loss = 0.007840\n",
      "Epoch 50, batch 57: loss = 0.008422\n",
      "Epoch 50, batch 58: loss = 0.008147\n",
      "Epoch 50, batch 59: loss = 0.008139\n",
      "Epoch 50, batch 60: loss = 0.008467\n",
      "Epoch 50, batch 61: loss = 0.008747\n",
      "Epoch 50, batch 62: loss = 0.008862\n",
      "Epoch 50, batch 63: loss = 0.008105\n",
      "Epoch 50, batch 64: loss = 0.008450\n",
      "Epoch 50, batch 65: loss = 0.007723\n",
      "Epoch 50, batch 66: loss = 0.008347\n",
      "Epoch 50, batch 67: loss = 0.008123\n",
      "Epoch 50, batch 68: loss = 0.008128\n",
      "Epoch 50, batch 69: loss = 0.008114\n",
      "Epoch 50, batch 70: loss = 0.007922\n",
      "Epoch 50, batch 71: loss = 0.008546\n",
      "Epoch 50, batch 72: loss = 0.007974\n",
      "Epoch 50, batch 73: loss = 0.008279\n",
      "Epoch 50, batch 74: loss = 0.008113\n",
      "Epoch 50, batch 75: loss = 0.008511\n",
      "Epoch 50, batch 76: loss = 0.007718\n",
      "Epoch 50, batch 77: loss = 0.008048\n",
      "Epoch 50, batch 78: loss = 0.008162\n",
      "Epoch 50, batch 79: loss = 0.008029\n",
      "Epoch 50, batch 80: loss = 0.007842\n",
      "Epoch 50, batch 81: loss = 0.008394\n",
      "Epoch 50, batch 82: loss = 0.005578\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 50: val_loss = 0.034729\n",
      "Epoch 51, batch 0: loss = 0.007977\n",
      "Epoch 51, batch 1: loss = 0.008393\n",
      "Epoch 51, batch 2: loss = 0.008611\n",
      "Epoch 51, batch 3: loss = 0.008501\n",
      "Epoch 51, batch 4: loss = 0.008199\n",
      "Epoch 51, batch 5: loss = 0.008471\n",
      "Epoch 51, batch 6: loss = 0.008061\n",
      "Epoch 51, batch 7: loss = 0.008234\n",
      "Epoch 51, batch 8: loss = 0.007916\n",
      "Epoch 51, batch 9: loss = 0.008016\n",
      "Epoch 51, batch 10: loss = 0.007924\n",
      "Epoch 51, batch 11: loss = 0.007670\n",
      "Epoch 51, batch 12: loss = 0.007509\n",
      "Epoch 51, batch 13: loss = 0.007857\n",
      "Epoch 51, batch 14: loss = 0.007851\n",
      "Epoch 51, batch 15: loss = 0.008098\n",
      "Epoch 51, batch 16: loss = 0.007966\n",
      "Epoch 51, batch 17: loss = 0.008540\n",
      "Epoch 51, batch 18: loss = 0.008014\n",
      "Epoch 51, batch 19: loss = 0.008106\n",
      "Epoch 51, batch 20: loss = 0.008218\n",
      "Epoch 51, batch 21: loss = 0.008183\n",
      "Epoch 51, batch 22: loss = 0.008208\n",
      "Epoch 51, batch 23: loss = 0.008592\n",
      "Epoch 51, batch 24: loss = 0.007330\n",
      "Epoch 51, batch 25: loss = 0.008071\n",
      "Epoch 51, batch 26: loss = 0.008002\n",
      "Epoch 51, batch 27: loss = 0.008459\n",
      "Epoch 51, batch 28: loss = 0.008085\n",
      "Epoch 51, batch 29: loss = 0.007713\n",
      "Epoch 51, batch 30: loss = 0.008095\n",
      "Epoch 51, batch 31: loss = 0.007983\n",
      "Epoch 51, batch 32: loss = 0.007957\n",
      "Epoch 51, batch 33: loss = 0.007851\n",
      "Epoch 51, batch 34: loss = 0.008499\n",
      "Epoch 51, batch 35: loss = 0.007581\n",
      "Epoch 51, batch 36: loss = 0.007932\n",
      "Epoch 51, batch 37: loss = 0.008249\n",
      "Epoch 51, batch 38: loss = 0.008542\n",
      "Epoch 51, batch 39: loss = 0.007523\n",
      "Epoch 51, batch 40: loss = 0.007812\n",
      "Epoch 51, batch 41: loss = 0.007646\n",
      "Epoch 51, batch 42: loss = 0.007402\n",
      "Epoch 51, batch 43: loss = 0.007787\n",
      "Epoch 51, batch 44: loss = 0.007904\n",
      "Epoch 51, batch 45: loss = 0.007721\n",
      "Epoch 51, batch 46: loss = 0.007219\n",
      "Epoch 51, batch 47: loss = 0.008549\n",
      "Epoch 51, batch 48: loss = 0.008294\n",
      "Epoch 51, batch 49: loss = 0.007831\n",
      "Epoch 51, batch 50: loss = 0.008054\n",
      "Epoch 51, batch 51: loss = 0.008361\n",
      "Epoch 51, batch 52: loss = 0.007877\n",
      "Epoch 51, batch 53: loss = 0.008131\n",
      "Epoch 51, batch 54: loss = 0.008371\n",
      "Epoch 51, batch 55: loss = 0.007838\n",
      "Epoch 51, batch 56: loss = 0.008242\n",
      "Epoch 51, batch 57: loss = 0.007216\n",
      "Epoch 51, batch 58: loss = 0.008626\n",
      "Epoch 51, batch 59: loss = 0.008121\n",
      "Epoch 51, batch 60: loss = 0.007546\n",
      "Epoch 51, batch 61: loss = 0.007818\n",
      "Epoch 51, batch 62: loss = 0.007818\n",
      "Epoch 51, batch 63: loss = 0.008052\n",
      "Epoch 51, batch 64: loss = 0.007882\n",
      "Epoch 51, batch 65: loss = 0.008085\n",
      "Epoch 51, batch 66: loss = 0.007846\n",
      "Epoch 51, batch 67: loss = 0.007900\n",
      "Epoch 51, batch 68: loss = 0.007377\n",
      "Epoch 51, batch 69: loss = 0.008231\n",
      "Epoch 51, batch 70: loss = 0.007561\n",
      "Epoch 51, batch 71: loss = 0.007445\n",
      "Epoch 51, batch 72: loss = 0.007569\n",
      "Epoch 51, batch 73: loss = 0.007783\n",
      "Epoch 51, batch 74: loss = 0.007608\n",
      "Epoch 51, batch 75: loss = 0.009451\n",
      "Epoch 51, batch 76: loss = 0.007686\n",
      "Epoch 51, batch 77: loss = 0.008150\n",
      "Epoch 51, batch 78: loss = 0.008024\n",
      "Epoch 51, batch 79: loss = 0.007826\n",
      "Epoch 51, batch 80: loss = 0.007990\n",
      "Epoch 51, batch 81: loss = 0.007974\n",
      "Epoch 51, batch 82: loss = 0.006888\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 51: val_loss = 0.035191\n",
      "Epoch 52, batch 0: loss = 0.007546\n",
      "Epoch 52, batch 1: loss = 0.007400\n",
      "Epoch 52, batch 2: loss = 0.007705\n",
      "Epoch 52, batch 3: loss = 0.008026\n",
      "Epoch 52, batch 4: loss = 0.008190\n",
      "Epoch 52, batch 5: loss = 0.007531\n",
      "Epoch 52, batch 6: loss = 0.008094\n",
      "Epoch 52, batch 7: loss = 0.007580\n",
      "Epoch 52, batch 8: loss = 0.007801\n",
      "Epoch 52, batch 9: loss = 0.008063\n",
      "Epoch 52, batch 10: loss = 0.007598\n",
      "Epoch 52, batch 11: loss = 0.008161\n",
      "Epoch 52, batch 12: loss = 0.008245\n",
      "Epoch 52, batch 13: loss = 0.008624\n",
      "Epoch 52, batch 14: loss = 0.008024\n",
      "Epoch 52, batch 15: loss = 0.007514\n",
      "Epoch 52, batch 16: loss = 0.007789\n",
      "Epoch 52, batch 17: loss = 0.007863\n",
      "Epoch 52, batch 18: loss = 0.008784\n",
      "Epoch 52, batch 19: loss = 0.007818\n",
      "Epoch 52, batch 20: loss = 0.007931\n",
      "Epoch 52, batch 21: loss = 0.008058\n",
      "Epoch 52, batch 22: loss = 0.007847\n",
      "Epoch 52, batch 23: loss = 0.008338\n",
      "Epoch 52, batch 24: loss = 0.007527\n",
      "Epoch 52, batch 25: loss = 0.008166\n",
      "Epoch 52, batch 26: loss = 0.007474\n",
      "Epoch 52, batch 27: loss = 0.007532\n",
      "Epoch 52, batch 28: loss = 0.008187\n",
      "Epoch 52, batch 29: loss = 0.008369\n",
      "Epoch 52, batch 30: loss = 0.008245\n",
      "Epoch 52, batch 31: loss = 0.007958\n",
      "Epoch 52, batch 32: loss = 0.007583\n",
      "Epoch 52, batch 33: loss = 0.007649\n",
      "Epoch 52, batch 34: loss = 0.007622\n",
      "Epoch 52, batch 35: loss = 0.008118\n",
      "Epoch 52, batch 36: loss = 0.007483\n",
      "Epoch 52, batch 37: loss = 0.007588\n",
      "Epoch 52, batch 38: loss = 0.008057\n",
      "Epoch 52, batch 39: loss = 0.007770\n",
      "Epoch 52, batch 40: loss = 0.007433\n",
      "Epoch 52, batch 41: loss = 0.008637\n",
      "Epoch 52, batch 42: loss = 0.007582\n",
      "Epoch 52, batch 43: loss = 0.008776\n",
      "Epoch 52, batch 44: loss = 0.008314\n",
      "Epoch 52, batch 45: loss = 0.008226\n",
      "Epoch 52, batch 46: loss = 0.008070\n",
      "Epoch 52, batch 47: loss = 0.007794\n",
      "Epoch 52, batch 48: loss = 0.007788\n",
      "Epoch 52, batch 49: loss = 0.007953\n",
      "Epoch 52, batch 50: loss = 0.008801\n",
      "Epoch 52, batch 51: loss = 0.008928\n",
      "Epoch 52, batch 52: loss = 0.009024\n",
      "Epoch 52, batch 53: loss = 0.007615\n",
      "Epoch 52, batch 54: loss = 0.009068\n",
      "Epoch 52, batch 55: loss = 0.008320\n",
      "Epoch 52, batch 56: loss = 0.007942\n",
      "Epoch 52, batch 57: loss = 0.008118\n",
      "Epoch 52, batch 58: loss = 0.008214\n",
      "Epoch 52, batch 59: loss = 0.008018\n",
      "Epoch 52, batch 60: loss = 0.008691\n",
      "Epoch 52, batch 61: loss = 0.008199\n",
      "Epoch 52, batch 62: loss = 0.008561\n",
      "Epoch 52, batch 63: loss = 0.007509\n",
      "Epoch 52, batch 64: loss = 0.008053\n",
      "Epoch 52, batch 65: loss = 0.008040\n",
      "Epoch 52, batch 66: loss = 0.007587\n",
      "Epoch 52, batch 67: loss = 0.007963\n",
      "Epoch 52, batch 68: loss = 0.008304\n",
      "Epoch 52, batch 69: loss = 0.008422\n",
      "Epoch 52, batch 70: loss = 0.007664\n",
      "Epoch 52, batch 71: loss = 0.007867\n",
      "Epoch 52, batch 72: loss = 0.008555\n",
      "Epoch 52, batch 73: loss = 0.007923\n",
      "Epoch 52, batch 74: loss = 0.008676\n",
      "Epoch 52, batch 75: loss = 0.007576\n",
      "Epoch 52, batch 76: loss = 0.008099\n",
      "Epoch 52, batch 77: loss = 0.007411\n",
      "Epoch 52, batch 78: loss = 0.008106\n",
      "Epoch 52, batch 79: loss = 0.007883\n",
      "Epoch 52, batch 80: loss = 0.008207\n",
      "Epoch 52, batch 81: loss = 0.008376\n",
      "Epoch 52, batch 82: loss = 0.007514\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 52: val_loss = 0.035089\n",
      "Epoch 53, batch 0: loss = 0.008041\n",
      "Epoch 53, batch 1: loss = 0.008246\n",
      "Epoch 53, batch 2: loss = 0.008086\n",
      "Epoch 53, batch 3: loss = 0.008067\n",
      "Epoch 53, batch 4: loss = 0.008051\n",
      "Epoch 53, batch 5: loss = 0.008234\n",
      "Epoch 53, batch 6: loss = 0.007847\n",
      "Epoch 53, batch 7: loss = 0.007966\n",
      "Epoch 53, batch 8: loss = 0.008600\n",
      "Epoch 53, batch 9: loss = 0.008111\n",
      "Epoch 53, batch 10: loss = 0.008345\n",
      "Epoch 53, batch 11: loss = 0.008691\n",
      "Epoch 53, batch 12: loss = 0.008371\n",
      "Epoch 53, batch 13: loss = 0.007885\n",
      "Epoch 53, batch 14: loss = 0.007678\n",
      "Epoch 53, batch 15: loss = 0.008059\n",
      "Epoch 53, batch 16: loss = 0.007815\n",
      "Epoch 53, batch 17: loss = 0.007925\n",
      "Epoch 53, batch 18: loss = 0.007650\n",
      "Epoch 53, batch 19: loss = 0.007575\n",
      "Epoch 53, batch 20: loss = 0.007634\n",
      "Epoch 53, batch 21: loss = 0.007532\n",
      "Epoch 53, batch 22: loss = 0.007887\n",
      "Epoch 53, batch 23: loss = 0.007579\n",
      "Epoch 53, batch 24: loss = 0.008116\n",
      "Epoch 53, batch 25: loss = 0.007885\n",
      "Epoch 53, batch 26: loss = 0.008284\n",
      "Epoch 53, batch 27: loss = 0.007752\n",
      "Epoch 53, batch 28: loss = 0.007503\n",
      "Epoch 53, batch 29: loss = 0.007422\n",
      "Epoch 53, batch 30: loss = 0.008003\n",
      "Epoch 53, batch 31: loss = 0.007841\n",
      "Epoch 53, batch 32: loss = 0.007516\n",
      "Epoch 53, batch 33: loss = 0.007742\n",
      "Epoch 53, batch 34: loss = 0.007616\n",
      "Epoch 53, batch 35: loss = 0.007794\n",
      "Epoch 53, batch 36: loss = 0.008117\n",
      "Epoch 53, batch 37: loss = 0.007863\n",
      "Epoch 53, batch 38: loss = 0.008066\n",
      "Epoch 53, batch 39: loss = 0.008156\n",
      "Epoch 53, batch 40: loss = 0.007778\n",
      "Epoch 53, batch 41: loss = 0.008154\n",
      "Epoch 53, batch 42: loss = 0.007583\n",
      "Epoch 53, batch 43: loss = 0.007254\n",
      "Epoch 53, batch 44: loss = 0.007868\n",
      "Epoch 53, batch 45: loss = 0.007323\n",
      "Epoch 53, batch 46: loss = 0.008746\n",
      "Epoch 53, batch 47: loss = 0.008197\n",
      "Epoch 53, batch 48: loss = 0.007258\n",
      "Epoch 53, batch 49: loss = 0.007877\n",
      "Epoch 53, batch 50: loss = 0.008156\n",
      "Epoch 53, batch 51: loss = 0.008006\n",
      "Epoch 53, batch 52: loss = 0.008258\n",
      "Epoch 53, batch 53: loss = 0.007785\n",
      "Epoch 53, batch 54: loss = 0.007160\n",
      "Epoch 53, batch 55: loss = 0.007962\n",
      "Epoch 53, batch 56: loss = 0.007515\n",
      "Epoch 53, batch 57: loss = 0.007836\n",
      "Epoch 53, batch 58: loss = 0.007580\n",
      "Epoch 53, batch 59: loss = 0.007392\n",
      "Epoch 53, batch 60: loss = 0.007937\n",
      "Epoch 53, batch 61: loss = 0.007670\n",
      "Epoch 53, batch 62: loss = 0.007560\n",
      "Epoch 53, batch 63: loss = 0.007387\n",
      "Epoch 53, batch 64: loss = 0.007525\n",
      "Epoch 53, batch 65: loss = 0.008073\n",
      "Epoch 53, batch 66: loss = 0.007929\n",
      "Epoch 53, batch 67: loss = 0.007893\n",
      "Epoch 53, batch 68: loss = 0.008075\n",
      "Epoch 53, batch 69: loss = 0.007757\n",
      "Epoch 53, batch 70: loss = 0.007548\n",
      "Epoch 53, batch 71: loss = 0.007582\n",
      "Epoch 53, batch 72: loss = 0.007549\n",
      "Epoch 53, batch 73: loss = 0.007456\n",
      "Epoch 53, batch 74: loss = 0.008286\n",
      "Epoch 53, batch 75: loss = 0.008046\n",
      "Epoch 53, batch 76: loss = 0.008082\n",
      "Epoch 53, batch 77: loss = 0.007386\n",
      "Epoch 53, batch 78: loss = 0.007852\n",
      "Epoch 53, batch 79: loss = 0.007618\n",
      "Epoch 53, batch 80: loss = 0.007714\n",
      "Epoch 53, batch 81: loss = 0.007451\n",
      "Epoch 53, batch 82: loss = 0.006459\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 53: val_loss = 0.034995\n",
      "Epoch 54, batch 0: loss = 0.007630\n",
      "Epoch 54, batch 1: loss = 0.007602\n",
      "Epoch 54, batch 2: loss = 0.007705\n",
      "Epoch 54, batch 3: loss = 0.007855\n",
      "Epoch 54, batch 4: loss = 0.007939\n",
      "Epoch 54, batch 5: loss = 0.007250\n",
      "Epoch 54, batch 6: loss = 0.007886\n",
      "Epoch 54, batch 7: loss = 0.007605\n",
      "Epoch 54, batch 8: loss = 0.007648\n",
      "Epoch 54, batch 9: loss = 0.007732\n",
      "Epoch 54, batch 10: loss = 0.007965\n",
      "Epoch 54, batch 11: loss = 0.008788\n",
      "Epoch 54, batch 12: loss = 0.007445\n",
      "Epoch 54, batch 13: loss = 0.007609\n",
      "Epoch 54, batch 14: loss = 0.007788\n",
      "Epoch 54, batch 15: loss = 0.007308\n",
      "Epoch 54, batch 16: loss = 0.007752\n",
      "Epoch 54, batch 17: loss = 0.008270\n",
      "Epoch 54, batch 18: loss = 0.007886\n",
      "Epoch 54, batch 19: loss = 0.007549\n",
      "Epoch 54, batch 20: loss = 0.007763\n",
      "Epoch 54, batch 21: loss = 0.007355\n",
      "Epoch 54, batch 22: loss = 0.007953\n",
      "Epoch 54, batch 23: loss = 0.007661\n",
      "Epoch 54, batch 24: loss = 0.007545\n",
      "Epoch 54, batch 25: loss = 0.008147\n",
      "Epoch 54, batch 26: loss = 0.007535\n",
      "Epoch 54, batch 27: loss = 0.007612\n",
      "Epoch 54, batch 28: loss = 0.007713\n",
      "Epoch 54, batch 29: loss = 0.007828\n",
      "Epoch 54, batch 30: loss = 0.008136\n",
      "Epoch 54, batch 31: loss = 0.006979\n",
      "Epoch 54, batch 32: loss = 0.007382\n",
      "Epoch 54, batch 33: loss = 0.008279\n",
      "Epoch 54, batch 34: loss = 0.007599\n",
      "Epoch 54, batch 35: loss = 0.007605\n",
      "Epoch 54, batch 36: loss = 0.008007\n",
      "Epoch 54, batch 37: loss = 0.007793\n",
      "Epoch 54, batch 38: loss = 0.007820\n",
      "Epoch 54, batch 39: loss = 0.007800\n",
      "Epoch 54, batch 40: loss = 0.007848\n",
      "Epoch 54, batch 41: loss = 0.008052\n",
      "Epoch 54, batch 42: loss = 0.008401\n",
      "Epoch 54, batch 43: loss = 0.007656\n",
      "Epoch 54, batch 44: loss = 0.008106\n",
      "Epoch 54, batch 45: loss = 0.007980\n",
      "Epoch 54, batch 46: loss = 0.008189\n",
      "Epoch 54, batch 47: loss = 0.008022\n",
      "Epoch 54, batch 48: loss = 0.008068\n",
      "Epoch 54, batch 49: loss = 0.007828\n",
      "Epoch 54, batch 50: loss = 0.008112\n",
      "Epoch 54, batch 51: loss = 0.007973\n",
      "Epoch 54, batch 52: loss = 0.007846\n",
      "Epoch 54, batch 53: loss = 0.008152\n",
      "Epoch 54, batch 54: loss = 0.007888\n",
      "Epoch 54, batch 55: loss = 0.007218\n",
      "Epoch 54, batch 56: loss = 0.008184\n",
      "Epoch 54, batch 57: loss = 0.007397\n",
      "Epoch 54, batch 58: loss = 0.007361\n",
      "Epoch 54, batch 59: loss = 0.007596\n",
      "Epoch 54, batch 60: loss = 0.008152\n",
      "Epoch 54, batch 61: loss = 0.007733\n",
      "Epoch 54, batch 62: loss = 0.007547\n",
      "Epoch 54, batch 63: loss = 0.007968\n",
      "Epoch 54, batch 64: loss = 0.007913\n",
      "Epoch 54, batch 65: loss = 0.007875\n",
      "Epoch 54, batch 66: loss = 0.007792\n",
      "Epoch 54, batch 67: loss = 0.007687\n",
      "Epoch 54, batch 68: loss = 0.008265\n",
      "Epoch 54, batch 69: loss = 0.007528\n",
      "Epoch 54, batch 70: loss = 0.007816\n",
      "Epoch 54, batch 71: loss = 0.007846\n",
      "Epoch 54, batch 72: loss = 0.007691\n",
      "Epoch 54, batch 73: loss = 0.007489\n",
      "Epoch 54, batch 74: loss = 0.007519\n",
      "Epoch 54, batch 75: loss = 0.007378\n",
      "Epoch 54, batch 76: loss = 0.007242\n",
      "Epoch 54, batch 77: loss = 0.007484\n",
      "Epoch 54, batch 78: loss = 0.007099\n",
      "Epoch 54, batch 79: loss = 0.007175\n",
      "Epoch 54, batch 80: loss = 0.007789\n",
      "Epoch 54, batch 81: loss = 0.008162\n",
      "Epoch 54, batch 82: loss = 0.009495\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 54: val_loss = 0.034727\n",
      "Epoch 55, batch 0: loss = 0.007848\n",
      "Epoch 55, batch 1: loss = 0.007613\n",
      "Epoch 55, batch 2: loss = 0.007509\n",
      "Epoch 55, batch 3: loss = 0.007974\n",
      "Epoch 55, batch 4: loss = 0.007875\n",
      "Epoch 55, batch 5: loss = 0.007973\n",
      "Epoch 55, batch 6: loss = 0.007753\n",
      "Epoch 55, batch 7: loss = 0.007512\n",
      "Epoch 55, batch 8: loss = 0.008204\n",
      "Epoch 55, batch 9: loss = 0.008473\n",
      "Epoch 55, batch 10: loss = 0.007379\n",
      "Epoch 55, batch 11: loss = 0.008149\n",
      "Epoch 55, batch 12: loss = 0.007770\n",
      "Epoch 55, batch 13: loss = 0.007680\n",
      "Epoch 55, batch 14: loss = 0.007373\n",
      "Epoch 55, batch 15: loss = 0.007490\n",
      "Epoch 55, batch 16: loss = 0.007916\n",
      "Epoch 55, batch 17: loss = 0.007480\n",
      "Epoch 55, batch 18: loss = 0.007727\n",
      "Epoch 55, batch 19: loss = 0.007836\n",
      "Epoch 55, batch 20: loss = 0.007446\n",
      "Epoch 55, batch 21: loss = 0.007657\n",
      "Epoch 55, batch 22: loss = 0.007883\n",
      "Epoch 55, batch 23: loss = 0.007600\n",
      "Epoch 55, batch 24: loss = 0.008455\n",
      "Epoch 55, batch 25: loss = 0.007500\n",
      "Epoch 55, batch 26: loss = 0.007969\n",
      "Epoch 55, batch 27: loss = 0.007956\n",
      "Epoch 55, batch 28: loss = 0.007436\n",
      "Epoch 55, batch 29: loss = 0.007506\n",
      "Epoch 55, batch 30: loss = 0.007685\n",
      "Epoch 55, batch 31: loss = 0.007431\n",
      "Epoch 55, batch 32: loss = 0.007618\n",
      "Epoch 55, batch 33: loss = 0.007685\n",
      "Epoch 55, batch 34: loss = 0.007699\n",
      "Epoch 55, batch 35: loss = 0.008444\n",
      "Epoch 55, batch 36: loss = 0.007761\n",
      "Epoch 55, batch 37: loss = 0.007658\n",
      "Epoch 55, batch 38: loss = 0.007785\n",
      "Epoch 55, batch 39: loss = 0.007271\n",
      "Epoch 55, batch 40: loss = 0.007625\n",
      "Epoch 55, batch 41: loss = 0.007189\n",
      "Epoch 55, batch 42: loss = 0.007813\n",
      "Epoch 55, batch 43: loss = 0.008032\n",
      "Epoch 55, batch 44: loss = 0.007811\n",
      "Epoch 55, batch 45: loss = 0.007594\n",
      "Epoch 55, batch 46: loss = 0.008340\n",
      "Epoch 55, batch 47: loss = 0.007740\n",
      "Epoch 55, batch 48: loss = 0.007410\n",
      "Epoch 55, batch 49: loss = 0.007662\n",
      "Epoch 55, batch 50: loss = 0.007367\n",
      "Epoch 55, batch 51: loss = 0.008412\n",
      "Epoch 55, batch 52: loss = 0.007134\n",
      "Epoch 55, batch 53: loss = 0.008060\n",
      "Epoch 55, batch 54: loss = 0.007754\n",
      "Epoch 55, batch 55: loss = 0.007690\n",
      "Epoch 55, batch 56: loss = 0.007236\n",
      "Epoch 55, batch 57: loss = 0.007911\n",
      "Epoch 55, batch 58: loss = 0.007744\n",
      "Epoch 55, batch 59: loss = 0.007398\n",
      "Epoch 55, batch 60: loss = 0.007819\n",
      "Epoch 55, batch 61: loss = 0.007650\n",
      "Epoch 55, batch 62: loss = 0.007615\n",
      "Epoch 55, batch 63: loss = 0.008005\n",
      "Epoch 55, batch 64: loss = 0.007307\n",
      "Epoch 55, batch 65: loss = 0.007480\n",
      "Epoch 55, batch 66: loss = 0.007255\n",
      "Epoch 55, batch 67: loss = 0.006905\n",
      "Epoch 55, batch 68: loss = 0.007872\n",
      "Epoch 55, batch 69: loss = 0.007073\n",
      "Epoch 55, batch 70: loss = 0.007142\n",
      "Epoch 55, batch 71: loss = 0.006672\n",
      "Epoch 55, batch 72: loss = 0.007457\n",
      "Epoch 55, batch 73: loss = 0.007428\n",
      "Epoch 55, batch 74: loss = 0.007202\n",
      "Epoch 55, batch 75: loss = 0.007365\n",
      "Epoch 55, batch 76: loss = 0.007729\n",
      "Epoch 55, batch 77: loss = 0.006797\n",
      "Epoch 55, batch 78: loss = 0.007259\n",
      "Epoch 55, batch 79: loss = 0.007098\n",
      "Epoch 55, batch 80: loss = 0.007153\n",
      "Epoch 55, batch 81: loss = 0.007415\n",
      "Epoch 55, batch 82: loss = 0.007217\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 55: val_loss = 0.036187\n",
      "Epoch 56, batch 0: loss = 0.007391\n",
      "Epoch 56, batch 1: loss = 0.007867\n",
      "Epoch 56, batch 2: loss = 0.007592\n",
      "Epoch 56, batch 3: loss = 0.007807\n",
      "Epoch 56, batch 4: loss = 0.007564\n",
      "Epoch 56, batch 5: loss = 0.007332\n",
      "Epoch 56, batch 6: loss = 0.007634\n",
      "Epoch 56, batch 7: loss = 0.007477\n",
      "Epoch 56, batch 8: loss = 0.008371\n",
      "Epoch 56, batch 9: loss = 0.007672\n",
      "Epoch 56, batch 10: loss = 0.007668\n",
      "Epoch 56, batch 11: loss = 0.007906\n",
      "Epoch 56, batch 12: loss = 0.007644\n",
      "Epoch 56, batch 13: loss = 0.007763\n",
      "Epoch 56, batch 14: loss = 0.007541\n",
      "Epoch 56, batch 15: loss = 0.007442\n",
      "Epoch 56, batch 16: loss = 0.007084\n",
      "Epoch 56, batch 17: loss = 0.007395\n",
      "Epoch 56, batch 18: loss = 0.007609\n",
      "Epoch 56, batch 19: loss = 0.007728\n",
      "Epoch 56, batch 20: loss = 0.007847\n",
      "Epoch 56, batch 21: loss = 0.007587\n",
      "Epoch 56, batch 22: loss = 0.007204\n",
      "Epoch 56, batch 23: loss = 0.006792\n",
      "Epoch 56, batch 24: loss = 0.008861\n",
      "Epoch 56, batch 25: loss = 0.007410\n",
      "Epoch 56, batch 26: loss = 0.007309\n",
      "Epoch 56, batch 27: loss = 0.008403\n",
      "Epoch 56, batch 28: loss = 0.007608\n",
      "Epoch 56, batch 29: loss = 0.007708\n",
      "Epoch 56, batch 30: loss = 0.007823\n",
      "Epoch 56, batch 31: loss = 0.007464\n",
      "Epoch 56, batch 32: loss = 0.007649\n",
      "Epoch 56, batch 33: loss = 0.007183\n",
      "Epoch 56, batch 34: loss = 0.007650\n",
      "Epoch 56, batch 35: loss = 0.007230\n",
      "Epoch 56, batch 36: loss = 0.008041\n",
      "Epoch 56, batch 37: loss = 0.007049\n",
      "Epoch 56, batch 38: loss = 0.007759\n",
      "Epoch 56, batch 39: loss = 0.007389\n",
      "Epoch 56, batch 40: loss = 0.006905\n",
      "Epoch 56, batch 41: loss = 0.007461\n",
      "Epoch 56, batch 42: loss = 0.007462\n",
      "Epoch 56, batch 43: loss = 0.007120\n",
      "Epoch 56, batch 44: loss = 0.007471\n",
      "Epoch 56, batch 45: loss = 0.007831\n",
      "Epoch 56, batch 46: loss = 0.007511\n",
      "Epoch 56, batch 47: loss = 0.007399\n",
      "Epoch 56, batch 48: loss = 0.007903\n",
      "Epoch 56, batch 49: loss = 0.007542\n",
      "Epoch 56, batch 50: loss = 0.007422\n",
      "Epoch 56, batch 51: loss = 0.007270\n",
      "Epoch 56, batch 52: loss = 0.007628\n",
      "Epoch 56, batch 53: loss = 0.007134\n",
      "Epoch 56, batch 54: loss = 0.007537\n",
      "Epoch 56, batch 55: loss = 0.007090\n",
      "Epoch 56, batch 56: loss = 0.006948\n",
      "Epoch 56, batch 57: loss = 0.007471\n",
      "Epoch 56, batch 58: loss = 0.007609\n",
      "Epoch 56, batch 59: loss = 0.007317\n",
      "Epoch 56, batch 60: loss = 0.007560\n",
      "Epoch 56, batch 61: loss = 0.007367\n",
      "Epoch 56, batch 62: loss = 0.007422\n",
      "Epoch 56, batch 63: loss = 0.007725\n",
      "Epoch 56, batch 64: loss = 0.007477\n",
      "Epoch 56, batch 65: loss = 0.007606\n",
      "Epoch 56, batch 66: loss = 0.007726\n",
      "Epoch 56, batch 67: loss = 0.007942\n",
      "Epoch 56, batch 68: loss = 0.007170\n",
      "Epoch 56, batch 69: loss = 0.007049\n",
      "Epoch 56, batch 70: loss = 0.006713\n",
      "Epoch 56, batch 71: loss = 0.007662\n",
      "Epoch 56, batch 72: loss = 0.007683\n",
      "Epoch 56, batch 73: loss = 0.006964\n",
      "Epoch 56, batch 74: loss = 0.007958\n",
      "Epoch 56, batch 75: loss = 0.007565\n",
      "Epoch 56, batch 76: loss = 0.007440\n",
      "Epoch 56, batch 77: loss = 0.007616\n",
      "Epoch 56, batch 78: loss = 0.007358\n",
      "Epoch 56, batch 79: loss = 0.007127\n",
      "Epoch 56, batch 80: loss = 0.007742\n",
      "Epoch 56, batch 81: loss = 0.007251\n",
      "Epoch 56, batch 82: loss = 0.005250\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 56: val_loss = 0.034927\n",
      "Epoch 57, batch 0: loss = 0.007131\n",
      "Epoch 57, batch 1: loss = 0.007488\n",
      "Epoch 57, batch 2: loss = 0.007454\n",
      "Epoch 57, batch 3: loss = 0.007102\n",
      "Epoch 57, batch 4: loss = 0.007317\n",
      "Epoch 57, batch 5: loss = 0.007669\n",
      "Epoch 57, batch 6: loss = 0.008249\n",
      "Epoch 57, batch 7: loss = 0.007375\n",
      "Epoch 57, batch 8: loss = 0.007323\n",
      "Epoch 57, batch 9: loss = 0.007580\n",
      "Epoch 57, batch 10: loss = 0.007816\n",
      "Epoch 57, batch 11: loss = 0.007640\n",
      "Epoch 57, batch 12: loss = 0.007961\n",
      "Epoch 57, batch 13: loss = 0.007914\n",
      "Epoch 57, batch 14: loss = 0.007838\n",
      "Epoch 57, batch 15: loss = 0.007467\n",
      "Epoch 57, batch 16: loss = 0.007297\n",
      "Epoch 57, batch 17: loss = 0.007527\n",
      "Epoch 57, batch 18: loss = 0.007939\n",
      "Epoch 57, batch 19: loss = 0.007333\n",
      "Epoch 57, batch 20: loss = 0.006996\n",
      "Epoch 57, batch 21: loss = 0.007441\n",
      "Epoch 57, batch 22: loss = 0.007719\n",
      "Epoch 57, batch 23: loss = 0.007522\n",
      "Epoch 57, batch 24: loss = 0.007556\n",
      "Epoch 57, batch 25: loss = 0.007179\n",
      "Epoch 57, batch 26: loss = 0.008180\n",
      "Epoch 57, batch 27: loss = 0.007576\n",
      "Epoch 57, batch 28: loss = 0.007708\n",
      "Epoch 57, batch 29: loss = 0.007795\n",
      "Epoch 57, batch 30: loss = 0.007585\n",
      "Epoch 57, batch 31: loss = 0.007177\n",
      "Epoch 57, batch 32: loss = 0.007421\n",
      "Epoch 57, batch 33: loss = 0.007123\n",
      "Epoch 57, batch 34: loss = 0.007543\n",
      "Epoch 57, batch 35: loss = 0.007389\n",
      "Epoch 57, batch 36: loss = 0.007369\n",
      "Epoch 57, batch 37: loss = 0.006626\n",
      "Epoch 57, batch 38: loss = 0.007415\n",
      "Epoch 57, batch 39: loss = 0.007946\n",
      "Epoch 57, batch 40: loss = 0.007785\n",
      "Epoch 57, batch 41: loss = 0.007553\n",
      "Epoch 57, batch 42: loss = 0.007574\n",
      "Epoch 57, batch 43: loss = 0.007654\n",
      "Epoch 57, batch 44: loss = 0.007191\n",
      "Epoch 57, batch 45: loss = 0.007275\n",
      "Epoch 57, batch 46: loss = 0.007922\n",
      "Epoch 57, batch 47: loss = 0.007258\n",
      "Epoch 57, batch 48: loss = 0.007423\n",
      "Epoch 57, batch 49: loss = 0.007057\n",
      "Epoch 57, batch 50: loss = 0.007593\n",
      "Epoch 57, batch 51: loss = 0.007210\n",
      "Epoch 57, batch 52: loss = 0.007358\n",
      "Epoch 57, batch 53: loss = 0.006877\n",
      "Epoch 57, batch 54: loss = 0.007197\n",
      "Epoch 57, batch 55: loss = 0.006748\n",
      "Epoch 57, batch 56: loss = 0.007701\n",
      "Epoch 57, batch 57: loss = 0.006999\n",
      "Epoch 57, batch 58: loss = 0.007395\n",
      "Epoch 57, batch 59: loss = 0.007208\n",
      "Epoch 57, batch 60: loss = 0.007223\n",
      "Epoch 57, batch 61: loss = 0.007123\n",
      "Epoch 57, batch 62: loss = 0.006957\n",
      "Epoch 57, batch 63: loss = 0.006884\n",
      "Epoch 57, batch 64: loss = 0.007561\n",
      "Epoch 57, batch 65: loss = 0.007667\n",
      "Epoch 57, batch 66: loss = 0.007544\n",
      "Epoch 57, batch 67: loss = 0.007396\n",
      "Epoch 57, batch 68: loss = 0.007659\n",
      "Epoch 57, batch 69: loss = 0.007318\n",
      "Epoch 57, batch 70: loss = 0.007202\n",
      "Epoch 57, batch 71: loss = 0.007347\n",
      "Epoch 57, batch 72: loss = 0.007031\n",
      "Epoch 57, batch 73: loss = 0.007284\n",
      "Epoch 57, batch 74: loss = 0.007615\n",
      "Epoch 57, batch 75: loss = 0.007721\n",
      "Epoch 57, batch 76: loss = 0.007101\n",
      "Epoch 57, batch 77: loss = 0.007176\n",
      "Epoch 57, batch 78: loss = 0.007703\n",
      "Epoch 57, batch 79: loss = 0.007170\n",
      "Epoch 57, batch 80: loss = 0.007380\n",
      "Epoch 57, batch 81: loss = 0.007021\n",
      "Epoch 57, batch 82: loss = 0.004275\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 57: val_loss = 0.040149\n",
      "Epoch 58, batch 0: loss = 0.007976\n",
      "Epoch 58, batch 1: loss = 0.008106\n",
      "Epoch 58, batch 2: loss = 0.007516\n",
      "Epoch 58, batch 3: loss = 0.008100\n",
      "Epoch 58, batch 4: loss = 0.007743\n",
      "Epoch 58, batch 5: loss = 0.007873\n",
      "Epoch 58, batch 6: loss = 0.007839\n",
      "Epoch 58, batch 7: loss = 0.007831\n",
      "Epoch 58, batch 8: loss = 0.008174\n",
      "Epoch 58, batch 9: loss = 0.007586\n",
      "Epoch 58, batch 10: loss = 0.007542\n",
      "Epoch 58, batch 11: loss = 0.007968\n",
      "Epoch 58, batch 12: loss = 0.007792\n",
      "Epoch 58, batch 13: loss = 0.007988\n",
      "Epoch 58, batch 14: loss = 0.007878\n",
      "Epoch 58, batch 15: loss = 0.007731\n",
      "Epoch 58, batch 16: loss = 0.008630\n",
      "Epoch 58, batch 17: loss = 0.007991\n",
      "Epoch 58, batch 18: loss = 0.007508\n",
      "Epoch 58, batch 19: loss = 0.007254\n",
      "Epoch 58, batch 20: loss = 0.008130\n",
      "Epoch 58, batch 21: loss = 0.007044\n",
      "Epoch 58, batch 22: loss = 0.007530\n",
      "Epoch 58, batch 23: loss = 0.007255\n",
      "Epoch 58, batch 24: loss = 0.007449\n",
      "Epoch 58, batch 25: loss = 0.007918\n",
      "Epoch 58, batch 26: loss = 0.008083\n",
      "Epoch 58, batch 27: loss = 0.007644\n",
      "Epoch 58, batch 28: loss = 0.007466\n",
      "Epoch 58, batch 29: loss = 0.007185\n",
      "Epoch 58, batch 30: loss = 0.007491\n",
      "Epoch 58, batch 31: loss = 0.007100\n",
      "Epoch 58, batch 32: loss = 0.007390\n",
      "Epoch 58, batch 33: loss = 0.007244\n",
      "Epoch 58, batch 34: loss = 0.007329\n",
      "Epoch 58, batch 35: loss = 0.007087\n",
      "Epoch 58, batch 36: loss = 0.007511\n",
      "Epoch 58, batch 37: loss = 0.008055\n",
      "Epoch 58, batch 38: loss = 0.007156\n",
      "Epoch 58, batch 39: loss = 0.007040\n",
      "Epoch 58, batch 40: loss = 0.006935\n",
      "Epoch 58, batch 41: loss = 0.007746\n",
      "Epoch 58, batch 42: loss = 0.007161\n",
      "Epoch 58, batch 43: loss = 0.007257\n",
      "Epoch 58, batch 44: loss = 0.008097\n",
      "Epoch 58, batch 45: loss = 0.007105\n",
      "Epoch 58, batch 46: loss = 0.006953\n",
      "Epoch 58, batch 47: loss = 0.007508\n",
      "Epoch 58, batch 48: loss = 0.007664\n",
      "Epoch 58, batch 49: loss = 0.007788\n",
      "Epoch 58, batch 50: loss = 0.006994\n",
      "Epoch 58, batch 51: loss = 0.007313\n",
      "Epoch 58, batch 52: loss = 0.007486\n",
      "Epoch 58, batch 53: loss = 0.007534\n",
      "Epoch 58, batch 54: loss = 0.007212\n",
      "Epoch 58, batch 55: loss = 0.008057\n",
      "Epoch 58, batch 56: loss = 0.008024\n",
      "Epoch 58, batch 57: loss = 0.007532\n",
      "Epoch 58, batch 58: loss = 0.007757\n",
      "Epoch 58, batch 59: loss = 0.007666\n",
      "Epoch 58, batch 60: loss = 0.007481\n",
      "Epoch 58, batch 61: loss = 0.007398\n",
      "Epoch 58, batch 62: loss = 0.007778\n",
      "Epoch 58, batch 63: loss = 0.007622\n",
      "Epoch 58, batch 64: loss = 0.007480\n",
      "Epoch 58, batch 65: loss = 0.007774\n",
      "Epoch 58, batch 66: loss = 0.007209\n",
      "Epoch 58, batch 67: loss = 0.007502\n",
      "Epoch 58, batch 68: loss = 0.007931\n",
      "Epoch 58, batch 69: loss = 0.007693\n",
      "Epoch 58, batch 70: loss = 0.007720\n",
      "Epoch 58, batch 71: loss = 0.006997\n",
      "Epoch 58, batch 72: loss = 0.008043\n",
      "Epoch 58, batch 73: loss = 0.007273\n",
      "Epoch 58, batch 74: loss = 0.007605\n",
      "Epoch 58, batch 75: loss = 0.007476\n",
      "Epoch 58, batch 76: loss = 0.006818\n",
      "Epoch 58, batch 77: loss = 0.007043\n",
      "Epoch 58, batch 78: loss = 0.007403\n",
      "Epoch 58, batch 79: loss = 0.007520\n",
      "Epoch 58, batch 80: loss = 0.006764\n",
      "Epoch 58, batch 81: loss = 0.007491\n",
      "Epoch 58, batch 82: loss = 0.006337\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 58: val_loss = 0.036369\n",
      "Epoch 59, batch 0: loss = 0.007609\n",
      "Epoch 59, batch 1: loss = 0.007390\n",
      "Epoch 59, batch 2: loss = 0.007575\n",
      "Epoch 59, batch 3: loss = 0.007286\n",
      "Epoch 59, batch 4: loss = 0.007093\n",
      "Epoch 59, batch 5: loss = 0.006827\n",
      "Epoch 59, batch 6: loss = 0.007151\n",
      "Epoch 59, batch 7: loss = 0.008784\n",
      "Epoch 59, batch 8: loss = 0.009766\n",
      "Epoch 59, batch 9: loss = 0.010464\n",
      "Epoch 59, batch 10: loss = 0.009933\n",
      "Epoch 59, batch 11: loss = 0.010261\n",
      "Epoch 59, batch 12: loss = 0.010633\n",
      "Epoch 59, batch 13: loss = 0.010930\n",
      "Epoch 59, batch 14: loss = 0.010367\n",
      "Epoch 59, batch 15: loss = 0.009832\n",
      "Epoch 59, batch 16: loss = 0.009949\n",
      "Epoch 59, batch 17: loss = 0.009186\n",
      "Epoch 59, batch 18: loss = 0.009958\n",
      "Epoch 59, batch 19: loss = 0.009512\n",
      "Epoch 59, batch 20: loss = 0.009552\n",
      "Epoch 59, batch 21: loss = 0.009302\n",
      "Epoch 59, batch 22: loss = 0.009305\n",
      "Epoch 59, batch 23: loss = 0.008995\n",
      "Epoch 59, batch 24: loss = 0.008884\n",
      "Epoch 59, batch 25: loss = 0.008878\n",
      "Epoch 59, batch 26: loss = 0.008904\n",
      "Epoch 59, batch 27: loss = 0.008985\n",
      "Epoch 59, batch 28: loss = 0.009015\n",
      "Epoch 59, batch 29: loss = 0.009147\n",
      "Epoch 59, batch 30: loss = 0.009081\n",
      "Epoch 59, batch 31: loss = 0.008984\n",
      "Epoch 59, batch 32: loss = 0.009311\n",
      "Epoch 59, batch 33: loss = 0.009216\n",
      "Epoch 59, batch 34: loss = 0.008895\n",
      "Epoch 59, batch 35: loss = 0.009097\n",
      "Epoch 59, batch 36: loss = 0.008906\n",
      "Epoch 59, batch 37: loss = 0.009464\n",
      "Epoch 59, batch 38: loss = 0.009621\n",
      "Epoch 59, batch 39: loss = 0.008906\n",
      "Epoch 59, batch 40: loss = 0.010455\n",
      "Epoch 59, batch 41: loss = 0.010032\n",
      "Epoch 59, batch 42: loss = 0.009665\n",
      "Epoch 59, batch 43: loss = 0.010213\n",
      "Epoch 59, batch 44: loss = 0.009416\n",
      "Epoch 59, batch 45: loss = 0.008981\n",
      "Epoch 59, batch 46: loss = 0.010079\n",
      "Epoch 59, batch 47: loss = 0.009833\n",
      "Epoch 59, batch 48: loss = 0.009056\n",
      "Epoch 59, batch 49: loss = 0.008884\n",
      "Epoch 59, batch 50: loss = 0.009356\n",
      "Epoch 59, batch 51: loss = 0.009146\n",
      "Epoch 59, batch 52: loss = 0.008715\n",
      "Epoch 59, batch 53: loss = 0.008052\n",
      "Epoch 59, batch 54: loss = 0.008975\n",
      "Epoch 59, batch 55: loss = 0.008575\n",
      "Epoch 59, batch 56: loss = 0.008643\n",
      "Epoch 59, batch 57: loss = 0.009153\n",
      "Epoch 59, batch 58: loss = 0.010025\n",
      "Epoch 59, batch 59: loss = 0.008731\n",
      "Epoch 59, batch 60: loss = 0.008455\n",
      "Epoch 59, batch 61: loss = 0.008487\n",
      "Epoch 59, batch 62: loss = 0.008328\n",
      "Epoch 59, batch 63: loss = 0.008754\n",
      "Epoch 59, batch 64: loss = 0.007863\n",
      "Epoch 59, batch 65: loss = 0.009230\n",
      "Epoch 59, batch 66: loss = 0.008405\n",
      "Epoch 59, batch 67: loss = 0.008729\n",
      "Epoch 59, batch 68: loss = 0.008616\n",
      "Epoch 59, batch 69: loss = 0.009058\n",
      "Epoch 59, batch 70: loss = 0.008529\n",
      "Epoch 59, batch 71: loss = 0.008738\n",
      "Epoch 59, batch 72: loss = 0.008561\n",
      "Epoch 59, batch 73: loss = 0.008369\n",
      "Epoch 59, batch 74: loss = 0.008705\n",
      "Epoch 59, batch 75: loss = 0.008592\n",
      "Epoch 59, batch 76: loss = 0.008206\n",
      "Epoch 59, batch 77: loss = 0.007881\n",
      "Epoch 59, batch 78: loss = 0.008415\n",
      "Epoch 59, batch 79: loss = 0.008209\n",
      "Epoch 59, batch 80: loss = 0.007885\n",
      "Epoch 59, batch 81: loss = 0.008367\n",
      "Epoch 59, batch 82: loss = 0.007884\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 59: val_loss = 0.034121\n",
      "Epoch 60, batch 0: loss = 0.008624\n",
      "Epoch 60, batch 1: loss = 0.009398\n",
      "Epoch 60, batch 2: loss = 0.008992\n",
      "Epoch 60, batch 3: loss = 0.008938\n",
      "Epoch 60, batch 4: loss = 0.008925\n",
      "Epoch 60, batch 5: loss = 0.008525\n",
      "Epoch 60, batch 6: loss = 0.009453\n",
      "Epoch 60, batch 7: loss = 0.009069\n",
      "Epoch 60, batch 8: loss = 0.008971\n",
      "Epoch 60, batch 9: loss = 0.008658\n",
      "Epoch 60, batch 10: loss = 0.008664\n",
      "Epoch 60, batch 11: loss = 0.009180\n",
      "Epoch 60, batch 12: loss = 0.009057\n",
      "Epoch 60, batch 13: loss = 0.008925\n",
      "Epoch 60, batch 14: loss = 0.008901\n",
      "Epoch 60, batch 15: loss = 0.008435\n",
      "Epoch 60, batch 16: loss = 0.008230\n",
      "Epoch 60, batch 17: loss = 0.009062\n",
      "Epoch 60, batch 18: loss = 0.008421\n",
      "Epoch 60, batch 19: loss = 0.008474\n",
      "Epoch 60, batch 20: loss = 0.008152\n",
      "Epoch 60, batch 21: loss = 0.008064\n",
      "Epoch 60, batch 22: loss = 0.007863\n",
      "Epoch 60, batch 23: loss = 0.007975\n",
      "Epoch 60, batch 24: loss = 0.008429\n",
      "Epoch 60, batch 25: loss = 0.008401\n",
      "Epoch 60, batch 26: loss = 0.007894\n",
      "Epoch 60, batch 27: loss = 0.007956\n",
      "Epoch 60, batch 28: loss = 0.008239\n",
      "Epoch 60, batch 29: loss = 0.008129\n",
      "Epoch 60, batch 30: loss = 0.007816\n",
      "Epoch 60, batch 31: loss = 0.007675\n",
      "Epoch 60, batch 32: loss = 0.007956\n",
      "Epoch 60, batch 33: loss = 0.008081\n",
      "Epoch 60, batch 34: loss = 0.007733\n",
      "Epoch 60, batch 35: loss = 0.008432\n",
      "Epoch 60, batch 36: loss = 0.008231\n",
      "Epoch 60, batch 37: loss = 0.007846\n",
      "Epoch 60, batch 38: loss = 0.008436\n",
      "Epoch 60, batch 39: loss = 0.008735\n",
      "Epoch 60, batch 40: loss = 0.008048\n",
      "Epoch 60, batch 41: loss = 0.008443\n",
      "Epoch 60, batch 42: loss = 0.008155\n",
      "Epoch 60, batch 43: loss = 0.008875\n",
      "Epoch 60, batch 44: loss = 0.008115\n",
      "Epoch 60, batch 45: loss = 0.008351\n",
      "Epoch 60, batch 46: loss = 0.008096\n",
      "Epoch 60, batch 47: loss = 0.007783\n",
      "Epoch 60, batch 48: loss = 0.008848\n",
      "Epoch 60, batch 49: loss = 0.007941\n",
      "Epoch 60, batch 50: loss = 0.007938\n",
      "Epoch 60, batch 51: loss = 0.008024\n",
      "Epoch 60, batch 52: loss = 0.008336\n",
      "Epoch 60, batch 53: loss = 0.007787\n",
      "Epoch 60, batch 54: loss = 0.008623\n",
      "Epoch 60, batch 55: loss = 0.008095\n",
      "Epoch 60, batch 56: loss = 0.008796\n",
      "Epoch 60, batch 57: loss = 0.007691\n",
      "Epoch 60, batch 58: loss = 0.007604\n",
      "Epoch 60, batch 59: loss = 0.007871\n",
      "Epoch 60, batch 60: loss = 0.007986\n",
      "Epoch 60, batch 61: loss = 0.008289\n",
      "Epoch 60, batch 62: loss = 0.008140\n",
      "Epoch 60, batch 63: loss = 0.008421\n",
      "Epoch 60, batch 64: loss = 0.008397\n",
      "Epoch 60, batch 65: loss = 0.007961\n",
      "Epoch 60, batch 66: loss = 0.007535\n",
      "Epoch 60, batch 67: loss = 0.007617\n",
      "Epoch 60, batch 68: loss = 0.007603\n",
      "Epoch 60, batch 69: loss = 0.007751\n",
      "Epoch 60, batch 70: loss = 0.008196\n",
      "Epoch 60, batch 71: loss = 0.007995\n",
      "Epoch 60, batch 72: loss = 0.007577\n",
      "Epoch 60, batch 73: loss = 0.007494\n",
      "Epoch 60, batch 74: loss = 0.007531\n",
      "Epoch 60, batch 75: loss = 0.008125\n",
      "Epoch 60, batch 76: loss = 0.007674\n",
      "Epoch 60, batch 77: loss = 0.007448\n",
      "Epoch 60, batch 78: loss = 0.007493\n",
      "Epoch 60, batch 79: loss = 0.007742\n",
      "Epoch 60, batch 80: loss = 0.007682\n",
      "Epoch 60, batch 81: loss = 0.007722\n",
      "Epoch 60, batch 82: loss = 0.010339\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 60: val_loss = 0.033553\n",
      "Epoch 61, batch 0: loss = 0.007338\n",
      "Epoch 61, batch 1: loss = 0.008123\n",
      "Epoch 61, batch 2: loss = 0.007916\n",
      "Epoch 61, batch 3: loss = 0.008476\n",
      "Epoch 61, batch 4: loss = 0.008183\n",
      "Epoch 61, batch 5: loss = 0.007865\n",
      "Epoch 61, batch 6: loss = 0.008305\n",
      "Epoch 61, batch 7: loss = 0.008293\n",
      "Epoch 61, batch 8: loss = 0.008511\n",
      "Epoch 61, batch 9: loss = 0.007418\n",
      "Epoch 61, batch 10: loss = 0.007824\n",
      "Epoch 61, batch 11: loss = 0.007848\n",
      "Epoch 61, batch 12: loss = 0.008062\n",
      "Epoch 61, batch 13: loss = 0.007437\n",
      "Epoch 61, batch 14: loss = 0.007687\n",
      "Epoch 61, batch 15: loss = 0.008534\n",
      "Epoch 61, batch 16: loss = 0.008062\n",
      "Epoch 61, batch 17: loss = 0.007679\n",
      "Epoch 61, batch 18: loss = 0.007786\n",
      "Epoch 61, batch 19: loss = 0.007539\n",
      "Epoch 61, batch 20: loss = 0.007621\n",
      "Epoch 61, batch 21: loss = 0.007367\n",
      "Epoch 61, batch 22: loss = 0.007073\n",
      "Epoch 61, batch 23: loss = 0.007719\n",
      "Epoch 61, batch 24: loss = 0.007571\n",
      "Epoch 61, batch 25: loss = 0.007742\n",
      "Epoch 61, batch 26: loss = 0.007639\n",
      "Epoch 61, batch 27: loss = 0.007878\n",
      "Epoch 61, batch 28: loss = 0.007529\n",
      "Epoch 61, batch 29: loss = 0.007385\n",
      "Epoch 61, batch 30: loss = 0.008025\n",
      "Epoch 61, batch 31: loss = 0.007453\n",
      "Epoch 61, batch 32: loss = 0.007040\n",
      "Epoch 61, batch 33: loss = 0.007376\n",
      "Epoch 61, batch 34: loss = 0.008074\n",
      "Epoch 61, batch 35: loss = 0.007010\n",
      "Epoch 61, batch 36: loss = 0.007357\n",
      "Epoch 61, batch 37: loss = 0.007500\n",
      "Epoch 61, batch 38: loss = 0.007378\n",
      "Epoch 61, batch 39: loss = 0.007201\n",
      "Epoch 61, batch 40: loss = 0.007514\n",
      "Epoch 61, batch 41: loss = 0.007764\n",
      "Epoch 61, batch 42: loss = 0.008351\n",
      "Epoch 61, batch 43: loss = 0.007566\n",
      "Epoch 61, batch 44: loss = 0.007842\n",
      "Epoch 61, batch 45: loss = 0.007383\n",
      "Epoch 61, batch 46: loss = 0.007410\n",
      "Epoch 61, batch 47: loss = 0.007302\n",
      "Epoch 61, batch 48: loss = 0.007471\n",
      "Epoch 61, batch 49: loss = 0.007633\n",
      "Epoch 61, batch 50: loss = 0.007780\n",
      "Epoch 61, batch 51: loss = 0.007485\n",
      "Epoch 61, batch 52: loss = 0.007869\n",
      "Epoch 61, batch 53: loss = 0.007359\n",
      "Epoch 61, batch 54: loss = 0.007467\n",
      "Epoch 61, batch 55: loss = 0.007968\n",
      "Epoch 61, batch 56: loss = 0.007439\n",
      "Epoch 61, batch 57: loss = 0.006831\n",
      "Epoch 61, batch 58: loss = 0.006901\n",
      "Epoch 61, batch 59: loss = 0.007181\n",
      "Epoch 61, batch 60: loss = 0.007163\n",
      "Epoch 61, batch 61: loss = 0.007335\n",
      "Epoch 61, batch 62: loss = 0.007616\n",
      "Epoch 61, batch 63: loss = 0.006963\n",
      "Epoch 61, batch 64: loss = 0.007615\n",
      "Epoch 61, batch 65: loss = 0.007844\n",
      "Epoch 61, batch 66: loss = 0.007119\n",
      "Epoch 61, batch 67: loss = 0.007159\n",
      "Epoch 61, batch 68: loss = 0.006969\n",
      "Epoch 61, batch 69: loss = 0.007338\n",
      "Epoch 61, batch 70: loss = 0.007685\n",
      "Epoch 61, batch 71: loss = 0.007681\n",
      "Epoch 61, batch 72: loss = 0.007691\n",
      "Epoch 61, batch 73: loss = 0.007764\n",
      "Epoch 61, batch 74: loss = 0.008000\n",
      "Epoch 61, batch 75: loss = 0.007072\n",
      "Epoch 61, batch 76: loss = 0.007860\n",
      "Epoch 61, batch 77: loss = 0.007423\n",
      "Epoch 61, batch 78: loss = 0.007222\n",
      "Epoch 61, batch 79: loss = 0.007471\n",
      "Epoch 61, batch 80: loss = 0.007505\n",
      "Epoch 61, batch 81: loss = 0.007364\n",
      "Epoch 61, batch 82: loss = 0.005791\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 61: val_loss = 0.034163\n",
      "Epoch 62, batch 0: loss = 0.007459\n",
      "Epoch 62, batch 1: loss = 0.007116\n",
      "Epoch 62, batch 2: loss = 0.007249\n",
      "Epoch 62, batch 3: loss = 0.007753\n",
      "Epoch 62, batch 4: loss = 0.007737\n",
      "Epoch 62, batch 5: loss = 0.007185\n",
      "Epoch 62, batch 6: loss = 0.007524\n",
      "Epoch 62, batch 7: loss = 0.007475\n",
      "Epoch 62, batch 8: loss = 0.006994\n",
      "Epoch 62, batch 9: loss = 0.007852\n",
      "Epoch 62, batch 10: loss = 0.007574\n",
      "Epoch 62, batch 11: loss = 0.007722\n",
      "Epoch 62, batch 12: loss = 0.007163\n",
      "Epoch 62, batch 13: loss = 0.007298\n",
      "Epoch 62, batch 14: loss = 0.007758\n",
      "Epoch 62, batch 15: loss = 0.007533\n",
      "Epoch 62, batch 16: loss = 0.007500\n",
      "Epoch 62, batch 17: loss = 0.007000\n",
      "Epoch 62, batch 18: loss = 0.007002\n",
      "Epoch 62, batch 19: loss = 0.008056\n",
      "Epoch 62, batch 20: loss = 0.007717\n",
      "Epoch 62, batch 21: loss = 0.008009\n",
      "Epoch 62, batch 22: loss = 0.007748\n",
      "Epoch 62, batch 23: loss = 0.007199\n",
      "Epoch 62, batch 24: loss = 0.008528\n",
      "Epoch 62, batch 25: loss = 0.007058\n",
      "Epoch 62, batch 26: loss = 0.007509\n",
      "Epoch 62, batch 27: loss = 0.007459\n",
      "Epoch 62, batch 28: loss = 0.007516\n",
      "Epoch 62, batch 29: loss = 0.007134\n",
      "Epoch 62, batch 30: loss = 0.008205\n",
      "Epoch 62, batch 31: loss = 0.007391\n",
      "Epoch 62, batch 32: loss = 0.007070\n",
      "Epoch 62, batch 33: loss = 0.007283\n",
      "Epoch 62, batch 34: loss = 0.007787\n",
      "Epoch 62, batch 35: loss = 0.007186\n",
      "Epoch 62, batch 36: loss = 0.007478\n",
      "Epoch 62, batch 37: loss = 0.007219\n",
      "Epoch 62, batch 38: loss = 0.007812\n",
      "Epoch 62, batch 39: loss = 0.007829\n",
      "Epoch 62, batch 40: loss = 0.007869\n",
      "Epoch 62, batch 41: loss = 0.007260\n",
      "Epoch 62, batch 42: loss = 0.007434\n",
      "Epoch 62, batch 43: loss = 0.007473\n",
      "Epoch 62, batch 44: loss = 0.007609\n",
      "Epoch 62, batch 45: loss = 0.007178\n",
      "Epoch 62, batch 46: loss = 0.007179\n",
      "Epoch 62, batch 47: loss = 0.007367\n",
      "Epoch 62, batch 48: loss = 0.007842\n",
      "Epoch 62, batch 49: loss = 0.007468\n",
      "Epoch 62, batch 50: loss = 0.007391\n",
      "Epoch 62, batch 51: loss = 0.007346\n",
      "Epoch 62, batch 52: loss = 0.007575\n",
      "Epoch 62, batch 53: loss = 0.007458\n",
      "Epoch 62, batch 54: loss = 0.007605\n",
      "Epoch 62, batch 55: loss = 0.007108\n",
      "Epoch 62, batch 56: loss = 0.007494\n",
      "Epoch 62, batch 57: loss = 0.006991\n",
      "Epoch 62, batch 58: loss = 0.007285\n",
      "Epoch 62, batch 59: loss = 0.007522\n",
      "Epoch 62, batch 60: loss = 0.006998\n",
      "Epoch 62, batch 61: loss = 0.007542\n",
      "Epoch 62, batch 62: loss = 0.007161\n",
      "Epoch 62, batch 63: loss = 0.006994\n",
      "Epoch 62, batch 64: loss = 0.007657\n",
      "Epoch 62, batch 65: loss = 0.007736\n",
      "Epoch 62, batch 66: loss = 0.007242\n",
      "Epoch 62, batch 67: loss = 0.006787\n",
      "Epoch 62, batch 68: loss = 0.006945\n",
      "Epoch 62, batch 69: loss = 0.007177\n",
      "Epoch 62, batch 70: loss = 0.007460\n",
      "Epoch 62, batch 71: loss = 0.007763\n",
      "Epoch 62, batch 72: loss = 0.007621\n",
      "Epoch 62, batch 73: loss = 0.007144\n",
      "Epoch 62, batch 74: loss = 0.007411\n",
      "Epoch 62, batch 75: loss = 0.006645\n",
      "Epoch 62, batch 76: loss = 0.007032\n",
      "Epoch 62, batch 77: loss = 0.006957\n",
      "Epoch 62, batch 78: loss = 0.006888\n",
      "Epoch 62, batch 79: loss = 0.007850\n",
      "Epoch 62, batch 80: loss = 0.007087\n",
      "Epoch 62, batch 81: loss = 0.007571\n",
      "Epoch 62, batch 82: loss = 0.006023\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 62: val_loss = 0.035863\n",
      "Epoch 63, batch 0: loss = 0.007610\n",
      "Epoch 63, batch 1: loss = 0.007508\n",
      "Epoch 63, batch 2: loss = 0.007515\n",
      "Epoch 63, batch 3: loss = 0.007327\n",
      "Epoch 63, batch 4: loss = 0.007215\n",
      "Epoch 63, batch 5: loss = 0.007749\n",
      "Epoch 63, batch 6: loss = 0.007362\n",
      "Epoch 63, batch 7: loss = 0.006979\n",
      "Epoch 63, batch 8: loss = 0.007404\n",
      "Epoch 63, batch 9: loss = 0.007519\n",
      "Epoch 63, batch 10: loss = 0.007185\n",
      "Epoch 63, batch 11: loss = 0.007041\n",
      "Epoch 63, batch 12: loss = 0.006988\n",
      "Epoch 63, batch 13: loss = 0.006803\n",
      "Epoch 63, batch 14: loss = 0.007641\n",
      "Epoch 63, batch 15: loss = 0.008164\n",
      "Epoch 63, batch 16: loss = 0.007271\n",
      "Epoch 63, batch 17: loss = 0.007820\n",
      "Epoch 63, batch 18: loss = 0.006781\n",
      "Epoch 63, batch 19: loss = 0.007543\n",
      "Epoch 63, batch 20: loss = 0.007321\n",
      "Epoch 63, batch 21: loss = 0.007134\n",
      "Epoch 63, batch 22: loss = 0.006802\n",
      "Epoch 63, batch 23: loss = 0.007051\n",
      "Epoch 63, batch 24: loss = 0.007363\n",
      "Epoch 63, batch 25: loss = 0.007251\n",
      "Epoch 63, batch 26: loss = 0.007462\n",
      "Epoch 63, batch 27: loss = 0.007344\n",
      "Epoch 63, batch 28: loss = 0.007082\n",
      "Epoch 63, batch 29: loss = 0.006561\n",
      "Epoch 63, batch 30: loss = 0.007185\n",
      "Epoch 63, batch 31: loss = 0.007038\n",
      "Epoch 63, batch 32: loss = 0.007327\n",
      "Epoch 63, batch 33: loss = 0.006841\n",
      "Epoch 63, batch 34: loss = 0.007358\n",
      "Epoch 63, batch 35: loss = 0.007343\n",
      "Epoch 63, batch 36: loss = 0.007192\n",
      "Epoch 63, batch 37: loss = 0.007709\n",
      "Epoch 63, batch 38: loss = 0.007310\n",
      "Epoch 63, batch 39: loss = 0.007386\n",
      "Epoch 63, batch 40: loss = 0.007340\n",
      "Epoch 63, batch 41: loss = 0.007244\n",
      "Epoch 63, batch 42: loss = 0.007360\n",
      "Epoch 63, batch 43: loss = 0.007150\n",
      "Epoch 63, batch 44: loss = 0.006999\n",
      "Epoch 63, batch 45: loss = 0.006990\n",
      "Epoch 63, batch 46: loss = 0.007725\n",
      "Epoch 63, batch 47: loss = 0.007160\n",
      "Epoch 63, batch 48: loss = 0.007144\n",
      "Epoch 63, batch 49: loss = 0.007274\n",
      "Epoch 63, batch 50: loss = 0.007402\n",
      "Epoch 63, batch 51: loss = 0.007061\n",
      "Epoch 63, batch 52: loss = 0.007582\n",
      "Epoch 63, batch 53: loss = 0.007568\n",
      "Epoch 63, batch 54: loss = 0.007007\n",
      "Epoch 63, batch 55: loss = 0.007223\n",
      "Epoch 63, batch 56: loss = 0.007754\n",
      "Epoch 63, batch 57: loss = 0.006905\n",
      "Epoch 63, batch 58: loss = 0.007638\n",
      "Epoch 63, batch 59: loss = 0.006890\n",
      "Epoch 63, batch 60: loss = 0.007491\n",
      "Epoch 63, batch 61: loss = 0.007414\n",
      "Epoch 63, batch 62: loss = 0.007541\n",
      "Epoch 63, batch 63: loss = 0.007579\n",
      "Epoch 63, batch 64: loss = 0.007095\n",
      "Epoch 63, batch 65: loss = 0.008607\n",
      "Epoch 63, batch 66: loss = 0.008132\n",
      "Epoch 63, batch 67: loss = 0.008602\n",
      "Epoch 63, batch 68: loss = 0.007810\n",
      "Epoch 63, batch 69: loss = 0.007363\n",
      "Epoch 63, batch 70: loss = 0.008272\n",
      "Epoch 63, batch 71: loss = 0.008525\n",
      "Epoch 63, batch 72: loss = 0.007619\n",
      "Epoch 63, batch 73: loss = 0.008207\n",
      "Epoch 63, batch 74: loss = 0.007529\n",
      "Epoch 63, batch 75: loss = 0.007497\n",
      "Epoch 63, batch 76: loss = 0.007623\n",
      "Epoch 63, batch 77: loss = 0.008823\n",
      "Epoch 63, batch 78: loss = 0.008729\n",
      "Epoch 63, batch 79: loss = 0.008274\n",
      "Epoch 63, batch 80: loss = 0.008719\n",
      "Epoch 63, batch 81: loss = 0.008568\n",
      "Epoch 63, batch 82: loss = 0.007713\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 63: val_loss = 0.036836\n",
      "Epoch 64, batch 0: loss = 0.008372\n",
      "Epoch 64, batch 1: loss = 0.008679\n",
      "Epoch 64, batch 2: loss = 0.007909\n",
      "Epoch 64, batch 3: loss = 0.008374\n",
      "Epoch 64, batch 4: loss = 0.008195\n",
      "Epoch 64, batch 5: loss = 0.008450\n",
      "Epoch 64, batch 6: loss = 0.008854\n",
      "Epoch 64, batch 7: loss = 0.008755\n",
      "Epoch 64, batch 8: loss = 0.007820\n",
      "Epoch 64, batch 9: loss = 0.009280\n",
      "Epoch 64, batch 10: loss = 0.007905\n",
      "Epoch 64, batch 11: loss = 0.008351\n",
      "Epoch 64, batch 12: loss = 0.007903\n",
      "Epoch 64, batch 13: loss = 0.008360\n",
      "Epoch 64, batch 14: loss = 0.007606\n",
      "Epoch 64, batch 15: loss = 0.007987\n",
      "Epoch 64, batch 16: loss = 0.007937\n",
      "Epoch 64, batch 17: loss = 0.008319\n",
      "Epoch 64, batch 18: loss = 0.007289\n",
      "Epoch 64, batch 19: loss = 0.008009\n",
      "Epoch 64, batch 20: loss = 0.007695\n",
      "Epoch 64, batch 21: loss = 0.007956\n",
      "Epoch 64, batch 22: loss = 0.007849\n",
      "Epoch 64, batch 23: loss = 0.007597\n",
      "Epoch 64, batch 24: loss = 0.007773\n",
      "Epoch 64, batch 25: loss = 0.008187\n",
      "Epoch 64, batch 26: loss = 0.007775\n",
      "Epoch 64, batch 27: loss = 0.008806\n",
      "Epoch 64, batch 28: loss = 0.007791\n",
      "Epoch 64, batch 29: loss = 0.008146\n",
      "Epoch 64, batch 30: loss = 0.007115\n",
      "Epoch 64, batch 31: loss = 0.007418\n",
      "Epoch 64, batch 32: loss = 0.007267\n",
      "Epoch 64, batch 33: loss = 0.007860\n",
      "Epoch 64, batch 34: loss = 0.007332\n",
      "Epoch 64, batch 35: loss = 0.007530\n",
      "Epoch 64, batch 36: loss = 0.007271\n",
      "Epoch 64, batch 37: loss = 0.007765\n",
      "Epoch 64, batch 38: loss = 0.008049\n",
      "Epoch 64, batch 39: loss = 0.007828\n",
      "Epoch 64, batch 40: loss = 0.006980\n",
      "Epoch 64, batch 41: loss = 0.007251\n",
      "Epoch 64, batch 42: loss = 0.007267\n",
      "Epoch 64, batch 43: loss = 0.007967\n",
      "Epoch 64, batch 44: loss = 0.007666\n",
      "Epoch 64, batch 45: loss = 0.007179\n",
      "Epoch 64, batch 46: loss = 0.007590\n",
      "Epoch 64, batch 47: loss = 0.007530\n",
      "Epoch 64, batch 48: loss = 0.007808\n",
      "Epoch 64, batch 49: loss = 0.007403\n",
      "Epoch 64, batch 50: loss = 0.007547\n",
      "Epoch 64, batch 51: loss = 0.007731\n",
      "Epoch 64, batch 52: loss = 0.007565\n",
      "Epoch 64, batch 53: loss = 0.007942\n",
      "Epoch 64, batch 54: loss = 0.007646\n",
      "Epoch 64, batch 55: loss = 0.007442\n",
      "Epoch 64, batch 56: loss = 0.008354\n",
      "Epoch 64, batch 57: loss = 0.007585\n",
      "Epoch 64, batch 58: loss = 0.007542\n",
      "Epoch 64, batch 59: loss = 0.007616\n",
      "Epoch 64, batch 60: loss = 0.007767\n",
      "Epoch 64, batch 61: loss = 0.006904\n",
      "Epoch 64, batch 62: loss = 0.007515\n",
      "Epoch 64, batch 63: loss = 0.007829\n",
      "Epoch 64, batch 64: loss = 0.007513\n",
      "Epoch 64, batch 65: loss = 0.007683\n",
      "Epoch 64, batch 66: loss = 0.007354\n",
      "Epoch 64, batch 67: loss = 0.006721\n",
      "Epoch 64, batch 68: loss = 0.007862\n",
      "Epoch 64, batch 69: loss = 0.007802\n",
      "Epoch 64, batch 70: loss = 0.007634\n",
      "Epoch 64, batch 71: loss = 0.006768\n",
      "Epoch 64, batch 72: loss = 0.007367\n",
      "Epoch 64, batch 73: loss = 0.006966\n",
      "Epoch 64, batch 74: loss = 0.007822\n",
      "Epoch 64, batch 75: loss = 0.007074\n",
      "Epoch 64, batch 76: loss = 0.007553\n",
      "Epoch 64, batch 77: loss = 0.007465\n",
      "Epoch 64, batch 78: loss = 0.007317\n",
      "Epoch 64, batch 79: loss = 0.007037\n",
      "Epoch 64, batch 80: loss = 0.007259\n",
      "Epoch 64, batch 81: loss = 0.007153\n",
      "Epoch 64, batch 82: loss = 0.007584\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 64: val_loss = 0.037013\n",
      "Epoch 65, batch 0: loss = 0.007750\n",
      "Epoch 65, batch 1: loss = 0.007040\n",
      "Epoch 65, batch 2: loss = 0.008303\n",
      "Epoch 65, batch 3: loss = 0.007782\n",
      "Epoch 65, batch 4: loss = 0.007399\n",
      "Epoch 65, batch 5: loss = 0.007628\n",
      "Epoch 65, batch 6: loss = 0.007416\n",
      "Epoch 65, batch 7: loss = 0.007714\n",
      "Epoch 65, batch 8: loss = 0.007571\n",
      "Epoch 65, batch 9: loss = 0.007581\n",
      "Epoch 65, batch 10: loss = 0.007211\n",
      "Epoch 65, batch 11: loss = 0.007561\n",
      "Epoch 65, batch 12: loss = 0.007357\n",
      "Epoch 65, batch 13: loss = 0.007807\n",
      "Epoch 65, batch 14: loss = 0.007320\n",
      "Epoch 65, batch 15: loss = 0.007977\n",
      "Epoch 65, batch 16: loss = 0.007504\n",
      "Epoch 65, batch 17: loss = 0.007117\n",
      "Epoch 65, batch 18: loss = 0.007260\n",
      "Epoch 65, batch 19: loss = 0.006879\n",
      "Epoch 65, batch 20: loss = 0.007761\n",
      "Epoch 65, batch 21: loss = 0.007086\n",
      "Epoch 65, batch 22: loss = 0.007220\n",
      "Epoch 65, batch 23: loss = 0.007170\n",
      "Epoch 65, batch 24: loss = 0.007459\n",
      "Epoch 65, batch 25: loss = 0.007163\n",
      "Epoch 65, batch 26: loss = 0.006980\n",
      "Epoch 65, batch 27: loss = 0.007383\n",
      "Epoch 65, batch 28: loss = 0.007467\n",
      "Epoch 65, batch 29: loss = 0.007839\n",
      "Epoch 65, batch 30: loss = 0.007200\n",
      "Epoch 65, batch 31: loss = 0.007410\n",
      "Epoch 65, batch 32: loss = 0.007246\n",
      "Epoch 65, batch 33: loss = 0.006866\n",
      "Epoch 65, batch 34: loss = 0.007480\n",
      "Epoch 65, batch 35: loss = 0.007204\n",
      "Epoch 65, batch 36: loss = 0.007072\n",
      "Epoch 65, batch 37: loss = 0.007107\n",
      "Epoch 65, batch 38: loss = 0.007220\n",
      "Epoch 65, batch 39: loss = 0.006813\n",
      "Epoch 65, batch 40: loss = 0.007426\n",
      "Epoch 65, batch 41: loss = 0.007135\n",
      "Epoch 65, batch 42: loss = 0.007225\n",
      "Epoch 65, batch 43: loss = 0.006868\n",
      "Epoch 65, batch 44: loss = 0.008144\n",
      "Epoch 65, batch 45: loss = 0.006723\n",
      "Epoch 65, batch 46: loss = 0.007410\n",
      "Epoch 65, batch 47: loss = 0.007738\n",
      "Epoch 65, batch 48: loss = 0.007165\n",
      "Epoch 65, batch 49: loss = 0.007119\n",
      "Epoch 65, batch 50: loss = 0.007435\n",
      "Epoch 65, batch 51: loss = 0.007097\n",
      "Epoch 65, batch 52: loss = 0.006967\n",
      "Epoch 65, batch 53: loss = 0.007114\n",
      "Epoch 65, batch 54: loss = 0.007482\n",
      "Epoch 65, batch 55: loss = 0.007298\n",
      "Epoch 65, batch 56: loss = 0.007535\n",
      "Epoch 65, batch 57: loss = 0.007282\n",
      "Epoch 65, batch 58: loss = 0.006946\n",
      "Epoch 65, batch 59: loss = 0.007103\n",
      "Epoch 65, batch 60: loss = 0.006799\n",
      "Epoch 65, batch 61: loss = 0.007333\n",
      "Epoch 65, batch 62: loss = 0.007149\n",
      "Epoch 65, batch 63: loss = 0.006881\n",
      "Epoch 65, batch 64: loss = 0.007314\n",
      "Epoch 65, batch 65: loss = 0.006773\n",
      "Epoch 65, batch 66: loss = 0.007022\n",
      "Epoch 65, batch 67: loss = 0.006992\n",
      "Epoch 65, batch 68: loss = 0.007452\n",
      "Epoch 65, batch 69: loss = 0.006944\n",
      "Epoch 65, batch 70: loss = 0.006658\n",
      "Epoch 65, batch 71: loss = 0.007382\n",
      "Epoch 65, batch 72: loss = 0.007016\n",
      "Epoch 65, batch 73: loss = 0.007381\n",
      "Epoch 65, batch 74: loss = 0.007791\n",
      "Epoch 65, batch 75: loss = 0.007038\n",
      "Epoch 65, batch 76: loss = 0.007513\n",
      "Epoch 65, batch 77: loss = 0.007223\n",
      "Epoch 65, batch 78: loss = 0.007123\n",
      "Epoch 65, batch 79: loss = 0.007081\n",
      "Epoch 65, batch 80: loss = 0.007227\n",
      "Epoch 65, batch 81: loss = 0.007247\n",
      "Epoch 65, batch 82: loss = 0.006471\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 65: val_loss = 0.034701\n",
      "Epoch 66, batch 0: loss = 0.007242\n",
      "Epoch 66, batch 1: loss = 0.006835\n",
      "Epoch 66, batch 2: loss = 0.007354\n",
      "Epoch 66, batch 3: loss = 0.006679\n",
      "Epoch 66, batch 4: loss = 0.006672\n",
      "Epoch 66, batch 5: loss = 0.006544\n",
      "Epoch 66, batch 6: loss = 0.006830\n",
      "Epoch 66, batch 7: loss = 0.007229\n",
      "Epoch 66, batch 8: loss = 0.006867\n",
      "Epoch 66, batch 9: loss = 0.007032\n",
      "Epoch 66, batch 10: loss = 0.007174\n",
      "Epoch 66, batch 11: loss = 0.007004\n",
      "Epoch 66, batch 12: loss = 0.007278\n",
      "Epoch 66, batch 13: loss = 0.007216\n",
      "Epoch 66, batch 14: loss = 0.007008\n",
      "Epoch 66, batch 15: loss = 0.007495\n",
      "Epoch 66, batch 16: loss = 0.007208\n",
      "Epoch 66, batch 17: loss = 0.007421\n",
      "Epoch 66, batch 18: loss = 0.007289\n",
      "Epoch 66, batch 19: loss = 0.007192\n",
      "Epoch 66, batch 20: loss = 0.007232\n",
      "Epoch 66, batch 21: loss = 0.007747\n",
      "Epoch 66, batch 22: loss = 0.006822\n",
      "Epoch 66, batch 23: loss = 0.007290\n",
      "Epoch 66, batch 24: loss = 0.006657\n",
      "Epoch 66, batch 25: loss = 0.007229\n",
      "Epoch 66, batch 26: loss = 0.006821\n",
      "Epoch 66, batch 27: loss = 0.007206\n",
      "Epoch 66, batch 28: loss = 0.007167\n",
      "Epoch 66, batch 29: loss = 0.007929\n",
      "Epoch 66, batch 30: loss = 0.007198\n",
      "Epoch 66, batch 31: loss = 0.007374\n",
      "Epoch 66, batch 32: loss = 0.007821\n",
      "Epoch 66, batch 33: loss = 0.007288\n",
      "Epoch 66, batch 34: loss = 0.007112\n",
      "Epoch 66, batch 35: loss = 0.007025\n",
      "Epoch 66, batch 36: loss = 0.007523\n",
      "Epoch 66, batch 37: loss = 0.007629\n",
      "Epoch 66, batch 38: loss = 0.007158\n",
      "Epoch 66, batch 39: loss = 0.007403\n",
      "Epoch 66, batch 40: loss = 0.007011\n",
      "Epoch 66, batch 41: loss = 0.007415\n",
      "Epoch 66, batch 42: loss = 0.007215\n",
      "Epoch 66, batch 43: loss = 0.006995\n",
      "Epoch 66, batch 44: loss = 0.007217\n",
      "Epoch 66, batch 45: loss = 0.007368\n",
      "Epoch 66, batch 46: loss = 0.007728\n",
      "Epoch 66, batch 47: loss = 0.007836\n",
      "Epoch 66, batch 48: loss = 0.007851\n",
      "Epoch 66, batch 49: loss = 0.007976\n",
      "Epoch 66, batch 50: loss = 0.007293\n",
      "Epoch 66, batch 51: loss = 0.007031\n",
      "Epoch 66, batch 52: loss = 0.006869\n",
      "Epoch 66, batch 53: loss = 0.007327\n",
      "Epoch 66, batch 54: loss = 0.006917\n",
      "Epoch 66, batch 55: loss = 0.006890\n",
      "Epoch 66, batch 56: loss = 0.006911\n",
      "Epoch 66, batch 57: loss = 0.007474\n",
      "Epoch 66, batch 58: loss = 0.007078\n",
      "Epoch 66, batch 59: loss = 0.006893\n",
      "Epoch 66, batch 60: loss = 0.007155\n",
      "Epoch 66, batch 61: loss = 0.007126\n",
      "Epoch 66, batch 62: loss = 0.006898\n",
      "Epoch 66, batch 63: loss = 0.006931\n",
      "Epoch 66, batch 64: loss = 0.006976\n",
      "Epoch 66, batch 65: loss = 0.006987\n",
      "Epoch 66, batch 66: loss = 0.007262\n",
      "Epoch 66, batch 67: loss = 0.006746\n",
      "Epoch 66, batch 68: loss = 0.006949\n",
      "Epoch 66, batch 69: loss = 0.007377\n",
      "Epoch 66, batch 70: loss = 0.007357\n",
      "Epoch 66, batch 71: loss = 0.007212\n",
      "Epoch 66, batch 72: loss = 0.007490\n",
      "Epoch 66, batch 73: loss = 0.007212\n",
      "Epoch 66, batch 74: loss = 0.006568\n",
      "Epoch 66, batch 75: loss = 0.007439\n",
      "Epoch 66, batch 76: loss = 0.007510\n",
      "Epoch 66, batch 77: loss = 0.006984\n",
      "Epoch 66, batch 78: loss = 0.006918\n",
      "Epoch 66, batch 79: loss = 0.006400\n",
      "Epoch 66, batch 80: loss = 0.007187\n",
      "Epoch 66, batch 81: loss = 0.007137\n",
      "Epoch 66, batch 82: loss = 0.007554\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 66: val_loss = 0.034157\n",
      "Epoch 67, batch 0: loss = 0.006784\n",
      "Epoch 67, batch 1: loss = 0.007535\n",
      "Epoch 67, batch 2: loss = 0.006933\n",
      "Epoch 67, batch 3: loss = 0.006968\n",
      "Epoch 67, batch 4: loss = 0.006929\n",
      "Epoch 67, batch 5: loss = 0.007087\n",
      "Epoch 67, batch 6: loss = 0.007546\n",
      "Epoch 67, batch 7: loss = 0.006737\n",
      "Epoch 67, batch 8: loss = 0.007036\n",
      "Epoch 67, batch 9: loss = 0.006729\n",
      "Epoch 67, batch 10: loss = 0.006930\n",
      "Epoch 67, batch 11: loss = 0.006759\n",
      "Epoch 67, batch 12: loss = 0.007694\n",
      "Epoch 67, batch 13: loss = 0.007131\n",
      "Epoch 67, batch 14: loss = 0.006536\n",
      "Epoch 67, batch 15: loss = 0.007015\n",
      "Epoch 67, batch 16: loss = 0.007584\n",
      "Epoch 67, batch 17: loss = 0.007280\n",
      "Epoch 67, batch 18: loss = 0.007114\n",
      "Epoch 67, batch 19: loss = 0.007450\n",
      "Epoch 67, batch 20: loss = 0.007614\n",
      "Epoch 67, batch 21: loss = 0.007479\n",
      "Epoch 67, batch 22: loss = 0.006961\n",
      "Epoch 67, batch 23: loss = 0.006921\n",
      "Epoch 67, batch 24: loss = 0.007191\n",
      "Epoch 67, batch 25: loss = 0.007152\n",
      "Epoch 67, batch 26: loss = 0.006866\n",
      "Epoch 67, batch 27: loss = 0.006628\n",
      "Epoch 67, batch 28: loss = 0.006872\n",
      "Epoch 67, batch 29: loss = 0.006869\n",
      "Epoch 67, batch 30: loss = 0.007069\n",
      "Epoch 67, batch 31: loss = 0.007008\n",
      "Epoch 67, batch 32: loss = 0.006916\n",
      "Epoch 67, batch 33: loss = 0.006845\n",
      "Epoch 67, batch 34: loss = 0.007231\n",
      "Epoch 67, batch 35: loss = 0.007060\n",
      "Epoch 67, batch 36: loss = 0.006638\n",
      "Epoch 67, batch 37: loss = 0.007260\n",
      "Epoch 67, batch 38: loss = 0.007065\n",
      "Epoch 67, batch 39: loss = 0.006839\n",
      "Epoch 67, batch 40: loss = 0.007201\n",
      "Epoch 67, batch 41: loss = 0.006944\n",
      "Epoch 67, batch 42: loss = 0.006927\n",
      "Epoch 67, batch 43: loss = 0.007065\n",
      "Epoch 67, batch 44: loss = 0.006807\n",
      "Epoch 67, batch 45: loss = 0.006775\n",
      "Epoch 67, batch 46: loss = 0.006898\n",
      "Epoch 67, batch 47: loss = 0.007123\n",
      "Epoch 67, batch 48: loss = 0.007256\n",
      "Epoch 67, batch 49: loss = 0.006839\n",
      "Epoch 67, batch 50: loss = 0.007196\n",
      "Epoch 67, batch 51: loss = 0.007118\n",
      "Epoch 67, batch 52: loss = 0.006862\n",
      "Epoch 67, batch 53: loss = 0.006771\n",
      "Epoch 67, batch 54: loss = 0.006721\n",
      "Epoch 67, batch 55: loss = 0.006596\n",
      "Epoch 67, batch 56: loss = 0.006478\n",
      "Epoch 67, batch 57: loss = 0.006769\n",
      "Epoch 67, batch 58: loss = 0.006799\n",
      "Epoch 67, batch 59: loss = 0.007107\n",
      "Epoch 67, batch 60: loss = 0.007104\n",
      "Epoch 67, batch 61: loss = 0.006966\n",
      "Epoch 67, batch 62: loss = 0.007454\n",
      "Epoch 67, batch 63: loss = 0.007375\n",
      "Epoch 67, batch 64: loss = 0.007490\n",
      "Epoch 67, batch 65: loss = 0.006274\n",
      "Epoch 67, batch 66: loss = 0.007207\n",
      "Epoch 67, batch 67: loss = 0.006695\n",
      "Epoch 67, batch 68: loss = 0.006608\n",
      "Epoch 67, batch 69: loss = 0.006641\n",
      "Epoch 67, batch 70: loss = 0.007184\n",
      "Epoch 67, batch 71: loss = 0.006835\n",
      "Epoch 67, batch 72: loss = 0.007215\n",
      "Epoch 67, batch 73: loss = 0.006873\n",
      "Epoch 67, batch 74: loss = 0.007336\n",
      "Epoch 67, batch 75: loss = 0.007565\n",
      "Epoch 67, batch 76: loss = 0.006933\n",
      "Epoch 67, batch 77: loss = 0.007216\n",
      "Epoch 67, batch 78: loss = 0.006998\n",
      "Epoch 67, batch 79: loss = 0.006924\n",
      "Epoch 67, batch 80: loss = 0.006822\n",
      "Epoch 67, batch 81: loss = 0.006483\n",
      "Epoch 67, batch 82: loss = 0.007477\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 67: val_loss = 0.033741\n",
      "Epoch 68, batch 0: loss = 0.006952\n",
      "Epoch 68, batch 1: loss = 0.007607\n",
      "Epoch 68, batch 2: loss = 0.007127\n",
      "Epoch 68, batch 3: loss = 0.006981\n",
      "Epoch 68, batch 4: loss = 0.007596\n",
      "Epoch 68, batch 5: loss = 0.007559\n",
      "Epoch 68, batch 6: loss = 0.006831\n",
      "Epoch 68, batch 7: loss = 0.007093\n",
      "Epoch 68, batch 8: loss = 0.006959\n",
      "Epoch 68, batch 9: loss = 0.007401\n",
      "Epoch 68, batch 10: loss = 0.007076\n",
      "Epoch 68, batch 11: loss = 0.006628\n",
      "Epoch 68, batch 12: loss = 0.007187\n",
      "Epoch 68, batch 13: loss = 0.007012\n",
      "Epoch 68, batch 14: loss = 0.006652\n",
      "Epoch 68, batch 15: loss = 0.007158\n",
      "Epoch 68, batch 16: loss = 0.006834\n",
      "Epoch 68, batch 17: loss = 0.007212\n",
      "Epoch 68, batch 18: loss = 0.006902\n",
      "Epoch 68, batch 19: loss = 0.007291\n",
      "Epoch 68, batch 20: loss = 0.007311\n",
      "Epoch 68, batch 21: loss = 0.006929\n",
      "Epoch 68, batch 22: loss = 0.007086\n",
      "Epoch 68, batch 23: loss = 0.006916\n",
      "Epoch 68, batch 24: loss = 0.007344\n",
      "Epoch 68, batch 25: loss = 0.006841\n",
      "Epoch 68, batch 26: loss = 0.007029\n",
      "Epoch 68, batch 27: loss = 0.006765\n",
      "Epoch 68, batch 28: loss = 0.007168\n",
      "Epoch 68, batch 29: loss = 0.006895\n",
      "Epoch 68, batch 30: loss = 0.006446\n",
      "Epoch 68, batch 31: loss = 0.007175\n",
      "Epoch 68, batch 32: loss = 0.007718\n",
      "Epoch 68, batch 33: loss = 0.006784\n",
      "Epoch 68, batch 34: loss = 0.007051\n",
      "Epoch 68, batch 35: loss = 0.007091\n",
      "Epoch 68, batch 36: loss = 0.006779\n",
      "Epoch 68, batch 37: loss = 0.006663\n",
      "Epoch 68, batch 38: loss = 0.007504\n",
      "Epoch 68, batch 39: loss = 0.006665\n",
      "Epoch 68, batch 40: loss = 0.006702\n",
      "Epoch 68, batch 41: loss = 0.007183\n",
      "Epoch 68, batch 42: loss = 0.007246\n",
      "Epoch 68, batch 43: loss = 0.006723\n",
      "Epoch 68, batch 44: loss = 0.007055\n",
      "Epoch 68, batch 45: loss = 0.006762\n",
      "Epoch 68, batch 46: loss = 0.007119\n",
      "Epoch 68, batch 47: loss = 0.007395\n",
      "Epoch 68, batch 48: loss = 0.006474\n",
      "Epoch 68, batch 49: loss = 0.006584\n",
      "Epoch 68, batch 50: loss = 0.007555\n",
      "Epoch 68, batch 51: loss = 0.006783\n",
      "Epoch 68, batch 52: loss = 0.006861\n",
      "Epoch 68, batch 53: loss = 0.006461\n",
      "Epoch 68, batch 54: loss = 0.006931\n",
      "Epoch 68, batch 55: loss = 0.006521\n",
      "Epoch 68, batch 56: loss = 0.006939\n",
      "Epoch 68, batch 57: loss = 0.006743\n",
      "Epoch 68, batch 58: loss = 0.006912\n",
      "Epoch 68, batch 59: loss = 0.006902\n",
      "Epoch 68, batch 60: loss = 0.006688\n",
      "Epoch 68, batch 61: loss = 0.006954\n",
      "Epoch 68, batch 62: loss = 0.007060\n",
      "Epoch 68, batch 63: loss = 0.007410\n",
      "Epoch 68, batch 64: loss = 0.007150\n",
      "Epoch 68, batch 65: loss = 0.006607\n",
      "Epoch 68, batch 66: loss = 0.007149\n",
      "Epoch 68, batch 67: loss = 0.007298\n",
      "Epoch 68, batch 68: loss = 0.006635\n",
      "Epoch 68, batch 69: loss = 0.007007\n",
      "Epoch 68, batch 70: loss = 0.007244\n",
      "Epoch 68, batch 71: loss = 0.007154\n",
      "Epoch 68, batch 72: loss = 0.006995\n",
      "Epoch 68, batch 73: loss = 0.006949\n",
      "Epoch 68, batch 74: loss = 0.006719\n",
      "Epoch 68, batch 75: loss = 0.007024\n",
      "Epoch 68, batch 76: loss = 0.006576\n",
      "Epoch 68, batch 77: loss = 0.007194\n",
      "Epoch 68, batch 78: loss = 0.006693\n",
      "Epoch 68, batch 79: loss = 0.006677\n",
      "Epoch 68, batch 80: loss = 0.006740\n",
      "Epoch 68, batch 81: loss = 0.006918\n",
      "Epoch 68, batch 82: loss = 0.005645\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 68: val_loss = 0.033347\n",
      "Epoch 69, batch 0: loss = 0.006705\n",
      "Epoch 69, batch 1: loss = 0.006970\n",
      "Epoch 69, batch 2: loss = 0.007267\n",
      "Epoch 69, batch 3: loss = 0.006567\n",
      "Epoch 69, batch 4: loss = 0.006600\n",
      "Epoch 69, batch 5: loss = 0.007236\n",
      "Epoch 69, batch 6: loss = 0.006518\n",
      "Epoch 69, batch 7: loss = 0.006877\n",
      "Epoch 69, batch 8: loss = 0.006599\n",
      "Epoch 69, batch 9: loss = 0.007006\n",
      "Epoch 69, batch 10: loss = 0.007528\n",
      "Epoch 69, batch 11: loss = 0.006863\n",
      "Epoch 69, batch 12: loss = 0.006868\n",
      "Epoch 69, batch 13: loss = 0.006537\n",
      "Epoch 69, batch 14: loss = 0.007057\n",
      "Epoch 69, batch 15: loss = 0.006809\n",
      "Epoch 69, batch 16: loss = 0.006578\n",
      "Epoch 69, batch 17: loss = 0.006923\n",
      "Epoch 69, batch 18: loss = 0.006544\n",
      "Epoch 69, batch 19: loss = 0.007448\n",
      "Epoch 69, batch 20: loss = 0.006809\n",
      "Epoch 69, batch 21: loss = 0.007069\n",
      "Epoch 69, batch 22: loss = 0.007274\n",
      "Epoch 69, batch 23: loss = 0.007109\n",
      "Epoch 69, batch 24: loss = 0.006720\n",
      "Epoch 69, batch 25: loss = 0.006727\n",
      "Epoch 69, batch 26: loss = 0.007360\n",
      "Epoch 69, batch 27: loss = 0.007195\n",
      "Epoch 69, batch 28: loss = 0.006745\n",
      "Epoch 69, batch 29: loss = 0.006895\n",
      "Epoch 69, batch 30: loss = 0.006982\n",
      "Epoch 69, batch 31: loss = 0.006751\n",
      "Epoch 69, batch 32: loss = 0.006675\n",
      "Epoch 69, batch 33: loss = 0.006618\n",
      "Epoch 69, batch 34: loss = 0.006745\n",
      "Epoch 69, batch 35: loss = 0.006464\n",
      "Epoch 69, batch 36: loss = 0.007220\n",
      "Epoch 69, batch 37: loss = 0.006505\n",
      "Epoch 69, batch 38: loss = 0.007215\n",
      "Epoch 69, batch 39: loss = 0.006813\n",
      "Epoch 69, batch 40: loss = 0.006353\n",
      "Epoch 69, batch 41: loss = 0.006594\n",
      "Epoch 69, batch 42: loss = 0.007055\n",
      "Epoch 69, batch 43: loss = 0.006785\n",
      "Epoch 69, batch 44: loss = 0.006398\n",
      "Epoch 69, batch 45: loss = 0.006625\n",
      "Epoch 69, batch 46: loss = 0.006647\n",
      "Epoch 69, batch 47: loss = 0.006986\n",
      "Epoch 69, batch 48: loss = 0.006670\n",
      "Epoch 69, batch 49: loss = 0.006904\n",
      "Epoch 69, batch 50: loss = 0.006771\n",
      "Epoch 69, batch 51: loss = 0.007001\n",
      "Epoch 69, batch 52: loss = 0.006872\n",
      "Epoch 69, batch 53: loss = 0.006784\n",
      "Epoch 69, batch 54: loss = 0.006979\n",
      "Epoch 69, batch 55: loss = 0.007068\n",
      "Epoch 69, batch 56: loss = 0.006953\n",
      "Epoch 69, batch 57: loss = 0.006616\n",
      "Epoch 69, batch 58: loss = 0.006614\n",
      "Epoch 69, batch 59: loss = 0.007136\n",
      "Epoch 69, batch 60: loss = 0.007891\n",
      "Epoch 69, batch 61: loss = 0.006578\n",
      "Epoch 69, batch 62: loss = 0.007256\n",
      "Epoch 69, batch 63: loss = 0.007149\n",
      "Epoch 69, batch 64: loss = 0.007203\n",
      "Epoch 69, batch 65: loss = 0.006400\n",
      "Epoch 69, batch 66: loss = 0.006621\n",
      "Epoch 69, batch 67: loss = 0.006714\n",
      "Epoch 69, batch 68: loss = 0.006606\n",
      "Epoch 69, batch 69: loss = 0.006862\n",
      "Epoch 69, batch 70: loss = 0.006647\n",
      "Epoch 69, batch 71: loss = 0.007130\n",
      "Epoch 69, batch 72: loss = 0.006729\n",
      "Epoch 69, batch 73: loss = 0.006827\n",
      "Epoch 69, batch 74: loss = 0.006495\n",
      "Epoch 69, batch 75: loss = 0.006849\n",
      "Epoch 69, batch 76: loss = 0.006665\n",
      "Epoch 69, batch 77: loss = 0.007152\n",
      "Epoch 69, batch 78: loss = 0.007159\n",
      "Epoch 69, batch 79: loss = 0.006866\n",
      "Epoch 69, batch 80: loss = 0.006807\n",
      "Epoch 69, batch 81: loss = 0.006931\n",
      "Epoch 69, batch 82: loss = 0.008059\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 69: val_loss = 0.033991\n",
      "Epoch 70, batch 0: loss = 0.007528\n",
      "Epoch 70, batch 1: loss = 0.007812\n",
      "Epoch 70, batch 2: loss = 0.007610\n",
      "Epoch 70, batch 3: loss = 0.008331\n",
      "Epoch 70, batch 4: loss = 0.008387\n",
      "Epoch 70, batch 5: loss = 0.008381\n",
      "Epoch 70, batch 6: loss = 0.007898\n",
      "Epoch 70, batch 7: loss = 0.008219\n",
      "Epoch 70, batch 8: loss = 0.007626\n",
      "Epoch 70, batch 9: loss = 0.007530\n",
      "Epoch 70, batch 10: loss = 0.008354\n",
      "Epoch 70, batch 11: loss = 0.009010\n",
      "Epoch 70, batch 12: loss = 0.008193\n",
      "Epoch 70, batch 13: loss = 0.008202\n",
      "Epoch 70, batch 14: loss = 0.008378\n",
      "Epoch 70, batch 15: loss = 0.007445\n",
      "Epoch 70, batch 16: loss = 0.007243\n",
      "Epoch 70, batch 17: loss = 0.007964\n",
      "Epoch 70, batch 18: loss = 0.008210\n",
      "Epoch 70, batch 19: loss = 0.007215\n",
      "Epoch 70, batch 20: loss = 0.007760\n",
      "Epoch 70, batch 21: loss = 0.007743\n",
      "Epoch 70, batch 22: loss = 0.008425\n",
      "Epoch 70, batch 23: loss = 0.007861\n",
      "Epoch 70, batch 24: loss = 0.007969\n",
      "Epoch 70, batch 25: loss = 0.007234\n",
      "Epoch 70, batch 26: loss = 0.008303\n",
      "Epoch 70, batch 27: loss = 0.007516\n",
      "Epoch 70, batch 28: loss = 0.007443\n",
      "Epoch 70, batch 29: loss = 0.007402\n",
      "Epoch 70, batch 30: loss = 0.007924\n",
      "Epoch 70, batch 31: loss = 0.007184\n",
      "Epoch 70, batch 32: loss = 0.007184\n",
      "Epoch 70, batch 33: loss = 0.007133\n",
      "Epoch 70, batch 34: loss = 0.007536\n",
      "Epoch 70, batch 35: loss = 0.007851\n",
      "Epoch 70, batch 36: loss = 0.009070\n",
      "Epoch 70, batch 37: loss = 0.011295\n",
      "Epoch 70, batch 38: loss = 0.014778\n",
      "Epoch 70, batch 39: loss = 0.010997\n",
      "Epoch 70, batch 40: loss = 0.012387\n",
      "Epoch 70, batch 41: loss = 0.011542\n",
      "Epoch 70, batch 42: loss = 0.010818\n",
      "Epoch 70, batch 43: loss = 0.011574\n",
      "Epoch 70, batch 44: loss = 0.012151\n",
      "Epoch 70, batch 45: loss = 0.011402\n",
      "Epoch 70, batch 46: loss = 0.011088\n",
      "Epoch 70, batch 47: loss = 0.012326\n",
      "Epoch 70, batch 48: loss = 0.011154\n",
      "Epoch 70, batch 49: loss = 0.010502\n",
      "Epoch 70, batch 50: loss = 0.009907\n",
      "Epoch 70, batch 51: loss = 0.011666\n",
      "Epoch 70, batch 52: loss = 0.010817\n",
      "Epoch 70, batch 53: loss = 0.010176\n",
      "Epoch 70, batch 54: loss = 0.009622\n",
      "Epoch 70, batch 55: loss = 0.010800\n",
      "Epoch 70, batch 56: loss = 0.011041\n",
      "Epoch 70, batch 57: loss = 0.010899\n",
      "Epoch 70, batch 58: loss = 0.009921\n",
      "Epoch 70, batch 59: loss = 0.011504\n",
      "Epoch 70, batch 60: loss = 0.010505\n",
      "Epoch 70, batch 61: loss = 0.011562\n",
      "Epoch 70, batch 62: loss = 0.010678\n",
      "Epoch 70, batch 63: loss = 0.010471\n",
      "Epoch 70, batch 64: loss = 0.010690\n",
      "Epoch 70, batch 65: loss = 0.010495\n",
      "Epoch 70, batch 66: loss = 0.011001\n",
      "Epoch 70, batch 67: loss = 0.010163\n",
      "Epoch 70, batch 68: loss = 0.009840\n",
      "Epoch 70, batch 69: loss = 0.009907\n",
      "Epoch 70, batch 70: loss = 0.009835\n",
      "Epoch 70, batch 71: loss = 0.011198\n",
      "Epoch 70, batch 72: loss = 0.010785\n",
      "Epoch 70, batch 73: loss = 0.009975\n",
      "Epoch 70, batch 74: loss = 0.008989\n",
      "Epoch 70, batch 75: loss = 0.009952\n",
      "Epoch 70, batch 76: loss = 0.008873\n",
      "Epoch 70, batch 77: loss = 0.008645\n",
      "Epoch 70, batch 78: loss = 0.009221\n",
      "Epoch 70, batch 79: loss = 0.010031\n",
      "Epoch 70, batch 80: loss = 0.009037\n",
      "Epoch 70, batch 81: loss = 0.009191\n",
      "Epoch 70, batch 82: loss = 0.007391\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 70: val_loss = 0.033850\n",
      "Epoch 71, batch 0: loss = 0.009416\n",
      "Epoch 71, batch 1: loss = 0.009268\n",
      "Epoch 71, batch 2: loss = 0.009384\n",
      "Epoch 71, batch 3: loss = 0.009780\n",
      "Epoch 71, batch 4: loss = 0.008779\n",
      "Epoch 71, batch 5: loss = 0.008736\n",
      "Epoch 71, batch 6: loss = 0.009393\n",
      "Epoch 71, batch 7: loss = 0.008608\n",
      "Epoch 71, batch 8: loss = 0.008925\n",
      "Epoch 71, batch 9: loss = 0.009095\n",
      "Epoch 71, batch 10: loss = 0.009588\n",
      "Epoch 71, batch 11: loss = 0.008785\n",
      "Epoch 71, batch 12: loss = 0.008916\n",
      "Epoch 71, batch 13: loss = 0.008868\n",
      "Epoch 71, batch 14: loss = 0.007913\n",
      "Epoch 71, batch 15: loss = 0.008207\n",
      "Epoch 71, batch 16: loss = 0.008669\n",
      "Epoch 71, batch 17: loss = 0.008489\n",
      "Epoch 71, batch 18: loss = 0.008387\n",
      "Epoch 71, batch 19: loss = 0.008608\n",
      "Epoch 71, batch 20: loss = 0.008878\n",
      "Epoch 71, batch 21: loss = 0.008229\n",
      "Epoch 71, batch 22: loss = 0.008467\n",
      "Epoch 71, batch 23: loss = 0.008100\n",
      "Epoch 71, batch 24: loss = 0.008297\n",
      "Epoch 71, batch 25: loss = 0.008482\n",
      "Epoch 71, batch 26: loss = 0.008947\n",
      "Epoch 71, batch 27: loss = 0.007933\n",
      "Epoch 71, batch 28: loss = 0.008176\n",
      "Epoch 71, batch 29: loss = 0.008057\n",
      "Epoch 71, batch 30: loss = 0.008673\n",
      "Epoch 71, batch 31: loss = 0.008545\n",
      "Epoch 71, batch 32: loss = 0.007617\n",
      "Epoch 71, batch 33: loss = 0.008341\n",
      "Epoch 71, batch 34: loss = 0.008578\n",
      "Epoch 71, batch 35: loss = 0.008331\n",
      "Epoch 71, batch 36: loss = 0.008161\n",
      "Epoch 71, batch 37: loss = 0.007955\n",
      "Epoch 71, batch 38: loss = 0.008158\n",
      "Epoch 71, batch 39: loss = 0.007602\n",
      "Epoch 71, batch 40: loss = 0.008654\n",
      "Epoch 71, batch 41: loss = 0.007773\n",
      "Epoch 71, batch 42: loss = 0.007598\n",
      "Epoch 71, batch 43: loss = 0.007837\n",
      "Epoch 71, batch 44: loss = 0.007404\n",
      "Epoch 71, batch 45: loss = 0.007773\n",
      "Epoch 71, batch 46: loss = 0.008490\n",
      "Epoch 71, batch 47: loss = 0.008479\n",
      "Epoch 71, batch 48: loss = 0.008097\n",
      "Epoch 71, batch 49: loss = 0.007831\n",
      "Epoch 71, batch 50: loss = 0.007823\n",
      "Epoch 71, batch 51: loss = 0.008011\n",
      "Epoch 71, batch 52: loss = 0.007473\n",
      "Epoch 71, batch 53: loss = 0.008032\n",
      "Epoch 71, batch 54: loss = 0.008225\n",
      "Epoch 71, batch 55: loss = 0.008044\n",
      "Epoch 71, batch 56: loss = 0.007770\n",
      "Epoch 71, batch 57: loss = 0.008865\n",
      "Epoch 71, batch 58: loss = 0.008309\n",
      "Epoch 71, batch 59: loss = 0.007302\n",
      "Epoch 71, batch 60: loss = 0.007754\n",
      "Epoch 71, batch 61: loss = 0.007877\n",
      "Epoch 71, batch 62: loss = 0.008177\n",
      "Epoch 71, batch 63: loss = 0.007671\n",
      "Epoch 71, batch 64: loss = 0.008039\n",
      "Epoch 71, batch 65: loss = 0.007821\n",
      "Epoch 71, batch 66: loss = 0.008169\n",
      "Epoch 71, batch 67: loss = 0.007723\n",
      "Epoch 71, batch 68: loss = 0.008457\n",
      "Epoch 71, batch 69: loss = 0.007463\n",
      "Epoch 71, batch 70: loss = 0.008081\n",
      "Epoch 71, batch 71: loss = 0.008107\n",
      "Epoch 71, batch 72: loss = 0.008168\n",
      "Epoch 71, batch 73: loss = 0.007930\n",
      "Epoch 71, batch 74: loss = 0.007314\n",
      "Epoch 71, batch 75: loss = 0.008410\n",
      "Epoch 71, batch 76: loss = 0.007910\n",
      "Epoch 71, batch 77: loss = 0.007700\n",
      "Epoch 71, batch 78: loss = 0.007524\n",
      "Epoch 71, batch 79: loss = 0.007672\n",
      "Epoch 71, batch 80: loss = 0.008558\n",
      "Epoch 71, batch 81: loss = 0.007970\n",
      "Epoch 71, batch 82: loss = 0.006629\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 71: val_loss = 0.037934\n",
      "Epoch 72, batch 0: loss = 0.008125\n",
      "Epoch 72, batch 1: loss = 0.007605\n",
      "Epoch 72, batch 2: loss = 0.007833\n",
      "Epoch 72, batch 3: loss = 0.007372\n",
      "Epoch 72, batch 4: loss = 0.007738\n",
      "Epoch 72, batch 5: loss = 0.008033\n",
      "Epoch 72, batch 6: loss = 0.008264\n",
      "Epoch 72, batch 7: loss = 0.007876\n",
      "Epoch 72, batch 8: loss = 0.007703\n",
      "Epoch 72, batch 9: loss = 0.007294\n",
      "Epoch 72, batch 10: loss = 0.007860\n",
      "Epoch 72, batch 11: loss = 0.007553\n",
      "Epoch 72, batch 12: loss = 0.007205\n",
      "Epoch 72, batch 13: loss = 0.007284\n",
      "Epoch 72, batch 14: loss = 0.007579\n",
      "Epoch 72, batch 15: loss = 0.007709\n",
      "Epoch 72, batch 16: loss = 0.008928\n",
      "Epoch 72, batch 17: loss = 0.007586\n",
      "Epoch 72, batch 18: loss = 0.008037\n",
      "Epoch 72, batch 19: loss = 0.007484\n",
      "Epoch 72, batch 20: loss = 0.007630\n",
      "Epoch 72, batch 21: loss = 0.007466\n",
      "Epoch 72, batch 22: loss = 0.007601\n",
      "Epoch 72, batch 23: loss = 0.007745\n",
      "Epoch 72, batch 24: loss = 0.007865\n",
      "Epoch 72, batch 25: loss = 0.007795\n",
      "Epoch 72, batch 26: loss = 0.007932\n",
      "Epoch 72, batch 27: loss = 0.008075\n",
      "Epoch 72, batch 28: loss = 0.008144\n",
      "Epoch 72, batch 29: loss = 0.007657\n",
      "Epoch 72, batch 30: loss = 0.007527\n",
      "Epoch 72, batch 31: loss = 0.007706\n",
      "Epoch 72, batch 32: loss = 0.007469\n",
      "Epoch 72, batch 33: loss = 0.007154\n",
      "Epoch 72, batch 34: loss = 0.007385\n",
      "Epoch 72, batch 35: loss = 0.007256\n",
      "Epoch 72, batch 36: loss = 0.007285\n",
      "Epoch 72, batch 37: loss = 0.006836\n",
      "Epoch 72, batch 38: loss = 0.007281\n",
      "Epoch 72, batch 39: loss = 0.007085\n",
      "Epoch 72, batch 40: loss = 0.007754\n",
      "Epoch 72, batch 41: loss = 0.007833\n",
      "Epoch 72, batch 42: loss = 0.007608\n",
      "Epoch 72, batch 43: loss = 0.007671\n",
      "Epoch 72, batch 44: loss = 0.007331\n",
      "Epoch 72, batch 45: loss = 0.006943\n",
      "Epoch 72, batch 46: loss = 0.007693\n",
      "Epoch 72, batch 47: loss = 0.007970\n",
      "Epoch 72, batch 48: loss = 0.007243\n",
      "Epoch 72, batch 49: loss = 0.007295\n",
      "Epoch 72, batch 50: loss = 0.007341\n",
      "Epoch 72, batch 51: loss = 0.007321\n",
      "Epoch 72, batch 52: loss = 0.007822\n",
      "Epoch 72, batch 53: loss = 0.007242\n",
      "Epoch 72, batch 54: loss = 0.008312\n",
      "Epoch 72, batch 55: loss = 0.007287\n",
      "Epoch 72, batch 56: loss = 0.007283\n",
      "Epoch 72, batch 57: loss = 0.007109\n",
      "Epoch 72, batch 58: loss = 0.007039\n",
      "Epoch 72, batch 59: loss = 0.007578\n",
      "Epoch 72, batch 60: loss = 0.007476\n",
      "Epoch 72, batch 61: loss = 0.007425\n",
      "Epoch 72, batch 62: loss = 0.007160\n",
      "Epoch 72, batch 63: loss = 0.007668\n",
      "Epoch 72, batch 64: loss = 0.007435\n",
      "Epoch 72, batch 65: loss = 0.007881\n",
      "Epoch 72, batch 66: loss = 0.007352\n",
      "Epoch 72, batch 67: loss = 0.007315\n",
      "Epoch 72, batch 68: loss = 0.007080\n",
      "Epoch 72, batch 69: loss = 0.007326\n",
      "Epoch 72, batch 70: loss = 0.007229\n",
      "Epoch 72, batch 71: loss = 0.007396\n",
      "Epoch 72, batch 72: loss = 0.007174\n",
      "Epoch 72, batch 73: loss = 0.007587\n",
      "Epoch 72, batch 74: loss = 0.006794\n",
      "Epoch 72, batch 75: loss = 0.007241\n",
      "Epoch 72, batch 76: loss = 0.007366\n",
      "Epoch 72, batch 77: loss = 0.007384\n",
      "Epoch 72, batch 78: loss = 0.007565\n",
      "Epoch 72, batch 79: loss = 0.006663\n",
      "Epoch 72, batch 80: loss = 0.007020\n",
      "Epoch 72, batch 81: loss = 0.006817\n",
      "Epoch 72, batch 82: loss = 0.006246\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 72: val_loss = 0.034302\n",
      "Epoch 73, batch 0: loss = 0.006951\n",
      "Epoch 73, batch 1: loss = 0.006866\n",
      "Epoch 73, batch 2: loss = 0.007565\n",
      "Epoch 73, batch 3: loss = 0.006858\n",
      "Epoch 73, batch 4: loss = 0.007651\n",
      "Epoch 73, batch 5: loss = 0.007095\n",
      "Epoch 73, batch 6: loss = 0.007285\n",
      "Epoch 73, batch 7: loss = 0.007452\n",
      "Epoch 73, batch 8: loss = 0.007861\n",
      "Epoch 73, batch 9: loss = 0.006844\n",
      "Epoch 73, batch 10: loss = 0.007521\n",
      "Epoch 73, batch 11: loss = 0.006968\n",
      "Epoch 73, batch 12: loss = 0.007424\n",
      "Epoch 73, batch 13: loss = 0.007263\n",
      "Epoch 73, batch 14: loss = 0.007104\n",
      "Epoch 73, batch 15: loss = 0.007506\n",
      "Epoch 73, batch 16: loss = 0.006985\n",
      "Epoch 73, batch 17: loss = 0.007298\n",
      "Epoch 73, batch 18: loss = 0.006971\n",
      "Epoch 73, batch 19: loss = 0.006954\n",
      "Epoch 73, batch 20: loss = 0.007042\n",
      "Epoch 73, batch 21: loss = 0.007184\n",
      "Epoch 73, batch 22: loss = 0.007291\n",
      "Epoch 73, batch 23: loss = 0.007471\n",
      "Epoch 73, batch 24: loss = 0.007454\n",
      "Epoch 73, batch 25: loss = 0.007896\n",
      "Epoch 73, batch 26: loss = 0.007422\n",
      "Epoch 73, batch 27: loss = 0.007775\n",
      "Epoch 73, batch 28: loss = 0.007585\n",
      "Epoch 73, batch 29: loss = 0.007350\n",
      "Epoch 73, batch 30: loss = 0.007591\n",
      "Epoch 73, batch 31: loss = 0.007188\n",
      "Epoch 73, batch 32: loss = 0.007611\n",
      "Epoch 73, batch 33: loss = 0.007253\n",
      "Epoch 73, batch 34: loss = 0.007264\n",
      "Epoch 73, batch 35: loss = 0.007560\n",
      "Epoch 73, batch 36: loss = 0.007640\n",
      "Epoch 73, batch 37: loss = 0.007250\n",
      "Epoch 73, batch 38: loss = 0.007038\n",
      "Epoch 73, batch 39: loss = 0.007348\n",
      "Epoch 73, batch 40: loss = 0.007380\n",
      "Epoch 73, batch 41: loss = 0.006873\n",
      "Epoch 73, batch 42: loss = 0.007758\n",
      "Epoch 73, batch 43: loss = 0.007013\n",
      "Epoch 73, batch 44: loss = 0.007670\n",
      "Epoch 73, batch 45: loss = 0.007145\n",
      "Epoch 73, batch 46: loss = 0.007809\n",
      "Epoch 73, batch 47: loss = 0.007151\n",
      "Epoch 73, batch 48: loss = 0.007295\n",
      "Epoch 73, batch 49: loss = 0.006856\n",
      "Epoch 73, batch 50: loss = 0.006955\n",
      "Epoch 73, batch 51: loss = 0.007618\n",
      "Epoch 73, batch 52: loss = 0.006759\n",
      "Epoch 73, batch 53: loss = 0.006797\n",
      "Epoch 73, batch 54: loss = 0.007275\n",
      "Epoch 73, batch 55: loss = 0.006737\n",
      "Epoch 73, batch 56: loss = 0.008488\n",
      "Epoch 73, batch 57: loss = 0.007232\n",
      "Epoch 73, batch 58: loss = 0.006913\n",
      "Epoch 73, batch 59: loss = 0.006646\n",
      "Epoch 73, batch 60: loss = 0.007759\n",
      "Epoch 73, batch 61: loss = 0.007263\n",
      "Epoch 73, batch 62: loss = 0.006798\n",
      "Epoch 73, batch 63: loss = 0.007157\n",
      "Epoch 73, batch 64: loss = 0.007228\n",
      "Epoch 73, batch 65: loss = 0.006715\n",
      "Epoch 73, batch 66: loss = 0.006984\n",
      "Epoch 73, batch 67: loss = 0.006680\n",
      "Epoch 73, batch 68: loss = 0.007569\n",
      "Epoch 73, batch 69: loss = 0.007536\n",
      "Epoch 73, batch 70: loss = 0.007232\n",
      "Epoch 73, batch 71: loss = 0.006892\n",
      "Epoch 73, batch 72: loss = 0.006887\n",
      "Epoch 73, batch 73: loss = 0.007089\n",
      "Epoch 73, batch 74: loss = 0.007737\n",
      "Epoch 73, batch 75: loss = 0.006736\n",
      "Epoch 73, batch 76: loss = 0.006780\n",
      "Epoch 73, batch 77: loss = 0.006745\n",
      "Epoch 73, batch 78: loss = 0.007104\n",
      "Epoch 73, batch 79: loss = 0.007051\n",
      "Epoch 73, batch 80: loss = 0.006977\n",
      "Epoch 73, batch 81: loss = 0.007263\n",
      "Epoch 73, batch 82: loss = 0.007313\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 73: val_loss = 0.033974\n",
      "Epoch 74, batch 0: loss = 0.007063\n",
      "Epoch 74, batch 1: loss = 0.007347\n",
      "Epoch 74, batch 2: loss = 0.007444\n",
      "Epoch 74, batch 3: loss = 0.007124\n",
      "Epoch 74, batch 4: loss = 0.007146\n",
      "Epoch 74, batch 5: loss = 0.007135\n",
      "Epoch 74, batch 6: loss = 0.007053\n",
      "Epoch 74, batch 7: loss = 0.007097\n",
      "Epoch 74, batch 8: loss = 0.007240\n",
      "Epoch 74, batch 9: loss = 0.007161\n",
      "Epoch 74, batch 10: loss = 0.007119\n",
      "Epoch 74, batch 11: loss = 0.007420\n",
      "Epoch 74, batch 12: loss = 0.006615\n",
      "Epoch 74, batch 13: loss = 0.006870\n",
      "Epoch 74, batch 14: loss = 0.006895\n",
      "Epoch 74, batch 15: loss = 0.007081\n",
      "Epoch 74, batch 16: loss = 0.006640\n",
      "Epoch 74, batch 17: loss = 0.006928\n",
      "Epoch 74, batch 18: loss = 0.006779\n",
      "Epoch 74, batch 19: loss = 0.006978\n",
      "Epoch 74, batch 20: loss = 0.007211\n",
      "Epoch 74, batch 21: loss = 0.006323\n",
      "Epoch 74, batch 22: loss = 0.007105\n",
      "Epoch 74, batch 23: loss = 0.006788\n",
      "Epoch 74, batch 24: loss = 0.007023\n",
      "Epoch 74, batch 25: loss = 0.006847\n",
      "Epoch 74, batch 26: loss = 0.007092\n",
      "Epoch 74, batch 27: loss = 0.007039\n",
      "Epoch 74, batch 28: loss = 0.007257\n",
      "Epoch 74, batch 29: loss = 0.007166\n",
      "Epoch 74, batch 30: loss = 0.007017\n",
      "Epoch 74, batch 31: loss = 0.007012\n",
      "Epoch 74, batch 32: loss = 0.007248\n",
      "Epoch 74, batch 33: loss = 0.007435\n",
      "Epoch 74, batch 34: loss = 0.006902\n",
      "Epoch 74, batch 35: loss = 0.006966\n",
      "Epoch 74, batch 36: loss = 0.006700\n",
      "Epoch 74, batch 37: loss = 0.007052\n",
      "Epoch 74, batch 38: loss = 0.007195\n",
      "Epoch 74, batch 39: loss = 0.006569\n",
      "Epoch 74, batch 40: loss = 0.006747\n",
      "Epoch 74, batch 41: loss = 0.007058\n",
      "Epoch 74, batch 42: loss = 0.006970\n",
      "Epoch 74, batch 43: loss = 0.007354\n",
      "Epoch 74, batch 44: loss = 0.006665\n",
      "Epoch 74, batch 45: loss = 0.006748\n",
      "Epoch 74, batch 46: loss = 0.006887\n",
      "Epoch 74, batch 47: loss = 0.006824\n",
      "Epoch 74, batch 48: loss = 0.007540\n",
      "Epoch 74, batch 49: loss = 0.006856\n",
      "Epoch 74, batch 50: loss = 0.006936\n",
      "Epoch 74, batch 51: loss = 0.006642\n",
      "Epoch 74, batch 52: loss = 0.007194\n",
      "Epoch 74, batch 53: loss = 0.006812\n",
      "Epoch 74, batch 54: loss = 0.006657\n",
      "Epoch 74, batch 55: loss = 0.007427\n",
      "Epoch 74, batch 56: loss = 0.006953\n",
      "Epoch 74, batch 57: loss = 0.006794\n",
      "Epoch 74, batch 58: loss = 0.006871\n",
      "Epoch 74, batch 59: loss = 0.006664\n",
      "Epoch 74, batch 60: loss = 0.006730\n",
      "Epoch 74, batch 61: loss = 0.006591\n",
      "Epoch 74, batch 62: loss = 0.006850\n",
      "Epoch 74, batch 63: loss = 0.006819\n",
      "Epoch 74, batch 64: loss = 0.007504\n",
      "Epoch 74, batch 65: loss = 0.006696\n",
      "Epoch 74, batch 66: loss = 0.006794\n",
      "Epoch 74, batch 67: loss = 0.007361\n",
      "Epoch 74, batch 68: loss = 0.007543\n",
      "Epoch 74, batch 69: loss = 0.006798\n",
      "Epoch 74, batch 70: loss = 0.006825\n",
      "Epoch 74, batch 71: loss = 0.006753\n",
      "Epoch 74, batch 72: loss = 0.006520\n",
      "Epoch 74, batch 73: loss = 0.006691\n",
      "Epoch 74, batch 74: loss = 0.006391\n",
      "Epoch 74, batch 75: loss = 0.006966\n",
      "Epoch 74, batch 76: loss = 0.006727\n",
      "Epoch 74, batch 77: loss = 0.007192\n",
      "Epoch 74, batch 78: loss = 0.006920\n",
      "Epoch 74, batch 79: loss = 0.006777\n",
      "Epoch 74, batch 80: loss = 0.007048\n",
      "Epoch 74, batch 81: loss = 0.007513\n",
      "Epoch 74, batch 82: loss = 0.004739\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 74: val_loss = 0.033824\n",
      "Epoch 75, batch 0: loss = 0.007059\n",
      "Epoch 75, batch 1: loss = 0.006372\n",
      "Epoch 75, batch 2: loss = 0.006661\n",
      "Epoch 75, batch 3: loss = 0.007402\n",
      "Epoch 75, batch 4: loss = 0.006739\n",
      "Epoch 75, batch 5: loss = 0.006313\n",
      "Epoch 75, batch 6: loss = 0.007899\n",
      "Epoch 75, batch 7: loss = 0.006904\n",
      "Epoch 75, batch 8: loss = 0.006988\n",
      "Epoch 75, batch 9: loss = 0.006787\n",
      "Epoch 75, batch 10: loss = 0.006627\n",
      "Epoch 75, batch 11: loss = 0.006811\n",
      "Epoch 75, batch 12: loss = 0.007195\n",
      "Epoch 75, batch 13: loss = 0.006825\n",
      "Epoch 75, batch 14: loss = 0.007541\n",
      "Epoch 75, batch 15: loss = 0.006749\n",
      "Epoch 75, batch 16: loss = 0.006725\n",
      "Epoch 75, batch 17: loss = 0.006660\n",
      "Epoch 75, batch 18: loss = 0.006280\n",
      "Epoch 75, batch 19: loss = 0.006797\n",
      "Epoch 75, batch 20: loss = 0.006550\n",
      "Epoch 75, batch 21: loss = 0.007004\n",
      "Epoch 75, batch 22: loss = 0.006820\n",
      "Epoch 75, batch 23: loss = 0.006711\n",
      "Epoch 75, batch 24: loss = 0.007505\n",
      "Epoch 75, batch 25: loss = 0.007473\n",
      "Epoch 75, batch 26: loss = 0.006966\n",
      "Epoch 75, batch 27: loss = 0.006663\n",
      "Epoch 75, batch 28: loss = 0.006570\n",
      "Epoch 75, batch 29: loss = 0.006902\n",
      "Epoch 75, batch 30: loss = 0.007173\n",
      "Epoch 75, batch 31: loss = 0.006851\n",
      "Epoch 75, batch 32: loss = 0.006861\n",
      "Epoch 75, batch 33: loss = 0.006715\n",
      "Epoch 75, batch 34: loss = 0.007015\n",
      "Epoch 75, batch 35: loss = 0.007023\n",
      "Epoch 75, batch 36: loss = 0.006324\n",
      "Epoch 75, batch 37: loss = 0.006457\n",
      "Epoch 75, batch 38: loss = 0.006960\n",
      "Epoch 75, batch 39: loss = 0.007121\n",
      "Epoch 75, batch 40: loss = 0.007062\n",
      "Epoch 75, batch 41: loss = 0.006406\n",
      "Epoch 75, batch 42: loss = 0.006644\n",
      "Epoch 75, batch 43: loss = 0.006549\n",
      "Epoch 75, batch 44: loss = 0.006950\n",
      "Epoch 75, batch 45: loss = 0.007129\n",
      "Epoch 75, batch 46: loss = 0.006726\n",
      "Epoch 75, batch 47: loss = 0.007237\n",
      "Epoch 75, batch 48: loss = 0.007340\n",
      "Epoch 75, batch 49: loss = 0.006905\n",
      "Epoch 75, batch 50: loss = 0.007007\n",
      "Epoch 75, batch 51: loss = 0.006759\n",
      "Epoch 75, batch 52: loss = 0.006750\n",
      "Epoch 75, batch 53: loss = 0.006844\n",
      "Epoch 75, batch 54: loss = 0.006543\n",
      "Epoch 75, batch 55: loss = 0.006914\n",
      "Epoch 75, batch 56: loss = 0.006591\n",
      "Epoch 75, batch 57: loss = 0.007137\n",
      "Epoch 75, batch 58: loss = 0.006498\n",
      "Epoch 75, batch 59: loss = 0.007103\n",
      "Epoch 75, batch 60: loss = 0.006572\n",
      "Epoch 75, batch 61: loss = 0.006470\n",
      "Epoch 75, batch 62: loss = 0.007041\n",
      "Epoch 75, batch 63: loss = 0.006719\n",
      "Epoch 75, batch 64: loss = 0.006664\n",
      "Epoch 75, batch 65: loss = 0.007277\n",
      "Epoch 75, batch 66: loss = 0.006927\n",
      "Epoch 75, batch 67: loss = 0.006946\n",
      "Epoch 75, batch 68: loss = 0.006567\n",
      "Epoch 75, batch 69: loss = 0.006908\n",
      "Epoch 75, batch 70: loss = 0.006431\n",
      "Epoch 75, batch 71: loss = 0.006307\n",
      "Epoch 75, batch 72: loss = 0.006570\n",
      "Epoch 75, batch 73: loss = 0.006306\n",
      "Epoch 75, batch 74: loss = 0.006567\n",
      "Epoch 75, batch 75: loss = 0.006575\n",
      "Epoch 75, batch 76: loss = 0.006895\n",
      "Epoch 75, batch 77: loss = 0.006655\n",
      "Epoch 75, batch 78: loss = 0.006884\n",
      "Epoch 75, batch 79: loss = 0.006137\n",
      "Epoch 75, batch 80: loss = 0.006691\n",
      "Epoch 75, batch 81: loss = 0.006395\n",
      "Epoch 75, batch 82: loss = 0.004377\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 75: val_loss = 0.039101\n",
      "Epoch 76, batch 0: loss = 0.006693\n",
      "Epoch 76, batch 1: loss = 0.006470\n",
      "Epoch 76, batch 2: loss = 0.007081\n",
      "Epoch 76, batch 3: loss = 0.006965\n",
      "Epoch 76, batch 4: loss = 0.007126\n",
      "Epoch 76, batch 5: loss = 0.007158\n",
      "Epoch 76, batch 6: loss = 0.007209\n",
      "Epoch 76, batch 7: loss = 0.006897\n",
      "Epoch 76, batch 8: loss = 0.006462\n",
      "Epoch 76, batch 9: loss = 0.006910\n",
      "Epoch 76, batch 10: loss = 0.007287\n",
      "Epoch 76, batch 11: loss = 0.007002\n",
      "Epoch 76, batch 12: loss = 0.006653\n",
      "Epoch 76, batch 13: loss = 0.006778\n",
      "Epoch 76, batch 14: loss = 0.006904\n",
      "Epoch 76, batch 15: loss = 0.006833\n",
      "Epoch 76, batch 16: loss = 0.006859\n",
      "Epoch 76, batch 17: loss = 0.006693\n",
      "Epoch 76, batch 18: loss = 0.007063\n",
      "Epoch 76, batch 19: loss = 0.007278\n",
      "Epoch 76, batch 20: loss = 0.006761\n",
      "Epoch 76, batch 21: loss = 0.006638\n",
      "Epoch 76, batch 22: loss = 0.006378\n",
      "Epoch 76, batch 23: loss = 0.006993\n",
      "Epoch 76, batch 24: loss = 0.006328\n",
      "Epoch 76, batch 25: loss = 0.007055\n",
      "Epoch 76, batch 26: loss = 0.007022\n",
      "Epoch 76, batch 27: loss = 0.006916\n",
      "Epoch 76, batch 28: loss = 0.006611\n",
      "Epoch 76, batch 29: loss = 0.006544\n",
      "Epoch 76, batch 30: loss = 0.006479\n",
      "Epoch 76, batch 31: loss = 0.007205\n",
      "Epoch 76, batch 32: loss = 0.006873\n",
      "Epoch 76, batch 33: loss = 0.006395\n",
      "Epoch 76, batch 34: loss = 0.006448\n",
      "Epoch 76, batch 35: loss = 0.006897\n",
      "Epoch 76, batch 36: loss = 0.006562\n",
      "Epoch 76, batch 37: loss = 0.006816\n",
      "Epoch 76, batch 38: loss = 0.006372\n",
      "Epoch 76, batch 39: loss = 0.006687\n",
      "Epoch 76, batch 40: loss = 0.006928\n",
      "Epoch 76, batch 41: loss = 0.006979\n",
      "Epoch 76, batch 42: loss = 0.006428\n",
      "Epoch 76, batch 43: loss = 0.006673\n",
      "Epoch 76, batch 44: loss = 0.006648\n",
      "Epoch 76, batch 45: loss = 0.006381\n",
      "Epoch 76, batch 46: loss = 0.006735\n",
      "Epoch 76, batch 47: loss = 0.006424\n",
      "Epoch 76, batch 48: loss = 0.006457\n",
      "Epoch 76, batch 49: loss = 0.006739\n",
      "Epoch 76, batch 50: loss = 0.006676\n",
      "Epoch 76, batch 51: loss = 0.006561\n",
      "Epoch 76, batch 52: loss = 0.006864\n",
      "Epoch 76, batch 53: loss = 0.006800\n",
      "Epoch 76, batch 54: loss = 0.006835\n",
      "Epoch 76, batch 55: loss = 0.007038\n",
      "Epoch 76, batch 56: loss = 0.006812\n",
      "Epoch 76, batch 57: loss = 0.006689\n",
      "Epoch 76, batch 58: loss = 0.007019\n",
      "Epoch 76, batch 59: loss = 0.006743\n",
      "Epoch 76, batch 60: loss = 0.006702\n",
      "Epoch 76, batch 61: loss = 0.006767\n",
      "Epoch 76, batch 62: loss = 0.006647\n",
      "Epoch 76, batch 63: loss = 0.006663\n",
      "Epoch 76, batch 64: loss = 0.006854\n",
      "Epoch 76, batch 65: loss = 0.006454\n",
      "Epoch 76, batch 66: loss = 0.006391\n",
      "Epoch 76, batch 67: loss = 0.006513\n",
      "Epoch 76, batch 68: loss = 0.006355\n",
      "Epoch 76, batch 69: loss = 0.006768\n",
      "Epoch 76, batch 70: loss = 0.007261\n",
      "Epoch 76, batch 71: loss = 0.006945\n",
      "Epoch 76, batch 72: loss = 0.006541\n",
      "Epoch 76, batch 73: loss = 0.007364\n",
      "Epoch 76, batch 74: loss = 0.006638\n",
      "Epoch 76, batch 75: loss = 0.006924\n",
      "Epoch 76, batch 76: loss = 0.006599\n",
      "Epoch 76, batch 77: loss = 0.006584\n",
      "Epoch 76, batch 78: loss = 0.006662\n",
      "Epoch 76, batch 79: loss = 0.006545\n",
      "Epoch 76, batch 80: loss = 0.006347\n",
      "Epoch 76, batch 81: loss = 0.007092\n",
      "Epoch 76, batch 82: loss = 0.006182\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 76: val_loss = 0.041450\n",
      "Epoch 77, batch 0: loss = 0.007434\n",
      "Epoch 77, batch 1: loss = 0.007349\n",
      "Epoch 77, batch 2: loss = 0.006898\n",
      "Epoch 77, batch 3: loss = 0.006249\n",
      "Epoch 77, batch 4: loss = 0.006518\n",
      "Epoch 77, batch 5: loss = 0.006772\n",
      "Epoch 77, batch 6: loss = 0.006942\n",
      "Epoch 77, batch 7: loss = 0.006583\n",
      "Epoch 77, batch 8: loss = 0.007206\n",
      "Epoch 77, batch 9: loss = 0.006787\n",
      "Epoch 77, batch 10: loss = 0.006683\n",
      "Epoch 77, batch 11: loss = 0.006738\n",
      "Epoch 77, batch 12: loss = 0.006855\n",
      "Epoch 77, batch 13: loss = 0.007446\n",
      "Epoch 77, batch 14: loss = 0.006846\n",
      "Epoch 77, batch 15: loss = 0.006888\n",
      "Epoch 77, batch 16: loss = 0.007603\n",
      "Epoch 77, batch 17: loss = 0.006609\n",
      "Epoch 77, batch 18: loss = 0.006608\n",
      "Epoch 77, batch 19: loss = 0.006339\n",
      "Epoch 77, batch 20: loss = 0.006757\n",
      "Epoch 77, batch 21: loss = 0.006713\n",
      "Epoch 77, batch 22: loss = 0.007042\n",
      "Epoch 77, batch 23: loss = 0.007175\n",
      "Epoch 77, batch 24: loss = 0.007221\n",
      "Epoch 77, batch 25: loss = 0.006507\n",
      "Epoch 77, batch 26: loss = 0.006976\n",
      "Epoch 77, batch 27: loss = 0.007137\n",
      "Epoch 77, batch 28: loss = 0.006765\n",
      "Epoch 77, batch 29: loss = 0.006959\n",
      "Epoch 77, batch 30: loss = 0.006345\n",
      "Epoch 77, batch 31: loss = 0.007384\n",
      "Epoch 77, batch 32: loss = 0.007138\n",
      "Epoch 77, batch 33: loss = 0.006884\n",
      "Epoch 77, batch 34: loss = 0.007223\n",
      "Epoch 77, batch 35: loss = 0.006834\n",
      "Epoch 77, batch 36: loss = 0.007021\n",
      "Epoch 77, batch 37: loss = 0.007471\n",
      "Epoch 77, batch 38: loss = 0.006529\n",
      "Epoch 77, batch 39: loss = 0.006940\n",
      "Epoch 77, batch 40: loss = 0.006905\n",
      "Epoch 77, batch 41: loss = 0.007223\n",
      "Epoch 77, batch 42: loss = 0.006517\n",
      "Epoch 77, batch 43: loss = 0.006809\n",
      "Epoch 77, batch 44: loss = 0.006907\n",
      "Epoch 77, batch 45: loss = 0.006920\n",
      "Epoch 77, batch 46: loss = 0.006451\n",
      "Epoch 77, batch 47: loss = 0.006749\n",
      "Epoch 77, batch 48: loss = 0.007286\n",
      "Epoch 77, batch 49: loss = 0.006757\n",
      "Epoch 77, batch 50: loss = 0.007166\n",
      "Epoch 77, batch 51: loss = 0.006923\n",
      "Epoch 77, batch 52: loss = 0.006952\n",
      "Epoch 77, batch 53: loss = 0.006557\n",
      "Epoch 77, batch 54: loss = 0.006428\n",
      "Epoch 77, batch 55: loss = 0.006363\n",
      "Epoch 77, batch 56: loss = 0.006533\n",
      "Epoch 77, batch 57: loss = 0.006374\n",
      "Epoch 77, batch 58: loss = 0.006375\n",
      "Epoch 77, batch 59: loss = 0.006782\n",
      "Epoch 77, batch 60: loss = 0.006676\n",
      "Epoch 77, batch 61: loss = 0.007283\n",
      "Epoch 77, batch 62: loss = 0.006297\n",
      "Epoch 77, batch 63: loss = 0.007047\n",
      "Epoch 77, batch 64: loss = 0.006509\n",
      "Epoch 77, batch 65: loss = 0.007127\n",
      "Epoch 77, batch 66: loss = 0.006395\n",
      "Epoch 77, batch 67: loss = 0.006853\n",
      "Epoch 77, batch 68: loss = 0.006434\n",
      "Epoch 77, batch 69: loss = 0.006697\n",
      "Epoch 77, batch 70: loss = 0.006707\n",
      "Epoch 77, batch 71: loss = 0.006819\n",
      "Epoch 77, batch 72: loss = 0.006605\n",
      "Epoch 77, batch 73: loss = 0.006664\n",
      "Epoch 77, batch 74: loss = 0.006608\n",
      "Epoch 77, batch 75: loss = 0.006936\n",
      "Epoch 77, batch 76: loss = 0.006497\n",
      "Epoch 77, batch 77: loss = 0.007013\n",
      "Epoch 77, batch 78: loss = 0.006518\n",
      "Epoch 77, batch 79: loss = 0.006757\n",
      "Epoch 77, batch 80: loss = 0.006266\n",
      "Epoch 77, batch 81: loss = 0.006392\n",
      "Epoch 77, batch 82: loss = 0.010922\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 77: val_loss = 0.041013\n",
      "Epoch 78, batch 0: loss = 0.006376\n",
      "Epoch 78, batch 1: loss = 0.006814\n",
      "Epoch 78, batch 2: loss = 0.006890\n",
      "Epoch 78, batch 3: loss = 0.007003\n",
      "Epoch 78, batch 4: loss = 0.006829\n",
      "Epoch 78, batch 5: loss = 0.006729\n",
      "Epoch 78, batch 6: loss = 0.006633\n",
      "Epoch 78, batch 7: loss = 0.006886\n",
      "Epoch 78, batch 8: loss = 0.007009\n",
      "Epoch 78, batch 9: loss = 0.006875\n",
      "Epoch 78, batch 10: loss = 0.006844\n",
      "Epoch 78, batch 11: loss = 0.006543\n",
      "Epoch 78, batch 12: loss = 0.007251\n",
      "Epoch 78, batch 13: loss = 0.006550\n",
      "Epoch 78, batch 14: loss = 0.006945\n",
      "Epoch 78, batch 15: loss = 0.007388\n",
      "Epoch 78, batch 16: loss = 0.006594\n",
      "Epoch 78, batch 17: loss = 0.006203\n",
      "Epoch 78, batch 18: loss = 0.006873\n",
      "Epoch 78, batch 19: loss = 0.006643\n",
      "Epoch 78, batch 20: loss = 0.006504\n",
      "Epoch 78, batch 21: loss = 0.006451\n",
      "Epoch 78, batch 22: loss = 0.006384\n",
      "Epoch 78, batch 23: loss = 0.006504\n",
      "Epoch 78, batch 24: loss = 0.006454\n",
      "Epoch 78, batch 25: loss = 0.007211\n",
      "Epoch 78, batch 26: loss = 0.006394\n",
      "Epoch 78, batch 27: loss = 0.006496\n",
      "Epoch 78, batch 28: loss = 0.006353\n",
      "Epoch 78, batch 29: loss = 0.006704\n",
      "Epoch 78, batch 30: loss = 0.006414\n",
      "Epoch 78, batch 31: loss = 0.006568\n",
      "Epoch 78, batch 32: loss = 0.006734\n",
      "Epoch 78, batch 33: loss = 0.006351\n",
      "Epoch 78, batch 34: loss = 0.006297\n",
      "Epoch 78, batch 35: loss = 0.006491\n",
      "Epoch 78, batch 36: loss = 0.006661\n",
      "Epoch 78, batch 37: loss = 0.006958\n",
      "Epoch 78, batch 38: loss = 0.006947\n",
      "Epoch 78, batch 39: loss = 0.006564\n",
      "Epoch 78, batch 40: loss = 0.007025\n",
      "Epoch 78, batch 41: loss = 0.006849\n",
      "Epoch 78, batch 42: loss = 0.006811\n",
      "Epoch 78, batch 43: loss = 0.006626\n",
      "Epoch 78, batch 44: loss = 0.006279\n",
      "Epoch 78, batch 45: loss = 0.007180\n",
      "Epoch 78, batch 46: loss = 0.006408\n",
      "Epoch 78, batch 47: loss = 0.006647\n",
      "Epoch 78, batch 48: loss = 0.006280\n",
      "Epoch 78, batch 49: loss = 0.006308\n",
      "Epoch 78, batch 50: loss = 0.006123\n",
      "Epoch 78, batch 51: loss = 0.006355\n",
      "Epoch 78, batch 52: loss = 0.006175\n",
      "Epoch 78, batch 53: loss = 0.007169\n",
      "Epoch 78, batch 54: loss = 0.006492\n",
      "Epoch 78, batch 55: loss = 0.006767\n",
      "Epoch 78, batch 56: loss = 0.007000\n",
      "Epoch 78, batch 57: loss = 0.006542\n",
      "Epoch 78, batch 58: loss = 0.006707\n",
      "Epoch 78, batch 59: loss = 0.006760\n",
      "Epoch 78, batch 60: loss = 0.006928\n",
      "Epoch 78, batch 61: loss = 0.006414\n",
      "Epoch 78, batch 62: loss = 0.006542\n",
      "Epoch 78, batch 63: loss = 0.006612\n",
      "Epoch 78, batch 64: loss = 0.007335\n",
      "Epoch 78, batch 65: loss = 0.006621\n",
      "Epoch 78, batch 66: loss = 0.006515\n",
      "Epoch 78, batch 67: loss = 0.006934\n",
      "Epoch 78, batch 68: loss = 0.006429\n",
      "Epoch 78, batch 69: loss = 0.006540\n",
      "Epoch 78, batch 70: loss = 0.006284\n",
      "Epoch 78, batch 71: loss = 0.006504\n",
      "Epoch 78, batch 72: loss = 0.007055\n",
      "Epoch 78, batch 73: loss = 0.006507\n",
      "Epoch 78, batch 74: loss = 0.006446\n",
      "Epoch 78, batch 75: loss = 0.006534\n",
      "Epoch 78, batch 76: loss = 0.006663\n",
      "Epoch 78, batch 77: loss = 0.006630\n",
      "Epoch 78, batch 78: loss = 0.006732\n",
      "Epoch 78, batch 79: loss = 0.006371\n",
      "Epoch 78, batch 80: loss = 0.006945\n",
      "Epoch 78, batch 81: loss = 0.006334\n",
      "Epoch 78, batch 82: loss = 0.006644\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 78: val_loss = 0.041355\n",
      "Epoch 79, batch 0: loss = 0.006593\n",
      "Epoch 79, batch 1: loss = 0.006393\n",
      "Epoch 79, batch 2: loss = 0.006775\n",
      "Epoch 79, batch 3: loss = 0.007026\n",
      "Epoch 79, batch 4: loss = 0.006812\n",
      "Epoch 79, batch 5: loss = 0.006585\n",
      "Epoch 79, batch 6: loss = 0.006666\n",
      "Epoch 79, batch 7: loss = 0.006503\n",
      "Epoch 79, batch 8: loss = 0.006318\n",
      "Epoch 79, batch 9: loss = 0.006562\n",
      "Epoch 79, batch 10: loss = 0.006875\n",
      "Epoch 79, batch 11: loss = 0.006952\n",
      "Epoch 79, batch 12: loss = 0.006382\n",
      "Epoch 79, batch 13: loss = 0.006819\n",
      "Epoch 79, batch 14: loss = 0.006881\n",
      "Epoch 79, batch 15: loss = 0.006416\n",
      "Epoch 79, batch 16: loss = 0.007419\n",
      "Epoch 79, batch 17: loss = 0.007238\n",
      "Epoch 79, batch 18: loss = 0.006804\n",
      "Epoch 79, batch 19: loss = 0.006342\n",
      "Epoch 79, batch 20: loss = 0.007064\n",
      "Epoch 79, batch 21: loss = 0.006860\n",
      "Epoch 79, batch 22: loss = 0.007796\n",
      "Epoch 79, batch 23: loss = 0.007217\n",
      "Epoch 79, batch 24: loss = 0.006885\n",
      "Epoch 79, batch 25: loss = 0.007315\n",
      "Epoch 79, batch 26: loss = 0.006902\n",
      "Epoch 79, batch 27: loss = 0.006776\n",
      "Epoch 79, batch 28: loss = 0.007100\n",
      "Epoch 79, batch 29: loss = 0.007081\n",
      "Epoch 79, batch 30: loss = 0.007344\n",
      "Epoch 79, batch 31: loss = 0.006654\n",
      "Epoch 79, batch 32: loss = 0.006884\n",
      "Epoch 79, batch 33: loss = 0.007151\n",
      "Epoch 79, batch 34: loss = 0.007084\n",
      "Epoch 79, batch 35: loss = 0.006907\n",
      "Epoch 79, batch 36: loss = 0.007013\n",
      "Epoch 79, batch 37: loss = 0.007222\n",
      "Epoch 79, batch 38: loss = 0.006292\n",
      "Epoch 79, batch 39: loss = 0.006872\n",
      "Epoch 79, batch 40: loss = 0.006484\n",
      "Epoch 79, batch 41: loss = 0.007146\n",
      "Epoch 79, batch 42: loss = 0.006986\n",
      "Epoch 79, batch 43: loss = 0.006950\n",
      "Epoch 79, batch 44: loss = 0.006426\n",
      "Epoch 79, batch 45: loss = 0.006441\n",
      "Epoch 79, batch 46: loss = 0.006485\n",
      "Epoch 79, batch 47: loss = 0.006991\n",
      "Epoch 79, batch 48: loss = 0.006245\n",
      "Epoch 79, batch 49: loss = 0.006943\n",
      "Epoch 79, batch 50: loss = 0.006808\n",
      "Epoch 79, batch 51: loss = 0.006647\n",
      "Epoch 79, batch 52: loss = 0.006761\n",
      "Epoch 79, batch 53: loss = 0.006659\n",
      "Epoch 79, batch 54: loss = 0.006902\n",
      "Epoch 79, batch 55: loss = 0.006493\n",
      "Epoch 79, batch 56: loss = 0.006859\n",
      "Epoch 79, batch 57: loss = 0.006778\n",
      "Epoch 79, batch 58: loss = 0.006528\n",
      "Epoch 79, batch 59: loss = 0.006730\n",
      "Epoch 79, batch 60: loss = 0.006885\n",
      "Epoch 79, batch 61: loss = 0.006755\n",
      "Epoch 79, batch 62: loss = 0.006570\n",
      "Epoch 79, batch 63: loss = 0.006631\n",
      "Epoch 79, batch 64: loss = 0.006595\n",
      "Epoch 79, batch 65: loss = 0.006645\n",
      "Epoch 79, batch 66: loss = 0.006420\n",
      "Epoch 79, batch 67: loss = 0.006539\n",
      "Epoch 79, batch 68: loss = 0.006872\n",
      "Epoch 79, batch 69: loss = 0.006699\n",
      "Epoch 79, batch 70: loss = 0.006709\n",
      "Epoch 79, batch 71: loss = 0.006756\n",
      "Epoch 79, batch 72: loss = 0.006242\n",
      "Epoch 79, batch 73: loss = 0.006021\n",
      "Epoch 79, batch 74: loss = 0.006507\n",
      "Epoch 79, batch 75: loss = 0.007240\n",
      "Epoch 79, batch 76: loss = 0.006410\n",
      "Epoch 79, batch 77: loss = 0.006575\n",
      "Epoch 79, batch 78: loss = 0.006214\n",
      "Epoch 79, batch 79: loss = 0.006233\n",
      "Epoch 79, batch 80: loss = 0.006581\n",
      "Epoch 79, batch 81: loss = 0.006560\n",
      "Epoch 79, batch 82: loss = 0.006532\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 79: val_loss = 0.035608\n",
      "Epoch 80, batch 0: loss = 0.006613\n",
      "Epoch 80, batch 1: loss = 0.006911\n",
      "Epoch 80, batch 2: loss = 0.007048\n",
      "Epoch 80, batch 3: loss = 0.006333\n",
      "Epoch 80, batch 4: loss = 0.007025\n",
      "Epoch 80, batch 5: loss = 0.007231\n",
      "Epoch 80, batch 6: loss = 0.006467\n",
      "Epoch 80, batch 7: loss = 0.006917\n",
      "Epoch 80, batch 8: loss = 0.006966\n",
      "Epoch 80, batch 9: loss = 0.006149\n",
      "Epoch 80, batch 10: loss = 0.007862\n",
      "Epoch 80, batch 11: loss = 0.006739\n",
      "Epoch 80, batch 12: loss = 0.007265\n",
      "Epoch 80, batch 13: loss = 0.007085\n",
      "Epoch 80, batch 14: loss = 0.006619\n",
      "Epoch 80, batch 15: loss = 0.006986\n",
      "Epoch 80, batch 16: loss = 0.007014\n",
      "Epoch 80, batch 17: loss = 0.006622\n",
      "Epoch 80, batch 18: loss = 0.006308\n",
      "Epoch 80, batch 19: loss = 0.007031\n",
      "Epoch 80, batch 20: loss = 0.007688\n",
      "Epoch 80, batch 21: loss = 0.006856\n",
      "Epoch 80, batch 22: loss = 0.006502\n",
      "Epoch 80, batch 23: loss = 0.006609\n",
      "Epoch 80, batch 24: loss = 0.007105\n",
      "Epoch 80, batch 25: loss = 0.007175\n",
      "Epoch 80, batch 26: loss = 0.006700\n",
      "Epoch 80, batch 27: loss = 0.006842\n",
      "Epoch 80, batch 28: loss = 0.007328\n",
      "Epoch 80, batch 29: loss = 0.006320\n",
      "Epoch 80, batch 30: loss = 0.006906\n",
      "Epoch 80, batch 31: loss = 0.006832\n",
      "Epoch 80, batch 32: loss = 0.006851\n",
      "Epoch 80, batch 33: loss = 0.007069\n",
      "Epoch 80, batch 34: loss = 0.007168\n",
      "Epoch 80, batch 35: loss = 0.007273\n",
      "Epoch 80, batch 36: loss = 0.007003\n",
      "Epoch 80, batch 37: loss = 0.006625\n",
      "Epoch 80, batch 38: loss = 0.007086\n",
      "Epoch 80, batch 39: loss = 0.006497\n",
      "Epoch 80, batch 40: loss = 0.006661\n",
      "Epoch 80, batch 41: loss = 0.006601\n",
      "Epoch 80, batch 42: loss = 0.006751\n",
      "Epoch 80, batch 43: loss = 0.006847\n",
      "Epoch 80, batch 44: loss = 0.006338\n",
      "Epoch 80, batch 45: loss = 0.006806\n",
      "Epoch 80, batch 46: loss = 0.006269\n",
      "Epoch 80, batch 47: loss = 0.006637\n",
      "Epoch 80, batch 48: loss = 0.006339\n",
      "Epoch 80, batch 49: loss = 0.006492\n",
      "Epoch 80, batch 50: loss = 0.006923\n",
      "Epoch 80, batch 51: loss = 0.007230\n",
      "Epoch 80, batch 52: loss = 0.006269\n",
      "Epoch 80, batch 53: loss = 0.007217\n",
      "Epoch 80, batch 54: loss = 0.006738\n",
      "Epoch 80, batch 55: loss = 0.006589\n",
      "Epoch 80, batch 56: loss = 0.006472\n",
      "Epoch 80, batch 57: loss = 0.007394\n",
      "Epoch 80, batch 58: loss = 0.006392\n",
      "Epoch 80, batch 59: loss = 0.006480\n",
      "Epoch 80, batch 60: loss = 0.006355\n",
      "Epoch 80, batch 61: loss = 0.006505\n",
      "Epoch 80, batch 62: loss = 0.006678\n",
      "Epoch 80, batch 63: loss = 0.006828\n",
      "Epoch 80, batch 64: loss = 0.006391\n",
      "Epoch 80, batch 65: loss = 0.006244\n",
      "Epoch 80, batch 66: loss = 0.006725\n",
      "Epoch 80, batch 67: loss = 0.007040\n",
      "Epoch 80, batch 68: loss = 0.006242\n",
      "Epoch 80, batch 69: loss = 0.006587\n",
      "Epoch 80, batch 70: loss = 0.006772\n",
      "Epoch 80, batch 71: loss = 0.006541\n",
      "Epoch 80, batch 72: loss = 0.006248\n",
      "Epoch 80, batch 73: loss = 0.006843\n",
      "Epoch 80, batch 74: loss = 0.006056\n",
      "Epoch 80, batch 75: loss = 0.006492\n",
      "Epoch 80, batch 76: loss = 0.006296\n",
      "Epoch 80, batch 77: loss = 0.007288\n",
      "Epoch 80, batch 78: loss = 0.006374\n",
      "Epoch 80, batch 79: loss = 0.006019\n",
      "Epoch 80, batch 80: loss = 0.006018\n",
      "Epoch 80, batch 81: loss = 0.006961\n",
      "Epoch 80, batch 82: loss = 0.006462\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 80: val_loss = 0.038580\n",
      "Epoch 81, batch 0: loss = 0.006857\n",
      "Epoch 81, batch 1: loss = 0.006606\n",
      "Epoch 81, batch 2: loss = 0.006661\n",
      "Epoch 81, batch 3: loss = 0.006613\n",
      "Epoch 81, batch 4: loss = 0.007017\n",
      "Epoch 81, batch 5: loss = 0.006859\n",
      "Epoch 81, batch 6: loss = 0.006474\n",
      "Epoch 81, batch 7: loss = 0.006424\n",
      "Epoch 81, batch 8: loss = 0.006474\n",
      "Epoch 81, batch 9: loss = 0.006660\n",
      "Epoch 81, batch 10: loss = 0.006261\n",
      "Epoch 81, batch 11: loss = 0.006299\n",
      "Epoch 81, batch 12: loss = 0.006164\n",
      "Epoch 81, batch 13: loss = 0.006698\n",
      "Epoch 81, batch 14: loss = 0.006723\n",
      "Epoch 81, batch 15: loss = 0.006636\n",
      "Epoch 81, batch 16: loss = 0.006676\n",
      "Epoch 81, batch 17: loss = 0.006417\n",
      "Epoch 81, batch 18: loss = 0.006424\n",
      "Epoch 81, batch 19: loss = 0.006449\n",
      "Epoch 81, batch 20: loss = 0.006358\n",
      "Epoch 81, batch 21: loss = 0.006461\n",
      "Epoch 81, batch 22: loss = 0.006447\n",
      "Epoch 81, batch 23: loss = 0.006532\n",
      "Epoch 81, batch 24: loss = 0.006688\n",
      "Epoch 81, batch 25: loss = 0.006583\n",
      "Epoch 81, batch 26: loss = 0.006976\n",
      "Epoch 81, batch 27: loss = 0.006614\n",
      "Epoch 81, batch 28: loss = 0.006169\n",
      "Epoch 81, batch 29: loss = 0.006954\n",
      "Epoch 81, batch 30: loss = 0.006395\n",
      "Epoch 81, batch 31: loss = 0.006122\n",
      "Epoch 81, batch 32: loss = 0.005969\n",
      "Epoch 81, batch 33: loss = 0.006327\n",
      "Epoch 81, batch 34: loss = 0.006643\n",
      "Epoch 81, batch 35: loss = 0.006443\n",
      "Epoch 81, batch 36: loss = 0.006562\n",
      "Epoch 81, batch 37: loss = 0.006479\n",
      "Epoch 81, batch 38: loss = 0.006338\n",
      "Epoch 81, batch 39: loss = 0.006682\n",
      "Epoch 81, batch 40: loss = 0.006956\n",
      "Epoch 81, batch 41: loss = 0.006332\n",
      "Epoch 81, batch 42: loss = 0.005957\n",
      "Epoch 81, batch 43: loss = 0.006190\n",
      "Epoch 81, batch 44: loss = 0.006664\n",
      "Epoch 81, batch 45: loss = 0.006848\n",
      "Epoch 81, batch 46: loss = 0.006131\n",
      "Epoch 81, batch 47: loss = 0.006444\n",
      "Epoch 81, batch 48: loss = 0.006556\n",
      "Epoch 81, batch 49: loss = 0.006483\n",
      "Epoch 81, batch 50: loss = 0.006450\n",
      "Epoch 81, batch 51: loss = 0.006871\n",
      "Epoch 81, batch 52: loss = 0.006628\n",
      "Epoch 81, batch 53: loss = 0.006334\n",
      "Epoch 81, batch 54: loss = 0.006244\n",
      "Epoch 81, batch 55: loss = 0.006879\n",
      "Epoch 81, batch 56: loss = 0.006770\n",
      "Epoch 81, batch 57: loss = 0.006353\n",
      "Epoch 81, batch 58: loss = 0.006779\n",
      "Epoch 81, batch 59: loss = 0.006869\n",
      "Epoch 81, batch 60: loss = 0.007177\n",
      "Epoch 81, batch 61: loss = 0.006820\n",
      "Epoch 81, batch 62: loss = 0.006935\n",
      "Epoch 81, batch 63: loss = 0.007395\n",
      "Epoch 81, batch 64: loss = 0.007044\n",
      "Epoch 81, batch 65: loss = 0.006515\n",
      "Epoch 81, batch 66: loss = 0.007000\n",
      "Epoch 81, batch 67: loss = 0.007130\n",
      "Epoch 81, batch 68: loss = 0.007041\n",
      "Epoch 81, batch 69: loss = 0.006324\n",
      "Epoch 81, batch 70: loss = 0.006590\n",
      "Epoch 81, batch 71: loss = 0.006691\n",
      "Epoch 81, batch 72: loss = 0.007186\n",
      "Epoch 81, batch 73: loss = 0.006705\n",
      "Epoch 81, batch 74: loss = 0.006767\n",
      "Epoch 81, batch 75: loss = 0.006606\n",
      "Epoch 81, batch 76: loss = 0.007305\n",
      "Epoch 81, batch 77: loss = 0.006052\n",
      "Epoch 81, batch 78: loss = 0.006146\n",
      "Epoch 81, batch 79: loss = 0.006942\n",
      "Epoch 81, batch 80: loss = 0.006742\n",
      "Epoch 81, batch 81: loss = 0.006410\n",
      "Epoch 81, batch 82: loss = 0.004649\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 81: val_loss = 0.034643\n",
      "Epoch 82, batch 0: loss = 0.006801\n",
      "Epoch 82, batch 1: loss = 0.006518\n",
      "Epoch 82, batch 2: loss = 0.006847\n",
      "Epoch 82, batch 3: loss = 0.006556\n",
      "Epoch 82, batch 4: loss = 0.005991\n",
      "Epoch 82, batch 5: loss = 0.006707\n",
      "Epoch 82, batch 6: loss = 0.007338\n",
      "Epoch 82, batch 7: loss = 0.006801\n",
      "Epoch 82, batch 8: loss = 0.006575\n",
      "Epoch 82, batch 9: loss = 0.006536\n",
      "Epoch 82, batch 10: loss = 0.006896\n",
      "Epoch 82, batch 11: loss = 0.006828\n",
      "Epoch 82, batch 12: loss = 0.006494\n",
      "Epoch 82, batch 13: loss = 0.006417\n",
      "Epoch 82, batch 14: loss = 0.007031\n",
      "Epoch 82, batch 15: loss = 0.006820\n",
      "Epoch 82, batch 16: loss = 0.006617\n",
      "Epoch 82, batch 17: loss = 0.006668\n",
      "Epoch 82, batch 18: loss = 0.006092\n",
      "Epoch 82, batch 19: loss = 0.006462\n",
      "Epoch 82, batch 20: loss = 0.007056\n",
      "Epoch 82, batch 21: loss = 0.006289\n",
      "Epoch 82, batch 22: loss = 0.006817\n",
      "Epoch 82, batch 23: loss = 0.006829\n",
      "Epoch 82, batch 24: loss = 0.006492\n",
      "Epoch 82, batch 25: loss = 0.006114\n",
      "Epoch 82, batch 26: loss = 0.006847\n",
      "Epoch 82, batch 27: loss = 0.006633\n",
      "Epoch 82, batch 28: loss = 0.006690\n",
      "Epoch 82, batch 29: loss = 0.006375\n",
      "Epoch 82, batch 30: loss = 0.007153\n",
      "Epoch 82, batch 31: loss = 0.007608\n",
      "Epoch 82, batch 32: loss = 0.008440\n",
      "Epoch 82, batch 33: loss = 0.008619\n",
      "Epoch 82, batch 34: loss = 0.007453\n",
      "Epoch 82, batch 35: loss = 0.007815\n",
      "Epoch 82, batch 36: loss = 0.006904\n",
      "Epoch 82, batch 37: loss = 0.008001\n",
      "Epoch 82, batch 38: loss = 0.007562\n",
      "Epoch 82, batch 39: loss = 0.007300\n",
      "Epoch 82, batch 40: loss = 0.007780\n",
      "Epoch 82, batch 41: loss = 0.007674\n",
      "Epoch 82, batch 42: loss = 0.006770\n",
      "Epoch 82, batch 43: loss = 0.007476\n",
      "Epoch 82, batch 44: loss = 0.007387\n",
      "Epoch 82, batch 45: loss = 0.007436\n",
      "Epoch 82, batch 46: loss = 0.006776\n",
      "Epoch 82, batch 47: loss = 0.006989\n",
      "Epoch 82, batch 48: loss = 0.006537\n",
      "Epoch 82, batch 49: loss = 0.007356\n",
      "Epoch 82, batch 50: loss = 0.007021\n",
      "Epoch 82, batch 51: loss = 0.007035\n",
      "Epoch 82, batch 52: loss = 0.007289\n",
      "Epoch 82, batch 53: loss = 0.007380\n",
      "Epoch 82, batch 54: loss = 0.007384\n",
      "Epoch 82, batch 55: loss = 0.006720\n",
      "Epoch 82, batch 56: loss = 0.006701\n",
      "Epoch 82, batch 57: loss = 0.006791\n",
      "Epoch 82, batch 58: loss = 0.007153\n",
      "Epoch 82, batch 59: loss = 0.006813\n",
      "Epoch 82, batch 60: loss = 0.007080\n",
      "Epoch 82, batch 61: loss = 0.006874\n",
      "Epoch 82, batch 62: loss = 0.006818\n",
      "Epoch 82, batch 63: loss = 0.006744\n",
      "Epoch 82, batch 64: loss = 0.006090\n",
      "Epoch 82, batch 65: loss = 0.007105\n",
      "Epoch 82, batch 66: loss = 0.006912\n",
      "Epoch 82, batch 67: loss = 0.007131\n",
      "Epoch 82, batch 68: loss = 0.007354\n",
      "Epoch 82, batch 69: loss = 0.006499\n",
      "Epoch 82, batch 70: loss = 0.006962\n",
      "Epoch 82, batch 71: loss = 0.007116\n",
      "Epoch 82, batch 72: loss = 0.006487\n",
      "Epoch 82, batch 73: loss = 0.007251\n",
      "Epoch 82, batch 74: loss = 0.007582\n",
      "Epoch 82, batch 75: loss = 0.006506\n",
      "Epoch 82, batch 76: loss = 0.007092\n",
      "Epoch 82, batch 77: loss = 0.006991\n",
      "Epoch 82, batch 78: loss = 0.007169\n",
      "Epoch 82, batch 79: loss = 0.007034\n",
      "Epoch 82, batch 80: loss = 0.006793\n",
      "Epoch 82, batch 81: loss = 0.006228\n",
      "Epoch 82, batch 82: loss = 0.006924\n",
      "Validation\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 82: val_loss = 0.036853\n",
      "Epoch 83, batch 0: loss = 0.007111\n",
      "Epoch 83, batch 1: loss = 0.007629\n",
      "Epoch 83, batch 2: loss = 0.007419\n",
      "Epoch 83, batch 3: loss = 0.007128\n",
      "Epoch 83, batch 4: loss = 0.007268\n",
      "Epoch 83, batch 5: loss = 0.007496\n",
      "Epoch 83, batch 6: loss = 0.006623\n",
      "Epoch 83, batch 7: loss = 0.007127\n",
      "Epoch 83, batch 8: loss = 0.007547\n",
      "Epoch 83, batch 9: loss = 0.007145\n",
      "Epoch 83, batch 10: loss = 0.006714\n",
      "Epoch 83, batch 11: loss = 0.006947\n",
      "Epoch 83, batch 12: loss = 0.006946\n",
      "Epoch 83, batch 13: loss = 0.006746\n",
      "Epoch 83, batch 14: loss = 0.006804\n",
      "Epoch 83, batch 15: loss = 0.006815\n",
      "Epoch 83, batch 16: loss = 0.007295\n",
      "Epoch 83, batch 17: loss = 0.007287\n",
      "Epoch 83, batch 18: loss = 0.006434\n",
      "Epoch 83, batch 19: loss = 0.007200\n",
      "Epoch 83, batch 20: loss = 0.006651\n",
      "Epoch 83, batch 21: loss = 0.007054\n",
      "Epoch 83, batch 22: loss = 0.006278\n",
      "Epoch 83, batch 23: loss = 0.006390\n",
      "Epoch 83, batch 24: loss = 0.007289\n",
      "Epoch 83, batch 25: loss = 0.006858\n",
      "Epoch 83, batch 26: loss = 0.006661\n",
      "Epoch 83, batch 27: loss = 0.006639\n",
      "Epoch 83, batch 28: loss = 0.006623\n",
      "Epoch 83, batch 29: loss = 0.006606\n",
      "Epoch 83, batch 30: loss = 0.006696\n",
      "Epoch 83, batch 31: loss = 0.006667\n",
      "Epoch 83, batch 32: loss = 0.006859\n",
      "Epoch 83, batch 33: loss = 0.006639\n",
      "Epoch 83, batch 34: loss = 0.006980\n",
      "Epoch 83, batch 35: loss = 0.006623\n",
      "Epoch 83, batch 36: loss = 0.006394\n",
      "Epoch 83, batch 37: loss = 0.006300\n",
      "Epoch 83, batch 38: loss = 0.006934\n",
      "Epoch 83, batch 39: loss = 0.006362\n",
      "Epoch 83, batch 40: loss = 0.006357\n",
      "Epoch 83, batch 41: loss = 0.006353\n",
      "Epoch 83, batch 42: loss = 0.006776\n",
      "Epoch 83, batch 43: loss = 0.006357\n",
      "Epoch 83, batch 44: loss = 0.006866\n",
      "Epoch 83, batch 45: loss = 0.006519\n",
      "Epoch 83, batch 46: loss = 0.006916\n",
      "Epoch 83, batch 47: loss = 0.006709\n",
      "Epoch 83, batch 48: loss = 0.006330\n",
      "Epoch 83, batch 49: loss = 0.006248\n",
      "Epoch 83, batch 50: loss = 0.006518\n",
      "Epoch 83, batch 51: loss = 0.006392\n",
      "Epoch 83, batch 52: loss = 0.007647\n",
      "Epoch 83, batch 53: loss = 0.006634\n",
      "Epoch 83, batch 54: loss = 0.006811\n",
      "Epoch 83, batch 55: loss = 0.006319\n",
      "Epoch 83, batch 56: loss = 0.006712\n",
      "Epoch 83, batch 57: loss = 0.006339\n",
      "Epoch 83, batch 58: loss = 0.006322\n",
      "Epoch 83, batch 59: loss = 0.006090\n",
      "Epoch 83, batch 60: loss = 0.005730\n",
      "Epoch 83, batch 61: loss = 0.007002\n",
      "Epoch 83, batch 62: loss = 0.006140\n",
      "Epoch 83, batch 63: loss = 0.006283\n",
      "Epoch 83, batch 64: loss = 0.006623\n",
      "Epoch 83, batch 65: loss = 0.006467\n",
      "Epoch 83, batch 66: loss = 0.006168\n",
      "Epoch 83, batch 67: loss = 0.006290\n",
      "Epoch 83, batch 68: loss = 0.006649\n",
      "Epoch 83, batch 69: loss = 0.006615\n",
      "Epoch 83, batch 70: loss = 0.006592\n",
      "Epoch 83, batch 71: loss = 0.006280\n",
      "Epoch 83, batch 72: loss = 0.006604\n",
      "Epoch 83, batch 73: loss = 0.006521\n",
      "Epoch 83, batch 74: loss = 0.006395\n",
      "Epoch 83, batch 75: loss = 0.006490\n",
      "Epoch 83, batch 76: loss = 0.006464\n",
      "Epoch 83, batch 77: loss = 0.006167\n",
      "Epoch 83, batch 78: loss = 0.006315\n",
      "Epoch 83, batch 79: loss = 0.006905\n",
      "Epoch 83, batch 80: loss = 0.006691\n",
      "Epoch 83, batch 81: loss = 0.006226\n",
      "Epoch 83, batch 82: loss = 0.006201\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 83: val_loss = 0.038014\n",
      "Epoch 84, batch 0: loss = 0.006571\n",
      "Epoch 84, batch 1: loss = 0.006623\n",
      "Epoch 84, batch 2: loss = 0.006619\n",
      "Epoch 84, batch 3: loss = 0.006667\n",
      "Epoch 84, batch 4: loss = 0.006891\n",
      "Epoch 84, batch 5: loss = 0.006472\n",
      "Epoch 84, batch 6: loss = 0.006362\n",
      "Epoch 84, batch 7: loss = 0.006523\n",
      "Epoch 84, batch 8: loss = 0.006443\n",
      "Epoch 84, batch 9: loss = 0.006402\n",
      "Epoch 84, batch 10: loss = 0.006755\n",
      "Epoch 84, batch 11: loss = 0.006792\n",
      "Epoch 84, batch 12: loss = 0.006652\n",
      "Epoch 84, batch 13: loss = 0.006386\n",
      "Epoch 84, batch 14: loss = 0.006675\n",
      "Epoch 84, batch 15: loss = 0.006115\n",
      "Epoch 84, batch 16: loss = 0.006406\n",
      "Epoch 84, batch 17: loss = 0.006373\n",
      "Epoch 84, batch 18: loss = 0.006631\n",
      "Epoch 84, batch 19: loss = 0.006457\n",
      "Epoch 84, batch 20: loss = 0.006295\n",
      "Epoch 84, batch 21: loss = 0.006333\n",
      "Epoch 84, batch 22: loss = 0.006303\n",
      "Epoch 84, batch 23: loss = 0.005866\n",
      "Epoch 84, batch 24: loss = 0.006610\n",
      "Epoch 84, batch 25: loss = 0.006612\n",
      "Epoch 84, batch 26: loss = 0.006286\n",
      "Epoch 84, batch 27: loss = 0.006799\n",
      "Epoch 84, batch 28: loss = 0.006101\n",
      "Epoch 84, batch 29: loss = 0.006293\n",
      "Epoch 84, batch 30: loss = 0.006374\n",
      "Epoch 84, batch 31: loss = 0.006177\n",
      "Epoch 84, batch 32: loss = 0.006162\n",
      "Epoch 84, batch 33: loss = 0.006661\n",
      "Epoch 84, batch 34: loss = 0.006391\n",
      "Epoch 84, batch 35: loss = 0.006147\n",
      "Epoch 84, batch 36: loss = 0.006188\n",
      "Epoch 84, batch 37: loss = 0.006939\n",
      "Epoch 84, batch 38: loss = 0.006399\n",
      "Epoch 84, batch 39: loss = 0.005992\n",
      "Epoch 84, batch 40: loss = 0.006283\n",
      "Epoch 84, batch 41: loss = 0.006261\n",
      "Epoch 84, batch 42: loss = 0.006153\n",
      "Epoch 84, batch 43: loss = 0.006527\n",
      "Epoch 84, batch 44: loss = 0.006529\n",
      "Epoch 84, batch 45: loss = 0.006585\n",
      "Epoch 84, batch 46: loss = 0.006781\n",
      "Epoch 84, batch 47: loss = 0.006215\n",
      "Epoch 84, batch 48: loss = 0.006181\n",
      "Epoch 84, batch 49: loss = 0.006873\n",
      "Epoch 84, batch 50: loss = 0.006338\n",
      "Epoch 84, batch 51: loss = 0.006561\n",
      "Epoch 84, batch 52: loss = 0.005852\n",
      "Epoch 84, batch 53: loss = 0.006605\n",
      "Epoch 84, batch 54: loss = 0.006510\n",
      "Epoch 84, batch 55: loss = 0.006699\n",
      "Epoch 84, batch 56: loss = 0.006597\n",
      "Epoch 84, batch 57: loss = 0.006626\n",
      "Epoch 84, batch 58: loss = 0.006421\n",
      "Epoch 84, batch 59: loss = 0.006607\n",
      "Epoch 84, batch 60: loss = 0.006086\n",
      "Epoch 84, batch 61: loss = 0.006152\n",
      "Epoch 84, batch 62: loss = 0.006511\n",
      "Epoch 84, batch 63: loss = 0.006821\n",
      "Epoch 84, batch 64: loss = 0.007026\n",
      "Epoch 84, batch 65: loss = 0.006709\n",
      "Epoch 84, batch 66: loss = 0.006414\n",
      "Epoch 84, batch 67: loss = 0.006652\n",
      "Epoch 84, batch 68: loss = 0.006261\n",
      "Epoch 84, batch 69: loss = 0.006926\n",
      "Epoch 84, batch 70: loss = 0.006352\n",
      "Epoch 84, batch 71: loss = 0.006195\n",
      "Epoch 84, batch 72: loss = 0.006515\n",
      "Epoch 84, batch 73: loss = 0.006469\n",
      "Epoch 84, batch 74: loss = 0.006394\n",
      "Epoch 84, batch 75: loss = 0.006591\n",
      "Epoch 84, batch 76: loss = 0.006483\n",
      "Epoch 84, batch 77: loss = 0.006213\n",
      "Epoch 84, batch 78: loss = 0.006063\n",
      "Epoch 84, batch 79: loss = 0.006663\n",
      "Epoch 84, batch 80: loss = 0.006364\n",
      "Epoch 84, batch 81: loss = 0.006271\n",
      "Epoch 84, batch 82: loss = 0.006218\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 84: val_loss = 0.039876\n",
      "Epoch 85, batch 0: loss = 0.006650\n",
      "Epoch 85, batch 1: loss = 0.007315\n",
      "Epoch 85, batch 2: loss = 0.007445\n",
      "Epoch 85, batch 3: loss = 0.006686\n",
      "Epoch 85, batch 4: loss = 0.007040\n",
      "Epoch 85, batch 5: loss = 0.007402\n",
      "Epoch 85, batch 6: loss = 0.007588\n",
      "Epoch 85, batch 7: loss = 0.007205\n",
      "Epoch 85, batch 8: loss = 0.007058\n",
      "Epoch 85, batch 9: loss = 0.006720\n",
      "Epoch 85, batch 10: loss = 0.007889\n",
      "Epoch 85, batch 11: loss = 0.006711\n",
      "Epoch 85, batch 12: loss = 0.007140\n",
      "Epoch 85, batch 13: loss = 0.006945\n",
      "Epoch 85, batch 14: loss = 0.007002\n",
      "Epoch 85, batch 15: loss = 0.006680\n",
      "Epoch 85, batch 16: loss = 0.006502\n",
      "Epoch 85, batch 17: loss = 0.006759\n",
      "Epoch 85, batch 18: loss = 0.007318\n",
      "Epoch 85, batch 19: loss = 0.007045\n",
      "Epoch 85, batch 20: loss = 0.006674\n",
      "Epoch 85, batch 21: loss = 0.006886\n",
      "Epoch 85, batch 22: loss = 0.007215\n",
      "Epoch 85, batch 23: loss = 0.007237\n",
      "Epoch 85, batch 24: loss = 0.006802\n",
      "Epoch 85, batch 25: loss = 0.007085\n",
      "Epoch 85, batch 26: loss = 0.006721\n",
      "Epoch 85, batch 27: loss = 0.006835\n",
      "Epoch 85, batch 28: loss = 0.006505\n",
      "Epoch 85, batch 29: loss = 0.006425\n",
      "Epoch 85, batch 30: loss = 0.006322\n",
      "Epoch 85, batch 31: loss = 0.007119\n",
      "Epoch 85, batch 32: loss = 0.006644\n",
      "Epoch 85, batch 33: loss = 0.007134\n",
      "Epoch 85, batch 34: loss = 0.006787\n",
      "Epoch 85, batch 35: loss = 0.007011\n",
      "Epoch 85, batch 36: loss = 0.006902\n",
      "Epoch 85, batch 37: loss = 0.006723\n",
      "Epoch 85, batch 38: loss = 0.006643\n",
      "Epoch 85, batch 39: loss = 0.006241\n",
      "Epoch 85, batch 40: loss = 0.006347\n",
      "Epoch 85, batch 41: loss = 0.006742\n",
      "Epoch 85, batch 42: loss = 0.006180\n",
      "Epoch 85, batch 43: loss = 0.006565\n",
      "Epoch 85, batch 44: loss = 0.006546\n",
      "Epoch 85, batch 45: loss = 0.006162\n",
      "Epoch 85, batch 46: loss = 0.006820\n",
      "Epoch 85, batch 47: loss = 0.006474\n",
      "Epoch 85, batch 48: loss = 0.006554\n",
      "Epoch 85, batch 49: loss = 0.006736\n",
      "Epoch 85, batch 50: loss = 0.006989\n",
      "Epoch 85, batch 51: loss = 0.006180\n",
      "Epoch 85, batch 52: loss = 0.006293\n",
      "Epoch 85, batch 53: loss = 0.006928\n",
      "Epoch 85, batch 54: loss = 0.006734\n",
      "Epoch 85, batch 55: loss = 0.006933\n",
      "Epoch 85, batch 56: loss = 0.006712\n",
      "Epoch 85, batch 57: loss = 0.006487\n",
      "Epoch 85, batch 58: loss = 0.006373\n",
      "Epoch 85, batch 59: loss = 0.006468\n",
      "Epoch 85, batch 60: loss = 0.006359\n",
      "Epoch 85, batch 61: loss = 0.006528\n",
      "Epoch 85, batch 62: loss = 0.006757\n",
      "Epoch 85, batch 63: loss = 0.007046\n",
      "Epoch 85, batch 64: loss = 0.006235\n",
      "Epoch 85, batch 65: loss = 0.006146\n",
      "Epoch 85, batch 66: loss = 0.006792\n",
      "Epoch 85, batch 67: loss = 0.006005\n",
      "Epoch 85, batch 68: loss = 0.006119\n",
      "Epoch 85, batch 69: loss = 0.006886\n",
      "Epoch 85, batch 70: loss = 0.006249\n",
      "Epoch 85, batch 71: loss = 0.006775\n",
      "Epoch 85, batch 72: loss = 0.006139\n",
      "Epoch 85, batch 73: loss = 0.006767\n",
      "Epoch 85, batch 74: loss = 0.006328\n",
      "Epoch 85, batch 75: loss = 0.006703\n",
      "Epoch 85, batch 76: loss = 0.006489\n",
      "Epoch 85, batch 77: loss = 0.006487\n",
      "Epoch 85, batch 78: loss = 0.006670\n",
      "Epoch 85, batch 79: loss = 0.006209\n",
      "Epoch 85, batch 80: loss = 0.006876\n",
      "Epoch 85, batch 81: loss = 0.006275\n",
      "Epoch 85, batch 82: loss = 0.007673\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 85: val_loss = 0.040629\n",
      "Epoch 86, batch 0: loss = 0.007547\n",
      "Epoch 86, batch 1: loss = 0.006670\n",
      "Epoch 86, batch 2: loss = 0.007014\n",
      "Epoch 86, batch 3: loss = 0.006572\n",
      "Epoch 86, batch 4: loss = 0.006421\n",
      "Epoch 86, batch 5: loss = 0.006528\n",
      "Epoch 86, batch 6: loss = 0.006127\n",
      "Epoch 86, batch 7: loss = 0.006475\n",
      "Epoch 86, batch 8: loss = 0.006661\n",
      "Epoch 86, batch 9: loss = 0.006614\n",
      "Epoch 86, batch 10: loss = 0.006455\n",
      "Epoch 86, batch 11: loss = 0.006738\n",
      "Epoch 86, batch 12: loss = 0.006618\n",
      "Epoch 86, batch 13: loss = 0.006637\n",
      "Epoch 86, batch 14: loss = 0.006906\n",
      "Epoch 86, batch 15: loss = 0.006549\n",
      "Epoch 86, batch 16: loss = 0.006461\n",
      "Epoch 86, batch 17: loss = 0.006540\n",
      "Epoch 86, batch 18: loss = 0.006575\n",
      "Epoch 86, batch 19: loss = 0.006366\n",
      "Epoch 86, batch 20: loss = 0.006576\n",
      "Epoch 86, batch 21: loss = 0.006729\n",
      "Epoch 86, batch 22: loss = 0.006806\n",
      "Epoch 86, batch 23: loss = 0.006413\n",
      "Epoch 86, batch 24: loss = 0.006575\n",
      "Epoch 86, batch 25: loss = 0.006502\n",
      "Epoch 86, batch 26: loss = 0.006454\n",
      "Epoch 86, batch 27: loss = 0.006515\n",
      "Epoch 86, batch 28: loss = 0.006370\n",
      "Epoch 86, batch 29: loss = 0.006323\n",
      "Epoch 86, batch 30: loss = 0.006317\n",
      "Epoch 86, batch 31: loss = 0.006221\n",
      "Epoch 86, batch 32: loss = 0.006827\n",
      "Epoch 86, batch 33: loss = 0.006089\n",
      "Epoch 86, batch 34: loss = 0.006523\n",
      "Epoch 86, batch 35: loss = 0.006054\n",
      "Epoch 86, batch 36: loss = 0.006208\n",
      "Epoch 86, batch 37: loss = 0.006305\n",
      "Epoch 86, batch 38: loss = 0.007260\n",
      "Epoch 86, batch 39: loss = 0.007033\n",
      "Epoch 86, batch 40: loss = 0.006655\n",
      "Epoch 86, batch 41: loss = 0.006211\n",
      "Epoch 86, batch 42: loss = 0.006308\n",
      "Epoch 86, batch 43: loss = 0.006561\n",
      "Epoch 86, batch 44: loss = 0.006705\n",
      "Epoch 86, batch 45: loss = 0.006518\n",
      "Epoch 86, batch 46: loss = 0.006115\n",
      "Epoch 86, batch 47: loss = 0.006175\n",
      "Epoch 86, batch 48: loss = 0.006320\n",
      "Epoch 86, batch 49: loss = 0.006345\n",
      "Epoch 86, batch 50: loss = 0.006256\n",
      "Epoch 86, batch 51: loss = 0.006289\n",
      "Epoch 86, batch 52: loss = 0.006181\n",
      "Epoch 86, batch 53: loss = 0.006486\n",
      "Epoch 86, batch 54: loss = 0.006504\n",
      "Epoch 86, batch 55: loss = 0.006512\n",
      "Epoch 86, batch 56: loss = 0.006780\n",
      "Epoch 86, batch 57: loss = 0.006707\n",
      "Epoch 86, batch 58: loss = 0.006593\n",
      "Epoch 86, batch 59: loss = 0.006304\n",
      "Epoch 86, batch 60: loss = 0.006480\n",
      "Epoch 86, batch 61: loss = 0.006329\n",
      "Epoch 86, batch 62: loss = 0.006292\n",
      "Epoch 86, batch 63: loss = 0.006863\n",
      "Epoch 86, batch 64: loss = 0.006228\n",
      "Epoch 86, batch 65: loss = 0.006331\n",
      "Epoch 86, batch 66: loss = 0.005910\n",
      "Epoch 86, batch 67: loss = 0.006214\n",
      "Epoch 86, batch 68: loss = 0.006803\n",
      "Epoch 86, batch 69: loss = 0.006495\n",
      "Epoch 86, batch 70: loss = 0.006658\n",
      "Epoch 86, batch 71: loss = 0.005993\n",
      "Epoch 86, batch 72: loss = 0.006362\n",
      "Epoch 86, batch 73: loss = 0.006222\n",
      "Epoch 86, batch 74: loss = 0.006824\n",
      "Epoch 86, batch 75: loss = 0.006714\n",
      "Epoch 86, batch 76: loss = 0.006590\n",
      "Epoch 86, batch 77: loss = 0.006148\n",
      "Epoch 86, batch 78: loss = 0.007119\n",
      "Epoch 86, batch 79: loss = 0.006151\n",
      "Epoch 86, batch 80: loss = 0.006366\n",
      "Epoch 86, batch 81: loss = 0.006888\n",
      "Epoch 86, batch 82: loss = 0.006354\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 86: val_loss = 0.039684\n",
      "Epoch 87, batch 0: loss = 0.006124\n",
      "Epoch 87, batch 1: loss = 0.006536\n",
      "Epoch 87, batch 2: loss = 0.006647\n",
      "Epoch 87, batch 3: loss = 0.006442\n",
      "Epoch 87, batch 4: loss = 0.007018\n",
      "Epoch 87, batch 5: loss = 0.006725\n",
      "Epoch 87, batch 6: loss = 0.006489\n",
      "Epoch 87, batch 7: loss = 0.006561\n",
      "Epoch 87, batch 8: loss = 0.006179\n",
      "Epoch 87, batch 9: loss = 0.006827\n",
      "Epoch 87, batch 10: loss = 0.006413\n",
      "Epoch 87, batch 11: loss = 0.006870\n",
      "Epoch 87, batch 12: loss = 0.006681\n",
      "Epoch 87, batch 13: loss = 0.006347\n",
      "Epoch 87, batch 14: loss = 0.006302\n",
      "Epoch 87, batch 15: loss = 0.006988\n",
      "Epoch 87, batch 16: loss = 0.006412\n",
      "Epoch 87, batch 17: loss = 0.005994\n",
      "Epoch 87, batch 18: loss = 0.006707\n",
      "Epoch 87, batch 19: loss = 0.006463\n",
      "Epoch 87, batch 20: loss = 0.006174\n",
      "Epoch 87, batch 21: loss = 0.006321\n",
      "Epoch 87, batch 22: loss = 0.006101\n",
      "Epoch 87, batch 23: loss = 0.006723\n",
      "Epoch 87, batch 24: loss = 0.006336\n",
      "Epoch 87, batch 25: loss = 0.006226\n",
      "Epoch 87, batch 26: loss = 0.006412\n",
      "Epoch 87, batch 27: loss = 0.005778\n",
      "Epoch 87, batch 28: loss = 0.006194\n",
      "Epoch 87, batch 29: loss = 0.006165\n",
      "Epoch 87, batch 30: loss = 0.006047\n",
      "Epoch 87, batch 31: loss = 0.006307\n",
      "Epoch 87, batch 32: loss = 0.006732\n",
      "Epoch 87, batch 33: loss = 0.006247\n",
      "Epoch 87, batch 34: loss = 0.006250\n",
      "Epoch 87, batch 35: loss = 0.006458\n",
      "Epoch 87, batch 36: loss = 0.005981\n",
      "Epoch 87, batch 37: loss = 0.006086\n",
      "Epoch 87, batch 38: loss = 0.006002\n",
      "Epoch 87, batch 39: loss = 0.006217\n",
      "Epoch 87, batch 40: loss = 0.006578\n",
      "Epoch 87, batch 41: loss = 0.006397\n",
      "Epoch 87, batch 42: loss = 0.006509\n",
      "Epoch 87, batch 43: loss = 0.006637\n",
      "Epoch 87, batch 44: loss = 0.006226\n",
      "Epoch 87, batch 45: loss = 0.006109\n",
      "Epoch 87, batch 46: loss = 0.006170\n",
      "Epoch 87, batch 47: loss = 0.006235\n",
      "Epoch 87, batch 48: loss = 0.006228\n",
      "Epoch 87, batch 49: loss = 0.006115\n",
      "Epoch 87, batch 50: loss = 0.006282\n",
      "Epoch 87, batch 51: loss = 0.005925\n",
      "Epoch 87, batch 52: loss = 0.006264\n",
      "Epoch 87, batch 53: loss = 0.006069\n",
      "Epoch 87, batch 54: loss = 0.006257\n",
      "Epoch 87, batch 55: loss = 0.006220\n",
      "Epoch 87, batch 56: loss = 0.006517\n",
      "Epoch 87, batch 57: loss = 0.006274\n",
      "Epoch 87, batch 58: loss = 0.006681\n",
      "Epoch 87, batch 59: loss = 0.005940\n",
      "Epoch 87, batch 60: loss = 0.005947\n",
      "Epoch 87, batch 61: loss = 0.006363\n",
      "Epoch 87, batch 62: loss = 0.006492\n",
      "Epoch 87, batch 63: loss = 0.006335\n",
      "Epoch 87, batch 64: loss = 0.006170\n",
      "Epoch 87, batch 65: loss = 0.006163\n",
      "Epoch 87, batch 66: loss = 0.005917\n",
      "Epoch 87, batch 67: loss = 0.006528\n",
      "Epoch 87, batch 68: loss = 0.006492\n",
      "Epoch 87, batch 69: loss = 0.006150\n",
      "Epoch 87, batch 70: loss = 0.006202\n",
      "Epoch 87, batch 71: loss = 0.005857\n",
      "Epoch 87, batch 72: loss = 0.006016\n",
      "Epoch 87, batch 73: loss = 0.006041\n",
      "Epoch 87, batch 74: loss = 0.005810\n",
      "Epoch 87, batch 75: loss = 0.005851\n",
      "Epoch 87, batch 76: loss = 0.006173\n",
      "Epoch 87, batch 77: loss = 0.006375\n",
      "Epoch 87, batch 78: loss = 0.006359\n",
      "Epoch 87, batch 79: loss = 0.006628\n",
      "Epoch 87, batch 80: loss = 0.006499\n",
      "Epoch 87, batch 81: loss = 0.006705\n",
      "Epoch 87, batch 82: loss = 0.005535\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 87: val_loss = 0.038187\n",
      "Epoch 88, batch 0: loss = 0.005914\n",
      "Epoch 88, batch 1: loss = 0.006210\n",
      "Epoch 88, batch 2: loss = 0.006443\n",
      "Epoch 88, batch 3: loss = 0.005819\n",
      "Epoch 88, batch 4: loss = 0.006491\n",
      "Epoch 88, batch 5: loss = 0.006348\n",
      "Epoch 88, batch 6: loss = 0.006027\n",
      "Epoch 88, batch 7: loss = 0.006496\n",
      "Epoch 88, batch 8: loss = 0.006794\n",
      "Epoch 88, batch 9: loss = 0.006507\n",
      "Epoch 88, batch 10: loss = 0.006173\n",
      "Epoch 88, batch 11: loss = 0.005999\n",
      "Epoch 88, batch 12: loss = 0.006250\n",
      "Epoch 88, batch 13: loss = 0.006160\n",
      "Epoch 88, batch 14: loss = 0.006169\n",
      "Epoch 88, batch 15: loss = 0.006122\n",
      "Epoch 88, batch 16: loss = 0.006469\n",
      "Epoch 88, batch 17: loss = 0.005953\n",
      "Epoch 88, batch 18: loss = 0.006260\n",
      "Epoch 88, batch 19: loss = 0.005616\n",
      "Epoch 88, batch 20: loss = 0.006054\n",
      "Epoch 88, batch 21: loss = 0.006340\n",
      "Epoch 88, batch 22: loss = 0.006389\n",
      "Epoch 88, batch 23: loss = 0.006086\n",
      "Epoch 88, batch 24: loss = 0.006333\n",
      "Epoch 88, batch 25: loss = 0.005960\n",
      "Epoch 88, batch 26: loss = 0.006263\n",
      "Epoch 88, batch 27: loss = 0.006137\n",
      "Epoch 88, batch 28: loss = 0.005989\n",
      "Epoch 88, batch 29: loss = 0.006710\n",
      "Epoch 88, batch 30: loss = 0.005883\n",
      "Epoch 88, batch 31: loss = 0.005979\n",
      "Epoch 88, batch 32: loss = 0.005943\n",
      "Epoch 88, batch 33: loss = 0.006475\n",
      "Epoch 88, batch 34: loss = 0.006530\n",
      "Epoch 88, batch 35: loss = 0.006564\n",
      "Epoch 88, batch 36: loss = 0.006057\n",
      "Epoch 88, batch 37: loss = 0.005897\n",
      "Epoch 88, batch 38: loss = 0.006571\n",
      "Epoch 88, batch 39: loss = 0.006495\n",
      "Epoch 88, batch 40: loss = 0.006499\n",
      "Epoch 88, batch 41: loss = 0.006185\n",
      "Epoch 88, batch 42: loss = 0.006412\n",
      "Epoch 88, batch 43: loss = 0.006569\n",
      "Epoch 88, batch 44: loss = 0.006158\n",
      "Epoch 88, batch 45: loss = 0.006558\n",
      "Epoch 88, batch 46: loss = 0.006429\n",
      "Epoch 88, batch 47: loss = 0.006294\n",
      "Epoch 88, batch 48: loss = 0.006458\n",
      "Epoch 88, batch 49: loss = 0.006653\n",
      "Epoch 88, batch 50: loss = 0.006430\n",
      "Epoch 88, batch 51: loss = 0.006702\n",
      "Epoch 88, batch 52: loss = 0.005982\n",
      "Epoch 88, batch 53: loss = 0.005912\n",
      "Epoch 88, batch 54: loss = 0.006462\n",
      "Epoch 88, batch 55: loss = 0.006156\n",
      "Epoch 88, batch 56: loss = 0.006766\n",
      "Epoch 88, batch 57: loss = 0.006116\n",
      "Epoch 88, batch 58: loss = 0.006265\n",
      "Epoch 88, batch 59: loss = 0.006291\n",
      "Epoch 88, batch 60: loss = 0.006049\n",
      "Epoch 88, batch 61: loss = 0.006457\n",
      "Epoch 88, batch 62: loss = 0.006196\n",
      "Epoch 88, batch 63: loss = 0.006321\n",
      "Epoch 88, batch 64: loss = 0.006111\n",
      "Epoch 88, batch 65: loss = 0.006244\n",
      "Epoch 88, batch 66: loss = 0.006216\n",
      "Epoch 88, batch 67: loss = 0.006047\n",
      "Epoch 88, batch 68: loss = 0.006497\n",
      "Epoch 88, batch 69: loss = 0.005928\n",
      "Epoch 88, batch 70: loss = 0.006114\n",
      "Epoch 88, batch 71: loss = 0.006052\n",
      "Epoch 88, batch 72: loss = 0.006251\n",
      "Epoch 88, batch 73: loss = 0.006240\n",
      "Epoch 88, batch 74: loss = 0.006063\n",
      "Epoch 88, batch 75: loss = 0.006474\n",
      "Epoch 88, batch 76: loss = 0.006242\n",
      "Epoch 88, batch 77: loss = 0.005428\n",
      "Epoch 88, batch 78: loss = 0.006168\n",
      "Epoch 88, batch 79: loss = 0.006402\n",
      "Epoch 88, batch 80: loss = 0.006108\n",
      "Epoch 88, batch 81: loss = 0.006183\n",
      "Epoch 88, batch 82: loss = 0.005689\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 88: val_loss = 0.039146\n",
      "Epoch 89, batch 0: loss = 0.005970\n",
      "Epoch 89, batch 1: loss = 0.006136\n",
      "Epoch 89, batch 2: loss = 0.006404\n",
      "Epoch 89, batch 3: loss = 0.006085\n",
      "Epoch 89, batch 4: loss = 0.006234\n",
      "Epoch 89, batch 5: loss = 0.006417\n",
      "Epoch 89, batch 6: loss = 0.006140\n",
      "Epoch 89, batch 7: loss = 0.005960\n",
      "Epoch 89, batch 8: loss = 0.006437\n",
      "Epoch 89, batch 9: loss = 0.006149\n",
      "Epoch 89, batch 10: loss = 0.006259\n",
      "Epoch 89, batch 11: loss = 0.005872\n",
      "Epoch 89, batch 12: loss = 0.006031\n",
      "Epoch 89, batch 13: loss = 0.006475\n",
      "Epoch 89, batch 14: loss = 0.006233\n",
      "Epoch 89, batch 15: loss = 0.006303\n",
      "Epoch 89, batch 16: loss = 0.006524\n",
      "Epoch 89, batch 17: loss = 0.006239\n",
      "Epoch 89, batch 18: loss = 0.006128\n",
      "Epoch 89, batch 19: loss = 0.006022\n",
      "Epoch 89, batch 20: loss = 0.005924\n",
      "Epoch 89, batch 21: loss = 0.006440\n",
      "Epoch 89, batch 22: loss = 0.005886\n",
      "Epoch 89, batch 23: loss = 0.006346\n",
      "Epoch 89, batch 24: loss = 0.005996\n",
      "Epoch 89, batch 25: loss = 0.006363\n",
      "Epoch 89, batch 26: loss = 0.006104\n",
      "Epoch 89, batch 27: loss = 0.006132\n",
      "Epoch 89, batch 28: loss = 0.005971\n",
      "Epoch 89, batch 29: loss = 0.006013\n",
      "Epoch 89, batch 30: loss = 0.006099\n",
      "Epoch 89, batch 31: loss = 0.006303\n",
      "Epoch 89, batch 32: loss = 0.006293\n",
      "Epoch 89, batch 33: loss = 0.005771\n",
      "Epoch 89, batch 34: loss = 0.006211\n",
      "Epoch 89, batch 35: loss = 0.006152\n",
      "Epoch 89, batch 36: loss = 0.006000\n",
      "Epoch 89, batch 37: loss = 0.006233\n",
      "Epoch 89, batch 38: loss = 0.006134\n",
      "Epoch 89, batch 39: loss = 0.005971\n",
      "Epoch 89, batch 40: loss = 0.006226\n",
      "Epoch 89, batch 41: loss = 0.005937\n",
      "Epoch 89, batch 42: loss = 0.005941\n",
      "Epoch 89, batch 43: loss = 0.006254\n",
      "Epoch 89, batch 44: loss = 0.006458\n",
      "Epoch 89, batch 45: loss = 0.006596\n",
      "Epoch 89, batch 46: loss = 0.006167\n",
      "Epoch 89, batch 47: loss = 0.006110\n",
      "Epoch 89, batch 48: loss = 0.006111\n",
      "Epoch 89, batch 49: loss = 0.006139\n",
      "Epoch 89, batch 50: loss = 0.005692\n",
      "Epoch 89, batch 51: loss = 0.006112\n",
      "Epoch 89, batch 52: loss = 0.005627\n",
      "Epoch 89, batch 53: loss = 0.005956\n",
      "Epoch 89, batch 54: loss = 0.006432\n",
      "Epoch 89, batch 55: loss = 0.006644\n",
      "Epoch 89, batch 56: loss = 0.006442\n",
      "Epoch 89, batch 57: loss = 0.006465\n",
      "Epoch 89, batch 58: loss = 0.005800\n",
      "Epoch 89, batch 59: loss = 0.006347\n",
      "Epoch 89, batch 60: loss = 0.005707\n",
      "Epoch 89, batch 61: loss = 0.006030\n",
      "Epoch 89, batch 62: loss = 0.005879\n",
      "Epoch 89, batch 63: loss = 0.006501\n",
      "Epoch 89, batch 64: loss = 0.006053\n",
      "Epoch 89, batch 65: loss = 0.006390\n",
      "Epoch 89, batch 66: loss = 0.006121\n",
      "Epoch 89, batch 67: loss = 0.006122\n",
      "Epoch 89, batch 68: loss = 0.006000\n",
      "Epoch 89, batch 69: loss = 0.005975\n",
      "Epoch 89, batch 70: loss = 0.006094\n",
      "Epoch 89, batch 71: loss = 0.006589\n",
      "Epoch 89, batch 72: loss = 0.005825\n",
      "Epoch 89, batch 73: loss = 0.006168\n",
      "Epoch 89, batch 74: loss = 0.005805\n",
      "Epoch 89, batch 75: loss = 0.005938\n",
      "Epoch 89, batch 76: loss = 0.006367\n",
      "Epoch 89, batch 77: loss = 0.005990\n",
      "Epoch 89, batch 78: loss = 0.006554\n",
      "Epoch 89, batch 79: loss = 0.005975\n",
      "Epoch 89, batch 80: loss = 0.006595\n",
      "Epoch 89, batch 81: loss = 0.006433\n",
      "Epoch 89, batch 82: loss = 0.005159\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 89: val_loss = 0.036644\n",
      "Epoch 90, batch 0: loss = 0.006697\n",
      "Epoch 90, batch 1: loss = 0.006587\n",
      "Epoch 90, batch 2: loss = 0.007237\n",
      "Epoch 90, batch 3: loss = 0.006694\n",
      "Epoch 90, batch 4: loss = 0.006477\n",
      "Epoch 90, batch 5: loss = 0.006434\n",
      "Epoch 90, batch 6: loss = 0.007151\n",
      "Epoch 90, batch 7: loss = 0.006797\n",
      "Epoch 90, batch 8: loss = 0.006770\n",
      "Epoch 90, batch 9: loss = 0.006466\n",
      "Epoch 90, batch 10: loss = 0.006668\n",
      "Epoch 90, batch 11: loss = 0.006042\n",
      "Epoch 90, batch 12: loss = 0.006029\n",
      "Epoch 90, batch 13: loss = 0.006392\n",
      "Epoch 90, batch 14: loss = 0.006975\n",
      "Epoch 90, batch 15: loss = 0.006533\n",
      "Epoch 90, batch 16: loss = 0.006223\n",
      "Epoch 90, batch 17: loss = 0.006586\n",
      "Epoch 90, batch 18: loss = 0.006246\n",
      "Epoch 90, batch 19: loss = 0.006542\n",
      "Epoch 90, batch 20: loss = 0.006148\n",
      "Epoch 90, batch 21: loss = 0.006037\n",
      "Epoch 90, batch 22: loss = 0.006240\n",
      "Epoch 90, batch 23: loss = 0.005861\n",
      "Epoch 90, batch 24: loss = 0.006252\n",
      "Epoch 90, batch 25: loss = 0.006212\n",
      "Epoch 90, batch 26: loss = 0.005769\n",
      "Epoch 90, batch 27: loss = 0.006329\n",
      "Epoch 90, batch 28: loss = 0.006637\n",
      "Epoch 90, batch 29: loss = 0.006515\n",
      "Epoch 90, batch 30: loss = 0.006530\n",
      "Epoch 90, batch 31: loss = 0.006101\n",
      "Epoch 90, batch 32: loss = 0.006426\n",
      "Epoch 90, batch 33: loss = 0.005905\n",
      "Epoch 90, batch 34: loss = 0.006743\n",
      "Epoch 90, batch 35: loss = 0.006927\n",
      "Epoch 90, batch 36: loss = 0.006020\n",
      "Epoch 90, batch 37: loss = 0.006326\n",
      "Epoch 90, batch 38: loss = 0.006168\n",
      "Epoch 90, batch 39: loss = 0.005842\n",
      "Epoch 90, batch 40: loss = 0.005806\n",
      "Epoch 90, batch 41: loss = 0.006513\n",
      "Epoch 90, batch 42: loss = 0.006362\n",
      "Epoch 90, batch 43: loss = 0.006484\n",
      "Epoch 90, batch 44: loss = 0.006371\n",
      "Epoch 90, batch 45: loss = 0.006134\n",
      "Epoch 90, batch 46: loss = 0.005773\n",
      "Epoch 90, batch 47: loss = 0.006233\n",
      "Epoch 90, batch 48: loss = 0.006605\n",
      "Epoch 90, batch 49: loss = 0.005919\n",
      "Epoch 90, batch 50: loss = 0.006196\n",
      "Epoch 90, batch 51: loss = 0.006249\n",
      "Epoch 90, batch 52: loss = 0.006152\n",
      "Epoch 90, batch 53: loss = 0.006078\n",
      "Epoch 90, batch 54: loss = 0.006066\n",
      "Epoch 90, batch 55: loss = 0.006340\n",
      "Epoch 90, batch 56: loss = 0.006002\n",
      "Epoch 90, batch 57: loss = 0.006818\n",
      "Epoch 90, batch 58: loss = 0.006288\n",
      "Epoch 90, batch 59: loss = 0.006414\n",
      "Epoch 90, batch 60: loss = 0.006142\n",
      "Epoch 90, batch 61: loss = 0.006542\n",
      "Epoch 90, batch 62: loss = 0.005819\n",
      "Epoch 90, batch 63: loss = 0.006467\n",
      "Epoch 90, batch 64: loss = 0.006030\n",
      "Epoch 90, batch 65: loss = 0.006200\n",
      "Epoch 90, batch 66: loss = 0.006027\n",
      "Epoch 90, batch 67: loss = 0.005853\n",
      "Epoch 90, batch 68: loss = 0.005777\n",
      "Epoch 90, batch 69: loss = 0.006182\n",
      "Epoch 90, batch 70: loss = 0.006472\n",
      "Epoch 90, batch 71: loss = 0.006122\n",
      "Epoch 90, batch 72: loss = 0.005848\n",
      "Epoch 90, batch 73: loss = 0.006461\n",
      "Epoch 90, batch 74: loss = 0.005991\n",
      "Epoch 90, batch 75: loss = 0.005713\n",
      "Epoch 90, batch 76: loss = 0.006077\n",
      "Epoch 90, batch 77: loss = 0.005927\n",
      "Epoch 90, batch 78: loss = 0.006179\n",
      "Epoch 90, batch 79: loss = 0.006075\n",
      "Epoch 90, batch 80: loss = 0.006112\n",
      "Epoch 90, batch 81: loss = 0.006013\n",
      "Epoch 90, batch 82: loss = 0.006099\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 90: val_loss = 0.036023\n",
      "Epoch 91, batch 0: loss = 0.006078\n",
      "Epoch 91, batch 1: loss = 0.005812\n",
      "Epoch 91, batch 2: loss = 0.005888\n",
      "Epoch 91, batch 3: loss = 0.006458\n",
      "Epoch 91, batch 4: loss = 0.006051\n",
      "Epoch 91, batch 5: loss = 0.006304\n",
      "Epoch 91, batch 6: loss = 0.006320\n",
      "Epoch 91, batch 7: loss = 0.006013\n",
      "Epoch 91, batch 8: loss = 0.006257\n",
      "Epoch 91, batch 9: loss = 0.006166\n",
      "Epoch 91, batch 10: loss = 0.006382\n",
      "Epoch 91, batch 11: loss = 0.006126\n",
      "Epoch 91, batch 12: loss = 0.006541\n",
      "Epoch 91, batch 13: loss = 0.006519\n",
      "Epoch 91, batch 14: loss = 0.006064\n",
      "Epoch 91, batch 15: loss = 0.006084\n",
      "Epoch 91, batch 16: loss = 0.006081\n",
      "Epoch 91, batch 17: loss = 0.006421\n",
      "Epoch 91, batch 18: loss = 0.006185\n",
      "Epoch 91, batch 19: loss = 0.006368\n",
      "Epoch 91, batch 20: loss = 0.006721\n",
      "Epoch 91, batch 21: loss = 0.006629\n",
      "Epoch 91, batch 22: loss = 0.006560\n",
      "Epoch 91, batch 23: loss = 0.006365\n",
      "Epoch 91, batch 24: loss = 0.006406\n",
      "Epoch 91, batch 25: loss = 0.005763\n",
      "Epoch 91, batch 26: loss = 0.006149\n",
      "Epoch 91, batch 27: loss = 0.005857\n",
      "Epoch 91, batch 28: loss = 0.005562\n",
      "Epoch 91, batch 29: loss = 0.006091\n",
      "Epoch 91, batch 30: loss = 0.006093\n",
      "Epoch 91, batch 31: loss = 0.005904\n",
      "Epoch 91, batch 32: loss = 0.006232\n",
      "Epoch 91, batch 33: loss = 0.006304\n",
      "Epoch 91, batch 34: loss = 0.006020\n",
      "Epoch 91, batch 35: loss = 0.005703\n",
      "Epoch 91, batch 36: loss = 0.006155\n",
      "Epoch 91, batch 37: loss = 0.005927\n",
      "Epoch 91, batch 38: loss = 0.006440\n",
      "Epoch 91, batch 39: loss = 0.005993\n",
      "Epoch 91, batch 40: loss = 0.006477\n",
      "Epoch 91, batch 41: loss = 0.005686\n",
      "Epoch 91, batch 42: loss = 0.005845\n",
      "Epoch 91, batch 43: loss = 0.006205\n",
      "Epoch 91, batch 44: loss = 0.005976\n",
      "Epoch 91, batch 45: loss = 0.005802\n",
      "Epoch 91, batch 46: loss = 0.006004\n",
      "Epoch 91, batch 47: loss = 0.005824\n",
      "Epoch 91, batch 48: loss = 0.005872\n",
      "Epoch 91, batch 49: loss = 0.006475\n",
      "Epoch 91, batch 50: loss = 0.006110\n",
      "Epoch 91, batch 51: loss = 0.006419\n",
      "Epoch 91, batch 52: loss = 0.005835\n",
      "Epoch 91, batch 53: loss = 0.006128\n",
      "Epoch 91, batch 54: loss = 0.006116\n",
      "Epoch 91, batch 55: loss = 0.006023\n",
      "Epoch 91, batch 56: loss = 0.006156\n",
      "Epoch 91, batch 57: loss = 0.006180\n",
      "Epoch 91, batch 58: loss = 0.005875\n",
      "Epoch 91, batch 59: loss = 0.006417\n",
      "Epoch 91, batch 60: loss = 0.006329\n",
      "Epoch 91, batch 61: loss = 0.006326\n",
      "Epoch 91, batch 62: loss = 0.006043\n",
      "Epoch 91, batch 63: loss = 0.006286\n",
      "Epoch 91, batch 64: loss = 0.006056\n",
      "Epoch 91, batch 65: loss = 0.005957\n",
      "Epoch 91, batch 66: loss = 0.006068\n",
      "Epoch 91, batch 67: loss = 0.005679\n",
      "Epoch 91, batch 68: loss = 0.005589\n",
      "Epoch 91, batch 69: loss = 0.006257\n",
      "Epoch 91, batch 70: loss = 0.006038\n",
      "Epoch 91, batch 71: loss = 0.005847\n",
      "Epoch 91, batch 72: loss = 0.006441\n",
      "Epoch 91, batch 73: loss = 0.005859\n",
      "Epoch 91, batch 74: loss = 0.005513\n",
      "Epoch 91, batch 75: loss = 0.005876\n",
      "Epoch 91, batch 76: loss = 0.006061\n",
      "Epoch 91, batch 77: loss = 0.005701\n",
      "Epoch 91, batch 78: loss = 0.006118\n",
      "Epoch 91, batch 79: loss = 0.005998\n",
      "Epoch 91, batch 80: loss = 0.006183\n",
      "Epoch 91, batch 81: loss = 0.006214\n",
      "Epoch 91, batch 82: loss = 0.005241\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 91: val_loss = 0.040397\n",
      "Epoch 92, batch 0: loss = 0.009669\n",
      "Epoch 92, batch 1: loss = 0.008689\n",
      "Epoch 92, batch 2: loss = 0.007535\n",
      "Epoch 92, batch 3: loss = 0.006753\n",
      "Epoch 92, batch 4: loss = 0.007190\n",
      "Epoch 92, batch 5: loss = 0.007585\n",
      "Epoch 92, batch 6: loss = 0.007523\n",
      "Epoch 92, batch 7: loss = 0.007764\n",
      "Epoch 92, batch 8: loss = 0.007083\n",
      "Epoch 92, batch 9: loss = 0.007268\n",
      "Epoch 92, batch 10: loss = 0.007184\n",
      "Epoch 92, batch 11: loss = 0.007403\n",
      "Epoch 92, batch 12: loss = 0.007017\n",
      "Epoch 92, batch 13: loss = 0.006987\n",
      "Epoch 92, batch 14: loss = 0.006950\n",
      "Epoch 92, batch 15: loss = 0.007133\n",
      "Epoch 92, batch 16: loss = 0.007845\n",
      "Epoch 92, batch 17: loss = 0.006978\n",
      "Epoch 92, batch 18: loss = 0.006753\n",
      "Epoch 92, batch 19: loss = 0.006871\n",
      "Epoch 92, batch 20: loss = 0.006821\n",
      "Epoch 92, batch 21: loss = 0.007290\n",
      "Epoch 92, batch 22: loss = 0.007174\n",
      "Epoch 92, batch 23: loss = 0.007245\n",
      "Epoch 92, batch 24: loss = 0.005971\n",
      "Epoch 92, batch 25: loss = 0.006474\n",
      "Epoch 92, batch 26: loss = 0.007177\n",
      "Epoch 92, batch 27: loss = 0.007305\n",
      "Epoch 92, batch 28: loss = 0.007714\n",
      "Epoch 92, batch 29: loss = 0.007000\n",
      "Epoch 92, batch 30: loss = 0.006336\n",
      "Epoch 92, batch 31: loss = 0.006557\n",
      "Epoch 92, batch 32: loss = 0.006513\n",
      "Epoch 92, batch 33: loss = 0.007921\n",
      "Epoch 92, batch 34: loss = 0.006542\n",
      "Epoch 92, batch 35: loss = 0.006602\n",
      "Epoch 92, batch 36: loss = 0.006906\n",
      "Epoch 92, batch 37: loss = 0.006547\n",
      "Epoch 92, batch 38: loss = 0.006632\n",
      "Epoch 92, batch 39: loss = 0.006609\n",
      "Epoch 92, batch 40: loss = 0.006319\n",
      "Epoch 92, batch 41: loss = 0.007023\n",
      "Epoch 92, batch 42: loss = 0.006418\n",
      "Epoch 92, batch 43: loss = 0.007444\n",
      "Epoch 92, batch 44: loss = 0.006335\n",
      "Epoch 92, batch 45: loss = 0.006590\n",
      "Epoch 92, batch 46: loss = 0.007288\n",
      "Epoch 92, batch 47: loss = 0.006491\n",
      "Epoch 92, batch 48: loss = 0.006601\n",
      "Epoch 92, batch 49: loss = 0.006713\n",
      "Epoch 92, batch 50: loss = 0.006329\n",
      "Epoch 92, batch 51: loss = 0.006121\n",
      "Epoch 92, batch 52: loss = 0.006471\n",
      "Epoch 92, batch 53: loss = 0.006484\n",
      "Epoch 92, batch 54: loss = 0.006794\n",
      "Epoch 92, batch 55: loss = 0.006783\n",
      "Epoch 92, batch 56: loss = 0.006574\n",
      "Epoch 92, batch 57: loss = 0.006343\n",
      "Epoch 92, batch 58: loss = 0.006114\n",
      "Epoch 92, batch 59: loss = 0.007191\n",
      "Epoch 92, batch 60: loss = 0.006057\n",
      "Epoch 92, batch 61: loss = 0.006778\n",
      "Epoch 92, batch 62: loss = 0.006911\n",
      "Epoch 92, batch 63: loss = 0.005881\n",
      "Epoch 92, batch 64: loss = 0.006811\n",
      "Epoch 92, batch 65: loss = 0.006155\n",
      "Epoch 92, batch 66: loss = 0.006087\n",
      "Epoch 92, batch 67: loss = 0.006265\n",
      "Epoch 92, batch 68: loss = 0.006533\n",
      "Epoch 92, batch 69: loss = 0.006386\n",
      "Epoch 92, batch 70: loss = 0.006239\n",
      "Epoch 92, batch 71: loss = 0.006264\n",
      "Epoch 92, batch 72: loss = 0.006274\n",
      "Epoch 92, batch 73: loss = 0.006429\n",
      "Epoch 92, batch 74: loss = 0.006546\n",
      "Epoch 92, batch 75: loss = 0.007014\n",
      "Epoch 92, batch 76: loss = 0.006319\n",
      "Epoch 92, batch 77: loss = 0.006163\n",
      "Epoch 92, batch 78: loss = 0.006287\n",
      "Epoch 92, batch 79: loss = 0.006357\n",
      "Epoch 92, batch 80: loss = 0.006150\n",
      "Epoch 92, batch 81: loss = 0.006102\n",
      "Epoch 92, batch 82: loss = 0.006283\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 92: val_loss = 0.040991\n",
      "Epoch 93, batch 0: loss = 0.006210\n",
      "Epoch 93, batch 1: loss = 0.006448\n",
      "Epoch 93, batch 2: loss = 0.006272\n",
      "Epoch 93, batch 3: loss = 0.006913\n",
      "Epoch 93, batch 4: loss = 0.006224\n",
      "Epoch 93, batch 5: loss = 0.006276\n",
      "Epoch 93, batch 6: loss = 0.005814\n",
      "Epoch 93, batch 7: loss = 0.006305\n",
      "Epoch 93, batch 8: loss = 0.006315\n",
      "Epoch 93, batch 9: loss = 0.006453\n",
      "Epoch 93, batch 10: loss = 0.006809\n",
      "Epoch 93, batch 11: loss = 0.005988\n",
      "Epoch 93, batch 12: loss = 0.006315\n",
      "Epoch 93, batch 13: loss = 0.005855\n",
      "Epoch 93, batch 14: loss = 0.005890\n",
      "Epoch 93, batch 15: loss = 0.005965\n",
      "Epoch 93, batch 16: loss = 0.006236\n",
      "Epoch 93, batch 17: loss = 0.006464\n",
      "Epoch 93, batch 18: loss = 0.006216\n",
      "Epoch 93, batch 19: loss = 0.006179\n",
      "Epoch 93, batch 20: loss = 0.006302\n",
      "Epoch 93, batch 21: loss = 0.006314\n",
      "Epoch 93, batch 22: loss = 0.006041\n",
      "Epoch 93, batch 23: loss = 0.005850\n",
      "Epoch 93, batch 24: loss = 0.005443\n",
      "Epoch 93, batch 25: loss = 0.005713\n",
      "Epoch 93, batch 26: loss = 0.005945\n",
      "Epoch 93, batch 27: loss = 0.006227\n",
      "Epoch 93, batch 28: loss = 0.006303\n",
      "Epoch 93, batch 29: loss = 0.006320\n",
      "Epoch 93, batch 30: loss = 0.005874\n",
      "Epoch 93, batch 31: loss = 0.005867\n",
      "Epoch 93, batch 32: loss = 0.006081\n",
      "Epoch 93, batch 33: loss = 0.006207\n",
      "Epoch 93, batch 34: loss = 0.006561\n",
      "Epoch 93, batch 35: loss = 0.006125\n",
      "Epoch 93, batch 36: loss = 0.006029\n",
      "Epoch 93, batch 37: loss = 0.006001\n",
      "Epoch 93, batch 38: loss = 0.005837\n",
      "Epoch 93, batch 39: loss = 0.006507\n",
      "Epoch 93, batch 40: loss = 0.006203\n",
      "Epoch 93, batch 41: loss = 0.006096\n",
      "Epoch 93, batch 42: loss = 0.006221\n",
      "Epoch 93, batch 43: loss = 0.006572\n",
      "Epoch 93, batch 44: loss = 0.006244\n",
      "Epoch 93, batch 45: loss = 0.006034\n",
      "Epoch 93, batch 46: loss = 0.006410\n",
      "Epoch 93, batch 47: loss = 0.006106\n",
      "Epoch 93, batch 48: loss = 0.005808\n",
      "Epoch 93, batch 49: loss = 0.005795\n",
      "Epoch 93, batch 50: loss = 0.005509\n",
      "Epoch 93, batch 51: loss = 0.005936\n",
      "Epoch 93, batch 52: loss = 0.006043\n",
      "Epoch 93, batch 53: loss = 0.006091\n",
      "Epoch 93, batch 54: loss = 0.005956\n",
      "Epoch 93, batch 55: loss = 0.005524\n",
      "Epoch 93, batch 56: loss = 0.006380\n",
      "Epoch 93, batch 57: loss = 0.006230\n",
      "Epoch 93, batch 58: loss = 0.006156\n",
      "Epoch 93, batch 59: loss = 0.005610\n",
      "Epoch 93, batch 60: loss = 0.006744\n",
      "Epoch 93, batch 61: loss = 0.005927\n",
      "Epoch 93, batch 62: loss = 0.006041\n",
      "Epoch 93, batch 63: loss = 0.006137\n",
      "Epoch 93, batch 64: loss = 0.005798\n",
      "Epoch 93, batch 65: loss = 0.006079\n",
      "Epoch 93, batch 66: loss = 0.005695\n",
      "Epoch 93, batch 67: loss = 0.005848\n",
      "Epoch 93, batch 68: loss = 0.005932\n",
      "Epoch 93, batch 69: loss = 0.006122\n",
      "Epoch 93, batch 70: loss = 0.006137\n",
      "Epoch 93, batch 71: loss = 0.006243\n",
      "Epoch 93, batch 72: loss = 0.006028\n",
      "Epoch 93, batch 73: loss = 0.006084\n",
      "Epoch 93, batch 74: loss = 0.005796\n",
      "Epoch 93, batch 75: loss = 0.005603\n",
      "Epoch 93, batch 76: loss = 0.005998\n",
      "Epoch 93, batch 77: loss = 0.006398\n",
      "Epoch 93, batch 78: loss = 0.006209\n",
      "Epoch 93, batch 79: loss = 0.005910\n",
      "Epoch 93, batch 80: loss = 0.006059\n",
      "Epoch 93, batch 81: loss = 0.006206\n",
      "Epoch 93, batch 82: loss = 0.005006\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 93: val_loss = 0.039978\n",
      "Epoch 94, batch 0: loss = 0.005916\n",
      "Epoch 94, batch 1: loss = 0.006373\n",
      "Epoch 94, batch 2: loss = 0.006106\n",
      "Epoch 94, batch 3: loss = 0.006198\n",
      "Epoch 94, batch 4: loss = 0.005997\n",
      "Epoch 94, batch 5: loss = 0.006179\n",
      "Epoch 94, batch 6: loss = 0.006031\n",
      "Epoch 94, batch 7: loss = 0.006178\n",
      "Epoch 94, batch 8: loss = 0.005838\n",
      "Epoch 94, batch 9: loss = 0.006428\n",
      "Epoch 94, batch 10: loss = 0.005834\n",
      "Epoch 94, batch 11: loss = 0.005587\n",
      "Epoch 94, batch 12: loss = 0.006023\n",
      "Epoch 94, batch 13: loss = 0.005895\n",
      "Epoch 94, batch 14: loss = 0.006000\n",
      "Epoch 94, batch 15: loss = 0.005771\n",
      "Epoch 94, batch 16: loss = 0.006166\n",
      "Epoch 94, batch 17: loss = 0.005868\n",
      "Epoch 94, batch 18: loss = 0.005832\n",
      "Epoch 94, batch 19: loss = 0.005926\n",
      "Epoch 94, batch 20: loss = 0.006759\n",
      "Epoch 94, batch 21: loss = 0.006163\n",
      "Epoch 94, batch 22: loss = 0.006072\n",
      "Epoch 94, batch 23: loss = 0.006106\n",
      "Epoch 94, batch 24: loss = 0.006234\n",
      "Epoch 94, batch 25: loss = 0.006550\n",
      "Epoch 94, batch 26: loss = 0.005904\n",
      "Epoch 94, batch 27: loss = 0.005857\n",
      "Epoch 94, batch 28: loss = 0.005644\n",
      "Epoch 94, batch 29: loss = 0.006061\n",
      "Epoch 94, batch 30: loss = 0.006285\n",
      "Epoch 94, batch 31: loss = 0.006531\n",
      "Epoch 94, batch 32: loss = 0.005686\n",
      "Epoch 94, batch 33: loss = 0.006679\n",
      "Epoch 94, batch 34: loss = 0.006077\n",
      "Epoch 94, batch 35: loss = 0.005973\n",
      "Epoch 94, batch 36: loss = 0.005713\n",
      "Epoch 94, batch 37: loss = 0.005835\n",
      "Epoch 94, batch 38: loss = 0.006022\n",
      "Epoch 94, batch 39: loss = 0.005794\n",
      "Epoch 94, batch 40: loss = 0.005715\n",
      "Epoch 94, batch 41: loss = 0.005636\n",
      "Epoch 94, batch 42: loss = 0.006422\n",
      "Epoch 94, batch 43: loss = 0.006455\n",
      "Epoch 94, batch 44: loss = 0.005887\n",
      "Epoch 94, batch 45: loss = 0.005793\n",
      "Epoch 94, batch 46: loss = 0.005953\n",
      "Epoch 94, batch 47: loss = 0.005755\n",
      "Epoch 94, batch 48: loss = 0.005759\n",
      "Epoch 94, batch 49: loss = 0.006117\n",
      "Epoch 94, batch 50: loss = 0.005923\n",
      "Epoch 94, batch 51: loss = 0.006036\n",
      "Epoch 94, batch 52: loss = 0.006187\n",
      "Epoch 94, batch 53: loss = 0.005851\n",
      "Epoch 94, batch 54: loss = 0.006001\n",
      "Epoch 94, batch 55: loss = 0.006312\n",
      "Epoch 94, batch 56: loss = 0.005885\n",
      "Epoch 94, batch 57: loss = 0.006162\n",
      "Epoch 94, batch 58: loss = 0.006288\n",
      "Epoch 94, batch 59: loss = 0.005930\n",
      "Epoch 94, batch 60: loss = 0.005694\n",
      "Epoch 94, batch 61: loss = 0.005622\n",
      "Epoch 94, batch 62: loss = 0.006326\n",
      "Epoch 94, batch 63: loss = 0.005974\n",
      "Epoch 94, batch 64: loss = 0.006177\n",
      "Epoch 94, batch 65: loss = 0.005769\n",
      "Epoch 94, batch 66: loss = 0.005790\n",
      "Epoch 94, batch 67: loss = 0.006032\n",
      "Epoch 94, batch 68: loss = 0.005948\n",
      "Epoch 94, batch 69: loss = 0.005587\n",
      "Epoch 94, batch 70: loss = 0.006432\n",
      "Epoch 94, batch 71: loss = 0.006368\n",
      "Epoch 94, batch 72: loss = 0.005824\n",
      "Epoch 94, batch 73: loss = 0.006355\n",
      "Epoch 94, batch 74: loss = 0.005831\n",
      "Epoch 94, batch 75: loss = 0.006426\n",
      "Epoch 94, batch 76: loss = 0.005979\n",
      "Epoch 94, batch 77: loss = 0.005528\n",
      "Epoch 94, batch 78: loss = 0.006133\n",
      "Epoch 94, batch 79: loss = 0.005720\n",
      "Epoch 94, batch 80: loss = 0.005793\n",
      "Epoch 94, batch 81: loss = 0.006086\n",
      "Epoch 94, batch 82: loss = 0.006199\n",
      "Validation\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 94: val_loss = 0.041937\n",
      "Epoch 95, batch 0: loss = 0.006391\n",
      "Epoch 95, batch 1: loss = 0.006476\n",
      "Epoch 95, batch 2: loss = 0.006691\n",
      "Epoch 95, batch 3: loss = 0.006035\n",
      "Epoch 95, batch 4: loss = 0.005889\n",
      "Epoch 95, batch 5: loss = 0.006269\n",
      "Epoch 95, batch 6: loss = 0.006253\n",
      "Epoch 95, batch 7: loss = 0.005792\n",
      "Epoch 95, batch 8: loss = 0.005732\n",
      "Epoch 95, batch 9: loss = 0.005975\n",
      "Epoch 95, batch 10: loss = 0.005879\n",
      "Epoch 95, batch 11: loss = 0.005760\n",
      "Epoch 95, batch 12: loss = 0.006040\n",
      "Epoch 95, batch 13: loss = 0.005658\n",
      "Epoch 95, batch 14: loss = 0.005967\n",
      "Epoch 95, batch 15: loss = 0.006062\n",
      "Epoch 95, batch 16: loss = 0.005731\n",
      "Epoch 95, batch 17: loss = 0.005765\n",
      "Epoch 95, batch 18: loss = 0.005868\n",
      "Epoch 95, batch 19: loss = 0.005760\n",
      "Epoch 95, batch 20: loss = 0.006349\n",
      "Epoch 95, batch 21: loss = 0.005937\n",
      "Epoch 95, batch 22: loss = 0.006259\n",
      "Epoch 95, batch 23: loss = 0.006036\n",
      "Epoch 95, batch 24: loss = 0.006997\n",
      "Epoch 95, batch 25: loss = 0.006190\n",
      "Epoch 95, batch 26: loss = 0.006010\n",
      "Epoch 95, batch 27: loss = 0.005934\n",
      "Epoch 95, batch 28: loss = 0.006024\n",
      "Epoch 95, batch 29: loss = 0.005927\n",
      "Epoch 95, batch 30: loss = 0.005793\n",
      "Epoch 95, batch 31: loss = 0.006277\n",
      "Epoch 95, batch 32: loss = 0.005787\n",
      "Epoch 95, batch 33: loss = 0.005944\n",
      "Epoch 95, batch 34: loss = 0.005890\n",
      "Epoch 95, batch 35: loss = 0.006197\n",
      "Epoch 95, batch 36: loss = 0.006045\n",
      "Epoch 95, batch 37: loss = 0.006378\n",
      "Epoch 95, batch 38: loss = 0.005931\n",
      "Epoch 95, batch 39: loss = 0.005776\n",
      "Epoch 95, batch 40: loss = 0.005821\n",
      "Epoch 95, batch 41: loss = 0.005892\n",
      "Epoch 95, batch 42: loss = 0.006305\n",
      "Epoch 95, batch 43: loss = 0.005951\n",
      "Epoch 95, batch 44: loss = 0.006138\n",
      "Epoch 95, batch 45: loss = 0.006321\n",
      "Epoch 95, batch 46: loss = 0.005923\n",
      "Epoch 95, batch 47: loss = 0.005904\n",
      "Epoch 95, batch 48: loss = 0.005794\n",
      "Epoch 95, batch 49: loss = 0.006335\n",
      "Epoch 95, batch 50: loss = 0.006098\n",
      "Epoch 95, batch 51: loss = 0.005922\n",
      "Epoch 95, batch 52: loss = 0.005965\n",
      "Epoch 95, batch 53: loss = 0.005844\n",
      "Epoch 95, batch 54: loss = 0.006073\n",
      "Epoch 95, batch 55: loss = 0.005967\n",
      "Epoch 95, batch 56: loss = 0.006678\n",
      "Epoch 95, batch 57: loss = 0.005975\n",
      "Epoch 95, batch 58: loss = 0.005770\n",
      "Epoch 95, batch 59: loss = 0.006063\n",
      "Epoch 95, batch 60: loss = 0.007111\n",
      "Epoch 95, batch 61: loss = 0.007829\n",
      "Epoch 95, batch 62: loss = 0.008416\n",
      "Epoch 95, batch 63: loss = 0.008291\n",
      "Epoch 95, batch 64: loss = 0.008297\n",
      "Epoch 95, batch 65: loss = 0.007951\n",
      "Epoch 95, batch 66: loss = 0.007610\n",
      "Epoch 95, batch 67: loss = 0.007988\n",
      "Epoch 95, batch 68: loss = 0.007934\n",
      "Epoch 95, batch 69: loss = 0.007889\n",
      "Epoch 95, batch 70: loss = 0.008370\n",
      "Epoch 95, batch 71: loss = 0.007699\n",
      "Epoch 95, batch 72: loss = 0.007256\n",
      "Epoch 95, batch 73: loss = 0.007844\n",
      "Epoch 95, batch 74: loss = 0.007376\n",
      "Epoch 95, batch 75: loss = 0.007057\n",
      "Epoch 95, batch 76: loss = 0.007151\n",
      "Epoch 95, batch 77: loss = 0.007209\n",
      "Epoch 95, batch 78: loss = 0.007236\n",
      "Epoch 95, batch 79: loss = 0.007103\n",
      "Epoch 95, batch 80: loss = 0.006730\n",
      "Epoch 95, batch 81: loss = 0.007148\n",
      "Epoch 95, batch 82: loss = 0.010849\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 95: val_loss = 0.038144\n",
      "Epoch 96, batch 0: loss = 0.006933\n",
      "Epoch 96, batch 1: loss = 0.007192\n",
      "Epoch 96, batch 2: loss = 0.007237\n",
      "Epoch 96, batch 3: loss = 0.007098\n",
      "Epoch 96, batch 4: loss = 0.007331\n",
      "Epoch 96, batch 5: loss = 0.007298\n",
      "Epoch 96, batch 6: loss = 0.006886\n",
      "Epoch 96, batch 7: loss = 0.006799\n",
      "Epoch 96, batch 8: loss = 0.007011\n",
      "Epoch 96, batch 9: loss = 0.007034\n",
      "Epoch 96, batch 10: loss = 0.007438\n",
      "Epoch 96, batch 11: loss = 0.006715\n",
      "Epoch 96, batch 12: loss = 0.006839\n",
      "Epoch 96, batch 13: loss = 0.007459\n",
      "Epoch 96, batch 14: loss = 0.006930\n",
      "Epoch 96, batch 15: loss = 0.006613\n",
      "Epoch 96, batch 16: loss = 0.007011\n",
      "Epoch 96, batch 17: loss = 0.006599\n",
      "Epoch 96, batch 18: loss = 0.006490\n",
      "Epoch 96, batch 19: loss = 0.006775\n",
      "Epoch 96, batch 20: loss = 0.006281\n",
      "Epoch 96, batch 21: loss = 0.007149\n",
      "Epoch 96, batch 22: loss = 0.006687\n",
      "Epoch 96, batch 23: loss = 0.006670\n",
      "Epoch 96, batch 24: loss = 0.006221\n",
      "Epoch 96, batch 25: loss = 0.007076\n",
      "Epoch 96, batch 26: loss = 0.006662\n",
      "Epoch 96, batch 27: loss = 0.006310\n",
      "Epoch 96, batch 28: loss = 0.007009\n",
      "Epoch 96, batch 29: loss = 0.006306\n",
      "Epoch 96, batch 30: loss = 0.006453\n",
      "Epoch 96, batch 31: loss = 0.006304\n",
      "Epoch 96, batch 32: loss = 0.006003\n",
      "Epoch 96, batch 33: loss = 0.006703\n",
      "Epoch 96, batch 34: loss = 0.006524\n",
      "Epoch 96, batch 35: loss = 0.006647\n",
      "Epoch 96, batch 36: loss = 0.006288\n",
      "Epoch 96, batch 37: loss = 0.006518\n",
      "Epoch 96, batch 38: loss = 0.006270\n",
      "Epoch 96, batch 39: loss = 0.006661\n",
      "Epoch 96, batch 40: loss = 0.006134\n",
      "Epoch 96, batch 41: loss = 0.006190\n",
      "Epoch 96, batch 42: loss = 0.006392\n",
      "Epoch 96, batch 43: loss = 0.006727\n",
      "Epoch 96, batch 44: loss = 0.006312\n",
      "Epoch 96, batch 45: loss = 0.006478\n",
      "Epoch 96, batch 46: loss = 0.006691\n",
      "Epoch 96, batch 47: loss = 0.006389\n",
      "Epoch 96, batch 48: loss = 0.006094\n",
      "Epoch 96, batch 49: loss = 0.006307\n",
      "Epoch 96, batch 50: loss = 0.006602\n",
      "Epoch 96, batch 51: loss = 0.006280\n",
      "Epoch 96, batch 52: loss = 0.006119\n",
      "Epoch 96, batch 53: loss = 0.006630\n",
      "Epoch 96, batch 54: loss = 0.006288\n",
      "Epoch 96, batch 55: loss = 0.006101\n",
      "Epoch 96, batch 56: loss = 0.006406\n",
      "Epoch 96, batch 57: loss = 0.006402\n",
      "Epoch 96, batch 58: loss = 0.006280\n",
      "Epoch 96, batch 59: loss = 0.006341\n",
      "Epoch 96, batch 60: loss = 0.006132\n",
      "Epoch 96, batch 61: loss = 0.006327\n",
      "Epoch 96, batch 62: loss = 0.006355\n",
      "Epoch 96, batch 63: loss = 0.006515\n",
      "Epoch 96, batch 64: loss = 0.006988\n",
      "Epoch 96, batch 65: loss = 0.006642\n",
      "Epoch 96, batch 66: loss = 0.006569\n",
      "Epoch 96, batch 67: loss = 0.006930\n",
      "Epoch 96, batch 68: loss = 0.006498\n",
      "Epoch 96, batch 69: loss = 0.006909\n",
      "Epoch 96, batch 70: loss = 0.006754\n",
      "Epoch 96, batch 71: loss = 0.006283\n",
      "Epoch 96, batch 72: loss = 0.006512\n",
      "Epoch 96, batch 73: loss = 0.006488\n",
      "Epoch 96, batch 74: loss = 0.007149\n",
      "Epoch 96, batch 75: loss = 0.006186\n",
      "Epoch 96, batch 76: loss = 0.006464\n",
      "Epoch 96, batch 77: loss = 0.006502\n",
      "Epoch 96, batch 78: loss = 0.006787\n",
      "Epoch 96, batch 79: loss = 0.006045\n",
      "Epoch 96, batch 80: loss = 0.006292\n",
      "Epoch 96, batch 81: loss = 0.006525\n",
      "Epoch 96, batch 82: loss = 0.006200\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 96: val_loss = 0.041351\n",
      "Epoch 97, batch 0: loss = 0.006219\n",
      "Epoch 97, batch 1: loss = 0.007093\n",
      "Epoch 97, batch 2: loss = 0.006369\n",
      "Epoch 97, batch 3: loss = 0.006291\n",
      "Epoch 97, batch 4: loss = 0.006194\n",
      "Epoch 97, batch 5: loss = 0.006346\n",
      "Epoch 97, batch 6: loss = 0.006603\n",
      "Epoch 97, batch 7: loss = 0.006950\n",
      "Epoch 97, batch 8: loss = 0.006828\n",
      "Epoch 97, batch 9: loss = 0.006696\n",
      "Epoch 97, batch 10: loss = 0.006315\n",
      "Epoch 97, batch 11: loss = 0.006004\n",
      "Epoch 97, batch 12: loss = 0.006698\n",
      "Epoch 97, batch 13: loss = 0.006449\n",
      "Epoch 97, batch 14: loss = 0.006448\n",
      "Epoch 97, batch 15: loss = 0.006270\n",
      "Epoch 97, batch 16: loss = 0.006046\n",
      "Epoch 97, batch 17: loss = 0.006482\n",
      "Epoch 97, batch 18: loss = 0.006666\n",
      "Epoch 97, batch 19: loss = 0.006773\n",
      "Epoch 97, batch 20: loss = 0.006515\n",
      "Epoch 97, batch 21: loss = 0.006189\n",
      "Epoch 97, batch 22: loss = 0.005973\n",
      "Epoch 97, batch 23: loss = 0.006055\n",
      "Epoch 97, batch 24: loss = 0.006399\n",
      "Epoch 97, batch 25: loss = 0.006151\n",
      "Epoch 97, batch 26: loss = 0.006331\n",
      "Epoch 97, batch 27: loss = 0.007173\n",
      "Epoch 97, batch 28: loss = 0.007536\n",
      "Epoch 97, batch 29: loss = 0.007798\n",
      "Epoch 97, batch 30: loss = 0.007332\n",
      "Epoch 97, batch 31: loss = 0.007024\n",
      "Epoch 97, batch 32: loss = 0.007618\n",
      "Epoch 97, batch 33: loss = 0.007033\n",
      "Epoch 97, batch 34: loss = 0.006998\n",
      "Epoch 97, batch 35: loss = 0.006944\n",
      "Epoch 97, batch 36: loss = 0.007220\n",
      "Epoch 97, batch 37: loss = 0.007370\n",
      "Epoch 97, batch 38: loss = 0.007331\n",
      "Epoch 97, batch 39: loss = 0.007121\n",
      "Epoch 97, batch 40: loss = 0.006723\n",
      "Epoch 97, batch 41: loss = 0.007447\n",
      "Epoch 97, batch 42: loss = 0.006699\n",
      "Epoch 97, batch 43: loss = 0.007220\n",
      "Epoch 97, batch 44: loss = 0.006964\n",
      "Epoch 97, batch 45: loss = 0.006430\n",
      "Epoch 97, batch 46: loss = 0.007087\n",
      "Epoch 97, batch 47: loss = 0.006910\n",
      "Epoch 97, batch 48: loss = 0.006735\n",
      "Epoch 97, batch 49: loss = 0.006562\n",
      "Epoch 97, batch 50: loss = 0.006463\n",
      "Epoch 97, batch 51: loss = 0.006684\n",
      "Epoch 97, batch 52: loss = 0.006604\n",
      "Epoch 97, batch 53: loss = 0.006876\n",
      "Epoch 97, batch 54: loss = 0.007519\n",
      "Epoch 97, batch 55: loss = 0.006866\n",
      "Epoch 97, batch 56: loss = 0.006893\n",
      "Epoch 97, batch 57: loss = 0.006206\n",
      "Epoch 97, batch 58: loss = 0.006722\n",
      "Epoch 97, batch 59: loss = 0.006731\n",
      "Epoch 97, batch 60: loss = 0.006497\n",
      "Epoch 97, batch 61: loss = 0.006922\n",
      "Epoch 97, batch 62: loss = 0.006057\n",
      "Epoch 97, batch 63: loss = 0.006540\n",
      "Epoch 97, batch 64: loss = 0.006515\n",
      "Epoch 97, batch 65: loss = 0.006333\n",
      "Epoch 97, batch 66: loss = 0.006482\n",
      "Epoch 97, batch 67: loss = 0.006274\n",
      "Epoch 97, batch 68: loss = 0.006273\n",
      "Epoch 97, batch 69: loss = 0.005781\n",
      "Epoch 97, batch 70: loss = 0.006506\n",
      "Epoch 97, batch 71: loss = 0.006010\n",
      "Epoch 97, batch 72: loss = 0.006189\n",
      "Epoch 97, batch 73: loss = 0.005927\n",
      "Epoch 97, batch 74: loss = 0.005745\n",
      "Epoch 97, batch 75: loss = 0.006450\n",
      "Epoch 97, batch 76: loss = 0.006141\n",
      "Epoch 97, batch 77: loss = 0.006726\n",
      "Epoch 97, batch 78: loss = 0.006320\n",
      "Epoch 97, batch 79: loss = 0.006206\n",
      "Epoch 97, batch 80: loss = 0.006516\n",
      "Epoch 97, batch 81: loss = 0.006523\n",
      "Epoch 97, batch 82: loss = 0.005324\n",
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 97: val_loss = 0.039135\n",
      "Epoch 98, batch 0: loss = 0.006079\n",
      "Epoch 98, batch 1: loss = 0.006317\n",
      "Epoch 98, batch 2: loss = 0.006493\n",
      "Epoch 98, batch 3: loss = 0.006547\n",
      "Epoch 98, batch 4: loss = 0.006034\n",
      "Epoch 98, batch 5: loss = 0.006272\n",
      "Epoch 98, batch 6: loss = 0.006260\n",
      "Epoch 98, batch 7: loss = 0.006196\n",
      "Epoch 98, batch 8: loss = 0.006383\n",
      "Epoch 98, batch 9: loss = 0.006611\n",
      "Epoch 98, batch 10: loss = 0.006470\n",
      "Epoch 98, batch 11: loss = 0.006234\n",
      "Epoch 98, batch 12: loss = 0.006567\n",
      "Epoch 98, batch 13: loss = 0.006404\n",
      "Epoch 98, batch 14: loss = 0.006323\n",
      "Epoch 98, batch 15: loss = 0.006538\n",
      "Epoch 98, batch 16: loss = 0.006624\n",
      "Epoch 98, batch 17: loss = 0.006097\n",
      "Epoch 98, batch 18: loss = 0.006124\n",
      "Epoch 98, batch 19: loss = 0.006664\n",
      "Epoch 98, batch 20: loss = 0.006320\n",
      "Epoch 98, batch 21: loss = 0.005438\n",
      "Epoch 98, batch 22: loss = 0.006306\n",
      "Epoch 98, batch 23: loss = 0.006444\n",
      "Epoch 98, batch 24: loss = 0.006425\n",
      "Epoch 98, batch 25: loss = 0.005838\n",
      "Epoch 98, batch 26: loss = 0.006364\n",
      "Epoch 98, batch 27: loss = 0.006740\n",
      "Epoch 98, batch 28: loss = 0.005596\n",
      "Epoch 98, batch 29: loss = 0.005781\n",
      "Epoch 98, batch 30: loss = 0.006380\n",
      "Epoch 98, batch 31: loss = 0.006406\n",
      "Epoch 98, batch 32: loss = 0.006149\n",
      "Epoch 98, batch 33: loss = 0.005909\n",
      "Epoch 98, batch 34: loss = 0.006044\n",
      "Epoch 98, batch 35: loss = 0.006460\n",
      "Epoch 98, batch 36: loss = 0.006495\n",
      "Epoch 98, batch 37: loss = 0.006333\n",
      "Epoch 98, batch 38: loss = 0.006183\n",
      "Epoch 98, batch 39: loss = 0.006321\n",
      "Epoch 98, batch 40: loss = 0.006180\n",
      "Epoch 98, batch 41: loss = 0.006015\n",
      "Epoch 98, batch 42: loss = 0.006688\n",
      "Epoch 98, batch 43: loss = 0.006166\n",
      "Epoch 98, batch 44: loss = 0.007021\n",
      "Epoch 98, batch 45: loss = 0.006376\n",
      "Epoch 98, batch 46: loss = 0.007168\n",
      "Epoch 98, batch 47: loss = 0.006844\n",
      "Epoch 98, batch 48: loss = 0.006499\n",
      "Epoch 98, batch 49: loss = 0.006939\n",
      "Epoch 98, batch 50: loss = 0.006659\n",
      "Epoch 98, batch 51: loss = 0.007107\n",
      "Epoch 98, batch 52: loss = 0.007077\n",
      "Epoch 98, batch 53: loss = 0.007541\n",
      "Epoch 98, batch 54: loss = 0.006666\n",
      "Epoch 98, batch 55: loss = 0.007091\n",
      "Epoch 98, batch 56: loss = 0.006771\n",
      "Epoch 98, batch 57: loss = 0.006854\n",
      "Epoch 98, batch 58: loss = 0.006907\n",
      "Epoch 98, batch 59: loss = 0.006828\n",
      "Epoch 98, batch 60: loss = 0.006378\n",
      "Epoch 98, batch 61: loss = 0.006592\n",
      "Epoch 98, batch 62: loss = 0.006305\n",
      "Epoch 98, batch 63: loss = 0.006443\n",
      "Epoch 98, batch 64: loss = 0.006621\n",
      "Epoch 98, batch 65: loss = 0.006819\n",
      "Epoch 98, batch 66: loss = 0.006312\n",
      "Epoch 98, batch 67: loss = 0.006114\n",
      "Epoch 98, batch 68: loss = 0.006650\n",
      "Epoch 98, batch 69: loss = 0.007427\n",
      "Epoch 98, batch 70: loss = 0.006318\n",
      "Epoch 98, batch 71: loss = 0.006327\n",
      "Epoch 98, batch 72: loss = 0.006592\n",
      "Epoch 98, batch 73: loss = 0.006886\n",
      "Epoch 98, batch 74: loss = 0.006601\n",
      "Epoch 98, batch 75: loss = 0.006492\n",
      "Epoch 98, batch 76: loss = 0.006283\n",
      "Epoch 98, batch 77: loss = 0.006093\n",
      "Epoch 98, batch 78: loss = 0.006416\n",
      "Epoch 98, batch 79: loss = 0.006449\n",
      "Epoch 98, batch 80: loss = 0.006406\n",
      "Epoch 98, batch 81: loss = 0.006150\n",
      "Epoch 98, batch 82: loss = 0.007920\n",
      "Validation\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 98: val_loss = 0.039802\n",
      "Epoch 99, batch 0: loss = 0.006640\n",
      "Epoch 99, batch 1: loss = 0.006258\n",
      "Epoch 99, batch 2: loss = 0.006450\n",
      "Epoch 99, batch 3: loss = 0.006457\n",
      "Epoch 99, batch 4: loss = 0.006406\n",
      "Epoch 99, batch 5: loss = 0.006541\n",
      "Epoch 99, batch 6: loss = 0.006638\n",
      "Epoch 99, batch 7: loss = 0.006505\n",
      "Epoch 99, batch 8: loss = 0.006776\n",
      "Epoch 99, batch 9: loss = 0.006395\n",
      "Epoch 99, batch 10: loss = 0.006212\n",
      "Epoch 99, batch 11: loss = 0.006251\n",
      "Epoch 99, batch 12: loss = 0.006630\n",
      "Epoch 99, batch 13: loss = 0.006221\n",
      "Epoch 99, batch 14: loss = 0.006116\n",
      "Epoch 99, batch 15: loss = 0.006053\n",
      "Epoch 99, batch 16: loss = 0.006591\n",
      "Epoch 99, batch 17: loss = 0.006534\n",
      "Epoch 99, batch 18: loss = 0.006569\n",
      "Epoch 99, batch 19: loss = 0.006150\n",
      "Epoch 99, batch 20: loss = 0.006446\n",
      "Epoch 99, batch 21: loss = 0.006309\n",
      "Epoch 99, batch 22: loss = 0.006467\n",
      "Epoch 99, batch 23: loss = 0.006118\n",
      "Epoch 99, batch 24: loss = 0.006615\n",
      "Epoch 99, batch 25: loss = 0.006268\n",
      "Epoch 99, batch 26: loss = 0.006139\n",
      "Epoch 99, batch 27: loss = 0.006096\n",
      "Epoch 99, batch 28: loss = 0.006428\n",
      "Epoch 99, batch 29: loss = 0.006684\n",
      "Epoch 99, batch 30: loss = 0.006211\n",
      "Epoch 99, batch 31: loss = 0.005727\n",
      "Epoch 99, batch 32: loss = 0.006365\n",
      "Epoch 99, batch 33: loss = 0.005840\n",
      "Epoch 99, batch 34: loss = 0.006217\n",
      "Epoch 99, batch 35: loss = 0.006065\n",
      "Epoch 99, batch 36: loss = 0.006173\n",
      "Epoch 99, batch 37: loss = 0.006163\n",
      "Epoch 99, batch 38: loss = 0.006010\n",
      "Epoch 99, batch 39: loss = 0.005988\n",
      "Epoch 99, batch 40: loss = 0.005899\n",
      "Epoch 99, batch 41: loss = 0.006399\n",
      "Epoch 99, batch 42: loss = 0.006390\n",
      "Epoch 99, batch 43: loss = 0.006070\n",
      "Epoch 99, batch 44: loss = 0.006422\n",
      "Epoch 99, batch 45: loss = 0.006628\n",
      "Epoch 99, batch 46: loss = 0.006314\n",
      "Epoch 99, batch 47: loss = 0.006096\n",
      "Epoch 99, batch 48: loss = 0.006439\n",
      "Epoch 99, batch 49: loss = 0.006125\n",
      "Epoch 99, batch 50: loss = 0.006467\n",
      "Epoch 99, batch 51: loss = 0.005716\n",
      "Epoch 99, batch 52: loss = 0.006005\n",
      "Epoch 99, batch 53: loss = 0.006076\n",
      "Epoch 99, batch 54: loss = 0.006423\n",
      "Epoch 99, batch 55: loss = 0.005923\n",
      "Epoch 99, batch 56: loss = 0.006697\n",
      "Epoch 99, batch 57: loss = 0.006120\n",
      "Epoch 99, batch 58: loss = 0.006269\n",
      "Epoch 99, batch 59: loss = 0.005949\n",
      "Epoch 99, batch 60: loss = 0.006227\n",
      "Epoch 99, batch 61: loss = 0.005847\n",
      "Epoch 99, batch 62: loss = 0.005782\n",
      "Epoch 99, batch 63: loss = 0.006002\n",
      "Epoch 99, batch 64: loss = 0.006151\n",
      "Epoch 99, batch 65: loss = 0.006516\n",
      "Epoch 99, batch 66: loss = 0.006192\n",
      "Epoch 99, batch 67: loss = 0.006483\n",
      "Epoch 99, batch 68: loss = 0.006049\n",
      "Epoch 99, batch 69: loss = 0.006099\n",
      "Epoch 99, batch 70: loss = 0.005756\n",
      "Epoch 99, batch 71: loss = 0.006375\n",
      "Epoch 99, batch 72: loss = 0.006297\n",
      "Epoch 99, batch 73: loss = 0.005992\n",
      "Epoch 99, batch 74: loss = 0.005698\n",
      "Epoch 99, batch 75: loss = 0.005694\n",
      "Epoch 99, batch 76: loss = 0.006028\n",
      "Epoch 99, batch 77: loss = 0.006238\n",
      "Epoch 99, batch 78: loss = 0.006495\n",
      "Epoch 99, batch 79: loss = 0.006278\n",
      "Epoch 99, batch 80: loss = 0.006298\n",
      "Epoch 99, batch 81: loss = 0.006402\n",
      "Epoch 99, batch 82: loss = 0.004621\n",
      "Validation\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n",
      "Epoch 99: val_loss = 0.040465\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # previous_output = torch.zeros(1, 512, 102).to(device)\n",
    "    losses = []\n",
    "    for i, (midi_batch, motion_batch) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        \n",
    "        midi_batch = midi_batch.to(device).float()\n",
    "        motion_batch = motion_batch.to(device).float()\n",
    "        # print(\"midi_batch\", midi_batch.shape)\n",
    "        # print(\"motion_batch\", motion_batch.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(midi_batch) #midi_batch\n",
    "        # print(\"output.shape\", output.shape)\n",
    "\n",
    "        # motion_ground_truth_padding = F.pad(motion_batch, (0,0,0,1), value = 1) #<eot>\n",
    "        \n",
    "        # loss =  F.mse_loss(output, motion_ground_truth_padding)\n",
    "        loss =  F.mse_loss(output, motion_batch)\n",
    "        # loss = customized_mse_loss(output, motion_ground_truth_padding, previous_output, midi_batch)\n",
    "        # loss = customized_mse_loss(output, motion_batch, previous_output, midi_batch)\n",
    "\n",
    "        # losses 累計lose\n",
    "        losses.append(loss.cpu().item())\n",
    "        all_loss_list.append(loss.cpu().item())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "\n",
    "        print(f\"Epoch {epoch}, batch {i}: loss = {loss.cpu().item():.6f}\")\n",
    "\n",
    "        # scheduler.step(1)\n",
    "        # previous_output = output\n",
    "\n",
    "        loc_dt = datetime.datetime.today()\n",
    "        loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    val_loss = evaluate_lstm(model, val_dataloader) #CUDA out of memory\n",
    "    val_loss_per_epoch_list.append(val_loss)\n",
    "    print(f\"Epoch {epoch}: val_loss = {val_loss:.6f}\")\n",
    "    # save_best_model(\n",
    "    #         val_loss, epoch, model, optimizer, loss, loc_dt_format, mean_loss\n",
    "    #     )\n",
    "    avg_loss_list.append(mean_loss)\n",
    "    loc_dt = datetime.datetime.today()\n",
    "    loc_dt_format = loc_dt.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    if (epoch+1)%100 == 0:\n",
    "        torch.save({\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict':model.state_dict(),\n",
    "            'optimizer_state_dict':optimizer.state_dict(),\n",
    "            'loss':loss\n",
    "        }, \"./model_save/[100epoch]LSTM_save_epoch_\" + str(epoch)+ \"_\"+ str(loc_dt_format) + \"_avg_loss_\" + str(mean_loss) +\".tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ed6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-08_07-15-31\n",
      "[0.03527068529637104, 0.014298333505909127, 0.013967358552098992, 0.01363775688391852, 0.013296436114483568, 0.012952508853681117, 0.012659663615007716, 0.012539751401328179, 0.01244458570762212, 0.012188707343695393, 0.012096361055162298, 0.012038138796047992, 0.011926200745784375, 0.011552019112081412, 0.011678618367716491, 0.011494841146092099, 0.011358611599867603, 0.011213547426713518, 0.01095230941357742, 0.010807388422853616, 0.01073497620198023, 0.010573583733604616, 0.010993537975542516, 0.01044846988137228, 0.010373478328966233, 0.010181052340980035, 0.010325157538011491, 0.009981537540723761, 0.010183240376771933, 0.009962481087500072, 0.01036540784659874, 0.009824869357588062, 0.009654471145785716, 0.009538235681423222, 0.009508750076035419, 0.00945465119712683, 0.009370730067771602, 0.009349982635712767, 0.009124349712966436, 0.008938230013093316, 0.008850763467735195, 0.008976727937269642, 0.008699522578123823, 0.009057764827935811, 0.008598982962409416, 0.008459468226296356, 0.008472893241209438, 0.008280909423862236, 0.008362652924674821, 0.008285993356706507, 0.008242233667567551, 0.007981874620968318, 0.008020049505249923, 0.007832187805773622, 0.007786061648414077, 0.007624322161392634, 0.007492251638098654, 0.007385724072670003, 0.007545518026833075, 0.008954297128436437, 0.008254037861409316, 0.0075782247628253625, 0.0074003704666463005, 0.00747749914628375, 0.00772202810474548, 0.0072813064185341435, 0.007179166914064841, 0.007014249344861292, 0.006970522240791695, 0.006877042639282453, 0.009371960058763444, 0.008244034744440073, 0.00749681454645582, 0.0072349665731371166, 0.0069448956658682195, 0.006782798982977149, 0.00675335474289864, 0.006859929811388972, 0.006654746869736048, 0.006749772169369172, 0.00673533416723451, 0.006578823972313878, 0.00695419321622116, 0.006677300989044359, 0.0064493163365377, 0.006731930604002562, 0.00649917255301612, 0.006309877228306, 0.006236820739794926, 0.006145620589559695, 0.00628273282200098, 0.00609759268272354, 0.006798028704676643, 0.00609173792335822, 0.006021044789308525, 0.006515184602509421, 0.006598121290241021, 0.006607796402131936, 0.006471784791000277, 0.006224939094699291]\n"
     ]
    }
   ],
   "source": [
    "print(loc_dt_format)\n",
    "print(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430c6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.034755174070596695, 0.03602108359336853, 0.03683890402317047, 0.03726087138056755, 0.037167053669691086, 0.03636793792247772, 0.0354585237801075, 0.03668078035116196, 0.03521427512168884, 0.03620227426290512, 0.03565021976828575, 0.03761426359415054, 0.03619694337248802, 0.035053521394729614, 0.0353257916867733, 0.03566877543926239, 0.036303743720054626, 0.03533945605158806, 0.034703224897384644, 0.03544698655605316, 0.03524761274456978, 0.0353422537446022, 0.03563043102622032, 0.03519458696246147, 0.03514206036925316, 0.03450603038072586, 0.03492644801735878, 0.03533545881509781, 0.03437577560544014, 0.038354914635419846, 0.034545958042144775, 0.034831684082746506, 0.03485451638698578, 0.03501782566308975, 0.035392045974731445, 0.03513270616531372, 0.034407537430524826, 0.034421298652887344, 0.034103959798812866, 0.033657271414995193, 0.034283917397260666, 0.034016210585832596, 0.035315487533807755, 0.03440697491168976, 0.034257691353559494, 0.035415373742580414, 0.035023707896471024, 0.03462754935026169, 0.03571493551135063, 0.03505928814411163, 0.034728504717350006, 0.03519139438867569, 0.03508909419178963, 0.034995101392269135, 0.03472679480910301, 0.03618675470352173, 0.03492673113942146, 0.040148958563804626, 0.03636934235692024, 0.03412138298153877, 0.03355330973863602, 0.034163039177656174, 0.035863205790519714, 0.03683605045080185, 0.03701304644346237, 0.034701477736234665, 0.03415723145008087, 0.033740922808647156, 0.03334696218371391, 0.0339907631278038, 0.03385004773736, 0.03793426230549812, 0.03430207818746567, 0.033973921090364456, 0.03382449224591255, 0.03910111263394356, 0.041449666023254395, 0.041013166308403015, 0.04135514050722122, 0.035608064383268356, 0.038580067455768585, 0.034643374383449554, 0.0368526428937912, 0.038014162331819534, 0.039876263588666916, 0.04062887653708458, 0.03968434780836105, 0.03818743675947189, 0.03914574533700943, 0.03664408251643181, 0.03602292016148567, 0.04039706662297249, 0.0409914068877697, 0.03997800499200821, 0.04193666949868202, 0.03814377263188362, 0.041350606828927994, 0.039135053753852844, 0.039801664650440216, 0.04046546295285225]\n"
     ]
    }
   ],
   "source": [
    "print(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d43dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_lambda(epoch):\n",
    "#     # LR to be 0.1 * (1/1+0.01*epoch)\n",
    "#     base_lr = 0.1\n",
    "#     factor = 0.01\n",
    "#     return base_lr/(1+factor*epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f538a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a25a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5982f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(avg_loss_list))\n",
    "avg_loss_list_dataframe = pd.DataFrame(avg_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363e0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.006515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.006598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.006608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.006472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.006225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.035271\n",
       "1   0.014298\n",
       "2   0.013967\n",
       "3   0.013638\n",
       "4   0.013296\n",
       "..       ...\n",
       "95  0.006515\n",
       "96  0.006598\n",
       "97  0.006608\n",
       "98  0.006472\n",
       "99  0.006225\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss_list_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(avg_loss_list_dataframe.index), np.array(avg_loss_list_dataframe[0]))\n",
    "plt.savefig(\"avg_loss_training.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51793ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62b02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_dataframe = pd.DataFrame(all_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f51b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list_dataframe.index), np.array(loss_list_dataframe[0]))\n",
    "plt.savefig(\"training_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bac154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e5b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_per_epoch_list_dataframe = pd.DataFrame(val_loss_per_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ade5deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(val_loss_per_epoch_list_dataframe.index), np.array(val_loss_per_epoch_list_dataframe[0]))\n",
    "plt.savefig(\"training_val_loss.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = torch.as_tensor(input).to(torch.float32).to(device)\n",
    "        # print(target.shape)\n",
    "        # target = torch.as_tensor(target).to(torch.float32).to(device)\n",
    "        # TODO: target should be <sos>, should not random\n",
    "        outputs = model(input)\n",
    "        return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f49577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, specific_fps):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    piano_roll = midi_data.get_piano_roll(fs=specific_fps)  # 40fps #250fps\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "270a77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_name: ./BWV1001/vs1-1ada.mid\n",
      "filecode:  vs1-1ada\n",
      "./BWV1001/vs1-1ada.mid\n",
      "(8171, 128)\n",
      "str_name: ./BWV1001/vs1-2fug.mid\n",
      "filecode:  vs1-2fug\n",
      "./BWV1001/vs1-2fug.mid\n",
      "(11537, 128)\n",
      "str_name: ./BWV1001/vs1-3sic.mid\n",
      "filecode:  vs1-3sic\n",
      "./BWV1001/vs1-3sic.mid\n",
      "(6993, 128)\n",
      "str_name: ./BWV1001/vs1-4prs.mid\n",
      "filecode:  vs1-4prs\n",
      "./BWV1001/vs1-4prs.mid\n",
      "(7897, 128)\n"
     ]
    }
   ],
   "source": [
    "test_datapath = \"./BWV1001/\"\n",
    "change_fps = 40\n",
    "test_midi_path_list = glob.glob(test_datapath + \"*.mid\")\n",
    "test_data_list = []\n",
    "test_music_list = []\n",
    "for test_midi in test_midi_path_list:\n",
    "    str_name = test_midi\n",
    "    print(\"str_name:\", str_name)\n",
    "    filename = str_name.split('/')[2]\n",
    "    filecode = filename.split('.')[0]\n",
    "    print(\"filecode: \",filecode)\n",
    "    test_music_list.append(filecode)\n",
    "    \n",
    "    print(test_midi)\n",
    "    read_piano_roll = read_midi(test_midi, change_fps)\n",
    "    read_piano_roll_transpose = read_piano_roll.T\n",
    "    print(read_piano_roll_transpose.shape)\n",
    "    test_midi_len = read_piano_roll_transpose.shape[0]\n",
    "    test_data_list.append(read_piano_roll_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c66d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "def test_render_animation(fps, output, azim, prediction, ground_truth=None):\n",
    "    prediction_array = np.asarray(prediction)\n",
    "    print(prediction_array.size)\n",
    "    limit = len(prediction_array)\n",
    "    print(\"limit\", limit)\n",
    "    size = 6#6\n",
    "    fps = 40\n",
    "\n",
    "    # Skeleton layout\n",
    "    parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "    # joints_right = [1, 2, 12, 13, 14]\n",
    "\n",
    "    prediction_array[:, :, 2] += 0.1 #[:, :, 2]\n",
    "    if ground_truth is not None:\n",
    "        ground_truth[:, :, 2] += 0.1\n",
    "        poses = {'Prediction': prediction_array,\n",
    "                 'Ground_truth': ground_truth}\n",
    "    else:\n",
    "        poses = {'Prediction': prediction_array}\n",
    "    \n",
    "\n",
    "    fig = plt.figure()#(figsize=(size*len(poses), size))\n",
    "    # ax_3d = []\n",
    "    # lines_3d = []\n",
    "    radius = 1#14 #3.7#\n",
    "    # print(poses)\n",
    "    for index, (title, data) in enumerate(poses.items()):\n",
    "        ax = fig.add_subplot(1, len(poses), index + 1, projection='3d')\n",
    "        ax.clear()\n",
    "        print(data)\n",
    "        ims = [] #每一 frame 都存\n",
    "        for frame_index, each_frame in enumerate(data):\n",
    "            # print(\"each_frame\")\n",
    "            # print(each_frame)\n",
    "            ax.view_init(elev=15., azim=azim)\n",
    "            ax.set_xlim3d([-radius/2, radius/2])\n",
    "            ax.set_zlim3d([0, radius])\n",
    "            ax.set_ylim3d([-radius/2, radius/2])\n",
    "            ax.set_aspect('auto') #ax.set_aspect('equal')\n",
    "\n",
    "            # print(title)\n",
    "            points = ax.scatter(column(each_frame[:30], 0), column(each_frame[:30], 1), column(each_frame[:30], 2), cmap='jet', marker='o', label='body joint', color = 'black')\n",
    "            points_2 = ax.scatter(column(each_frame[30:32], 0), column(each_frame[30:32], 1), column(each_frame[30:32], 2), cmap='jet', marker='o', label='body joint', color = 'blue')\n",
    "            points_3 = ax.scatter(column(each_frame[32:34], 0), column(each_frame[32:34], 1), column(each_frame[32:34], 2), cmap='jet', marker='o', label='body joint', color = 'red')\n",
    "            \n",
    "            # ax.scatter(column(each_frame, 0), column(each_frame, 1), column(each_frame, 2), cmap='jet', marker='o', label='body joint')\n",
    "            # ax.legend()\n",
    "            # print(\"+++\")\n",
    "            \n",
    "            parents = [[0, 1], [1, 3], [3, 2], [0, 2],#head\n",
    "                        [8, 6], [6, 13], [13, 4], [4, 8],#shoulder\n",
    "                        [6, 4], [4, 5], [5, 7], [7, 6],#Upper torso\n",
    "                        [8, 18], [8, 20], [13, 21], [13, 19],\n",
    "                        [5, 20], [5, 21], [7, 18], [7, 19],\n",
    "                        [18, 19], [19, 21], [21, 20], [20, 18], #waist\n",
    "                        [18, 22], [20, 22], [22, 23], [22, 25], [23, 25], [24,23], [24, 25],  #right lag\n",
    "                        [21, 26], [19, 26], [26, 27], [26, 29], [27, 29], [28, 27], [28, 29], #left lag\n",
    "                        [8, 9], [9, 11], [9, 10], [10, 11], [10, 12], [9, 12], [11, 12], #right hand\n",
    "                        [13, 14], [14, 16], [14, 15], [16, 15], [14, 17], [16, 17], [15, 17], #left hand\n",
    "                        [30, 31], [32, 33],  #instrument\n",
    "                        # [31, 33], [30, 32], [30, 31], [32, 33], [31, 32], [30, 33] #instrument\n",
    "                        ]\n",
    "            lines = []\n",
    "            # draw line\n",
    "            \n",
    "            # lines = [ax.plot([each_frame[vs][0], each_frame[ve][0]],\n",
    "            #                  [each_frame[vs][1], each_frame[ve][1]],\n",
    "            #                  [each_frame[vs][2], each_frame[ve][2]]) for (vs, ve) in parents]\n",
    "            line_num = len(parents)\n",
    "            for idx, each_line in enumerate(parents):\n",
    "                vec_start = each_frame[each_line[0]]\n",
    "                vec_end = each_frame[each_line[1]]\n",
    "                # print(vec_start)\n",
    "                # print(vec_end)\n",
    "                line_color = \"black\"\n",
    "                if idx == line_num-2:\n",
    "                    line_color = \"blue\"\n",
    "                if idx == line_num-1:\n",
    "                    line_color = \"red\"\n",
    "                # ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]])\n",
    "                \n",
    "                temp, = ax.plot([vec_start[0], vec_end[0]], [vec_start[1], vec_end[1]], [vec_start[2], vec_end[2]], color=line_color)\n",
    "                lines.append(temp)\n",
    "\n",
    "            # ax.figure.savefig('./test_pic/pic' + str(frame_index) + '.png', dpi=100, bbox_inches = 'tight')\n",
    "\n",
    "            # ims.append([points])\n",
    "            # image_frame = [points].extend(lines)\n",
    "            ims.append([points]+[points_2]+[points_3]+lines) #TODO: try extend\n",
    "\n",
    "            # plt.cla()\n",
    "            # print(\"+++\")\n",
    "\n",
    "    anim = matplotlib.animation.ArtistAnimation(fig, ims, interval=1000/fps)\n",
    "\n",
    "    if output.endswith('.mp4'):\n",
    "        FFwriter = matplotlib.animation.FFMpegWriter(fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        anim.save(output, writer=FFwriter)\n",
    "    elif output.endswith('.gif'):\n",
    "        anim.save(output, fps=fps, dpi=100, writer='imagemagick')\n",
    "    else:\n",
    "        raise ValueError('Unsupported output format (only .mp4 and .gif are supported)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "791b9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(audio_path, plot_path, prediction, sample_time, fps, name=\"\"): #audio_path, plot_path, \n",
    "    # render_animation(fps, output='new_temp.mp4', azim=75, prediction=prediction)\n",
    "    test_render_animation(fps, output='new_temp_' + name + '.mp4', azim=75, prediction=prediction)\n",
    "\n",
    "    # # #merge with wav\n",
    "    input_video = ffmpeg.input('new_temp_' + name + '.mp4')\n",
    "    fluid_syn = FluidSynth()\n",
    "    fluid_syn.midi_to_audio(audio_path, './output' + name + '.wav')\n",
    "    input_audio = ffmpeg.input('./output' + name + '.wav')\n",
    "    # output = ffmpeg.output(video, audio, plot_path, vcodec='copy', acodec='aac', strict='experimental')\n",
    "    ffmpeg.concat(input_video, input_audio, v=1, a=1).output(plot_path).run()\n",
    "    # os.remove('new_temp_' + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca70a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 8171, 128)\n",
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 7.03780130e-02  1.48201942e-01  1.13053105e+00]\n",
      "  [ 3.99191119e-03  1.03696667e-01  1.14784489e+00]\n",
      "  [ 1.19927540e-01  7.99468383e-02  1.12749825e+00]\n",
      "  ...\n",
      "  [ 8.57516006e-03  1.11290395e-01  1.00593207e+00]\n",
      "  [-1.47943646e-01  9.75996703e-02  1.13619742e+00]\n",
      "  [ 7.59174749e-02  2.71773487e-01  7.66170776e-01]]\n",
      "\n",
      " [[ 6.93189055e-02  1.40933260e-01  1.08115206e+00]\n",
      "  [ 5.90476394e-03  9.18920487e-02  1.09790347e+00]\n",
      "  [ 1.18231714e-01  7.43449032e-02  1.07938442e+00]\n",
      "  ...\n",
      "  [ 1.30309416e-02  1.02461547e-01  9.63773108e-01]\n",
      "  [-1.40320912e-01  8.17995220e-02  1.09224627e+00]\n",
      "  [ 6.56984821e-02  2.49757484e-01  7.38122618e-01]]\n",
      "\n",
      " [[ 7.03626648e-02  1.40995979e-01  1.09947250e+00]\n",
      "  [ 8.37821513e-03  9.17309150e-02  1.11407599e+00]\n",
      "  [ 1.20925054e-01  7.58570284e-02  1.09397969e+00]\n",
      "  ...\n",
      "  [ 1.42155215e-02  1.02132984e-01  9.76647174e-01]\n",
      "  [-1.40909702e-01  8.00693780e-02  1.10844741e+00]\n",
      "  [ 6.32726327e-02  2.49144360e-01  7.44915283e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.52323966e-02  1.31344542e-01  1.07655481e+00]\n",
      "  [-1.43059157e-02  8.49775076e-02  1.09523866e+00]\n",
      "  [ 1.00244828e-01  7.20224753e-02  1.08532140e+00]\n",
      "  ...\n",
      "  [-4.24061902e-04  9.74434316e-02  9.58024240e-01]\n",
      "  [-1.44222587e-01  7.16134384e-02  1.05794725e+00]\n",
      "  [ 7.12354928e-02  2.63262749e-01  7.16327345e-01]]\n",
      "\n",
      " [[ 4.53232676e-02  1.30636439e-01  1.07649646e+00]\n",
      "  [-1.43874250e-02  8.44160542e-02  1.09524021e+00]\n",
      "  [ 1.00226730e-01  7.15719089e-02  1.08525017e+00]\n",
      "  ...\n",
      "  [-3.78967263e-04  9.69382972e-02  9.57930899e-01]\n",
      "  [-1.44702911e-01  7.02804849e-02  1.05878422e+00]\n",
      "  [ 7.03606457e-02  2.63031006e-01  7.17941678e-01]]\n",
      "\n",
      " [[ 4.54581305e-02  1.29966572e-01  1.07661614e+00]\n",
      "  [-1.44193713e-02  8.38919356e-02  1.09538475e+00]\n",
      "  [ 1.00249738e-01  7.10949302e-02  1.08530978e+00]\n",
      "  ...\n",
      "  [-2.95212027e-04  9.64599103e-02  9.57980669e-01]\n",
      "  [-1.45128474e-01  6.90633208e-02  1.05981097e+00]\n",
      "  [ 6.95901215e-02  2.62769312e-01  7.19527340e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-1ada.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-1ada.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 177 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 173 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-1ada.wav':\n",
      "  Duration: 00:03:24.29, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5596c63a4640] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5596c63a4640] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5596c63a4640] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-1ada_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=454 q=-1.0 Lsize=    3660kB time=00:03:24.31 bitrate= 146.7kbits/s speed= 116x    \n",
      "video:405kB audio:3202kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.442054%\n",
      "[aac @ 0x5596c63a2f00] Qavg: 182.785\n",
      "[libx264 @ 0x5596c63a4640] frame I:4     Avg QP:16.56  size: 13974\n",
      "[libx264 @ 0x5596c63a4640] frame P:251   Avg QP:22.55  size:  1097\n",
      "[libx264 @ 0x5596c63a4640] frame B:545   Avg QP:23.49  size:   153\n",
      "[libx264 @ 0x5596c63a4640] consecutive B-frames:  4.8% 11.5%  5.2% 78.5%\n",
      "[libx264 @ 0x5596c63a4640] mb I  I16..4: 28.8% 46.7% 24.5%\n",
      "[libx264 @ 0x5596c63a4640] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.3%  1.6%  1.6%  0.0%  0.0%    skip:95.5%\n",
      "[libx264 @ 0x5596c63a4640] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.2%  0.7%  0.3%  direct: 0.2%  skip:97.6%  L0:38.9% L1:43.5% BI:17.6%\n",
      "[libx264 @ 0x5596c63a4640] 8x8 transform intra:45.7% inter:22.8%\n",
      "[libx264 @ 0x5596c63a4640] coded y,uvDC,uvAC intra: 18.2% 1.7% 1.5% inter: 0.9% 0.3% 0.3%\n",
      "[libx264 @ 0x5596c63a4640] i16 v,h,dc,p: 80%  6% 13%  0%\n",
      "[libx264 @ 0x5596c63a4640] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43%  6% 50%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x5596c63a4640] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 32%  7%  1%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x5596c63a4640] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x5596c63a4640] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5596c63a4640] ref P L0: 71.3% 10.4% 10.7%  7.6%\n",
      "[libx264 @ 0x5596c63a4640] ref B L0: 83.6% 11.9%  4.5%\n",
      "[libx264 @ 0x5596c63a4640] ref B L1: 95.3%  4.7%\n",
      "[libx264 @ 0x5596c63a4640] kb/s:165.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 11537, 128)\n",
      "prediction.shape (1, 11537, 102)\n",
      "full_prediction (11537, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 7.28724301e-02  1.39670119e-01  1.04822156e+00]\n",
      "  [ 8.20372347e-03  9.18916464e-02  1.06442986e+00]\n",
      "  [ 1.13048248e-01  6.53120950e-02  1.04916809e+00]\n",
      "  ...\n",
      "  [ 1.28037315e-02  1.05798125e-01  9.40484023e-01]\n",
      "  [-1.16854690e-01  1.04780287e-01  1.04345582e+00]\n",
      "  [ 9.78927836e-02  2.56266803e-01  7.03586912e-01]]\n",
      "\n",
      " [[ 7.03160167e-02  1.36802942e-01  1.07051120e+00]\n",
      "  [ 1.04311015e-02  9.06466171e-02  1.08791730e+00]\n",
      "  [ 1.15400642e-01  6.17750660e-02  1.07000670e+00]\n",
      "  ...\n",
      "  [ 1.54607436e-02  1.04954109e-01  9.60259116e-01]\n",
      "  [-1.12678543e-01  1.08703472e-01  1.06481431e+00]\n",
      "  [ 8.96439105e-02  2.47485787e-01  7.14550889e-01]]\n",
      "\n",
      " [[ 7.01255277e-02  1.39810905e-01  1.09099600e+00]\n",
      "  [ 1.18177813e-02  9.34698954e-02  1.10798225e+00]\n",
      "  [ 1.17983572e-01  6.62987083e-02  1.08730099e+00]\n",
      "  ...\n",
      "  [ 1.45222191e-02  1.07633226e-01  9.77166033e-01]\n",
      "  [-1.15042761e-01  1.15073442e-01  1.08434758e+00]\n",
      "  [ 8.44913796e-02  2.50509620e-01  7.23621702e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.68540134e-02  1.41877040e-01  1.09264663e+00]\n",
      "  [-2.86217779e-04  9.12107602e-02  1.11029885e+00]\n",
      "  [ 1.12024844e-01  7.60745555e-02  1.09365067e+00]\n",
      "  ...\n",
      "  [ 4.90833446e-03  1.10569507e-01  9.77539337e-01]\n",
      "  [-1.34429306e-01  1.01128578e-01  1.10154006e+00]\n",
      "  [ 6.40161037e-02  2.47844696e-01  7.11397862e-01]]\n",
      "\n",
      " [[ 5.52947521e-02  1.40539005e-01  1.09290454e+00]\n",
      "  [-1.60675496e-03  9.08292606e-02  1.10993478e+00]\n",
      "  [ 1.10591531e-01  7.51662329e-02  1.09322987e+00]\n",
      "  ...\n",
      "  [ 3.64365382e-03  1.10135466e-01  9.76805782e-01]\n",
      "  [-1.34881407e-01  1.03428371e-01  1.09956119e+00]\n",
      "  [ 6.54506236e-02  2.45573327e-01  7.07761204e-01]]\n",
      "\n",
      " [[ 5.41720651e-02  1.39134452e-01  1.09239826e+00]\n",
      "  [-2.65896320e-03  9.02324840e-02  1.10894761e+00]\n",
      "  [ 1.09333321e-01  7.40238205e-02  1.09201798e+00]\n",
      "  ...\n",
      "  [ 2.73995427e-03  1.09509706e-01  9.75587881e-01]\n",
      "  [-1.35377541e-01  1.03954986e-01  1.09791223e+00]\n",
      "  [ 6.65866435e-02  2.43291914e-01  7.05572402e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-2fug.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-2fug.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 204 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 200 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-2fug.wav':\n",
      "  Duration: 00:04:48.34, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5562bd1b6680] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5562bd1b6680] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5562bd1b6680] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-2fug_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=344 q=-1.0 Lsize=    5048kB time=00:04:48.34 bitrate= 143.4kbits/s speed= 124x    \n",
      "video:464kB audio:4518kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.330122%\n",
      "[aac @ 0x5562bd1b5180] Qavg: 260.041\n",
      "[libx264 @ 0x5562bd1b6680] frame I:4     Avg QP:16.92  size: 13840\n",
      "[libx264 @ 0x5562bd1b6680] frame P:226   Avg QP:22.69  size:  1340\n",
      "[libx264 @ 0x5562bd1b6680] frame B:570   Avg QP:26.09  size:   204\n",
      "[libx264 @ 0x5562bd1b6680] consecutive B-frames:  2.2%  6.2%  6.0% 85.5%\n",
      "[libx264 @ 0x5562bd1b6680] mb I  I16..4: 25.9% 49.5% 24.7%\n",
      "[libx264 @ 0x5562bd1b6680] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.2%  1.7%  2.1%  0.0%  0.0%    skip:94.9%\n",
      "[libx264 @ 0x5562bd1b6680] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.6%  0.9%  0.4%  direct: 0.2%  skip:96.9%  L0:38.8% L1:42.6% BI:18.6%\n",
      "[libx264 @ 0x5562bd1b6680] 8x8 transform intra:48.5% inter:23.6%\n",
      "[libx264 @ 0x5562bd1b6680] coded y,uvDC,uvAC intra: 18.1% 1.8% 1.4% inter: 1.0% 0.4% 0.3%\n",
      "[libx264 @ 0x5562bd1b6680] i16 v,h,dc,p: 77%  8% 14%  0%\n",
      "[libx264 @ 0x5562bd1b6680] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 47%  9% 43%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x5562bd1b6680] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 30%  7%  1%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x5562bd1b6680] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x5562bd1b6680] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5562bd1b6680] ref P L0: 65.6% 10.2% 13.7% 10.5%\n",
      "[libx264 @ 0x5562bd1b6680] ref B L0: 85.4% 11.1%  3.5%\n",
      "[libx264 @ 0x5562bd1b6680] ref B L1: 96.1%  3.9%\n",
      "[libx264 @ 0x5562bd1b6680] kb/s:189.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 6993, 128)\n",
      "prediction.shape (1, 6993, 102)\n",
      "full_prediction (6993, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 0.07760053  0.14679988  1.11902997]\n",
      "  [ 0.01375506  0.10232699  1.13807139]\n",
      "  [ 0.12756509  0.07269758  1.11696038]\n",
      "  ...\n",
      "  [ 0.02016258  0.10835409  0.99798427]\n",
      "  [-0.15416956  0.04863963  1.10585175]\n",
      "  [ 0.09898946  0.30799693  0.8234329 ]]\n",
      "\n",
      " [[ 0.07808826  0.14126742  1.08880506]\n",
      "  [ 0.01670498  0.09711739  1.11028442]\n",
      "  [ 0.12781395  0.06997871  1.09177527]\n",
      "  ...\n",
      "  [ 0.02454965  0.10415067  0.97457997]\n",
      "  [-0.14890212  0.03543849  1.07931039]\n",
      "  [ 0.09480406  0.30096766  0.82029674]]\n",
      "\n",
      " [[ 0.07925871  0.14364986  1.10430083]\n",
      "  [ 0.01915241  0.09965845  1.12522111]\n",
      "  [ 0.13103025  0.07493564  1.10524187]\n",
      "  ...\n",
      "  [ 0.02523742  0.10671776  0.98615155]\n",
      "  [-0.15233342  0.03078532  1.08635703]\n",
      "  [ 0.09893748  0.31524187  0.8357235 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.12206455  0.10922922  1.10915444]\n",
      "  [ 0.06434232  0.06031414  1.12040458]\n",
      "  [ 0.17311506  0.03805513  1.09020576]\n",
      "  ...\n",
      "  [ 0.06979319  0.08810937  0.98021845]\n",
      "  [-0.05179304  0.07698748  1.05830625]\n",
      "  [ 0.1636401   0.27947149  0.70080725]]\n",
      "\n",
      " [[ 0.12236946  0.10846929  1.10886321]\n",
      "  [ 0.06453426  0.05967949  1.12010083]\n",
      "  [ 0.17323372  0.03744154  1.08979795]\n",
      "  ...\n",
      "  [ 0.07003792  0.08765855  0.9799364 ]\n",
      "  [-0.05092068  0.07658944  1.05778787]\n",
      "  [ 0.16423847  0.27927494  0.70053688]]\n",
      "\n",
      " [[ 0.12265999  0.10776701  1.10865555]\n",
      "  [ 0.06471899  0.05909079  1.11987612]\n",
      "  [ 0.17335394  0.03687879  1.08950267]\n",
      "  ...\n",
      "  [ 0.07027625  0.08723933  0.97972105]\n",
      "  [-0.05008566  0.07624327  1.05731509]\n",
      "  [ 0.16487531  0.27912724  0.70034895]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-3sic.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-3sic.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 187 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 183 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-3sic.wav':\n",
      "  Duration: 00:02:54.71, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55ec6494dc40] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55ec6494dc40] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55ec6494dc40] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-3sic_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=507 q=-1.0 Lsize=    3209kB time=00:02:54.73 bitrate= 150.5kbits/s speed= 111x    \n",
      "video:423kB audio:2739kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.489133%\n",
      "[aac @ 0x55ec6494c500] Qavg: 180.446\n",
      "[libx264 @ 0x55ec6494dc40] frame I:4     Avg QP:16.83  size: 13932\n",
      "[libx264 @ 0x55ec6494dc40] frame P:243   Avg QP:22.55  size:  1203\n",
      "[libx264 @ 0x55ec6494dc40] frame B:553   Avg QP:23.50  size:   153\n",
      "[libx264 @ 0x55ec6494dc40] consecutive B-frames:  5.4%  6.5%  2.6% 85.5%\n",
      "[libx264 @ 0x55ec6494dc40] mb I  I16..4: 26.9% 48.9% 24.2%\n",
      "[libx264 @ 0x55ec6494dc40] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.2%  1.6%  1.8%  0.0%  0.0%    skip:95.3%\n",
      "[libx264 @ 0x55ec6494dc40] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.2%  0.6%  0.3%  direct: 0.2%  skip:97.7%  L0:37.0% L1:42.1% BI:20.8%\n",
      "[libx264 @ 0x55ec6494dc40] 8x8 transform intra:45.9% inter:23.3%\n",
      "[libx264 @ 0x55ec6494dc40] coded y,uvDC,uvAC intra: 18.8% 2.1% 1.7% inter: 0.9% 0.3% 0.3%\n",
      "[libx264 @ 0x55ec6494dc40] i16 v,h,dc,p: 73% 11% 16%  0%\n",
      "[libx264 @ 0x55ec6494dc40] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45%  9% 45%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x55ec6494dc40] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 31%  7%  2%  6%  3%  3%  3%  3%\n",
      "[libx264 @ 0x55ec6494dc40] i8c dc,h,v,p: 98%  1%  1%  0%\n",
      "[libx264 @ 0x55ec6494dc40] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x55ec6494dc40] ref P L0: 72.0% 11.1% 10.3%  6.6%\n",
      "[libx264 @ 0x55ec6494dc40] ref B L0: 86.9%  9.7%  3.4%\n",
      "[libx264 @ 0x55ec6494dc40] ref B L1: 96.4%  3.6%\n",
      "[libx264 @ 0x55ec6494dc40] kb/s:173.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_input (1, 7897, 128)\n",
      "prediction.shape (1, 7897, 102)\n",
      "full_prediction (7897, 102)\n",
      "81600\n",
      "limit 800\n",
      "[[[ 6.71466440e-02  1.37967333e-01  1.08564875e+00]\n",
      "  [ 1.99664198e-03  9.26143602e-02  1.10101018e+00]\n",
      "  [ 1.12182364e-01  6.59757778e-02  1.08352587e+00]\n",
      "  ...\n",
      "  [ 8.30545556e-03  1.07689396e-01  9.70811820e-01]\n",
      "  [-1.20231681e-01  1.15370542e-01  1.08097587e+00]\n",
      "  [ 9.29147825e-02  2.56142229e-01  7.08813405e-01]]\n",
      "\n",
      " [[ 6.23026490e-02  1.31534383e-01  1.08873746e+00]\n",
      "  [ 8.32363963e-04  8.54918733e-02  1.10358760e+00]\n",
      "  [ 1.10307857e-01  5.97740412e-02  1.08491478e+00]\n",
      "  ...\n",
      "  [ 9.51401331e-03  1.02540001e-01  9.73851895e-01]\n",
      "  [-1.16677374e-01  1.11539014e-01  1.08594213e+00]\n",
      "  [ 8.30669627e-02  2.39951074e-01  7.06981635e-01]]\n",
      "\n",
      " [[ 6.16334379e-02  1.31198496e-01  1.10555873e+00]\n",
      "  [ 1.94137543e-03  8.41728970e-02  1.11850426e+00]\n",
      "  [ 1.12237260e-01  6.05879426e-02  1.09840581e+00]\n",
      "  ...\n",
      "  [ 9.31452494e-03  1.02702960e-01  9.86737943e-01]\n",
      "  [-1.19013861e-01  1.09368876e-01  1.10202274e+00]\n",
      "  [ 7.87770599e-02  2.39546344e-01  7.14285648e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.92549129e-02  1.29939303e-01  1.10261521e+00]\n",
      "  [-9.68298689e-03  8.36615041e-02  1.11520967e+00]\n",
      "  [ 1.00250006e-01  6.29330948e-02  1.09811316e+00]\n",
      "  ...\n",
      "  [-3.70999612e-03  1.02469116e-01  9.80908906e-01]\n",
      "  [-1.38528362e-01  1.09641530e-01  1.11655126e+00]\n",
      "  [ 4.66531217e-02  2.08043426e-01  7.08724833e-01]]\n",
      "\n",
      " [[ 4.93022203e-02  1.31364971e-01  1.10033545e+00]\n",
      "  [-9.36347898e-03  8.55101123e-02  1.11301825e+00]\n",
      "  [ 1.00593224e-01  6.43878728e-02  1.09639797e+00]\n",
      "  ...\n",
      "  [-3.45884822e-03  1.04430147e-01  9.78903031e-01]\n",
      "  [-1.39604896e-01  1.09263524e-01  1.11464725e+00]\n",
      "  [ 4.62485850e-02  2.09776968e-01  7.09011650e-01]]\n",
      "\n",
      " [[ 4.96369228e-02  1.32995561e-01  1.09932826e+00]\n",
      "  [-8.84211250e-03  8.74738693e-02  1.11179659e+00]\n",
      "  [ 1.00833677e-01  6.59627691e-02  1.09508727e+00]\n",
      "  ...\n",
      "  [-2.98050791e-03  1.06361225e-01  9.77818346e-01]\n",
      "  [-1.40502319e-01  1.09493658e-01  1.11325738e+00]\n",
      "  [ 4.71092761e-02  2.12640271e-01  7.10034883e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fluidsynth: panic: An error occurred while reading from stdin.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file './outputvs1-4prs.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.2 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/home/ilc/anaconda3/envs/sinica --cc=/tmp/build/80754af9/ffmpeg_1587154242452/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'new_temp_vs1-4prs.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:20.00, start: 0.000000, bitrate: 211 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x480, 206 kb/s, 40 fps, 40 tbr, 10240 tbn, 80 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Guessed Channel Layout for Input Stream #1.0 : stereo\n",
      "Input #1, wav, from './outputvs1-4prs.wav':\n",
      "  Duration: 00:03:17.43, bitrate: 1411 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> concat:in0:v0\n",
      "  Stream #1:0 (pcm_s16le) -> concat:in0:a0\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x56424cbc19c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x56424cbc19c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x56424cbc19c0] 264 - core 157 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=15 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './video_vs1-4prs_test_predict.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 640x480, q=-1--1, 40 fps, 10240 tbn, 40 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  800 fps=474 q=-1.0 Lsize=    3616kB time=00:03:17.43 bitrate= 150.0kbits/s speed= 117x    \n",
      "video:470kB audio:3095kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.431369%\n",
      "[aac @ 0x56424cbc0280] Qavg: 188.133\n",
      "[libx264 @ 0x56424cbc19c0] frame I:4     Avg QP:16.60  size: 13928\n",
      "[libx264 @ 0x56424cbc19c0] frame P:222   Avg QP:22.97  size:  1281\n",
      "[libx264 @ 0x56424cbc19c0] frame B:574   Avg QP:28.23  size:   244\n",
      "[libx264 @ 0x56424cbc19c0] consecutive B-frames:  0.9%  8.5%  5.6% 85.0%\n",
      "[libx264 @ 0x56424cbc19c0] mb I  I16..4: 28.5% 46.6% 24.8%\n",
      "[libx264 @ 0x56424cbc19c0] mb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.2%  1.8%  2.1%  0.0%  0.0%    skip:94.9%\n",
      "[libx264 @ 0x56424cbc19c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  1.9%  1.3%  0.6%  direct: 0.2%  skip:96.0%  L0:43.8% L1:42.3% BI:13.9%\n",
      "[libx264 @ 0x56424cbc19c0] 8x8 transform intra:47.3% inter:24.6%\n",
      "[libx264 @ 0x56424cbc19c0] coded y,uvDC,uvAC intra: 18.4% 1.8% 1.5% inter: 1.0% 0.4% 0.3%\n",
      "[libx264 @ 0x56424cbc19c0] i16 v,h,dc,p: 81%  5% 14%  0%\n",
      "[libx264 @ 0x56424cbc19c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 44%  6% 49%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x56424cbc19c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 43% 31%  7%  1%  6%  3%  3%  2%  3%\n",
      "[libx264 @ 0x56424cbc19c0] i8c dc,h,v,p: 99%  1%  1%  0%\n",
      "[libx264 @ 0x56424cbc19c0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x56424cbc19c0] ref P L0: 56.8%  8.6% 17.8% 16.7%\n",
      "[libx264 @ 0x56424cbc19c0] ref B L0: 82.2% 12.4%  5.3%\n",
      "[libx264 @ 0x56424cbc19c0] ref B L1: 94.2%  5.8%\n",
      "[libx264 @ 0x56424cbc19c0] kb/s:192.11\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        # first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        # print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        # test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        # print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        # print(len(Row_list_prediction), len(Row_list_prediction[0]),len(Row_list_prediction[0][0]))\n",
    "        plot(test_datapath + test_music_list[num_count] + \".mid\", \"./video_\" + filecode + \"_test_predict.mp4\", Row_list_prediction[:800], None, 40, filecode) #ow_list[0:900]\n",
    "        # print(\"prediction.shape\", prediction.shape)\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        # formated_motion = prediction_format(full_prediction)\n",
    "        # # # plot(formated_motion)\n",
    "        # audio_path = test_music_list[num_count][0]\n",
    "        # output_path = \"test_output_\" + filecode + \".mp4\"\n",
    "        # plot(formated_motion, audio_path, output_path, None, 10, filecode)\n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "772d4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8171, 112])\n",
      "test_input (1, 8171, 128)\n",
      "test_target torch.Size([1, 8171, 112])\n",
      "prediction.shape (1, 8171, 102)\n",
      "full_prediction (8171, 102)\n",
      "torch.Size([11537, 112])\n",
      "test_input (1, 11537, 128)\n",
      "test_target torch.Size([1, 11537, 112])\n",
      "prediction.shape (1, 11537, 102)\n",
      "full_prediction (11537, 102)\n",
      "torch.Size([6993, 112])\n",
      "test_input (1, 6993, 128)\n",
      "test_target torch.Size([1, 6993, 112])\n",
      "prediction.shape (1, 6993, 102)\n",
      "full_prediction (6993, 102)\n",
      "torch.Size([7897, 112])\n",
      "test_input (1, 7897, 128)\n",
      "test_target torch.Size([1, 7897, 112])\n",
      "prediction.shape (1, 7897, 102)\n",
      "full_prediction (7897, 102)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "full_prediction = pd.DataFrame()\n",
    "num_count = 0\n",
    "# read midi\n",
    "# test_dataloader = get_dataloader(test_datapath, batch_size=1)\n",
    "for test_batch in test_data_list:\n",
    "    with torch.no_grad():\n",
    "        first_target = torch.zeros(test_batch.shape[0],112)\n",
    "        print(first_target.shape)\n",
    "        test_input = test_batch[None, :]\n",
    "        test_target = first_target[None, :]\n",
    "        print(\"test_input\", test_input.shape)\n",
    "        print(\"test_target\", test_target.shape)\n",
    "        prediction = predict(model, test_input, device)\n",
    "        \n",
    "        # print(prediction.shape)\n",
    "        \n",
    "        prediction  = prediction[:, :, :102]\n",
    "        print(\"prediction.shape\", prediction.shape)\n",
    "        \n",
    "        # full_prediction.append(prediction)\n",
    "        full_prediction = pd.DataFrame(prediction[0])\n",
    "        print(\"full_prediction\", full_prediction.shape)\n",
    "        \n",
    "        # prev_prediction = prediction[0][:-1][None, :]\n",
    "        # print(prev_prediction.shape)\n",
    "        \n",
    "        Row_list_prediction =[]\n",
    "        \n",
    "        filecode = test_music_list[num_count]\n",
    "    \n",
    "        # Iterate over each row\n",
    "        for index, rows in full_prediction.iterrows():\n",
    "            #fill nan\n",
    "            rows = rows.fillna(0)\n",
    "            # Create list for the current row\n",
    "            my_list = rows.values.tolist()\n",
    "            # print(my_list)\n",
    "            \n",
    "            my_list_per3 = [my_list[i:i+3] for i in range(0, len(my_list), 3)]\n",
    "            # append the list to the final list\n",
    "            Row_list_prediction.append(my_list_per3)\n",
    "\n",
    "        prediction_arr = np.array(Row_list_prediction)\n",
    "        if not os.path.exists('./output_prediction/[midi]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/'):\n",
    "            os.makedirs('./output_prediction/[midi]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/')\n",
    "        midi_data_output = open('./output_prediction/[midi]'+str(num_layers)+'LSTM_hidden'+str(hidden_size)+'_'+str(num_epochs)+'epoch/prediction_'+\n",
    "                                filecode +'.pkl', 'wb')\n",
    "        pickle.dump(prediction_arr, midi_data_output)\n",
    "        midi_data_output.close()\n",
    "        \n",
    "        num_count += 1\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98bac6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "len(midi_data) 6706\n",
      "len(motion_data) 6706\n",
      "len(midi_data) 4525\n",
      "len(motion_data) 4525\n",
      "len(midi_data) 5281\n",
      "len(motion_data) 5281\n",
      "len(midi_data) 6069\n",
      "len(motion_data) 6069\n",
      "len(midi_data) 6061\n",
      "len(motion_data) 6061\n",
      "inputs.shape: torch.Size([5, 6706, 128])\n",
      "targets.shape: torch.Size([5, 6706, 112])\n",
      "outputs.shape: torch.Size([5, 6706, 112])\n"
     ]
    }
   ],
   "source": [
    "final_val_loss = evaluate_lstm(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee221509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04046545922756195\n"
     ]
    }
   ],
   "source": [
    "print(final_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caff77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
